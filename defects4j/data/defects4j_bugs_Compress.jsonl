{"project": "Compress", "bug_id": 1, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.FilterOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n * <p/>\n * <p/>\n * An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.\n * <p/>\n * <code><pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(&quot;testfile&quot;);\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * out.putNextEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered threadsafe.\n * \n * based on code from the jRPM project (jrpm.sourceforge.net)\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry cpioEntry;\n\n    private boolean closed = false;\n\n    private boolean finished;\n\n    private short entryFormat = FORMAT_NEW;\n\n    private final HashMap names = new HashMap();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    /**\n     * Construct the cpio output stream with a specified format\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this.out = new FilterOutputStream(out);\n        setFormat(format);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Set a default header format. This will be used if no format is defined in\n     * the cpioEntry given to putNextEntry().\n     * \n     * @param format\n     *            A CPIO format\n     */\n    private void setFormat(final short format) {\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown header type\");\n\n        }\n        synchronized (this) {\n            this.entryFormat = format;\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param e\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void putNextEntry(final CpioArchiveEntry e) throws IOException {\n        ensureOpen();\n        if (this.cpioEntry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis());\n        }\n\n        // TODO what happens if an entry has an other format than the\n        // outputstream?\n        if (e.getFormat() == -1) {\n            e.setFormat(this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.cpioEntry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(MAGIC_NEW.getBytes());\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(MAGIC_NEW_CRC.getBytes());\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(MAGIC_OLD_ASCII.getBytes());\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        writeAsciiLong(entry.getInode(), 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderSize() + entry.getName().length() + 1, 4);\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        writeAsciiLong(entry.getDevice(), 6, 8);\n        writeAsciiLong(entry.getInode(), 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        writeBinaryLong(entry.getDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getInode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderSize() + entry.getName().length() + 1, 2);\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    public void closeArchiveEntry() throws IOException {\n        ensureOpen();\n\n        if (this.cpioEntry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.cpioEntry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_MASK) == FORMAT_NEW_MASK) {\n            pad(this.cpioEntry.getSize(), 4);\n        } else if ((this.cpioEntry.getFormat() | FORMAT_OLD_BINARY) == FORMAT_OLD_BINARY) {\n            pad(this.cpioEntry.getSize(), 2);\n        }\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_CRC) == FORMAT_NEW_CRC) {\n            if (this.crc != this.cpioEntry.getChksum()) {\n                throw new IOException(\"CRC Error\");\n            }\n        }\n        this.cpioEntry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.cpioEntry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.cpioEntry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_CRC) == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.cpioEntry != null) {\n            closeArchiveEntry();\n        }\n        this.cpioEntry = new CpioArchiveEntry(this.entryFormat);\n        this.cpioEntry.setMode(0);\n        this.cpioEntry.setName(\"TRAILER!!!\");\n        this.cpioEntry.setNumberOfLinks(1);\n        writeHeader(this.cpioEntry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            super.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(final long count, final int border) throws IOException {\n        long skip = count % border;\n        if (skip > 0) {\n            byte tmp[] = new byte[(int) (border - skip)];\n            out.write(tmp);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        out.write(tmpStr.getBytes());\n    }\n\n    private void writeCString(final String str) throws IOException {\n        out.write(str.getBytes());\n        out.write('\\0');\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#putArchiveEntry\n     * (org.apache.commons.compress.archivers.ArchiveEntry)\n     */\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        this.putNextEntry((CpioArchiveEntry) entry);\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.OutputStream#write(int)\n     */\n    public void write(int b) throws IOException {\n        out.write(b);\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.FilterOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n * <p/>\n * <p/>\n * An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.\n * <p/>\n * <code><pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(&quot;testfile&quot;);\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * out.putNextEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered threadsafe.\n * \n * based on code from the jRPM project (jrpm.sourceforge.net)\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry cpioEntry;\n\n    private boolean closed = false;\n\n    private boolean finished;\n\n    private short entryFormat = FORMAT_NEW;\n\n    private final HashMap names = new HashMap();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    /**\n     * Construct the cpio output stream with a specified format\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this.out = new FilterOutputStream(out);\n        setFormat(format);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Set a default header format. This will be used if no format is defined in\n     * the cpioEntry given to putNextEntry().\n     * \n     * @param format\n     *            A CPIO format\n     */\n    private void setFormat(final short format) {\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown header type\");\n\n        }\n        synchronized (this) {\n            this.entryFormat = format;\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param e\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void putNextEntry(final CpioArchiveEntry e) throws IOException {\n        ensureOpen();\n        if (this.cpioEntry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis());\n        }\n\n        // TODO what happens if an entry has an other format than the\n        // outputstream?\n        if (e.getFormat() == -1) {\n            e.setFormat(this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.cpioEntry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(MAGIC_NEW.getBytes());\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(MAGIC_NEW_CRC.getBytes());\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(MAGIC_OLD_ASCII.getBytes());\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        writeAsciiLong(entry.getInode(), 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderSize() + entry.getName().length() + 1, 4);\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        writeAsciiLong(entry.getDevice(), 6, 8);\n        writeAsciiLong(entry.getInode(), 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        writeBinaryLong(entry.getDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getInode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderSize() + entry.getName().length() + 1, 2);\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    public void closeArchiveEntry() throws IOException {\n        ensureOpen();\n\n        if (this.cpioEntry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.cpioEntry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_MASK) == FORMAT_NEW_MASK) {\n            pad(this.cpioEntry.getSize(), 4);\n        } else if ((this.cpioEntry.getFormat() | FORMAT_OLD_BINARY) == FORMAT_OLD_BINARY) {\n            pad(this.cpioEntry.getSize(), 2);\n        }\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_CRC) == FORMAT_NEW_CRC) {\n            if (this.crc != this.cpioEntry.getChksum()) {\n                throw new IOException(\"CRC Error\");\n            }\n        }\n        this.cpioEntry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.cpioEntry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.cpioEntry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if ((this.cpioEntry.getFormat() | FORMAT_NEW_CRC) == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.cpioEntry != null) {\n            closeArchiveEntry();\n        }\n        this.cpioEntry = new CpioArchiveEntry(this.entryFormat);\n        this.cpioEntry.setMode(0);\n        this.cpioEntry.setName(\"TRAILER!!!\");\n        this.cpioEntry.setNumberOfLinks(1);\n        writeHeader(this.cpioEntry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            this.finish();\n            super.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(final long count, final int border) throws IOException {\n        long skip = count % border;\n        if (skip > 0) {\n            byte tmp[] = new byte[(int) (border - skip)];\n            out.write(tmp);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        out.write(tmpStr.getBytes());\n    }\n\n    private void writeCString(final String str) throws IOException {\n        out.write(str.getBytes());\n        out.write('\\0');\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#putArchiveEntry\n     * (org.apache.commons.compress.archivers.ArchiveEntry)\n     */\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        this.putNextEntry((CpioArchiveEntry) entry);\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.OutputStream#write(int)\n     */\n    public void write(int b) throws IOException {\n        out.write(b);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 2, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.ar.ArArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.ar;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\n\n/**\n * Implements the \"ar\" archive format as an input stream.\n * \n * @NotThreadSafe\n * \n */\npublic class ArArchiveInputStream extends ArchiveInputStream {\n\n    private final InputStream input;\n    private long offset = 0;\n    private boolean closed;\n    /*\n     * If getNextEnxtry has been called, the entry metadata is stored in\n     * currentEntry.\n     */\n    /*\n     * The offset where the current entry started. -1 if no entry has been\n     * called\n     */\n\n    public ArArchiveInputStream( final InputStream pInput ) {\n        input = pInput;\n        closed = false;\n    }\n\n    /**\n     * Returns the next AR entry in this stream.\n     * \n     * @return the next AR entry.\n     * @throws IOException\n     *             if the entry could not be read\n     */\n    public ArArchiveEntry getNextArEntry() throws IOException {\n                    // hit EOF before previous entry was complete\n                    // TODO: throw an exception instead?\n\n        if (offset == 0) {\n            final byte[] expected = ArArchiveEntry.HEADER.getBytes();\n            final byte[] realized = new byte[expected.length]; \n            final int read = read(realized);\n            if (read != expected.length) {\n                throw new IOException(\"failed to read header\");\n            }\n            for (int i = 0; i < expected.length; i++) {\n                if (expected[i] != realized[i]) {\n                    throw new IOException(\"invalid header \" + new String(realized));\n                }\n            }\n        }\n\n                // hit eof\n\n        if (input.available() == 0) {\n            return null;\n        }\n\n        if (offset % 2 != 0) {\n            read();\n        }\n        final byte[] name = new byte[16];\n        final byte[] lastmodified = new byte[12];\n        final byte[] userid = new byte[6];\n        final byte[] groupid = new byte[6];\n        final byte[] filemode = new byte[8];\n        final byte[] length = new byte[10];\n\n        read(name);\n        read(lastmodified);\n        read(userid);\n        read(groupid);\n        read(filemode);\n        read(length);\n\n        {\n            final byte[] expected = ArArchiveEntry.TRAILER.getBytes();\n            final byte[] realized = new byte[expected.length]; \n            final int read = read(realized);\n            if (read != expected.length) {\n                throw new IOException(\"failed to read entry header\");\n            }\n            for (int i = 0; i < expected.length; i++) {\n                if (expected[i] != realized[i]) {\n                    throw new IOException(\"invalid entry header. not read the content?\");\n                }\n            }\n        }\n\n        return new ArArchiveEntry(new String(name).trim(),\n                                          Long.parseLong(new String(length)\n                                                         .trim()));\n    }\n\n\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextArEntry();\n    }\n\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            input.close();\n        }\n    }\n\n    public int read() throws IOException {\n        final int ret = input.read();\n        offset += (ret > 0 ? 1 : 0);\n        return ret;\n    }\n\n    public int read(byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n\n    public int read(byte[] b, final int off, final int len) throws IOException {\n        int toRead = len;\n        final int ret = this.input.read(b, off, toRead);\n        offset += (ret > 0 ? ret : 0);\n        return ret;\n    }\n\n    public static boolean matches(byte[] signature, int length) {\n        // 3c21 7261 6863 0a3e\n\n        if (length < 8) {\n            return false;\n        }\n        if (signature[0] != 0x21) {\n            return false;\n        }\n        if (signature[1] != 0x3c) {\n            return false;\n        }\n        if (signature[2] != 0x61) {\n            return false;\n        }\n        if (signature[3] != 0x72) {\n            return false;\n        }\n        if (signature[4] != 0x63) {\n            return false;\n        }\n        if (signature[5] != 0x68) {\n            return false;\n        }\n        if (signature[6] != 0x3e) {\n            return false;\n        }\n        if (signature[7] != 0x0a) {\n            return false;\n        }\n\n        return true;\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.ar;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\n\n/**\n * Implements the \"ar\" archive format as an input stream.\n * \n * @NotThreadSafe\n * \n */\npublic class ArArchiveInputStream extends ArchiveInputStream {\n\n    private final InputStream input;\n    private long offset = 0;\n    private boolean closed;\n    /*\n     * If getNextEnxtry has been called, the entry metadata is stored in\n     * currentEntry.\n     */\n    private ArArchiveEntry currentEntry = null;\n    /*\n     * The offset where the current entry started. -1 if no entry has been\n     * called\n     */\n    private long entryOffset = -1;\n\n    public ArArchiveInputStream( final InputStream pInput ) {\n        input = pInput;\n        closed = false;\n    }\n\n    /**\n     * Returns the next AR entry in this stream.\n     * \n     * @return the next AR entry.\n     * @throws IOException\n     *             if the entry could not be read\n     */\n    public ArArchiveEntry getNextArEntry() throws IOException {\n        if (currentEntry != null) {\n            final long entryEnd = entryOffset + currentEntry.getLength();\n            while (offset < entryEnd) {\n                int x = read();\n                if (x == -1) {\n                    // hit EOF before previous entry was complete\n                    // TODO: throw an exception instead?\n                    return null;\n                }\n            }\n            currentEntry = null;\n        }\n\n        if (offset == 0) {\n            final byte[] expected = ArArchiveEntry.HEADER.getBytes();\n            final byte[] realized = new byte[expected.length]; \n            final int read = read(realized);\n            if (read != expected.length) {\n                throw new IOException(\"failed to read header\");\n            }\n            for (int i = 0; i < expected.length; i++) {\n                if (expected[i] != realized[i]) {\n                    throw new IOException(\"invalid header \" + new String(realized));\n                }\n            }\n        }\n\n        if (offset % 2 != 0) {\n            if (read() < 0) {\n                // hit eof\n                return null;\n            }\n        }\n\n        if (input.available() == 0) {\n            return null;\n        }\n\n        final byte[] name = new byte[16];\n        final byte[] lastmodified = new byte[12];\n        final byte[] userid = new byte[6];\n        final byte[] groupid = new byte[6];\n        final byte[] filemode = new byte[8];\n        final byte[] length = new byte[10];\n\n        read(name);\n        read(lastmodified);\n        read(userid);\n        read(groupid);\n        read(filemode);\n        read(length);\n\n        {\n            final byte[] expected = ArArchiveEntry.TRAILER.getBytes();\n            final byte[] realized = new byte[expected.length]; \n            final int read = read(realized);\n            if (read != expected.length) {\n                throw new IOException(\"failed to read entry header\");\n            }\n            for (int i = 0; i < expected.length; i++) {\n                if (expected[i] != realized[i]) {\n                    throw new IOException(\"invalid entry header. not read the content?\");\n                }\n            }\n        }\n\n        entryOffset = offset;\n        currentEntry = new ArArchiveEntry(new String(name).trim(),\n                                          Long.parseLong(new String(length)\n                                                         .trim()));\n        return currentEntry;\n    }\n\n\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextArEntry();\n    }\n\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            input.close();\n        }\n        currentEntry = null;\n    }\n\n    public int read() throws IOException {\n        byte[] single = new byte[1];\n        int num = read(single, 0, 1);\n        return num == -1 ? -1 : single[0] & 0xff;\n    }\n\n    public int read(byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n\n    public int read(byte[] b, final int off, final int len) throws IOException {\n        int toRead = len;\n        if (currentEntry != null) {\n            final long entryEnd = entryOffset + currentEntry.getLength();\n            if (len > 0 && entryEnd > offset) {\n                toRead = (int) Math.min(len, entryEnd - offset);\n            } else {\n                return -1;\n            }\n        }\n        final int ret = this.input.read(b, off, toRead);\n        offset += (ret > 0 ? ret : 0);\n        return ret;\n    }\n\n    public static boolean matches(byte[] signature, int length) {\n        // 3c21 7261 6863 0a3e\n\n        if (length < 8) {\n            return false;\n        }\n        if (signature[0] != 0x21) {\n            return false;\n        }\n        if (signature[1] != 0x3c) {\n            return false;\n        }\n        if (signature[2] != 0x61) {\n            return false;\n        }\n        if (signature[3] != 0x72) {\n            return false;\n        }\n        if (signature[4] != 0x63) {\n            return false;\n        }\n        if (signature[5] != 0x68) {\n            return false;\n        }\n        if (signature[6] != 0x3e) {\n            return false;\n        }\n        if (signature[7] != 0x0a) {\n            return false;\n        }\n\n        return true;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 3, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /* Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = os;\n\n        this.buffer = new TarBuffer(os, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    public void finish() throws IOException {\n        writeEOFRecord();\n        writeEOFRecord();\n    }\n\n    /**\n     * Ends the TAR archive and closes the underlying OutputStream.\n     * This means that finish() is called followed by calling the\n     * TarBuffer's close().\n     * @throws IOException on error\n     */\n    public void close() throws IOException {\n        if (!closed) {\n            finish();\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = entry.getName().getBytes(); // TODO is it correct to use the default charset here?\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    // used to be implemented via FilterOutputStream\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /* Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = os;\n\n        this.buffer = new TarBuffer(os, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    public void finish() throws IOException {\n        if(haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n    }\n\n    /**\n     * Ends the TAR archive and closes the underlying OutputStream.\n     * This means that finish() is called followed by calling the\n     * TarBuffer's close().\n     * @throws IOException on error\n     */\n    public void close() throws IOException {\n        if (!closed) {\n            finish();\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = entry.getName().getBytes(); // TODO is it correct to use the default charset here?\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    // used to be implemented via FilterOutputStream\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 4, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.File;\nimport java.io.FilterOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n * <p/>\n * <p/>\n * An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.\n * <p/>\n * <code><pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(\"testfile\");\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * entry.setMode(CpioConstants.C_ISREG); // regular file\n * ... set other attributes, e.g. time, number of links\n * out.putNextEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered threadsafe.\n * \n * based on code from the jRPM project (jrpm.sourceforge.net)\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry entry;\n\n    private boolean closed = false;\n\n    private boolean finished;\n\n    /**\n     * See {@link CpioArchiveEntry#setFormat(short)} for possible values.\n     */\n    private final short entryFormat;\n\n    private final HashMap names = new HashMap();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    /**\n     * Construct the cpio output stream with a specified format\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this.out = new FilterOutputStream(out);\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown format: \"+format);\n        \n        }\n        this.entryFormat = format;\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param entry\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     * @throws ClassCastException if entry is not an instance of CpioArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        CpioArchiveEntry e = (CpioArchiveEntry) entry;\n        ensureOpen();\n        if (this.entry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis());\n        }\n\n        final short format = e.getFormat();\n        if (format != this.entryFormat){\n            throw new IOException(\"Header format: \"+format+\" does not match existing format: \"+this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.entry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW));\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW_CRC));\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_OLD_ASCII));\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        writeAsciiLong(entry.getInode(), 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        writeAsciiLong(entry.getDevice(), 6, 8);\n        writeAsciiLong(entry.getInode(), 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        writeBinaryLong(entry.getDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getInode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    public void closeArchiveEntry() throws IOException {\n        ensureOpen();\n\n        if (this.entry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.entry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        pad(this.entry.getDataPadCount());\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            if (this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error\");\n            }\n        }\n        this.entry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.entry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.entry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.entry != null) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        this.entry = new CpioArchiveEntry(this.entryFormat);\n        this.entry.setName(CPIO_TRAILER);\n        this.entry.setNumberOfLinks(1);\n        writeHeader(this.entry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            this.finish();\n            out.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(int count) throws IOException{\n        if (count > 0){\n            byte buff[] = new byte[count];\n            out.write(buff);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        out.write(tmpStr.getBytes()); // TODO is it correct to use the default charset here?\n    }\n\n    private void writeCString(final String str) throws IOException {\n        out.write(str.getBytes()); // TODO is it correct to use the default charset here?\n        out.write('\\0');\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new CpioArchiveEntry(inputFile, entryName);\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.File;\nimport java.io.FilterOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n * <p/>\n * <p/>\n * An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.\n * <p/>\n * <code><pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(\"testfile\");\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * entry.setMode(CpioConstants.C_ISREG); // regular file\n * ... set other attributes, e.g. time, number of links\n * out.putNextEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered threadsafe.\n * \n * based on code from the jRPM project (jrpm.sourceforge.net)\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry entry;\n\n    private boolean closed = false;\n\n    private boolean finished;\n\n    /**\n     * See {@link CpioArchiveEntry#setFormat(short)} for possible values.\n     */\n    private final short entryFormat;\n\n    private final HashMap names = new HashMap();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    /**\n     * Construct the cpio output stream with a specified format\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this.out = new FilterOutputStream(out);\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown format: \"+format);\n        \n        }\n        this.entryFormat = format;\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param entry\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     * @throws ClassCastException if entry is not an instance of CpioArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        CpioArchiveEntry e = (CpioArchiveEntry) entry;\n        ensureOpen();\n        if (this.entry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis());\n        }\n\n        final short format = e.getFormat();\n        if (format != this.entryFormat){\n            throw new IOException(\"Header format: \"+format+\" does not match existing format: \"+this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.entry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW));\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW_CRC));\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_OLD_ASCII));\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        writeAsciiLong(entry.getInode(), 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        writeAsciiLong(entry.getDevice(), 6, 8);\n        writeAsciiLong(entry.getInode(), 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        writeBinaryLong(entry.getDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getInode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    public void closeArchiveEntry() throws IOException {\n        ensureOpen();\n\n        if (this.entry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.entry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        pad(this.entry.getDataPadCount());\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            if (this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error\");\n            }\n        }\n        this.entry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.entry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.entry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void finish() throws IOException {\n        ensureOpen();\n\n        if (this.finished) {\n            return;\n        }\n        if (this.entry != null) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        this.entry = new CpioArchiveEntry(this.entryFormat);\n        this.entry.setName(CPIO_TRAILER);\n        this.entry.setNumberOfLinks(1);\n        writeHeader(this.entry);\n        closeArchiveEntry();\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public void close() throws IOException {\n        if (!this.closed) {\n            out.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(int count) throws IOException{\n        if (count > 0){\n            byte buff[] = new byte[count];\n            out.write(buff);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuffer tmp = new StringBuffer();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        out.write(tmpStr.getBytes()); // TODO is it correct to use the default charset here?\n    }\n\n    private void writeCString(final String str) throws IOException {\n        out.write(str.getBytes()); // TODO is it correct to use the default charset here?\n        out.write('\\0');\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new CpioArchiveEntry(inputFile, entryName);\n    }\n\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /* Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = os;\n\n        this.buffer = new TarBuffer(os, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    public void finish() throws IOException {\n        if(haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    public void close() throws IOException {\n        if (!closed) {\n            finish();\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = entry.getName().getBytes(); // TODO is it correct to use the default charset here?\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    // used to be implemented via FilterOutputStream\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /* Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = os;\n\n        this.buffer = new TarBuffer(os, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    public void finish() throws IOException {\n        if(haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    public void close() throws IOException {\n        if (!closed) {\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = entry.getName().getBytes(); // TODO is it correct to use the default charset here?\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    // used to be implemented via FilterOutputStream\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.RandomAccessFile;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.zip.CRC32;\nimport java.util.zip.Deflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * Reimplementation of {@link java.util.zip.ZipOutputStream\n * java.util.zip.ZipOutputStream} that does handle the extended\n * functionality of this package, especially internal/external file\n * attributes and extra fields with different layouts for local file\n * data and central directory entries.\n *\n * <p>This class will try to use {@link java.io.RandomAccessFile\n * RandomAccessFile} when you know that the output is going to go to a\n * file.</p>\n *\n * <p>If RandomAccessFile cannot be used, this implementation will use\n * a Data Descriptor to store size and CRC information for {@link\n * #DEFLATED DEFLATED} entries, this means, you don't need to\n * calculate them yourself.  Unfortunately this is not possible for\n * the {@link #STORED STORED} method, here setting the CRC and\n * uncompressed size information is required before {@link\n * #putArchiveEntry(ArchiveEntry)} can be called.</p>\n * @NotThreadSafe\n */\npublic class ZipArchiveOutputStream extends ArchiveOutputStream {\n\n    static final int BYTE_MASK = 0xFF;\n    private static final int SHORT = 2;\n    private static final int WORD = 4;\n    static final int BUFFER_SIZE = 512;\n    /* \n     * Apparently Deflater.setInput gets slowed down a lot on Sun JVMs\n     * when it gets handed a really big buffer.  See\n     * https://issues.apache.org/bugzilla/show_bug.cgi?id=45396\n     *\n     * Using a buffer size of 8 kB proved to be a good compromise\n     */\n    private static final int DEFLATER_BLOCK_SIZE = 8192;\n\n    /**\n     * Compression method for deflated entries.\n     */\n    public static final int DEFLATED = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * Default compression level for deflated entries.\n     */\n    public static final int DEFAULT_COMPRESSION = Deflater.DEFAULT_COMPRESSION;\n\n    /**\n     * Compression method for stored entries.\n     */\n    public static final int STORED = java.util.zip.ZipEntry.STORED;\n\n    /**\n     * default encoding for file names and comment.\n     */\n    static final String DEFAULT_ENCODING = ZipEncodingHelper.UTF8;\n\n     /**\n     * General purpose flag, which indicates that filenames are\n     * written in utf-8.\n     */\n    public static final int EFS_FLAG = 1 << 11;\n\n    /**\n     * Current entry.\n     */\n    private ZipArchiveEntry entry;\n\n    /**\n     * The file comment.\n     */\n    private String comment = \"\";\n\n    /**\n     * Compression level for next entry.\n     */\n    private int level = DEFAULT_COMPRESSION;\n\n    /**\n     * Has the compression level changed when compared to the last\n     * entry?\n     */\n    private boolean hasCompressionLevelChanged = false;\n\n    /**\n     * Default compression method for next entry.\n     */\n    private int method = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * List of ZipArchiveEntries written so far.\n     */\n    private final List entries = new LinkedList();\n\n    /**\n     * CRC instance to avoid parsing DEFLATED data twice.\n     */\n    private final CRC32 crc = new CRC32();\n\n    /**\n     * Count the bytes written to out.\n     */\n    private long written = 0;\n\n    /**\n     * Data for local header data\n     */\n    private long dataStart = 0;\n\n    /**\n     * Offset for CRC entry in the local file header data for the\n     * current entry starts here.\n     */\n    private long localDataStart = 0;\n\n    /**\n     * Start of central directory.\n     */\n    private long cdOffset = 0;\n\n    /**\n     * Length of central directory.\n     */\n    private long cdLength = 0;\n\n    /**\n     * Helper, a 0 as ZipShort.\n     */\n    private static final byte[] ZERO = {0, 0};\n\n    /**\n     * Helper, a 0 as ZipLong.\n     */\n    private static final byte[] LZERO = {0, 0, 0, 0};\n\n    /**\n     * Holds the offsets of the LFH starts for each entry.\n     */\n    private final Map offsets = new HashMap();\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private String encoding = DEFAULT_ENCODING;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     *\n     * This field is of internal use and will be set in {@link\n     * #setEncoding(String)}.\n     */\n    private ZipEncoding zipEncoding =\n        ZipEncodingHelper.getZipEncoding(DEFAULT_ENCODING);\n\n    /**\n     * This Deflater object is used for output.\n     *\n     */\n    protected final Deflater def = new Deflater(level, true);\n\n    /**\n     * This buffer servers as a Deflater.\n     *\n     */\n    private final byte[] buf = new byte[BUFFER_SIZE];\n\n    /**\n     * Optional random access output.\n     */\n    private final RandomAccessFile raf;\n\n    private final OutputStream out;\n\n    /**\n     * whether to use the EFS flag when writing UTF-8 filenames or not.\n     */\n    private boolean useEFS = true; \n\n    /**\n     * Whether to encode non-encodable file names as UTF-8.\n     */\n    private boolean fallbackToUTF8 = false;\n\n    /**\n     * whether to create UnicodePathExtraField-s for each entry.\n     */\n    private UnicodeExtraFieldPolicy createUnicodeExtraFields =\n        UnicodeExtraFieldPolicy.NEVER;\n\n    /**\n     * Creates a new ZIP OutputStream filtering the underlying stream.\n     * @param out the outputstream to zip\n     */\n    public ZipArchiveOutputStream(OutputStream out) {\n        this.out = out;\n        this.raf = null;\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a File.  Will use\n     * random access if possible.\n     * @param file the file to zip to\n     * @throws IOException on error\n     */\n    public ZipArchiveOutputStream(File file) throws IOException {\n        OutputStream o = null;\n        RandomAccessFile _raf = null;\n        try {\n            _raf = new RandomAccessFile(file, \"rw\");\n            _raf.setLength(0);\n        } catch (IOException e) {\n            if (_raf != null) {\n                try {\n                    _raf.close();\n                } catch (IOException inner) {\n                    // ignore\n                }\n                _raf = null;\n            }\n            o = new FileOutputStream(file);\n        }\n        out = o;\n        raf = _raf;\n    }\n\n    /**\n     * This method indicates whether this archive is writing to a\n     * seekable stream (i.e., to a random access file).\n     *\n     * <p>For seekable streams, you don't need to calculate the CRC or\n     * uncompressed size for {@link #STORED} entries before\n     * invoking {@link #putArchiveEntry(ArchiveEntry)}.\n     * @return true if seekable\n     */\n    public boolean isSeekable() {\n        return raf != null;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     */\n    public void setEncoding(final String encoding) {\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        useEFS &= ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Whether to set the language encoding flag if the file name\n     * encoding is UTF-8.\n     *\n     * <p>Defaults to true.</p>\n     */\n    public void setUseLanguageEncodingFlag(boolean b) {\n        useEFS = b && ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * Whether to create Unicode Extra Fields.\n     *\n     * <p>Defaults to NEVER.</p>\n     */\n    public void setCreateUnicodeExtraFields(UnicodeExtraFieldPolicy b) {\n        createUnicodeExtraFields = b;\n    }\n\n    /**\n     * Whether to fall back to UTF and the language encoding flag if\n     * the file name cannot be encoded using the specified encoding.\n     *\n     * <p>Defaults to false.</p>\n     */\n    public void setFallbackToUTF8(boolean b) {\n        fallbackToUTF8 = b;\n    }\n\n    /* (non-Javadoc)\n     * @see org.apache.commons.compress.archivers.ArchiveOutputStream#finish()\n     */\n    public void finish() throws IOException {\n        if(entry != null) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        \n        cdOffset = written;\n        for (Iterator i = entries.iterator(); i.hasNext(); ) {\n            writeCentralFileHeader((ZipArchiveEntry) i.next());\n        }\n        cdLength = written - cdOffset;\n        writeCentralDirectoryEnd();\n        offsets.clear();\n        entries.clear();\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (entry == null) {\n            return;\n        }\n\n        long realCrc = crc.getValue();\n        crc.reset();\n\n        if (entry.getMethod() == DEFLATED) {\n            def.finish();\n            while (!def.finished()) {\n                deflate();\n            }\n\n            entry.setSize(ZipUtil.adjustToLong(def.getTotalIn()));\n            entry.setCompressedSize(ZipUtil.adjustToLong(def.getTotalOut()));\n            entry.setCrc(realCrc);\n\n            def.reset();\n\n            written += entry.getCompressedSize();\n        } else if (raf == null) {\n            if (entry.getCrc() != realCrc) {\n                throw new ZipException(\"bad CRC checksum for entry \"\n                                       + entry.getName() + \": \"\n                                       + Long.toHexString(entry.getCrc())\n                                       + \" instead of \"\n                                       + Long.toHexString(realCrc));\n            }\n\n            if (entry.getSize() != written - dataStart) {\n                throw new ZipException(\"bad size for entry \"\n                                       + entry.getName() + \": \"\n                                       + entry.getSize()\n                                       + \" instead of \"\n                                       + (written - dataStart));\n            }\n        } else { /* method is STORED and we used RandomAccessFile */\n            long size = written - dataStart;\n\n            entry.setSize(size);\n            entry.setCompressedSize(size);\n            entry.setCrc(realCrc);\n        }\n\n        // If random access output, write the local file header containing\n        // the correct CRC and compressed/uncompressed sizes\n        if (raf != null) {\n            long save = raf.getFilePointer();\n\n            raf.seek(localDataStart);\n            writeOut(ZipLong.getBytes(entry.getCrc()));\n            writeOut(ZipLong.getBytes(entry.getCompressedSize()));\n            writeOut(ZipLong.getBytes(entry.getSize()));\n            raf.seek(save);\n        }\n\n        writeDataDescriptor(entry);\n        entry = null;\n    }\n\n    /** {@inheritDoc} */\n // @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        closeArchiveEntry();\n\n        entry = ((ZipArchiveEntry) archiveEntry);\n        entries.add(entry);\n\n        if (entry.getMethod() == -1) { // not specified\n            entry.setMethod(method);\n        }\n\n        if (entry.getTime() == -1) { // not specified\n            entry.setTime(System.currentTimeMillis());\n        }\n\n        // Size/CRC not required if RandomAccessFile is used\n        if (entry.getMethod() == STORED && raf == null) {\n            if (entry.getSize() == -1) {\n                throw new ZipException(\"uncompressed size is required for\"\n                                       + \" STORED method when not writing to a\"\n                                       + \" file\");\n            }\n            if (entry.getCrc() == -1) {\n                throw new ZipException(\"crc checksum is required for STORED\"\n                                       + \" method when not writing to a file\");\n            }\n            entry.setCompressedSize(entry.getSize());\n        }\n\n        if (entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n            def.setLevel(level);\n            hasCompressionLevelChanged = false;\n        }\n        writeLocalFileHeader(entry);\n    }\n\n    /**\n     * Set the file comment.\n     * @param comment the comment\n     */\n    public void setComment(String comment) {\n        this.comment = comment;\n    }\n\n    /**\n     * Sets the compression level for subsequent entries.\n     *\n     * <p>Default is Deflater.DEFAULT_COMPRESSION.</p>\n     * @param level the compression level.\n     * @throws IllegalArgumentException if an invalid compression\n     * level is specified.\n     */\n    public void setLevel(int level) {\n        if (level < Deflater.DEFAULT_COMPRESSION\n            || level > Deflater.BEST_COMPRESSION) {\n            throw new IllegalArgumentException(\"Invalid compression level: \"\n                                               + level);\n        }\n        hasCompressionLevelChanged = (this.level != level);\n        this.level = level;\n    }\n\n    /**\n     * Sets the default compression method for subsequent entries.\n     *\n     * <p>Default is DEFLATED.</p>\n     * @param method an <code>int</code> from java.util.zip.ZipEntry\n     */\n    public void setMethod(int method) {\n        this.method = method;\n    }\n\n    /**\n     * Writes bytes to ZIP entry.\n     * @param b the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    public void write(byte[] b, int offset, int length) throws IOException {\n        if (entry.getMethod() == DEFLATED) {\n            if (length > 0) {\n                if (!def.finished()) {\n                    if (length <= DEFLATER_BLOCK_SIZE) {\n                        def.setInput(b, offset, length);\n                        deflateUntilInputIsNeeded();\n                    } else {\n                        final int fullblocks = length / DEFLATER_BLOCK_SIZE;\n                        for (int i = 0; i < fullblocks; i++) {\n                            def.setInput(b, offset + i * DEFLATER_BLOCK_SIZE,\n                                         DEFLATER_BLOCK_SIZE);\n                            deflateUntilInputIsNeeded();\n                        }\n                        final int done = fullblocks * DEFLATER_BLOCK_SIZE;\n                        if (done < length) {\n                            def.setInput(b, offset + done, length - done);\n                            deflateUntilInputIsNeeded();\n                        }\n                    }\n                }\n            }\n        } else {\n            writeOut(b, offset, length);\n            written += length;\n        }\n        crc.update(b, offset, length);\n    }\n\n    /**\n     * Closes this output stream and releases any system resources\n     * associated with the stream.\n     *\n     * @exception  IOException  if an I/O error occurs.\n     */\n    public void close() throws IOException {\n        finish();\n        if (raf != null) {\n            raf.close();\n        }\n        if (out != null) {\n            out.close();\n        }\n    }\n\n    /**\n     * Flushes this output stream and forces any buffered output bytes\n     * to be written out to the stream.\n     *\n     * @exception  IOException  if an I/O error occurs.\n     */\n    public void flush() throws IOException {\n        if (out != null) {\n            out.flush();\n        }\n    }\n\n    /*\n     * Various ZIP constants\n     */\n    /**\n     * local file header signature\n     */\n    static final byte[] LFH_SIG = ZipLong.LFH_SIG.getBytes();\n    /**\n     * data descriptor signature\n     */\n    static final byte[] DD_SIG = ZipLong.getBytes(0X08074B50L);\n    /**\n     * central file header signature\n     */\n    static final byte[] CFH_SIG = ZipLong.CFH_SIG.getBytes();\n    /**\n     * end of central dir signature\n     */\n    static final byte[] EOCD_SIG = ZipLong.getBytes(0X06054B50L);\n\n    /**\n     * Writes next block of compressed data to the output stream.\n     * @throws IOException on error\n     */\n    protected final void deflate() throws IOException {\n        int len = def.deflate(buf, 0, buf.length);\n        if (len > 0) {\n            writeOut(buf, 0, len);\n        }\n    }\n\n    /**\n     * Writes the local file header entry\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeLocalFileHeader(ZipArchiveEntry ze) throws IOException {\n\n        boolean encodable = zipEncoding.canEncode(ze.getName());\n        \n        final ZipEncoding entryEncoding;\n        \n        if (!encodable && fallbackToUTF8) {\n            entryEncoding = ZipEncodingHelper.UTF8_ZIP_ENCODING;\n        } else {\n            entryEncoding = zipEncoding;\n        }\n        \n        ByteBuffer name = entryEncoding.encode(ze.getName());        \n\n        if (createUnicodeExtraFields != UnicodeExtraFieldPolicy.NEVER) {\n\n            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                || !encodable) {\n                ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n                                                           name.array(),\n                                                           name.arrayOffset(),\n                                                           name.limit()));\n            }\n\n            String comm = ze.getComment();\n            if (comm != null && !\"\".equals(comm)) {\n\n                boolean commentEncodable = this.zipEncoding.canEncode(comm);\n\n                if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                    || !commentEncodable) {\n                    ByteBuffer commentB = entryEncoding.encode(comm);\n                    ze.addExtraField(new UnicodeCommentExtraField(comm,\n                                                                  commentB.array(),\n                                                                  commentB.arrayOffset(),\n                                                                  commentB.limit())\n                                     );\n                }\n            }\n        }\n\n        offsets.put(ze, ZipLong.getBytes(written));\n\n        writeOut(LFH_SIG);\n        written += WORD;\n\n        //store method in local variable to prevent multiple method calls\n        final int zipMethod = ze.getMethod();\n\n        writeVersionNeededToExtractAndGeneralPurposeBits(zipMethod,\n                                                         !encodable\n                                                         && fallbackToUTF8);\n        written += WORD;\n\n        // compression method\n        writeOut(ZipShort.getBytes(zipMethod));\n        written += SHORT;\n\n        // last mod. time and date\n        writeOut(ZipUtil.toDosTime(ze.getTime()));\n        written += WORD;\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        localDataStart = written;\n        if (zipMethod == DEFLATED || raf != null) {\n            writeOut(LZERO);\n            writeOut(LZERO);\n            writeOut(LZERO);\n        } else {\n            writeOut(ZipLong.getBytes(ze.getCrc()));\n            writeOut(ZipLong.getBytes(ze.getSize()));\n            writeOut(ZipLong.getBytes(ze.getSize()));\n        }\n        // CheckStyle:MagicNumber OFF\n        written += 12;\n        // CheckStyle:MagicNumber ON\n\n        // file name length\n        writeOut(ZipShort.getBytes(name.limit()));\n        written += SHORT;\n\n        // extra field length\n        byte[] extra = ze.getLocalFileDataExtra();\n        writeOut(ZipShort.getBytes(extra.length));\n        written += SHORT;\n\n        // file name\n        writeOut(name.array(), name.arrayOffset(), name.limit());\n        written += name.limit();\n\n        // extra field\n        writeOut(extra);\n        written += extra.length;\n\n        dataStart = written;\n    }\n\n    /**\n     * Writes the data descriptor entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeDataDescriptor(ZipArchiveEntry ze) throws IOException {\n        if (ze.getMethod() != DEFLATED || raf != null) {\n            return;\n        }\n        writeOut(DD_SIG);\n        writeOut(ZipLong.getBytes(entry.getCrc()));\n        writeOut(ZipLong.getBytes(entry.getCompressedSize()));\n        writeOut(ZipLong.getBytes(entry.getSize()));\n        // CheckStyle:MagicNumber OFF\n        written += 16;\n        // CheckStyle:MagicNumber ON\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeCentralFileHeader(ZipArchiveEntry ze) throws IOException {\n        writeOut(CFH_SIG);\n        written += WORD;\n\n        // version made by\n        // CheckStyle:MagicNumber OFF\n        writeOut(ZipShort.getBytes((ze.getPlatform() << 8) | 20));\n        written += SHORT;\n\n        final int zipMethod = ze.getMethod();\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        writeVersionNeededToExtractAndGeneralPurposeBits(zipMethod,\n                                                         !encodable\n                                                         && fallbackToUTF8);\n        written += WORD;\n\n        // compression method\n        writeOut(ZipShort.getBytes(zipMethod));\n        written += SHORT;\n\n        // last mod. time and date\n        writeOut(ZipUtil.toDosTime(ze.getTime()));\n        written += WORD;\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        writeOut(ZipLong.getBytes(ze.getCrc()));\n        writeOut(ZipLong.getBytes(ze.getCompressedSize()));\n        writeOut(ZipLong.getBytes(ze.getSize()));\n        // CheckStyle:MagicNumber OFF\n        written += 12;\n        // CheckStyle:MagicNumber ON\n\n        // file name length\n        final ZipEncoding entryEncoding;\n        \n        if (!encodable && fallbackToUTF8) {\n            entryEncoding = ZipEncodingHelper.UTF8_ZIP_ENCODING;\n        } else {\n            entryEncoding = zipEncoding;\n        }\n        \n        ByteBuffer name = entryEncoding.encode(ze.getName());        \n\n        writeOut(ZipShort.getBytes(name.limit()));\n        written += SHORT;\n\n        // extra field length\n        byte[] extra = ze.getCentralDirectoryExtra();\n        writeOut(ZipShort.getBytes(extra.length));\n        written += SHORT;\n\n        // file comment length\n        String comm = ze.getComment();\n        if (comm == null) {\n            comm = \"\";\n        }\n        \n        ByteBuffer commentB = entryEncoding.encode(comm);\n        \n        writeOut(ZipShort.getBytes(commentB.limit()));\n        written += SHORT;\n\n        // disk number start\n        writeOut(ZERO);\n        written += SHORT;\n\n        // internal file attributes\n        writeOut(ZipShort.getBytes(ze.getInternalAttributes()));\n        written += SHORT;\n\n        // external file attributes\n        writeOut(ZipLong.getBytes(ze.getExternalAttributes()));\n        written += WORD;\n\n        // relative offset of LFH\n        writeOut((byte[]) offsets.get(ze));\n        written += WORD;\n\n        // file name\n        writeOut(name.array(), name.arrayOffset(), name.limit());\n        written += name.limit();\n\n        // extra field\n        writeOut(extra);\n        written += extra.length;\n\n        // file comment\n        writeOut(commentB.array(), commentB.arrayOffset(), commentB.limit());\n        written += commentB.limit();\n    }\n\n    /**\n     * Writes the &quot;End of central dir record&quot;.\n     * @throws IOException on error\n     */\n    protected void writeCentralDirectoryEnd() throws IOException {\n        writeOut(EOCD_SIG);\n\n        // disk numbers\n        writeOut(ZERO);\n        writeOut(ZERO);\n\n        // number of entries\n        byte[] num = ZipShort.getBytes(entries.size());\n        writeOut(num);\n        writeOut(num);\n\n        // length and location of CD\n        writeOut(ZipLong.getBytes(cdLength));\n        writeOut(ZipLong.getBytes(cdOffset));\n\n        // ZIP file comment\n        ByteBuffer data = this.zipEncoding.encode(comment);\n        writeOut(ZipShort.getBytes(data.limit()));\n        writeOut(data.array(), data.arrayOffset(), data.limit());\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(byte[] data) throws IOException {\n        writeOut(data, 0, data.length);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(byte[] data, int offset, int length)\n        throws IOException {\n        if (raf != null) {\n            raf.write(data, offset, length);\n        } else {\n            out.write(data, offset, length);\n        }\n    }\n\n    private void deflateUntilInputIsNeeded() throws IOException {\n        while (!def.needsInput()) {\n            deflate();\n        }\n    }\n\n    private void writeVersionNeededToExtractAndGeneralPurposeBits(final int\n                                                                  zipMethod,\n                                                                  final boolean\n                                                                  utfFallback)\n        throws IOException {\n\n        // CheckStyle:MagicNumber OFF\n        int versionNeededToExtract = 10;\n        int generalPurposeFlag = (useEFS || utfFallback) ? EFS_FLAG : 0;\n        if (zipMethod == DEFLATED && raf == null) {\n            // requires version 2 as we are going to store length info\n            // in the data descriptor\n            versionNeededToExtract =  20;\n            // bit3 set to signal, we use a data descriptor\n            generalPurposeFlag |= 8;\n        }\n        // CheckStyle:MagicNumber ON\n\n        // version needed to extract\n        writeOut(ZipShort.getBytes(versionNeededToExtract));\n        // general purpose bit flag\n        writeOut(ZipShort.getBytes(generalPurposeFlag));\n    }\n\n    /**\n     * enum that represents the possible policies for creating Unicode\n     * extra fields.\n     */\n    public static final class UnicodeExtraFieldPolicy {\n        /**\n         * Always create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy ALWAYS =\n            new UnicodeExtraFieldPolicy(\"always\");\n        /**\n         * Never create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy NEVER =\n            new UnicodeExtraFieldPolicy(\"never\");\n        /**\n         * Create Unicode extra fields for filenames that cannot be\n         * encoded using the specified encoding.\n         */\n        public static final UnicodeExtraFieldPolicy NOT_ENCODEABLE =\n            new UnicodeExtraFieldPolicy(\"not encodeable\");\n\n        private final String name;\n        private UnicodeExtraFieldPolicy(String n) {\n            name = n;\n        }\n        public String toString() {\n            return name;\n        }\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new ZipArchiveEntry(inputFile, entryName);\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.RandomAccessFile;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.zip.CRC32;\nimport java.util.zip.Deflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\n\n/**\n * Reimplementation of {@link java.util.zip.ZipOutputStream\n * java.util.zip.ZipOutputStream} that does handle the extended\n * functionality of this package, especially internal/external file\n * attributes and extra fields with different layouts for local file\n * data and central directory entries.\n *\n * <p>This class will try to use {@link java.io.RandomAccessFile\n * RandomAccessFile} when you know that the output is going to go to a\n * file.</p>\n *\n * <p>If RandomAccessFile cannot be used, this implementation will use\n * a Data Descriptor to store size and CRC information for {@link\n * #DEFLATED DEFLATED} entries, this means, you don't need to\n * calculate them yourself.  Unfortunately this is not possible for\n * the {@link #STORED STORED} method, here setting the CRC and\n * uncompressed size information is required before {@link\n * #putArchiveEntry(ArchiveEntry)} can be called.</p>\n * @NotThreadSafe\n */\npublic class ZipArchiveOutputStream extends ArchiveOutputStream {\n\n    static final int BYTE_MASK = 0xFF;\n    private static final int SHORT = 2;\n    private static final int WORD = 4;\n    static final int BUFFER_SIZE = 512;\n    /* \n     * Apparently Deflater.setInput gets slowed down a lot on Sun JVMs\n     * when it gets handed a really big buffer.  See\n     * https://issues.apache.org/bugzilla/show_bug.cgi?id=45396\n     *\n     * Using a buffer size of 8 kB proved to be a good compromise\n     */\n    private static final int DEFLATER_BLOCK_SIZE = 8192;\n\n    /**\n     * Compression method for deflated entries.\n     */\n    public static final int DEFLATED = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * Default compression level for deflated entries.\n     */\n    public static final int DEFAULT_COMPRESSION = Deflater.DEFAULT_COMPRESSION;\n\n    /**\n     * Compression method for stored entries.\n     */\n    public static final int STORED = java.util.zip.ZipEntry.STORED;\n\n    /**\n     * default encoding for file names and comment.\n     */\n    static final String DEFAULT_ENCODING = ZipEncodingHelper.UTF8;\n\n     /**\n     * General purpose flag, which indicates that filenames are\n     * written in utf-8.\n     */\n    public static final int EFS_FLAG = 1 << 11;\n\n    /**\n     * Current entry.\n     */\n    private ZipArchiveEntry entry;\n\n    /**\n     * The file comment.\n     */\n    private String comment = \"\";\n\n    /**\n     * Compression level for next entry.\n     */\n    private int level = DEFAULT_COMPRESSION;\n\n    /**\n     * Has the compression level changed when compared to the last\n     * entry?\n     */\n    private boolean hasCompressionLevelChanged = false;\n\n    /**\n     * Default compression method for next entry.\n     */\n    private int method = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * List of ZipArchiveEntries written so far.\n     */\n    private final List entries = new LinkedList();\n\n    /**\n     * CRC instance to avoid parsing DEFLATED data twice.\n     */\n    private final CRC32 crc = new CRC32();\n\n    /**\n     * Count the bytes written to out.\n     */\n    private long written = 0;\n\n    /**\n     * Data for local header data\n     */\n    private long dataStart = 0;\n\n    /**\n     * Offset for CRC entry in the local file header data for the\n     * current entry starts here.\n     */\n    private long localDataStart = 0;\n\n    /**\n     * Start of central directory.\n     */\n    private long cdOffset = 0;\n\n    /**\n     * Length of central directory.\n     */\n    private long cdLength = 0;\n\n    /**\n     * Helper, a 0 as ZipShort.\n     */\n    private static final byte[] ZERO = {0, 0};\n\n    /**\n     * Helper, a 0 as ZipLong.\n     */\n    private static final byte[] LZERO = {0, 0, 0, 0};\n\n    /**\n     * Holds the offsets of the LFH starts for each entry.\n     */\n    private final Map offsets = new HashMap();\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private String encoding = DEFAULT_ENCODING;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     *\n     * This field is of internal use and will be set in {@link\n     * #setEncoding(String)}.\n     */\n    private ZipEncoding zipEncoding =\n        ZipEncodingHelper.getZipEncoding(DEFAULT_ENCODING);\n\n    /**\n     * This Deflater object is used for output.\n     *\n     */\n    protected final Deflater def = new Deflater(level, true);\n\n    /**\n     * This buffer servers as a Deflater.\n     *\n     */\n    private final byte[] buf = new byte[BUFFER_SIZE];\n\n    /**\n     * Optional random access output.\n     */\n    private final RandomAccessFile raf;\n\n    private final OutputStream out;\n\n    /**\n     * whether to use the EFS flag when writing UTF-8 filenames or not.\n     */\n    private boolean useEFS = true; \n\n    /**\n     * Whether to encode non-encodable file names as UTF-8.\n     */\n    private boolean fallbackToUTF8 = false;\n\n    /**\n     * whether to create UnicodePathExtraField-s for each entry.\n     */\n    private UnicodeExtraFieldPolicy createUnicodeExtraFields =\n        UnicodeExtraFieldPolicy.NEVER;\n\n    /**\n     * Creates a new ZIP OutputStream filtering the underlying stream.\n     * @param out the outputstream to zip\n     */\n    public ZipArchiveOutputStream(OutputStream out) {\n        this.out = out;\n        this.raf = null;\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a File.  Will use\n     * random access if possible.\n     * @param file the file to zip to\n     * @throws IOException on error\n     */\n    public ZipArchiveOutputStream(File file) throws IOException {\n        OutputStream o = null;\n        RandomAccessFile _raf = null;\n        try {\n            _raf = new RandomAccessFile(file, \"rw\");\n            _raf.setLength(0);\n        } catch (IOException e) {\n            if (_raf != null) {\n                try {\n                    _raf.close();\n                } catch (IOException inner) {\n                    // ignore\n                }\n                _raf = null;\n            }\n            o = new FileOutputStream(file);\n        }\n        out = o;\n        raf = _raf;\n    }\n\n    /**\n     * This method indicates whether this archive is writing to a\n     * seekable stream (i.e., to a random access file).\n     *\n     * <p>For seekable streams, you don't need to calculate the CRC or\n     * uncompressed size for {@link #STORED} entries before\n     * invoking {@link #putArchiveEntry(ArchiveEntry)}.\n     * @return true if seekable\n     */\n    public boolean isSeekable() {\n        return raf != null;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     */\n    public void setEncoding(final String encoding) {\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        useEFS &= ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Whether to set the language encoding flag if the file name\n     * encoding is UTF-8.\n     *\n     * <p>Defaults to true.</p>\n     */\n    public void setUseLanguageEncodingFlag(boolean b) {\n        useEFS = b && ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * Whether to create Unicode Extra Fields.\n     *\n     * <p>Defaults to NEVER.</p>\n     */\n    public void setCreateUnicodeExtraFields(UnicodeExtraFieldPolicy b) {\n        createUnicodeExtraFields = b;\n    }\n\n    /**\n     * Whether to fall back to UTF and the language encoding flag if\n     * the file name cannot be encoded using the specified encoding.\n     *\n     * <p>Defaults to false.</p>\n     */\n    public void setFallbackToUTF8(boolean b) {\n        fallbackToUTF8 = b;\n    }\n\n    /* (non-Javadoc)\n     * @see org.apache.commons.compress.archivers.ArchiveOutputStream#finish()\n     */\n    public void finish() throws IOException {\n        if(entry != null) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        \n        cdOffset = written;\n        for (Iterator i = entries.iterator(); i.hasNext(); ) {\n            writeCentralFileHeader((ZipArchiveEntry) i.next());\n        }\n        cdLength = written - cdOffset;\n        writeCentralDirectoryEnd();\n        offsets.clear();\n        entries.clear();\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     * @throws IOException on error\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (entry == null) {\n            return;\n        }\n\n        long realCrc = crc.getValue();\n        crc.reset();\n\n        if (entry.getMethod() == DEFLATED) {\n            def.finish();\n            while (!def.finished()) {\n                deflate();\n            }\n\n            entry.setSize(ZipUtil.adjustToLong(def.getTotalIn()));\n            entry.setCompressedSize(ZipUtil.adjustToLong(def.getTotalOut()));\n            entry.setCrc(realCrc);\n\n            def.reset();\n\n            written += entry.getCompressedSize();\n        } else if (raf == null) {\n            if (entry.getCrc() != realCrc) {\n                throw new ZipException(\"bad CRC checksum for entry \"\n                                       + entry.getName() + \": \"\n                                       + Long.toHexString(entry.getCrc())\n                                       + \" instead of \"\n                                       + Long.toHexString(realCrc));\n            }\n\n            if (entry.getSize() != written - dataStart) {\n                throw new ZipException(\"bad size for entry \"\n                                       + entry.getName() + \": \"\n                                       + entry.getSize()\n                                       + \" instead of \"\n                                       + (written - dataStart));\n            }\n        } else { /* method is STORED and we used RandomAccessFile */\n            long size = written - dataStart;\n\n            entry.setSize(size);\n            entry.setCompressedSize(size);\n            entry.setCrc(realCrc);\n        }\n\n        // If random access output, write the local file header containing\n        // the correct CRC and compressed/uncompressed sizes\n        if (raf != null) {\n            long save = raf.getFilePointer();\n\n            raf.seek(localDataStart);\n            writeOut(ZipLong.getBytes(entry.getCrc()));\n            writeOut(ZipLong.getBytes(entry.getCompressedSize()));\n            writeOut(ZipLong.getBytes(entry.getSize()));\n            raf.seek(save);\n        }\n\n        writeDataDescriptor(entry);\n        entry = null;\n    }\n\n    /** {@inheritDoc} */\n // @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        closeArchiveEntry();\n\n        entry = ((ZipArchiveEntry) archiveEntry);\n        entries.add(entry);\n\n        if (entry.getMethod() == -1) { // not specified\n            entry.setMethod(method);\n        }\n\n        if (entry.getTime() == -1) { // not specified\n            entry.setTime(System.currentTimeMillis());\n        }\n\n        // Size/CRC not required if RandomAccessFile is used\n        if (entry.getMethod() == STORED && raf == null) {\n            if (entry.getSize() == -1) {\n                throw new ZipException(\"uncompressed size is required for\"\n                                       + \" STORED method when not writing to a\"\n                                       + \" file\");\n            }\n            if (entry.getCrc() == -1) {\n                throw new ZipException(\"crc checksum is required for STORED\"\n                                       + \" method when not writing to a file\");\n            }\n            entry.setCompressedSize(entry.getSize());\n        }\n\n        if (entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n            def.setLevel(level);\n            hasCompressionLevelChanged = false;\n        }\n        writeLocalFileHeader(entry);\n    }\n\n    /**\n     * Set the file comment.\n     * @param comment the comment\n     */\n    public void setComment(String comment) {\n        this.comment = comment;\n    }\n\n    /**\n     * Sets the compression level for subsequent entries.\n     *\n     * <p>Default is Deflater.DEFAULT_COMPRESSION.</p>\n     * @param level the compression level.\n     * @throws IllegalArgumentException if an invalid compression\n     * level is specified.\n     */\n    public void setLevel(int level) {\n        if (level < Deflater.DEFAULT_COMPRESSION\n            || level > Deflater.BEST_COMPRESSION) {\n            throw new IllegalArgumentException(\"Invalid compression level: \"\n                                               + level);\n        }\n        hasCompressionLevelChanged = (this.level != level);\n        this.level = level;\n    }\n\n    /**\n     * Sets the default compression method for subsequent entries.\n     *\n     * <p>Default is DEFLATED.</p>\n     * @param method an <code>int</code> from java.util.zip.ZipEntry\n     */\n    public void setMethod(int method) {\n        this.method = method;\n    }\n\n    /**\n     * Writes bytes to ZIP entry.\n     * @param b the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    public void write(byte[] b, int offset, int length) throws IOException {\n        if (entry.getMethod() == DEFLATED) {\n            if (length > 0) {\n                if (!def.finished()) {\n                    if (length <= DEFLATER_BLOCK_SIZE) {\n                        def.setInput(b, offset, length);\n                        deflateUntilInputIsNeeded();\n                    } else {\n                        final int fullblocks = length / DEFLATER_BLOCK_SIZE;\n                        for (int i = 0; i < fullblocks; i++) {\n                            def.setInput(b, offset + i * DEFLATER_BLOCK_SIZE,\n                                         DEFLATER_BLOCK_SIZE);\n                            deflateUntilInputIsNeeded();\n                        }\n                        final int done = fullblocks * DEFLATER_BLOCK_SIZE;\n                        if (done < length) {\n                            def.setInput(b, offset + done, length - done);\n                            deflateUntilInputIsNeeded();\n                        }\n                    }\n                }\n            }\n        } else {\n            writeOut(b, offset, length);\n            written += length;\n        }\n        crc.update(b, offset, length);\n    }\n\n    /**\n     * Closes this output stream and releases any system resources\n     * associated with the stream.\n     *\n     * @exception  IOException  if an I/O error occurs.\n     */\n    public void close() throws IOException {\n        if (raf != null) {\n            raf.close();\n        }\n        if (out != null) {\n            out.close();\n        }\n    }\n\n    /**\n     * Flushes this output stream and forces any buffered output bytes\n     * to be written out to the stream.\n     *\n     * @exception  IOException  if an I/O error occurs.\n     */\n    public void flush() throws IOException {\n        if (out != null) {\n            out.flush();\n        }\n    }\n\n    /*\n     * Various ZIP constants\n     */\n    /**\n     * local file header signature\n     */\n    static final byte[] LFH_SIG = ZipLong.LFH_SIG.getBytes();\n    /**\n     * data descriptor signature\n     */\n    static final byte[] DD_SIG = ZipLong.getBytes(0X08074B50L);\n    /**\n     * central file header signature\n     */\n    static final byte[] CFH_SIG = ZipLong.CFH_SIG.getBytes();\n    /**\n     * end of central dir signature\n     */\n    static final byte[] EOCD_SIG = ZipLong.getBytes(0X06054B50L);\n\n    /**\n     * Writes next block of compressed data to the output stream.\n     * @throws IOException on error\n     */\n    protected final void deflate() throws IOException {\n        int len = def.deflate(buf, 0, buf.length);\n        if (len > 0) {\n            writeOut(buf, 0, len);\n        }\n    }\n\n    /**\n     * Writes the local file header entry\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeLocalFileHeader(ZipArchiveEntry ze) throws IOException {\n\n        boolean encodable = zipEncoding.canEncode(ze.getName());\n        \n        final ZipEncoding entryEncoding;\n        \n        if (!encodable && fallbackToUTF8) {\n            entryEncoding = ZipEncodingHelper.UTF8_ZIP_ENCODING;\n        } else {\n            entryEncoding = zipEncoding;\n        }\n        \n        ByteBuffer name = entryEncoding.encode(ze.getName());        \n\n        if (createUnicodeExtraFields != UnicodeExtraFieldPolicy.NEVER) {\n\n            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                || !encodable) {\n                ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n                                                           name.array(),\n                                                           name.arrayOffset(),\n                                                           name.limit()));\n            }\n\n            String comm = ze.getComment();\n            if (comm != null && !\"\".equals(comm)) {\n\n                boolean commentEncodable = this.zipEncoding.canEncode(comm);\n\n                if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                    || !commentEncodable) {\n                    ByteBuffer commentB = entryEncoding.encode(comm);\n                    ze.addExtraField(new UnicodeCommentExtraField(comm,\n                                                                  commentB.array(),\n                                                                  commentB.arrayOffset(),\n                                                                  commentB.limit())\n                                     );\n                }\n            }\n        }\n\n        offsets.put(ze, ZipLong.getBytes(written));\n\n        writeOut(LFH_SIG);\n        written += WORD;\n\n        //store method in local variable to prevent multiple method calls\n        final int zipMethod = ze.getMethod();\n\n        writeVersionNeededToExtractAndGeneralPurposeBits(zipMethod,\n                                                         !encodable\n                                                         && fallbackToUTF8);\n        written += WORD;\n\n        // compression method\n        writeOut(ZipShort.getBytes(zipMethod));\n        written += SHORT;\n\n        // last mod. time and date\n        writeOut(ZipUtil.toDosTime(ze.getTime()));\n        written += WORD;\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        localDataStart = written;\n        if (zipMethod == DEFLATED || raf != null) {\n            writeOut(LZERO);\n            writeOut(LZERO);\n            writeOut(LZERO);\n        } else {\n            writeOut(ZipLong.getBytes(ze.getCrc()));\n            writeOut(ZipLong.getBytes(ze.getSize()));\n            writeOut(ZipLong.getBytes(ze.getSize()));\n        }\n        // CheckStyle:MagicNumber OFF\n        written += 12;\n        // CheckStyle:MagicNumber ON\n\n        // file name length\n        writeOut(ZipShort.getBytes(name.limit()));\n        written += SHORT;\n\n        // extra field length\n        byte[] extra = ze.getLocalFileDataExtra();\n        writeOut(ZipShort.getBytes(extra.length));\n        written += SHORT;\n\n        // file name\n        writeOut(name.array(), name.arrayOffset(), name.limit());\n        written += name.limit();\n\n        // extra field\n        writeOut(extra);\n        written += extra.length;\n\n        dataStart = written;\n    }\n\n    /**\n     * Writes the data descriptor entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeDataDescriptor(ZipArchiveEntry ze) throws IOException {\n        if (ze.getMethod() != DEFLATED || raf != null) {\n            return;\n        }\n        writeOut(DD_SIG);\n        writeOut(ZipLong.getBytes(entry.getCrc()));\n        writeOut(ZipLong.getBytes(entry.getCompressedSize()));\n        writeOut(ZipLong.getBytes(entry.getSize()));\n        // CheckStyle:MagicNumber OFF\n        written += 16;\n        // CheckStyle:MagicNumber ON\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeCentralFileHeader(ZipArchiveEntry ze) throws IOException {\n        writeOut(CFH_SIG);\n        written += WORD;\n\n        // version made by\n        // CheckStyle:MagicNumber OFF\n        writeOut(ZipShort.getBytes((ze.getPlatform() << 8) | 20));\n        written += SHORT;\n\n        final int zipMethod = ze.getMethod();\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        writeVersionNeededToExtractAndGeneralPurposeBits(zipMethod,\n                                                         !encodable\n                                                         && fallbackToUTF8);\n        written += WORD;\n\n        // compression method\n        writeOut(ZipShort.getBytes(zipMethod));\n        written += SHORT;\n\n        // last mod. time and date\n        writeOut(ZipUtil.toDosTime(ze.getTime()));\n        written += WORD;\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        writeOut(ZipLong.getBytes(ze.getCrc()));\n        writeOut(ZipLong.getBytes(ze.getCompressedSize()));\n        writeOut(ZipLong.getBytes(ze.getSize()));\n        // CheckStyle:MagicNumber OFF\n        written += 12;\n        // CheckStyle:MagicNumber ON\n\n        // file name length\n        final ZipEncoding entryEncoding;\n        \n        if (!encodable && fallbackToUTF8) {\n            entryEncoding = ZipEncodingHelper.UTF8_ZIP_ENCODING;\n        } else {\n            entryEncoding = zipEncoding;\n        }\n        \n        ByteBuffer name = entryEncoding.encode(ze.getName());        \n\n        writeOut(ZipShort.getBytes(name.limit()));\n        written += SHORT;\n\n        // extra field length\n        byte[] extra = ze.getCentralDirectoryExtra();\n        writeOut(ZipShort.getBytes(extra.length));\n        written += SHORT;\n\n        // file comment length\n        String comm = ze.getComment();\n        if (comm == null) {\n            comm = \"\";\n        }\n        \n        ByteBuffer commentB = entryEncoding.encode(comm);\n        \n        writeOut(ZipShort.getBytes(commentB.limit()));\n        written += SHORT;\n\n        // disk number start\n        writeOut(ZERO);\n        written += SHORT;\n\n        // internal file attributes\n        writeOut(ZipShort.getBytes(ze.getInternalAttributes()));\n        written += SHORT;\n\n        // external file attributes\n        writeOut(ZipLong.getBytes(ze.getExternalAttributes()));\n        written += WORD;\n\n        // relative offset of LFH\n        writeOut((byte[]) offsets.get(ze));\n        written += WORD;\n\n        // file name\n        writeOut(name.array(), name.arrayOffset(), name.limit());\n        written += name.limit();\n\n        // extra field\n        writeOut(extra);\n        written += extra.length;\n\n        // file comment\n        writeOut(commentB.array(), commentB.arrayOffset(), commentB.limit());\n        written += commentB.limit();\n    }\n\n    /**\n     * Writes the &quot;End of central dir record&quot;.\n     * @throws IOException on error\n     */\n    protected void writeCentralDirectoryEnd() throws IOException {\n        writeOut(EOCD_SIG);\n\n        // disk numbers\n        writeOut(ZERO);\n        writeOut(ZERO);\n\n        // number of entries\n        byte[] num = ZipShort.getBytes(entries.size());\n        writeOut(num);\n        writeOut(num);\n\n        // length and location of CD\n        writeOut(ZipLong.getBytes(cdLength));\n        writeOut(ZipLong.getBytes(cdOffset));\n\n        // ZIP file comment\n        ByteBuffer data = this.zipEncoding.encode(comment);\n        writeOut(ZipShort.getBytes(data.limit()));\n        writeOut(data.array(), data.arrayOffset(), data.limit());\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(byte[] data) throws IOException {\n        writeOut(data, 0, data.length);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(byte[] data, int offset, int length)\n        throws IOException {\n        if (raf != null) {\n            raf.write(data, offset, length);\n        } else {\n            out.write(data, offset, length);\n        }\n    }\n\n    private void deflateUntilInputIsNeeded() throws IOException {\n        while (!def.needsInput()) {\n            deflate();\n        }\n    }\n\n    private void writeVersionNeededToExtractAndGeneralPurposeBits(final int\n                                                                  zipMethod,\n                                                                  final boolean\n                                                                  utfFallback)\n        throws IOException {\n\n        // CheckStyle:MagicNumber OFF\n        int versionNeededToExtract = 10;\n        int generalPurposeFlag = (useEFS || utfFallback) ? EFS_FLAG : 0;\n        if (zipMethod == DEFLATED && raf == null) {\n            // requires version 2 as we are going to store length info\n            // in the data descriptor\n            versionNeededToExtract =  20;\n            // bit3 set to signal, we use a data descriptor\n            generalPurposeFlag |= 8;\n        }\n        // CheckStyle:MagicNumber ON\n\n        // version needed to extract\n        writeOut(ZipShort.getBytes(versionNeededToExtract));\n        // general purpose bit flag\n        writeOut(ZipShort.getBytes(generalPurposeFlag));\n    }\n\n    /**\n     * enum that represents the possible policies for creating Unicode\n     * extra fields.\n     */\n    public static final class UnicodeExtraFieldPolicy {\n        /**\n         * Always create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy ALWAYS =\n            new UnicodeExtraFieldPolicy(\"always\");\n        /**\n         * Never create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy NEVER =\n            new UnicodeExtraFieldPolicy(\"never\");\n        /**\n         * Create Unicode extra fields for filenames that cannot be\n         * encoded using the specified encoding.\n         */\n        public static final UnicodeExtraFieldPolicy NOT_ENCODEABLE =\n            new UnicodeExtraFieldPolicy(\"not encodeable\");\n\n        private final String name;\n        private UnicodeExtraFieldPolicy(String n) {\n            name = n;\n        }\n        public String toString() {\n            return name;\n        }\n    }\n\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        return new ZipArchiveEntry(inputFile, entryName);\n    }\n}\n"}, {"class_name": "org.apache.commons.compress.changes.ChangeSetPerformer", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.changes;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.Iterator;\nimport java.util.LinkedHashSet;\nimport java.util.Set;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Performs ChangeSet operations on a stream.\n * This class is thread safe and can be used multiple times.\n * It operates on a copy of the ChangeSet. If the ChangeSet changes,\n * a new Performer must be created.\n * \n * @ThreadSafe\n * @Immutable\n */\npublic class ChangeSetPerformer {\n    private final Set changes;\n    \n    /**\n     * Constructs a ChangeSetPerformer with the changes from this ChangeSet\n     * @param changeSet the ChangeSet which operations are used for performing\n     */\n    public ChangeSetPerformer(final ChangeSet changeSet) {\n        changes = changeSet.getChanges();\n    }\n    \n    /**\n     * Performs all changes collected in this ChangeSet on the input stream and\n     * streams the result to the output stream. Perform may be called more than once.\n     * \n     * This method finishes the stream, no other entries should be added\n     * after that.\n     * \n     * @param in\n     *            the InputStream to perform the changes on\n     * @param out\n     *            the resulting OutputStream with all modifications\n     * @throws IOException\n     *             if an read/write error occurs\n     * @return the results of this operation\n     */\n    public ChangeSetResults perform(ArchiveInputStream in, ArchiveOutputStream out)\n            throws IOException {\n        ChangeSetResults results = new ChangeSetResults();\n        \n        Set workingSet = new LinkedHashSet(changes);\n        \n        for (Iterator it = workingSet.iterator(); it.hasNext();) {\n            Change change = (Change) it.next();\n\n            if (change.type() == Change.TYPE_ADD && change.isReplaceMode()) {\n                copyStream(change.getInput(), out, change.getEntry());\n                it.remove();\n                results.addedFromChangeSet(change.getEntry().getName());\n            }\n        }\n\n        ArchiveEntry entry = null;\n        while ((entry = in.getNextEntry()) != null) {\n            boolean copy = true;\n\n            for (Iterator it = workingSet.iterator(); it.hasNext();) {\n                Change change = (Change) it.next();\n\n                final int type = change.type();\n                final String name = entry.getName();\n                if (type == Change.TYPE_DELETE && name != null) {\n                    if (name.equals(change.targetFile())) {\n                        copy = false;\n                        it.remove();\n                        results.deleted(name);\n                        break;\n                    }\n                } else if(type == Change.TYPE_DELETE_DIR && name != null) {\n                    if (name.startsWith(change.targetFile() + \"/\")) {\n                        copy = false;\n                        results.deleted(name);\n                        break;\n                    }\n                }\n            }\n\n            if (copy) {\n                if (!isDeletedLater(workingSet, entry) && !results.hasBeenAdded(entry.getName())) {\n                    copyStream(in, out, entry);\n                    results.addedFromStream(entry.getName());\n                }\n            }\n        }\n        \n        // Adds files which hasn't been added from the original and do not have replace mode on\n        for (Iterator it = workingSet.iterator(); it.hasNext();) {\n            Change change = (Change) it.next();\n\n            if (change.type() == Change.TYPE_ADD && \n                !change.isReplaceMode() && \n                !results.hasBeenAdded(change.getEntry().getName())) {\n                copyStream(change.getInput(), out, change.getEntry());\n                it.remove();\n                results.addedFromChangeSet(change.getEntry().getName());\n            }\n        }\n        return results;\n    }\n\n    /**\n     * Checks if an ArchiveEntry is deleted later in the ChangeSet. This is\n     * necessary if an file is added with this ChangeSet, but later became\n     * deleted in the same set.\n     * \n     * @param entry\n     *            the entry to check\n     * @return true, if this entry has an deletion change later, false otherwise\n     */\n    private boolean isDeletedLater(Set workingSet, ArchiveEntry entry) {\n        String source = entry.getName();\n\n        if (!workingSet.isEmpty()) {\n            for (Iterator it = workingSet.iterator(); it.hasNext();) {\n                Change change = (Change) it.next();\n                final int type = change.type();\n                String target = change.targetFile();\n                if (type == Change.TYPE_DELETE && source.equals(target)) {\n                    return true;\n                }\n\n                if (type == Change.TYPE_DELETE_DIR && source.startsWith(target + \"/\")){\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    /**\n     * Copies the ArchiveEntry to the Output stream\n     * \n     * @param in\n     *            the stream to read the data from\n     * @param out\n     *            the stream to write the data to\n     * @param entry\n     *            the entry to write\n     * @throws IOException\n     *             if data cannot be read or written\n     */\n    private void copyStream(InputStream in, ArchiveOutputStream out,\n            ArchiveEntry entry) throws IOException {\n        out.putArchiveEntry(entry);\n        IOUtils.copy(in, out);\n        out.closeArchiveEntry();\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.changes;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.Iterator;\nimport java.util.LinkedHashSet;\nimport java.util.Set;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Performs ChangeSet operations on a stream.\n * This class is thread safe and can be used multiple times.\n * It operates on a copy of the ChangeSet. If the ChangeSet changes,\n * a new Performer must be created.\n * \n * @ThreadSafe\n * @Immutable\n */\npublic class ChangeSetPerformer {\n    private final Set changes;\n    \n    /**\n     * Constructs a ChangeSetPerformer with the changes from this ChangeSet\n     * @param changeSet the ChangeSet which operations are used for performing\n     */\n    public ChangeSetPerformer(final ChangeSet changeSet) {\n        changes = changeSet.getChanges();\n    }\n    \n    /**\n     * Performs all changes collected in this ChangeSet on the input stream and\n     * streams the result to the output stream. Perform may be called more than once.\n     * \n     * This method finishes the stream, no other entries should be added\n     * after that.\n     * \n     * @param in\n     *            the InputStream to perform the changes on\n     * @param out\n     *            the resulting OutputStream with all modifications\n     * @throws IOException\n     *             if an read/write error occurs\n     * @return the results of this operation\n     */\n    public ChangeSetResults perform(ArchiveInputStream in, ArchiveOutputStream out)\n            throws IOException {\n        ChangeSetResults results = new ChangeSetResults();\n        \n        Set workingSet = new LinkedHashSet(changes);\n        \n        for (Iterator it = workingSet.iterator(); it.hasNext();) {\n            Change change = (Change) it.next();\n\n            if (change.type() == Change.TYPE_ADD && change.isReplaceMode()) {\n                copyStream(change.getInput(), out, change.getEntry());\n                it.remove();\n                results.addedFromChangeSet(change.getEntry().getName());\n            }\n        }\n\n        ArchiveEntry entry = null;\n        while ((entry = in.getNextEntry()) != null) {\n            boolean copy = true;\n\n            for (Iterator it = workingSet.iterator(); it.hasNext();) {\n                Change change = (Change) it.next();\n\n                final int type = change.type();\n                final String name = entry.getName();\n                if (type == Change.TYPE_DELETE && name != null) {\n                    if (name.equals(change.targetFile())) {\n                        copy = false;\n                        it.remove();\n                        results.deleted(name);\n                        break;\n                    }\n                } else if(type == Change.TYPE_DELETE_DIR && name != null) {\n                    if (name.startsWith(change.targetFile() + \"/\")) {\n                        copy = false;\n                        results.deleted(name);\n                        break;\n                    }\n                }\n            }\n\n            if (copy) {\n                if (!isDeletedLater(workingSet, entry) && !results.hasBeenAdded(entry.getName())) {\n                    copyStream(in, out, entry);\n                    results.addedFromStream(entry.getName());\n                }\n            }\n        }\n        \n        // Adds files which hasn't been added from the original and do not have replace mode on\n        for (Iterator it = workingSet.iterator(); it.hasNext();) {\n            Change change = (Change) it.next();\n\n            if (change.type() == Change.TYPE_ADD && \n                !change.isReplaceMode() && \n                !results.hasBeenAdded(change.getEntry().getName())) {\n                copyStream(change.getInput(), out, change.getEntry());\n                it.remove();\n                results.addedFromChangeSet(change.getEntry().getName());\n            }\n        }\n        out.finish();\n        return results;\n    }\n\n    /**\n     * Checks if an ArchiveEntry is deleted later in the ChangeSet. This is\n     * necessary if an file is added with this ChangeSet, but later became\n     * deleted in the same set.\n     * \n     * @param entry\n     *            the entry to check\n     * @return true, if this entry has an deletion change later, false otherwise\n     */\n    private boolean isDeletedLater(Set workingSet, ArchiveEntry entry) {\n        String source = entry.getName();\n\n        if (!workingSet.isEmpty()) {\n            for (Iterator it = workingSet.iterator(); it.hasNext();) {\n                Change change = (Change) it.next();\n                final int type = change.type();\n                String target = change.targetFile();\n                if (type == Change.TYPE_DELETE && source.equals(target)) {\n                    return true;\n                }\n\n                if (type == Change.TYPE_DELETE_DIR && source.startsWith(target + \"/\")){\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    /**\n     * Copies the ArchiveEntry to the Output stream\n     * \n     * @param in\n     *            the stream to read the data from\n     * @param out\n     *            the stream to write the data to\n     * @param entry\n     *            the entry to write\n     * @throws IOException\n     *             if data cannot be read or written\n     */\n    private void copyStream(InputStream in, ArchiveOutputStream out,\n            ArchiveEntry entry) throws IOException {\n        out.putArchiveEntry(entry);\n        IOUtils.copy(in, out);\n        out.closeArchiveEntry();\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 5, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\n\n/**\n * Implements an input stream that can read Zip archives.\n * <p>\n * Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information\n * is not available from the header.\n * <p>\n * The {@link ZipFile} class is preferred when reading from files.\n *  \n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SHORT = 2;\n    private static final int WORD = 4;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     */\n    private final ZipEncoding zipEncoding;\n\n    /**\n     * Whether to look for and use Unicode extra fields.\n     */\n    private final boolean useUnicodeExtraFields;\n\n    private final InputStream in;\n\n    private final Inflater inf = new Inflater(true);\n    private final CRC32 crc = new CRC32();\n\n    private final byte[] buf = new byte[ZipArchiveOutputStream.BUFFER_SIZE];\n\n    private ZipArchiveEntry current = null;\n    private boolean closed = false;\n    private boolean hitCentralDirectory = false;\n    private int readBytesOfEntry = 0, offsetInBuffer = 0;\n    private int bytesReadFromStream = 0;\n    private int lengthOfLastRead = 0;\n    private boolean hasDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     4 bytes  (0x04034b50)\n      version needed to extract       2 bytes\n      general purpose bit flag        2 bytes\n      compression method              2 bytes\n      last mod file time              2 bytes\n      last mod file date              2 bytes\n      crc-32                          4 bytes\n      compressed size                 4 bytes\n      uncompressed size               4 bytes\n      file name length                2 bytes\n      extra field length              2 bytes\n    */\n\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.length);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n        }\n        byte[] lfh = new byte[LFH_LEN];\n        try {\n            readFully(lfh);\n        } catch (EOFException e) {\n            return null;\n        }\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.CFH_SIG)) {\n            hitCentralDirectory = true;\n            return null;\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new ZipArchiveEntry();\n\n        int versionMadeBy = ZipShort.getValue(lfh, off);\n        off += SHORT;\n        current.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT)\n                            & ZipFile.NIBLET_MASK);\n\n        final int generalPurposeFlag = ZipShort.getValue(lfh, off);\n        final boolean hasEFS = \n            (generalPurposeFlag & ZipArchiveOutputStream.EFS_FLAG) != 0;\n        final ZipEncoding entryEncoding =\n            hasEFS ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        hasDataDescriptor = (generalPurposeFlag & 8) != 0;\n\n        off += SHORT;\n\n        current.setMethod(ZipShort.getValue(lfh, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfh, off));\n        current.setTime(time);\n        off += WORD;\n\n        if (!hasDataDescriptor) {\n            current.setCrc(ZipLong.getValue(lfh, off));\n            off += WORD;\n\n            current.setCompressedSize(ZipLong.getValue(lfh, off));\n            off += WORD;\n\n            current.setSize(ZipLong.getValue(lfh, off));\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(lfh, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(lfh, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.setName(entryEncoding.decode(fileName));\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.setExtra(extraData);\n\n        if (!hasEFS && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current, fileName, null);\n        }\n        return current;\n    }\n\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    public int read(byte[] buffer, int start, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (inf.finished() || current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (start <= buffer.length && length >= 0 && start >= 0\n            && buffer.length - start >= length) {\n            if (current.getMethod() == ZipArchiveOutputStream.STORED) {\n                int csize = (int) current.getSize();\n                if (readBytesOfEntry >= csize) {\n                    return -1;\n                }\n                if (offsetInBuffer >= lengthOfLastRead) {\n                    offsetInBuffer = 0;\n                    if ((lengthOfLastRead = in.read(buf)) == -1) {\n                        return -1;\n                    }\n                    count(lengthOfLastRead);\n                    bytesReadFromStream += lengthOfLastRead;\n                }\n                int toRead = length > lengthOfLastRead\n                    ? lengthOfLastRead - offsetInBuffer\n                    : length;\n                if ((csize - readBytesOfEntry) < toRead) {\n                    toRead = csize - readBytesOfEntry;\n                }\n                System.arraycopy(buf, offsetInBuffer, buffer, start, toRead);\n                offsetInBuffer += toRead;\n                readBytesOfEntry += toRead;\n                crc.update(buffer, start, toRead);\n                return toRead;\n            }\n            if (inf.needsInput()) {\n                fill();\n                if (lengthOfLastRead > 0) {\n                    bytesReadFromStream += lengthOfLastRead;\n                }\n            }\n            int read = 0;\n            try {\n                read = inf.inflate(buffer, start, length);\n            } catch (DataFormatException e) {\n                throw new ZipException(e.getMessage());\n            }\n            if (read == 0 && inf.finished()) {\n                return -1;\n            }\n            crc.update(buffer, start, read);\n            return read;\n        }\n        throw new ArrayIndexOutOfBoundsException();\n    }\n\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n        }\n    }\n\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            byte[] b = new byte[1024];\n            while (skipped != value) {\n                long rem = value - skipped;\n                int x = read(b, 0, (int) (b.length > rem ? rem : b.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /*\n     *  This test assumes that the zip file does not have any additional leading content,\n     *  which is something that is allowed by the specification (e.g. self-extracting zips)\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG); // empty zip\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected){\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;        \n    }\n\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n        // Ensure all entry bytes are read\n        skip(Long.MAX_VALUE);\n        int inB;\n        if (current.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            inB = inf.getTotalIn();\n        } else {\n            inB = readBytesOfEntry;\n        }\n        int diff = 0;\n\n        // Pushback any required bytes\n        if ((diff = bytesReadFromStream - inB) != 0) {\n            ((PushbackInputStream) in).unread(buf,\n                                              lengthOfLastRead - diff, diff);\n        }\n\n        if (hasDataDescriptor) {\n            readFully(new byte[4 * WORD]);\n        }\n\n        inf.reset();\n        readBytesOfEntry = offsetInBuffer = bytesReadFromStream =\n            lengthOfLastRead = 0;\n        crc.reset();\n        current = null;\n    }\n\n    private void fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if ((lengthOfLastRead = in.read(buf)) > 0) {\n            inf.setInput(buf, 0, lengthOfLastRead);\n        }\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = 0, x = 0;\n        while (count != b.length) {\n            count += x = in.read(b, count, b.length - count);\n            if (x == -1) {\n                throw new EOFException();\n            }\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\n\n/**\n * Implements an input stream that can read Zip archives.\n * <p>\n * Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information\n * is not available from the header.\n * <p>\n * The {@link ZipFile} class is preferred when reading from files.\n *  \n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SHORT = 2;\n    private static final int WORD = 4;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     */\n    private final ZipEncoding zipEncoding;\n\n    /**\n     * Whether to look for and use Unicode extra fields.\n     */\n    private final boolean useUnicodeExtraFields;\n\n    private final InputStream in;\n\n    private final Inflater inf = new Inflater(true);\n    private final CRC32 crc = new CRC32();\n\n    private final byte[] buf = new byte[ZipArchiveOutputStream.BUFFER_SIZE];\n\n    private ZipArchiveEntry current = null;\n    private boolean closed = false;\n    private boolean hitCentralDirectory = false;\n    private int readBytesOfEntry = 0, offsetInBuffer = 0;\n    private int bytesReadFromStream = 0;\n    private int lengthOfLastRead = 0;\n    private boolean hasDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     4 bytes  (0x04034b50)\n      version needed to extract       2 bytes\n      general purpose bit flag        2 bytes\n      compression method              2 bytes\n      last mod file time              2 bytes\n      last mod file date              2 bytes\n      crc-32                          4 bytes\n      compressed size                 4 bytes\n      uncompressed size               4 bytes\n      file name length                2 bytes\n      extra field length              2 bytes\n    */\n\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.length);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n        }\n        byte[] lfh = new byte[LFH_LEN];\n        try {\n            readFully(lfh);\n        } catch (EOFException e) {\n            return null;\n        }\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.CFH_SIG)) {\n            hitCentralDirectory = true;\n            return null;\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new ZipArchiveEntry();\n\n        int versionMadeBy = ZipShort.getValue(lfh, off);\n        off += SHORT;\n        current.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT)\n                            & ZipFile.NIBLET_MASK);\n\n        final int generalPurposeFlag = ZipShort.getValue(lfh, off);\n        final boolean hasEFS = \n            (generalPurposeFlag & ZipArchiveOutputStream.EFS_FLAG) != 0;\n        final ZipEncoding entryEncoding =\n            hasEFS ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        hasDataDescriptor = (generalPurposeFlag & 8) != 0;\n\n        off += SHORT;\n\n        current.setMethod(ZipShort.getValue(lfh, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfh, off));\n        current.setTime(time);\n        off += WORD;\n\n        if (!hasDataDescriptor) {\n            current.setCrc(ZipLong.getValue(lfh, off));\n            off += WORD;\n\n            current.setCompressedSize(ZipLong.getValue(lfh, off));\n            off += WORD;\n\n            current.setSize(ZipLong.getValue(lfh, off));\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(lfh, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(lfh, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.setName(entryEncoding.decode(fileName));\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.setExtra(extraData);\n\n        if (!hasEFS && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current, fileName, null);\n        }\n        return current;\n    }\n\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    public int read(byte[] buffer, int start, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (inf.finished() || current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (start <= buffer.length && length >= 0 && start >= 0\n            && buffer.length - start >= length) {\n            if (current.getMethod() == ZipArchiveOutputStream.STORED) {\n                int csize = (int) current.getSize();\n                if (readBytesOfEntry >= csize) {\n                    return -1;\n                }\n                if (offsetInBuffer >= lengthOfLastRead) {\n                    offsetInBuffer = 0;\n                    if ((lengthOfLastRead = in.read(buf)) == -1) {\n                        return -1;\n                    }\n                    count(lengthOfLastRead);\n                    bytesReadFromStream += lengthOfLastRead;\n                }\n                int toRead = length > lengthOfLastRead\n                    ? lengthOfLastRead - offsetInBuffer\n                    : length;\n                if ((csize - readBytesOfEntry) < toRead) {\n                    toRead = csize - readBytesOfEntry;\n                }\n                System.arraycopy(buf, offsetInBuffer, buffer, start, toRead);\n                offsetInBuffer += toRead;\n                readBytesOfEntry += toRead;\n                crc.update(buffer, start, toRead);\n                return toRead;\n            }\n            if (inf.needsInput()) {\n                fill();\n                if (lengthOfLastRead > 0) {\n                    bytesReadFromStream += lengthOfLastRead;\n                }\n            }\n            int read = 0;\n            try {\n                read = inf.inflate(buffer, start, length);\n            } catch (DataFormatException e) {\n                throw new ZipException(e.getMessage());\n            }\n            if (read == 0) {\n                if (inf.finished()) {\n                    return -1;\n                } else if (lengthOfLastRead == -1) {\n                    throw new IOException(\"Truncated ZIP file\");\n                }\n            }\n            crc.update(buffer, start, read);\n            return read;\n        }\n        throw new ArrayIndexOutOfBoundsException();\n    }\n\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n        }\n    }\n\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            byte[] b = new byte[1024];\n            while (skipped != value) {\n                long rem = value - skipped;\n                int x = read(b, 0, (int) (b.length > rem ? rem : b.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /*\n     *  This test assumes that the zip file does not have any additional leading content,\n     *  which is something that is allowed by the specification (e.g. self-extracting zips)\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG); // empty zip\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected){\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;        \n    }\n\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n        // Ensure all entry bytes are read\n        skip(Long.MAX_VALUE);\n        int inB;\n        if (current.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            inB = inf.getTotalIn();\n        } else {\n            inB = readBytesOfEntry;\n        }\n        int diff = 0;\n\n        // Pushback any required bytes\n        if ((diff = bytesReadFromStream - inB) != 0) {\n            ((PushbackInputStream) in).unread(buf,\n                                              lengthOfLastRead - diff, diff);\n        }\n\n        if (hasDataDescriptor) {\n            readFully(new byte[4 * WORD]);\n        }\n\n        inf.reset();\n        readBytesOfEntry = offsetInBuffer = bytesReadFromStream =\n            lengthOfLastRead = 0;\n        crc.reset();\n        current = null;\n    }\n\n    private void fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if ((lengthOfLastRead = in.read(buf)) > 0) {\n            inf.setInput(buf, 0, lengthOfLastRead);\n        }\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = 0, x = 0;\n        while (count != b.length) {\n            count += x = in.read(b, count, b.length - count);\n            if (x == -1) {\n                throw new EOFException();\n            }\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 6, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveEntry", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry, Cloneable {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap/*<ZipShort, ZipExtraField>*/ extraFields = null;\n    private String name = null;\n\n    /**\n     * Creates a new zip entry with the specified name.\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields());\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.extraFields = extraFields != null ? (LinkedHashMap) extraFields.clone() : null;\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields());\n        return e;\n    }\n\n    /**\n     * Checks whether the compression method of this entry is supported,\n     * i.e. whether the content of this entry can be accessed.\n     *\n     * @since Commons Compress 1.1\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *         >COMPRESS-93</a>\n     * @return <code>true</code> if the compression method is known\n     *         and supported, <code>false</code> otherwise\n     */\n    public boolean isSupportedCompressionMethod() {\n        return method == STORED || method == DEFLATED;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     */\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     */\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap();\n        for (int i = 0; i < fields.length; i++) {\n            extraFields.put(fields[i].getHeaderId(), fields[i]);\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        if (extraFields == null) {\n            return new ZipExtraField[0];\n        }\n        ZipExtraField[] result = new ZipExtraField[extraFields.size()];\n        return (ZipExtraField[]) extraFields.values().toArray(result);\n    }\n\n    /**\n     * Adds an extra fields - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (extraFields == null) {\n            extraFields = new LinkedHashMap();\n        }\n        extraFields.put(ze.getHeaderId(), ze);\n        setExtra();\n    }\n\n    /**\n     * Adds an extra fields - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        LinkedHashMap copy = extraFields;\n        extraFields = new LinkedHashMap();\n        extraFields.put(ze.getHeaderId(), ze);\n        if (copy != null) {\n            copy.remove(ze.getHeaderId());\n            extraFields.putAll(copy);\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra fields.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return (ZipExtraField) extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Throws an Exception if extra data cannot be parsed into extra fields.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local = ExtraFieldUtils.parse(extra, true);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields()));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central = ExtraFieldUtils.parse(b, false);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields());\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        this.name = name;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (int i = 0; i < f.length; i++) {\n                ZipExtraField existing = getExtraField(f[i].getHeaderId());\n                if (existing == null) {\n                    addExtraField(f[i]);\n                } else {\n                    if (local) {\n                        byte[] b = f[i].getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = f[i].getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDocs} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        if (name == null) {\n            if (other.name != null) {\n                return false;\n            }\n        } else if (!name.equals(other.name)) {\n            return false;\n        }\n        return true;\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry, Cloneable {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap/*<ZipShort, ZipExtraField>*/ extraFields = null;\n    private String name = null;\n\n    /**\n     * Creates a new zip entry with the specified name.\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields());\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.extraFields = extraFields != null ? (LinkedHashMap) extraFields.clone() : null;\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields());\n        return e;\n    }\n\n    /**\n     * Checks whether the compression method of this entry is supported,\n     * i.e. whether the content of this entry can be accessed.\n     *\n     * @since Commons Compress 1.1\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *         >COMPRESS-93</a>\n     * @return <code>true</code> if the compression method is known\n     *         and supported, <code>false</code> otherwise\n     */\n    public boolean isSupportedCompressionMethod() {\n        return method == STORED || method == DEFLATED;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     */\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     */\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap();\n        for (int i = 0; i < fields.length; i++) {\n            extraFields.put(fields[i].getHeaderId(), fields[i]);\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        if (extraFields == null) {\n            return new ZipExtraField[0];\n        }\n        ZipExtraField[] result = new ZipExtraField[extraFields.size()];\n        return (ZipExtraField[]) extraFields.values().toArray(result);\n    }\n\n    /**\n     * Adds an extra fields - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (extraFields == null) {\n            extraFields = new LinkedHashMap();\n        }\n        extraFields.put(ze.getHeaderId(), ze);\n        setExtra();\n    }\n\n    /**\n     * Adds an extra fields - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        LinkedHashMap copy = extraFields;\n        extraFields = new LinkedHashMap();\n        extraFields.put(ze.getHeaderId(), ze);\n        if (copy != null) {\n            copy.remove(ze.getHeaderId());\n            extraFields.putAll(copy);\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra fields.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return (ZipExtraField) extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Throws an Exception if extra data cannot be parsed into extra fields.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local = ExtraFieldUtils.parse(extra, true);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields()));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central = ExtraFieldUtils.parse(b, false);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields());\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        this.name = name;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (int i = 0; i < f.length; i++) {\n                ZipExtraField existing = getExtraField(f[i].getHeaderId());\n                if (existing == null) {\n                    addExtraField(f[i]);\n                } else {\n                    if (local) {\n                        byte[] b = f[i].getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = f[i].getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDocs} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        String myName = getName();\n        String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        return true;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 7, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     * Leading spaces are ignored.\n     * Parsing stops when a NUL is found, or a trailing space,\n     * or the buffer length is reached.\n     *\n     * Behaviour with non-octal input is currently undefined.\n     * \n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal string.\n     */\n    public static long parseOctal(byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        boolean stillPadding = true;\n        int     end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            final byte currentByte = buffer[i];\n            if (currentByte == 0) { // Found trailing null\n                break;\n            }\n\n            // Ignore leading spaces ('0' can be ignored anyway)\n            if (currentByte == (byte) ' ' || currentByte == '0') {\n                if (stillPadding) {\n                    continue;\n                }\n\n                if (currentByte == (byte) ' ') { // Found trailing space\n                    break;\n                }\n            }\n\n            stillPadding = false;\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        \"Invalid octal digit at position \"+i+\" in '\"+new String(buffer, offset, length)+\"'\");\n            }\n            result = (result << 3) + (currentByte - '0');// TODO needs to reject invalid bytes\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            if (buffer[i] == 0) {\n                break;\n            }\n            result.append((char) buffer[i]);\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     * Leading spaces are ignored.\n     * Parsing stops when a NUL is found, or a trailing space,\n     * or the buffer length is reached.\n     *\n     * Behaviour with non-octal input is currently undefined.\n     * \n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal string.\n     */\n    public static long parseOctal(byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        boolean stillPadding = true;\n        int     end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            final byte currentByte = buffer[i];\n            if (currentByte == 0) { // Found trailing null\n                break;\n            }\n\n            // Ignore leading spaces ('0' can be ignored anyway)\n            if (currentByte == (byte) ' ' || currentByte == '0') {\n                if (stillPadding) {\n                    continue;\n                }\n\n                if (currentByte == (byte) ' ') { // Found trailing space\n                    break;\n                }\n            }\n\n            stillPadding = false;\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        \"Invalid octal digit at position \"+i+\" in '\"+new String(buffer, offset, length)+\"'\");\n            }\n            result = (result << 3) + (currentByte - '0');// TODO needs to reject invalid bytes\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            byte b = buffer[i];\n            if (b == 0) { // Trailing null\n                break;\n            }\n            result.append((char) (b & 0xFF)); // Allow for sign-extension\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 8, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     * Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.\n     *\n     * The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        boolean stillPadding = true;\n        int     end = offset + length;\n        int     start = offset;\n\n        for (int i = start; i < end; i++){\n            final byte currentByte = buffer[i];\n            if (currentByte == 0) {\n                break;\n            }\n\n        // Skip leading spaces\n            if (currentByte == (byte) ' ' || currentByte == '0') {\n                if (stillPadding) {\n                   continue;\n            }\n                if (currentByte == (byte) ' ') {\n                break;\n                }\n            }\n\n        // Must have trailing NUL or space\n        // May have additional NUL or space\n\n            stillPadding = false;\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length);\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            byte b = buffer[i];\n            if (b == 0) { // Trailing null\n                break;\n            }\n            result.append((char) (b & 0xFF)); // Allow for sign-extension\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     * Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.\n     *\n     * The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        boolean allNUL = true;\n        for (int i = start; i < end; i++){\n            if (buffer[i] != 0){\n                allNUL = false;\n                break;\n            }\n        }\n        if (allNUL) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Must have trailing NUL or space\n        byte trailer;\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        // May have additional NUL or space\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length);\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            byte b = buffer[i];\n            if (b == 0) { // Trailing null\n                break;\n            }\n            result.append((char) (b & 0xFF)); // Allow for sign-extension\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 9, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n    \n    /** indicates if this archive is finished */\n    private boolean finished = false;\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = new CountingOutputStream(os);\n\n        this.buffer = new TarBuffer(out, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n        \n        if(haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        buffer.flushBlock();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n        \n        if (!closed) {\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = ArchiveUtils.toAsciiBytes(entry.getName());\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n        count(numToWrite);\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n    \n    /** indicates if this archive is finished */\n    private boolean finished = false;\n    \n    private final OutputStream out;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        out = new CountingOutputStream(os);\n\n        this.buffer = new TarBuffer(out, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesWritten();\n    }\n\n    @Override\n    public long getBytesWritten() {\n        return ((CountingOutputStream) out).getBytesWritten();\n    }\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n        \n        if(haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        buffer.flushBlock();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n        \n        if (!closed) {\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        if (entry.getName().length() >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                final byte[] nameBytes = ArchiveUtils.toAsciiBytes(entry.getName());\n                longLinkEntry.setSize(nameBytes.length + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(nameBytes);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entry.getName()\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        entry.writeEntryHeader(recordBuf);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entry.getName();\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 10, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipFile", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.EOFException;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.RandomAccessFile;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.Enumeration;\nimport java.util.HashMap;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC_SHORT;\n\n/**\n * Replacement for <code>java.util.ZipFile</code>.\n *\n * <p>This class adds support for file name encodings other than UTF-8\n * (which is required to work on ZIP files created by native zip tools\n * and is able to skip a preamble like the one found in self\n * extracting archives.  Furthermore it returns instances of\n * <code>org.apache.commons.compress.archivers.zip.ZipArchiveEntry</code>\n * instead of <code>java.util.zip.ZipEntry</code>.</p>\n *\n * <p>It doesn't extend <code>java.util.zip.ZipFile</code> as it would\n * have to reimplement all methods anyway.  Like\n * <code>java.util.ZipFile</code>, it uses RandomAccessFile under the\n * covers and supports compressed and uncompressed entries.  As of\n * Apache Commons Compress it also transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The method signatures mimic the ones of\n * <code>java.util.zip.ZipFile</code>, with a couple of exceptions:\n *\n * <ul>\n *   <li>There is no getName method.</li>\n *   <li>entries has been renamed to getEntries.</li>\n *   <li>getEntries and getEntry return\n *   <code>org.apache.commons.compress.archivers.zip.ZipArchiveEntry</code>\n *   instances.</li>\n *   <li>close is allowed to throw IOException.</li>\n * </ul>\n *\n */\npublic class ZipFile {\n    private static final int HASH_SIZE = 509;\n    static final int NIBLET_MASK = 0x0f;\n    static final int BYTE_SHIFT = 8;\n    private static final int POS_0 = 0;\n    private static final int POS_1 = 1;\n    private static final int POS_2 = 2;\n    private static final int POS_3 = 3;\n\n    /**\n     * Maps ZipArchiveEntrys to two longs, recording the offsets of\n     * the local file headers and the start of entry data.\n     */\n    private final Map<ZipArchiveEntry, OffsetEntry> entries =\n        new LinkedHashMap<ZipArchiveEntry, OffsetEntry>(HASH_SIZE);\n\n    /**\n     * Maps String to ZipArchiveEntrys, name -> actual entry.\n     */\n    private final Map<String, ZipArchiveEntry> nameMap =\n        new HashMap<String, ZipArchiveEntry>(HASH_SIZE);\n\n    private static final class OffsetEntry {\n        private long headerOffset = -1;\n        private long dataOffset = -1;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private final String encoding;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     */\n    private final ZipEncoding zipEncoding;\n\n    /**\n     * File name of actual source.\n     */\n    private final String archiveName;\n\n    /**\n     * The actual data source.\n     */\n    private final RandomAccessFile archive;\n\n    /**\n     * Whether to look for and use Unicode extra fields.\n     */\n    private final boolean useUnicodeExtraFields;\n\n    /**\n     * Whether the file is closed.\n     */\n    private boolean closed;\n\n    /**\n     * Opens the given file for reading, assuming \"UTF8\" for file names.\n     *\n     * @param f the archive.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f) throws IOException {\n        this(f, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Opens the given file for reading, assuming \"UTF8\".\n     *\n     * @param name name of the archive.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(String name) throws IOException {\n        this(new File(name), ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names, scanning unicode extra fields.\n     *\n     * @param name name of the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(String name, String encoding) throws IOException {\n        this(new File(name), encoding, true);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names and scanning for unicode extra fields.\n     *\n     * @param f the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f, String encoding) throws IOException {\n        this(f, encoding, true);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names.\n     *\n     * @param f the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f, String encoding, boolean useUnicodeExtraFields)\n        throws IOException {\n        this.archiveName = f.getAbsolutePath();\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        archive = new RandomAccessFile(f, \"r\");\n        boolean success = false;\n        try {\n            Map<ZipArchiveEntry, NameAndComment> entriesWithoutUTF8Flag =\n                populateFromCentralDirectory();\n            resolveLocalFileHeaderData(entriesWithoutUTF8Flag);\n            success = true;\n        } finally {\n            if (!success) {\n                try {\n                    closed = true;\n                    archive.close();\n                } catch (IOException e2) { // NOPMD\n                    // swallow, throw the original exception instead\n                }\n            }\n        }\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Closes the archive.\n     * @throws IOException if an error occurs closing the archive.\n     */\n    public void close() throws IOException {\n        // this flag is only written here and read in finalize() which\n        // can never be run in parallel.\n        // no synchronization needed.\n        closed = true;\n\n        archive.close();\n    }\n\n    /**\n     * close a zipfile quietly; throw no io fault, do nothing\n     * on a null parameter\n     * @param zipfile file to close, can be null\n     */\n    public static void closeQuietly(ZipFile zipfile) {\n        if (zipfile != null) {\n            try {\n                zipfile.close();\n            } catch (IOException e) { // NOPMD\n                //ignore, that's why the method is called \"quietly\"\n            }\n        }\n    }\n\n    /**\n     * Returns all entries.\n     *\n     * <p>Entries will be returned in the same order they appear\n     * within the archive's central directory.</p>\n     *\n     * @return all entries as {@link ZipArchiveEntry} instances\n     */\n    public Enumeration<ZipArchiveEntry> getEntries() {\n        return Collections.enumeration(entries.keySet());\n    }\n\n    /**\n     * Returns all entries in physical order.\n     *\n     * <p>Entries will be returned in the same order their contents\n     * appear within the archive.</p>\n     *\n     * @return all entries as {@link ZipArchiveEntry} instances\n     *\n     * @since Commons Compress 1.1\n     */\n    public Enumeration<ZipArchiveEntry> getEntriesInPhysicalOrder() {\n        ZipArchiveEntry[] allEntries =\n            entries.keySet().toArray(new ZipArchiveEntry[0]);\n        Arrays.sort(allEntries, OFFSET_COMPARATOR);\n        return Collections.enumeration(Arrays.asList(allEntries));\n    }\n\n    /**\n     * Returns a named entry - or <code>null</code> if no entry by\n     * that name exists.\n     * @param name name of the entry.\n     * @return the ZipArchiveEntry corresponding to the given name - or\n     * <code>null</code> if not present.\n     */\n    public ZipArchiveEntry getEntry(String name) {\n        return nameMap.get(name);\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since Apache Commons Compress 1.1\n     */\n    public boolean canReadEntryData(ZipArchiveEntry ze) {\n        return ZipUtil.canHandleEntryData(ze);\n    }\n\n    /**\n     * Returns an InputStream for reading the contents of the given entry.\n     *\n     * @param ze the entry to get the stream for.\n     * @return a stream to read the entry from.\n     * @throws IOException if unable to create an input stream from the zipenty\n     * @throws ZipException if the zipentry uses an unsupported feature\n     */\n    public InputStream getInputStream(ZipArchiveEntry ze)\n        throws IOException, ZipException {\n        OffsetEntry offsetEntry = entries.get(ze);\n        if (offsetEntry == null) {\n            return null;\n        }\n        ZipUtil.checkRequestedFeatures(ze);\n        long start = offsetEntry.dataOffset;\n        BoundedInputStream bis =\n            new BoundedInputStream(start, ze.getCompressedSize());\n        switch (ze.getMethod()) {\n            case ZipArchiveEntry.STORED:\n                return bis;\n            case ZipArchiveEntry.DEFLATED:\n                bis.addDummy();\n                final Inflater inflater = new Inflater(true);\n                return new InflaterInputStream(bis, inflater) {\n                    @Override\n                    public void close() throws IOException {\n                        super.close();\n                        inflater.end();\n                    }\n                };\n            default:\n                throw new ZipException(\"Found unsupported compression method \"\n                                       + ze.getMethod());\n        }\n    }\n\n    /**\n     * Ensures that the close method of this zipfile is called when\n     * there are no more references to it.\n     * @see #close()\n     */\n    @Override\n    protected void finalize() throws Throwable {\n        try {\n            if (!closed) {\n                System.err.println(\"Cleaning up unclosed ZipFile for archive \"\n                                   + archiveName);\n                close();\n            }\n        } finally {\n            super.finalize();\n        }\n    }\n\n    /**\n     * Length of a \"central directory\" entry structure without file\n     * name, extra fields or comment.\n     */\n    private static final int CFH_LEN =\n        /* version made by                 */ SHORT\n        /* version needed to extract       */ + SHORT\n        /* general purpose bit flag        */ + SHORT\n        /* compression method              */ + SHORT\n        /* last mod file time              */ + SHORT\n        /* last mod file date              */ + SHORT\n        /* crc-32                          */ + WORD\n        /* compressed size                 */ + WORD\n        /* uncompressed size               */ + WORD\n        /* filename length                 */ + SHORT\n        /* extra field length              */ + SHORT\n        /* file comment length             */ + SHORT\n        /* disk number start               */ + SHORT\n        /* internal file attributes        */ + SHORT\n        /* external file attributes        */ + WORD\n        /* relative offset of local header */ + WORD;\n\n    private static final long CFH_SIG =\n        ZipLong.getValue(ZipArchiveOutputStream.CFH_SIG);\n\n    /**\n     * Reads the central directory of the given archive and populates\n     * the internal tables with ZipArchiveEntry instances.\n     *\n     * <p>The ZipArchiveEntrys will know all data that can be obtained from\n     * the central directory alone, but not the data that requires the\n     * local file header or additional data to be read.</p>\n     *\n     * @return a map of zipentries that didn't have the language\n     * encoding flag set when read.\n     */\n    private Map<ZipArchiveEntry, NameAndComment> populateFromCentralDirectory()\n        throws IOException {\n        HashMap<ZipArchiveEntry, NameAndComment> noUTF8Flag =\n            new HashMap<ZipArchiveEntry, NameAndComment>();\n\n        positionAtCentralDirectory();\n\n        byte[] signatureBytes = new byte[WORD];\n        archive.readFully(signatureBytes);\n        long sig = ZipLong.getValue(signatureBytes);\n\n        if (sig != CFH_SIG && startsWithLocalFileHeader()) {\n            throw new IOException(\"central directory is empty, can't expand\"\n                                  + \" corrupt archive.\");\n        }\n\n        while (sig == CFH_SIG) {\n            readCentralDirectoryEntry(noUTF8Flag);\n            archive.readFully(signatureBytes);\n            sig = ZipLong.getValue(signatureBytes);\n        }\n        return noUTF8Flag;\n    }\n\n    /**\n     * Reads an individual entry of the central directory, creats an\n     * ZipArchiveEntry from it and adds it to the global maps.\n     *\n     * @param noUTF8Flag map used to collect entries that don't have\n     * their UTF-8 flag set and whose name will be set by data read\n     * from the local file header later.  The current entry may be\n     * added to this map.\n     */\n    private void\n        readCentralDirectoryEntry(Map<ZipArchiveEntry, NameAndComment> noUTF8Flag)\n        throws IOException {\n        byte[] cfh = new byte[CFH_LEN];\n\n        archive.readFully(cfh);\n        int off = 0;\n        ZipArchiveEntry ze = new ZipArchiveEntry();\n\n        int versionMadeBy = ZipShort.getValue(cfh, off);\n        off += SHORT;\n        ze.setPlatform((versionMadeBy >> BYTE_SHIFT) & NIBLET_MASK);\n\n        off += SHORT; // skip version info\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(cfh, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding =\n            hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        ze.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        ze.setMethod(ZipShort.getValue(cfh, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(cfh, off));\n        ze.setTime(time);\n        off += WORD;\n\n        ze.setCrc(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        ze.setCompressedSize(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        ze.setSize(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        int fileNameLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int commentLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int diskStart = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        ze.setInternalAttributes(ZipShort.getValue(cfh, off));\n        off += SHORT;\n\n        ze.setExternalAttributes(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        byte[] fileName = new byte[fileNameLen];\n        archive.readFully(fileName);\n        ze.setName(entryEncoding.decode(fileName), fileName);\n\n        // LFH offset,\n        OffsetEntry offset = new OffsetEntry();\n        offset.headerOffset = ZipLong.getValue(cfh, off);\n        // data offset will be filled later\n        entries.put(ze, offset);\n\n        nameMap.put(ze.getName(), ze);\n\n        byte[] cdExtraData = new byte[extraLen];\n        archive.readFully(cdExtraData);\n        ze.setCentralDirectoryExtra(cdExtraData);\n\n        setSizesAndOffsetFromZip64Extra(ze, offset, diskStart);\n\n        byte[] comment = new byte[commentLen];\n        archive.readFully(comment);\n        ze.setComment(entryEncoding.decode(comment));\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            noUTF8Flag.put(ze, new NameAndComment(fileName, comment));\n        }\n    }\n\n    /**\n     * If the entry holds a Zip64 extended information extra field,\n     * read sizes from there if the entry's sizes are set to\n     * 0xFFFFFFFFF, do the same for the offset of the local file\n     * header.\n     *\n     * <p>Ensures the Zip64 extra either knows both compressed and\n     * uncompressed size or neither of both as the internal logic in\n     * ExtraFieldUtils forces the field to create local header data\n     * even if they are never used - and here a field with only one\n     * size would be invalid.</p>\n     */\n    private void setSizesAndOffsetFromZip64Extra(ZipArchiveEntry ze,\n                                                 OffsetEntry offset,\n                                                 int diskStart)\n        throws IOException {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            ze.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        if (z64 != null) {\n            boolean hasUncompressedSize = ze.getSize() == ZIP64_MAGIC;\n            boolean hasCompressedSize = ze.getCompressedSize() == ZIP64_MAGIC;\n            boolean hasRelativeHeaderOffset =\n                offset.headerOffset == ZIP64_MAGIC;\n            z64.reparseCentralDirectoryData(hasUncompressedSize,\n                                            hasCompressedSize,\n                                            hasRelativeHeaderOffset,\n                                            diskStart == ZIP64_MAGIC_SHORT);\n\n            if (hasUncompressedSize) {\n                ze.setSize(z64.getSize().getLongValue());\n            } else if (hasCompressedSize) {\n                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n            }\n\n            if (hasCompressedSize) {\n                ze.setCompressedSize(z64.getCompressedSize().getLongValue());\n            } else if (hasUncompressedSize) {\n                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n            }\n\n            if (hasRelativeHeaderOffset) {\n                offset.headerOffset =\n                    z64.getRelativeHeaderOffset().getLongValue();\n            }\n        }\n    }\n\n    /**\n     * Length of the \"End of central directory record\" - which is\n     * supposed to be the last structure of the archive - without file\n     * comment.\n     */\n    private static final int MIN_EOCD_SIZE =\n        /* end of central dir signature    */ WORD\n        /* number of this disk             */ + SHORT\n        /* number of the disk with the     */\n        /* start of the central directory  */ + SHORT\n        /* total number of entries in      */\n        /* the central dir on this disk    */ + SHORT\n        /* total number of entries in      */\n        /* the central dir                 */ + SHORT\n        /* size of the central directory   */ + WORD\n        /* offset of start of central      */\n        /* directory with respect to       */\n        /* the starting disk number        */ + WORD\n        /* zipfile comment length          */ + SHORT;\n\n    /**\n     * Maximum length of the \"End of central directory record\" with a\n     * file comment.\n     */\n    private static final int MAX_EOCD_SIZE = MIN_EOCD_SIZE\n        /* maximum length of zipfile comment */ + ZIP64_MAGIC_SHORT;\n\n    /**\n     * Offset of the field that holds the location of the first\n     * central directory entry inside the \"End of central directory\n     * record\" relative to the start of the \"End of central directory\n     * record\".\n     */\n    private static final int CFD_LOCATOR_OFFSET =\n        /* end of central dir signature    */ WORD\n        /* number of this disk             */ + SHORT\n        /* number of the disk with the     */\n        /* start of the central directory  */ + SHORT\n        /* total number of entries in      */\n        /* the central dir on this disk    */ + SHORT\n        /* total number of entries in      */\n        /* the central dir                 */ + SHORT\n        /* size of the central directory   */ + WORD;\n\n    /**\n     * Length of the \"Zip64 end of central directory locator\" - which\n     * should be right in front of the \"end of central directory\n     * record\" if one is present at all.\n     */\n    private static final int ZIP64_EOCDL_LENGTH =\n        /* zip64 end of central dir locator sig */ WORD\n        /* number of the disk with the start    */\n        /* start of the zip64 end of            */\n        /* central directory                    */ + WORD\n        /* relative offset of the zip64         */\n        /* end of central directory record      */ + DWORD\n        /* total number of disks                */ + WORD;\n\n    /**\n     * Offset of the field that holds the location of the \"Zip64 end\n     * of central directory record\" inside the \"Zip64 end of central\n     * directory locator\" relative to the start of the \"Zip64 end of\n     * central directory locator\".\n     */\n    private static final int ZIP64_EOCDL_LOCATOR_OFFSET =\n        /* zip64 end of central dir locator sig */ WORD\n        /* number of the disk with the start    */\n        /* start of the zip64 end of            */\n        /* central directory                    */ + WORD;\n\n    /**\n     * Offset of the field that holds the location of the first\n     * central directory entry inside the \"Zip64 end of central\n     * directory record\" relative to the start of the \"Zip64 end of\n     * central directory record\".\n     */\n    private static final int ZIP64_EOCD_CFD_LOCATOR_OFFSET =\n        /* zip64 end of central dir        */\n        /* signature                       */ WORD\n        /* size of zip64 end of central    */\n        /* directory record                */ + DWORD\n        /* version made by                 */ + SHORT\n        /* version needed to extract       */ + SHORT\n        /* number of this disk             */ + WORD\n        /* number of the disk with the     */\n        /* start of the central directory  */ + WORD\n        /* total number of entries in the  */\n        /* central directory on this disk  */ + DWORD\n        /* total number of entries in the  */\n        /* central directory               */ + DWORD\n        /* size of the central directory   */ + DWORD;\n\n    /**\n     * Searches for either the &quot;Zip64 end of central directory\n     * locator&quot; or the &quot;End of central dir record&quot;, parses\n     * it and positions the stream at the first central directory\n     * record.\n     */\n    private void positionAtCentralDirectory()\n        throws IOException {\n        boolean found = tryToLocateSignature(MIN_EOCD_SIZE + ZIP64_EOCDL_LENGTH,\n                                             MAX_EOCD_SIZE + ZIP64_EOCDL_LENGTH,\n                                             ZipArchiveOutputStream\n                                             .ZIP64_EOCD_LOC_SIG);\n        if (!found) {\n            // not a ZIP64 archive\n            positionAtCentralDirectory32();\n        } else {\n            positionAtCentralDirectory64();\n        }\n    }\n\n    /**\n     * Parses the &quot;Zip64 end of central directory locator&quot;,\n     * finds the &quot;Zip64 end of central directory record&quot; using the\n     * parsed information, parses that and positions the stream at the\n     * first central directory record.\n     */\n    private void positionAtCentralDirectory64()\n        throws IOException {\n        skipBytes(ZIP64_EOCDL_LOCATOR_OFFSET);\n        byte[] zip64EocdOffset = new byte[DWORD];\n        archive.readFully(zip64EocdOffset);\n        archive.seek(ZipEightByteInteger.getLongValue(zip64EocdOffset));\n        byte[] sig = new byte[WORD];\n        archive.readFully(sig);\n        if (sig[POS_0] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_0]\n            || sig[POS_1] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_1]\n            || sig[POS_2] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_2]\n            || sig[POS_3] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_3]\n            ) {\n            throw new ZipException(\"archive's ZIP64 end of central \"\n                                   + \"directory locator is corrupt.\");\n        }\n        skipBytes(ZIP64_EOCD_CFD_LOCATOR_OFFSET\n                  - WORD /* signature has already been read */);\n        byte[] cfdOffset = new byte[DWORD];\n        archive.readFully(cfdOffset);\n        archive.seek(ZipEightByteInteger.getLongValue(cfdOffset));\n    }\n\n    /**\n     * Searches for the &quot;End of central dir record&quot;, parses\n     * it and positions the stream at the first central directory\n     * record.\n     */\n    private void positionAtCentralDirectory32()\n        throws IOException {\n        boolean found = tryToLocateSignature(MIN_EOCD_SIZE, MAX_EOCD_SIZE,\n                                             ZipArchiveOutputStream.EOCD_SIG);\n        if (!found) {\n            throw new ZipException(\"archive is not a ZIP archive\");\n        }\n        skipBytes(CFD_LOCATOR_OFFSET);\n        byte[] cfdOffset = new byte[WORD];\n        archive.readFully(cfdOffset);\n        archive.seek(ZipLong.getValue(cfdOffset));\n    }\n\n    /**\n     * Searches the archive backwards from minDistance to maxDistance\n     * for the given signature, positions the RandomaccessFile right\n     * at the signature if it has been found.\n     */\n    private boolean tryToLocateSignature(long minDistanceFromEnd,\n                                         long maxDistanceFromEnd,\n                                         byte[] sig) throws IOException {\n        boolean found = false;\n        long off = archive.length() - minDistanceFromEnd;\n        final long stopSearching =\n            Math.max(0L, archive.length() - maxDistanceFromEnd);\n        if (off >= 0) {\n            for (; off >= stopSearching; off--) {\n                archive.seek(off);\n                int curr = archive.read();\n                if (curr == -1) {\n                    break;\n                }\n                if (curr == sig[POS_0]) {\n                    curr = archive.read();\n                    if (curr == sig[POS_1]) {\n                        curr = archive.read();\n                        if (curr == sig[POS_2]) {\n                            curr = archive.read();\n                            if (curr == sig[POS_3]) {\n                                found = true;\n                                break;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        if (found) {\n            archive.seek(off);\n        }\n        return found;\n    }\n\n    /**\n     * Skips the given number of bytes or throws an EOFException if\n     * skipping failed.\n     */ \n    private void skipBytes(final int count) throws IOException {\n        int totalSkipped = 0;\n        while (totalSkipped < count) {\n            int skippedNow = archive.skipBytes(count - totalSkipped);\n            if (skippedNow <= 0) {\n                throw new EOFException();\n            }\n            totalSkipped += skippedNow;\n        }\n    }\n\n    /**\n     * Number of bytes in local file header up to the &quot;length of\n     * filename&quot; entry.\n     */\n    private static final long LFH_OFFSET_FOR_FILENAME_LENGTH =\n        /* local file header signature     */ WORD\n        /* version needed to extract       */ + SHORT\n        /* general purpose bit flag        */ + SHORT\n        /* compression method              */ + SHORT\n        /* last mod file time              */ + SHORT\n        /* last mod file date              */ + SHORT\n        /* crc-32                          */ + WORD\n        /* compressed size                 */ + WORD\n        /* uncompressed size               */ + WORD;\n\n    /**\n     * Walks through all recorded entries and adds the data available\n     * from the local file header.\n     *\n     * <p>Also records the offsets for the data to read from the\n     * entries.</p>\n     */\n    private void resolveLocalFileHeaderData(Map<ZipArchiveEntry, NameAndComment>\n                                            entriesWithoutUTF8Flag)\n        throws IOException {\n        // changing the name of a ZipArchiveEntry is going to change\n        // the hashcode - see COMPRESS-164\n        // Map needs to be reconstructed in order to keep central\n        // directory order\n        for (ZipArchiveEntry ze : entries.keySet()) {\n            OffsetEntry offsetEntry = entries.get(ze);\n            long offset = offsetEntry.headerOffset;\n            archive.seek(offset + LFH_OFFSET_FOR_FILENAME_LENGTH);\n            byte[] b = new byte[SHORT];\n            archive.readFully(b);\n            int fileNameLen = ZipShort.getValue(b);\n            archive.readFully(b);\n            int extraFieldLen = ZipShort.getValue(b);\n            int lenToSkip = fileNameLen;\n            while (lenToSkip > 0) {\n                int skipped = archive.skipBytes(lenToSkip);\n                if (skipped <= 0) {\n                    throw new RuntimeException(\"failed to skip file name in\"\n                                               + \" local file header\");\n                }\n                lenToSkip -= skipped;\n            }\n            byte[] localExtraData = new byte[extraFieldLen];\n            archive.readFully(localExtraData);\n            ze.setExtra(localExtraData);\n            offsetEntry.dataOffset = offset + LFH_OFFSET_FOR_FILENAME_LENGTH\n                + SHORT + SHORT + fileNameLen + extraFieldLen;\n\n            if (entriesWithoutUTF8Flag.containsKey(ze)) {\n                String orig = ze.getName();\n                NameAndComment nc = entriesWithoutUTF8Flag.get(ze);\n                ZipUtil.setNameAndCommentFromExtraFields(ze, nc.name,\n                                                         nc.comment);\n                if (!orig.equals(ze.getName())) {\n                    nameMap.remove(orig);\n                    nameMap.put(ze.getName(), ze);\n                }\n            }\n        }\n    }\n\n    /**\n     * Checks whether the archive starts with a LFH.  If it doesn't,\n     * it may be an empty archive.\n     */\n    private boolean startsWithLocalFileHeader() throws IOException {\n        archive.seek(0);\n        final byte[] start = new byte[WORD];\n        archive.readFully(start);\n        for (int i = 0; i < start.length; i++) {\n            if (start[i] != ZipArchiveOutputStream.LFH_SIG[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * InputStream that delegates requests to the underlying\n     * RandomAccessFile, making sure that only bytes from a certain\n     * range can be read.\n     */\n    private class BoundedInputStream extends InputStream {\n        private long remaining;\n        private long loc;\n        private boolean addDummyByte = false;\n\n        BoundedInputStream(long start, long remaining) {\n            this.remaining = remaining;\n            loc = start;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (remaining-- <= 0) {\n                if (addDummyByte) {\n                    addDummyByte = false;\n                    return 0;\n                }\n                return -1;\n            }\n            synchronized (archive) {\n                archive.seek(loc++);\n                return archive.read();\n            }\n        }\n\n        @Override\n        public int read(byte[] b, int off, int len) throws IOException {\n            if (remaining <= 0) {\n                if (addDummyByte) {\n                    addDummyByte = false;\n                    b[off] = 0;\n                    return 1;\n                }\n                return -1;\n            }\n\n            if (len <= 0) {\n                return 0;\n            }\n\n            if (len > remaining) {\n                len = (int) remaining;\n            }\n            int ret = -1;\n            synchronized (archive) {\n                archive.seek(loc);\n                ret = archive.read(b, off, len);\n            }\n            if (ret > 0) {\n                loc += ret;\n                remaining -= ret;\n            }\n            return ret;\n        }\n\n        /**\n         * Inflater needs an extra dummy byte for nowrap - see\n         * Inflater's javadocs.\n         */\n        void addDummy() {\n            addDummyByte = true;\n        }\n    }\n\n    private static final class NameAndComment {\n        private final byte[] name;\n        private final byte[] comment;\n        private NameAndComment(byte[] name, byte[] comment) {\n            this.name = name;\n            this.comment = comment;\n        }\n    }\n\n    /**\n     * Compares two ZipArchiveEntries based on their offset within the archive.\n     *\n     * <p>Won't return any meaningful results if one of the entries\n     * isn't part of the archive at all.</p>\n     *\n     * @since Commons Compress 1.1\n     */\n    private final Comparator<ZipArchiveEntry> OFFSET_COMPARATOR =\n        new Comparator<ZipArchiveEntry>() {\n        public int compare(ZipArchiveEntry e1, ZipArchiveEntry e2) {\n            if (e1 == e2)\n                return 0;\n\n            OffsetEntry off1 = entries.get(e1);\n            OffsetEntry off2 = entries.get(e2);\n            if (off1 == null) {\n                return 1;\n            }\n            if (off2 == null) {\n                return -1;\n            }\n            long val = (off1.headerOffset - off2.headerOffset);\n            return val == 0 ? 0 : val < 0 ? -1 : +1;\n        }\n    };\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.EOFException;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.RandomAccessFile;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.Enumeration;\nimport java.util.HashMap;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC_SHORT;\n\n/**\n * Replacement for <code>java.util.ZipFile</code>.\n *\n * <p>This class adds support for file name encodings other than UTF-8\n * (which is required to work on ZIP files created by native zip tools\n * and is able to skip a preamble like the one found in self\n * extracting archives.  Furthermore it returns instances of\n * <code>org.apache.commons.compress.archivers.zip.ZipArchiveEntry</code>\n * instead of <code>java.util.zip.ZipEntry</code>.</p>\n *\n * <p>It doesn't extend <code>java.util.zip.ZipFile</code> as it would\n * have to reimplement all methods anyway.  Like\n * <code>java.util.ZipFile</code>, it uses RandomAccessFile under the\n * covers and supports compressed and uncompressed entries.  As of\n * Apache Commons Compress it also transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The method signatures mimic the ones of\n * <code>java.util.zip.ZipFile</code>, with a couple of exceptions:\n *\n * <ul>\n *   <li>There is no getName method.</li>\n *   <li>entries has been renamed to getEntries.</li>\n *   <li>getEntries and getEntry return\n *   <code>org.apache.commons.compress.archivers.zip.ZipArchiveEntry</code>\n *   instances.</li>\n *   <li>close is allowed to throw IOException.</li>\n * </ul>\n *\n */\npublic class ZipFile {\n    private static final int HASH_SIZE = 509;\n    static final int NIBLET_MASK = 0x0f;\n    static final int BYTE_SHIFT = 8;\n    private static final int POS_0 = 0;\n    private static final int POS_1 = 1;\n    private static final int POS_2 = 2;\n    private static final int POS_3 = 3;\n\n    /**\n     * Maps ZipArchiveEntrys to two longs, recording the offsets of\n     * the local file headers and the start of entry data.\n     */\n    private final Map<ZipArchiveEntry, OffsetEntry> entries =\n        new LinkedHashMap<ZipArchiveEntry, OffsetEntry>(HASH_SIZE);\n\n    /**\n     * Maps String to ZipArchiveEntrys, name -> actual entry.\n     */\n    private final Map<String, ZipArchiveEntry> nameMap =\n        new HashMap<String, ZipArchiveEntry>(HASH_SIZE);\n\n    private static final class OffsetEntry {\n        private long headerOffset = -1;\n        private long dataOffset = -1;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private final String encoding;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     */\n    private final ZipEncoding zipEncoding;\n\n    /**\n     * File name of actual source.\n     */\n    private final String archiveName;\n\n    /**\n     * The actual data source.\n     */\n    private final RandomAccessFile archive;\n\n    /**\n     * Whether to look for and use Unicode extra fields.\n     */\n    private final boolean useUnicodeExtraFields;\n\n    /**\n     * Whether the file is closed.\n     */\n    private boolean closed;\n\n    /**\n     * Opens the given file for reading, assuming \"UTF8\" for file names.\n     *\n     * @param f the archive.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f) throws IOException {\n        this(f, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Opens the given file for reading, assuming \"UTF8\".\n     *\n     * @param name name of the archive.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(String name) throws IOException {\n        this(new File(name), ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names, scanning unicode extra fields.\n     *\n     * @param name name of the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(String name, String encoding) throws IOException {\n        this(new File(name), encoding, true);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names and scanning for unicode extra fields.\n     *\n     * @param f the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f, String encoding) throws IOException {\n        this(f, encoding, true);\n    }\n\n    /**\n     * Opens the given file for reading, assuming the specified\n     * encoding for file names.\n     *\n     * @param f the archive.\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     *\n     * @throws IOException if an error occurs while reading the file.\n     */\n    public ZipFile(File f, String encoding, boolean useUnicodeExtraFields)\n        throws IOException {\n        this.archiveName = f.getAbsolutePath();\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        archive = new RandomAccessFile(f, \"r\");\n        boolean success = false;\n        try {\n            Map<ZipArchiveEntry, NameAndComment> entriesWithoutUTF8Flag =\n                populateFromCentralDirectory();\n            resolveLocalFileHeaderData(entriesWithoutUTF8Flag);\n            success = true;\n        } finally {\n            if (!success) {\n                try {\n                    closed = true;\n                    archive.close();\n                } catch (IOException e2) { // NOPMD\n                    // swallow, throw the original exception instead\n                }\n            }\n        }\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Closes the archive.\n     * @throws IOException if an error occurs closing the archive.\n     */\n    public void close() throws IOException {\n        // this flag is only written here and read in finalize() which\n        // can never be run in parallel.\n        // no synchronization needed.\n        closed = true;\n\n        archive.close();\n    }\n\n    /**\n     * close a zipfile quietly; throw no io fault, do nothing\n     * on a null parameter\n     * @param zipfile file to close, can be null\n     */\n    public static void closeQuietly(ZipFile zipfile) {\n        if (zipfile != null) {\n            try {\n                zipfile.close();\n            } catch (IOException e) { // NOPMD\n                //ignore, that's why the method is called \"quietly\"\n            }\n        }\n    }\n\n    /**\n     * Returns all entries.\n     *\n     * <p>Entries will be returned in the same order they appear\n     * within the archive's central directory.</p>\n     *\n     * @return all entries as {@link ZipArchiveEntry} instances\n     */\n    public Enumeration<ZipArchiveEntry> getEntries() {\n        return Collections.enumeration(entries.keySet());\n    }\n\n    /**\n     * Returns all entries in physical order.\n     *\n     * <p>Entries will be returned in the same order their contents\n     * appear within the archive.</p>\n     *\n     * @return all entries as {@link ZipArchiveEntry} instances\n     *\n     * @since Commons Compress 1.1\n     */\n    public Enumeration<ZipArchiveEntry> getEntriesInPhysicalOrder() {\n        ZipArchiveEntry[] allEntries =\n            entries.keySet().toArray(new ZipArchiveEntry[0]);\n        Arrays.sort(allEntries, OFFSET_COMPARATOR);\n        return Collections.enumeration(Arrays.asList(allEntries));\n    }\n\n    /**\n     * Returns a named entry - or <code>null</code> if no entry by\n     * that name exists.\n     * @param name name of the entry.\n     * @return the ZipArchiveEntry corresponding to the given name - or\n     * <code>null</code> if not present.\n     */\n    public ZipArchiveEntry getEntry(String name) {\n        return nameMap.get(name);\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since Apache Commons Compress 1.1\n     */\n    public boolean canReadEntryData(ZipArchiveEntry ze) {\n        return ZipUtil.canHandleEntryData(ze);\n    }\n\n    /**\n     * Returns an InputStream for reading the contents of the given entry.\n     *\n     * @param ze the entry to get the stream for.\n     * @return a stream to read the entry from.\n     * @throws IOException if unable to create an input stream from the zipenty\n     * @throws ZipException if the zipentry uses an unsupported feature\n     */\n    public InputStream getInputStream(ZipArchiveEntry ze)\n        throws IOException, ZipException {\n        OffsetEntry offsetEntry = entries.get(ze);\n        if (offsetEntry == null) {\n            return null;\n        }\n        ZipUtil.checkRequestedFeatures(ze);\n        long start = offsetEntry.dataOffset;\n        BoundedInputStream bis =\n            new BoundedInputStream(start, ze.getCompressedSize());\n        switch (ze.getMethod()) {\n            case ZipArchiveEntry.STORED:\n                return bis;\n            case ZipArchiveEntry.DEFLATED:\n                bis.addDummy();\n                final Inflater inflater = new Inflater(true);\n                return new InflaterInputStream(bis, inflater) {\n                    @Override\n                    public void close() throws IOException {\n                        super.close();\n                        inflater.end();\n                    }\n                };\n            default:\n                throw new ZipException(\"Found unsupported compression method \"\n                                       + ze.getMethod());\n        }\n    }\n\n    /**\n     * Ensures that the close method of this zipfile is called when\n     * there are no more references to it.\n     * @see #close()\n     */\n    @Override\n    protected void finalize() throws Throwable {\n        try {\n            if (!closed) {\n                System.err.println(\"Cleaning up unclosed ZipFile for archive \"\n                                   + archiveName);\n                close();\n            }\n        } finally {\n            super.finalize();\n        }\n    }\n\n    /**\n     * Length of a \"central directory\" entry structure without file\n     * name, extra fields or comment.\n     */\n    private static final int CFH_LEN =\n        /* version made by                 */ SHORT\n        /* version needed to extract       */ + SHORT\n        /* general purpose bit flag        */ + SHORT\n        /* compression method              */ + SHORT\n        /* last mod file time              */ + SHORT\n        /* last mod file date              */ + SHORT\n        /* crc-32                          */ + WORD\n        /* compressed size                 */ + WORD\n        /* uncompressed size               */ + WORD\n        /* filename length                 */ + SHORT\n        /* extra field length              */ + SHORT\n        /* file comment length             */ + SHORT\n        /* disk number start               */ + SHORT\n        /* internal file attributes        */ + SHORT\n        /* external file attributes        */ + WORD\n        /* relative offset of local header */ + WORD;\n\n    private static final long CFH_SIG =\n        ZipLong.getValue(ZipArchiveOutputStream.CFH_SIG);\n\n    /**\n     * Reads the central directory of the given archive and populates\n     * the internal tables with ZipArchiveEntry instances.\n     *\n     * <p>The ZipArchiveEntrys will know all data that can be obtained from\n     * the central directory alone, but not the data that requires the\n     * local file header or additional data to be read.</p>\n     *\n     * @return a map of zipentries that didn't have the language\n     * encoding flag set when read.\n     */\n    private Map<ZipArchiveEntry, NameAndComment> populateFromCentralDirectory()\n        throws IOException {\n        HashMap<ZipArchiveEntry, NameAndComment> noUTF8Flag =\n            new HashMap<ZipArchiveEntry, NameAndComment>();\n\n        positionAtCentralDirectory();\n\n        byte[] signatureBytes = new byte[WORD];\n        archive.readFully(signatureBytes);\n        long sig = ZipLong.getValue(signatureBytes);\n\n        if (sig != CFH_SIG && startsWithLocalFileHeader()) {\n            throw new IOException(\"central directory is empty, can't expand\"\n                                  + \" corrupt archive.\");\n        }\n\n        while (sig == CFH_SIG) {\n            readCentralDirectoryEntry(noUTF8Flag);\n            archive.readFully(signatureBytes);\n            sig = ZipLong.getValue(signatureBytes);\n        }\n        return noUTF8Flag;\n    }\n\n    /**\n     * Reads an individual entry of the central directory, creats an\n     * ZipArchiveEntry from it and adds it to the global maps.\n     *\n     * @param noUTF8Flag map used to collect entries that don't have\n     * their UTF-8 flag set and whose name will be set by data read\n     * from the local file header later.  The current entry may be\n     * added to this map.\n     */\n    private void\n        readCentralDirectoryEntry(Map<ZipArchiveEntry, NameAndComment> noUTF8Flag)\n        throws IOException {\n        byte[] cfh = new byte[CFH_LEN];\n\n        archive.readFully(cfh);\n        int off = 0;\n        ZipArchiveEntry ze = new ZipArchiveEntry();\n\n        int versionMadeBy = ZipShort.getValue(cfh, off);\n        off += SHORT;\n        ze.setPlatform((versionMadeBy >> BYTE_SHIFT) & NIBLET_MASK);\n\n        off += SHORT; // skip version info\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(cfh, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding =\n            hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        ze.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        ze.setMethod(ZipShort.getValue(cfh, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(cfh, off));\n        ze.setTime(time);\n        off += WORD;\n\n        ze.setCrc(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        ze.setCompressedSize(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        ze.setSize(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        int fileNameLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int commentLen = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        int diskStart = ZipShort.getValue(cfh, off);\n        off += SHORT;\n\n        ze.setInternalAttributes(ZipShort.getValue(cfh, off));\n        off += SHORT;\n\n        ze.setExternalAttributes(ZipLong.getValue(cfh, off));\n        off += WORD;\n\n        byte[] fileName = new byte[fileNameLen];\n        archive.readFully(fileName);\n        ze.setName(entryEncoding.decode(fileName), fileName);\n\n        // LFH offset,\n        OffsetEntry offset = new OffsetEntry();\n        offset.headerOffset = ZipLong.getValue(cfh, off);\n        // data offset will be filled later\n        entries.put(ze, offset);\n\n        nameMap.put(ze.getName(), ze);\n\n        byte[] cdExtraData = new byte[extraLen];\n        archive.readFully(cdExtraData);\n        ze.setCentralDirectoryExtra(cdExtraData);\n\n        setSizesAndOffsetFromZip64Extra(ze, offset, diskStart);\n\n        byte[] comment = new byte[commentLen];\n        archive.readFully(comment);\n        ze.setComment(entryEncoding.decode(comment));\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            noUTF8Flag.put(ze, new NameAndComment(fileName, comment));\n        }\n    }\n\n    /**\n     * If the entry holds a Zip64 extended information extra field,\n     * read sizes from there if the entry's sizes are set to\n     * 0xFFFFFFFFF, do the same for the offset of the local file\n     * header.\n     *\n     * <p>Ensures the Zip64 extra either knows both compressed and\n     * uncompressed size or neither of both as the internal logic in\n     * ExtraFieldUtils forces the field to create local header data\n     * even if they are never used - and here a field with only one\n     * size would be invalid.</p>\n     */\n    private void setSizesAndOffsetFromZip64Extra(ZipArchiveEntry ze,\n                                                 OffsetEntry offset,\n                                                 int diskStart)\n        throws IOException {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            ze.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        if (z64 != null) {\n            boolean hasUncompressedSize = ze.getSize() == ZIP64_MAGIC;\n            boolean hasCompressedSize = ze.getCompressedSize() == ZIP64_MAGIC;\n            boolean hasRelativeHeaderOffset =\n                offset.headerOffset == ZIP64_MAGIC;\n            z64.reparseCentralDirectoryData(hasUncompressedSize,\n                                            hasCompressedSize,\n                                            hasRelativeHeaderOffset,\n                                            diskStart == ZIP64_MAGIC_SHORT);\n\n            if (hasUncompressedSize) {\n                ze.setSize(z64.getSize().getLongValue());\n            } else if (hasCompressedSize) {\n                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n            }\n\n            if (hasCompressedSize) {\n                ze.setCompressedSize(z64.getCompressedSize().getLongValue());\n            } else if (hasUncompressedSize) {\n                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n            }\n\n            if (hasRelativeHeaderOffset) {\n                offset.headerOffset =\n                    z64.getRelativeHeaderOffset().getLongValue();\n            }\n        }\n    }\n\n    /**\n     * Length of the \"End of central directory record\" - which is\n     * supposed to be the last structure of the archive - without file\n     * comment.\n     */\n    private static final int MIN_EOCD_SIZE =\n        /* end of central dir signature    */ WORD\n        /* number of this disk             */ + SHORT\n        /* number of the disk with the     */\n        /* start of the central directory  */ + SHORT\n        /* total number of entries in      */\n        /* the central dir on this disk    */ + SHORT\n        /* total number of entries in      */\n        /* the central dir                 */ + SHORT\n        /* size of the central directory   */ + WORD\n        /* offset of start of central      */\n        /* directory with respect to       */\n        /* the starting disk number        */ + WORD\n        /* zipfile comment length          */ + SHORT;\n\n    /**\n     * Maximum length of the \"End of central directory record\" with a\n     * file comment.\n     */\n    private static final int MAX_EOCD_SIZE = MIN_EOCD_SIZE\n        /* maximum length of zipfile comment */ + ZIP64_MAGIC_SHORT;\n\n    /**\n     * Offset of the field that holds the location of the first\n     * central directory entry inside the \"End of central directory\n     * record\" relative to the start of the \"End of central directory\n     * record\".\n     */\n    private static final int CFD_LOCATOR_OFFSET =\n        /* end of central dir signature    */ WORD\n        /* number of this disk             */ + SHORT\n        /* number of the disk with the     */\n        /* start of the central directory  */ + SHORT\n        /* total number of entries in      */\n        /* the central dir on this disk    */ + SHORT\n        /* total number of entries in      */\n        /* the central dir                 */ + SHORT\n        /* size of the central directory   */ + WORD;\n\n    /**\n     * Length of the \"Zip64 end of central directory locator\" - which\n     * should be right in front of the \"end of central directory\n     * record\" if one is present at all.\n     */\n    private static final int ZIP64_EOCDL_LENGTH =\n        /* zip64 end of central dir locator sig */ WORD\n        /* number of the disk with the start    */\n        /* start of the zip64 end of            */\n        /* central directory                    */ + WORD\n        /* relative offset of the zip64         */\n        /* end of central directory record      */ + DWORD\n        /* total number of disks                */ + WORD;\n\n    /**\n     * Offset of the field that holds the location of the \"Zip64 end\n     * of central directory record\" inside the \"Zip64 end of central\n     * directory locator\" relative to the start of the \"Zip64 end of\n     * central directory locator\".\n     */\n    private static final int ZIP64_EOCDL_LOCATOR_OFFSET =\n        /* zip64 end of central dir locator sig */ WORD\n        /* number of the disk with the start    */\n        /* start of the zip64 end of            */\n        /* central directory                    */ + WORD;\n\n    /**\n     * Offset of the field that holds the location of the first\n     * central directory entry inside the \"Zip64 end of central\n     * directory record\" relative to the start of the \"Zip64 end of\n     * central directory record\".\n     */\n    private static final int ZIP64_EOCD_CFD_LOCATOR_OFFSET =\n        /* zip64 end of central dir        */\n        /* signature                       */ WORD\n        /* size of zip64 end of central    */\n        /* directory record                */ + DWORD\n        /* version made by                 */ + SHORT\n        /* version needed to extract       */ + SHORT\n        /* number of this disk             */ + WORD\n        /* number of the disk with the     */\n        /* start of the central directory  */ + WORD\n        /* total number of entries in the  */\n        /* central directory on this disk  */ + DWORD\n        /* total number of entries in the  */\n        /* central directory               */ + DWORD\n        /* size of the central directory   */ + DWORD;\n\n    /**\n     * Searches for either the &quot;Zip64 end of central directory\n     * locator&quot; or the &quot;End of central dir record&quot;, parses\n     * it and positions the stream at the first central directory\n     * record.\n     */\n    private void positionAtCentralDirectory()\n        throws IOException {\n        boolean found = tryToLocateSignature(MIN_EOCD_SIZE + ZIP64_EOCDL_LENGTH,\n                                             MAX_EOCD_SIZE + ZIP64_EOCDL_LENGTH,\n                                             ZipArchiveOutputStream\n                                             .ZIP64_EOCD_LOC_SIG);\n        if (!found) {\n            // not a ZIP64 archive\n            positionAtCentralDirectory32();\n        } else {\n            positionAtCentralDirectory64();\n        }\n    }\n\n    /**\n     * Parses the &quot;Zip64 end of central directory locator&quot;,\n     * finds the &quot;Zip64 end of central directory record&quot; using the\n     * parsed information, parses that and positions the stream at the\n     * first central directory record.\n     */\n    private void positionAtCentralDirectory64()\n        throws IOException {\n        skipBytes(ZIP64_EOCDL_LOCATOR_OFFSET);\n        byte[] zip64EocdOffset = new byte[DWORD];\n        archive.readFully(zip64EocdOffset);\n        archive.seek(ZipEightByteInteger.getLongValue(zip64EocdOffset));\n        byte[] sig = new byte[WORD];\n        archive.readFully(sig);\n        if (sig[POS_0] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_0]\n            || sig[POS_1] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_1]\n            || sig[POS_2] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_2]\n            || sig[POS_3] != ZipArchiveOutputStream.ZIP64_EOCD_SIG[POS_3]\n            ) {\n            throw new ZipException(\"archive's ZIP64 end of central \"\n                                   + \"directory locator is corrupt.\");\n        }\n        skipBytes(ZIP64_EOCD_CFD_LOCATOR_OFFSET\n                  - WORD /* signature has already been read */);\n        byte[] cfdOffset = new byte[DWORD];\n        archive.readFully(cfdOffset);\n        archive.seek(ZipEightByteInteger.getLongValue(cfdOffset));\n    }\n\n    /**\n     * Searches for the &quot;End of central dir record&quot;, parses\n     * it and positions the stream at the first central directory\n     * record.\n     */\n    private void positionAtCentralDirectory32()\n        throws IOException {\n        boolean found = tryToLocateSignature(MIN_EOCD_SIZE, MAX_EOCD_SIZE,\n                                             ZipArchiveOutputStream.EOCD_SIG);\n        if (!found) {\n            throw new ZipException(\"archive is not a ZIP archive\");\n        }\n        skipBytes(CFD_LOCATOR_OFFSET);\n        byte[] cfdOffset = new byte[WORD];\n        archive.readFully(cfdOffset);\n        archive.seek(ZipLong.getValue(cfdOffset));\n    }\n\n    /**\n     * Searches the archive backwards from minDistance to maxDistance\n     * for the given signature, positions the RandomaccessFile right\n     * at the signature if it has been found.\n     */\n    private boolean tryToLocateSignature(long minDistanceFromEnd,\n                                         long maxDistanceFromEnd,\n                                         byte[] sig) throws IOException {\n        boolean found = false;\n        long off = archive.length() - minDistanceFromEnd;\n        final long stopSearching =\n            Math.max(0L, archive.length() - maxDistanceFromEnd);\n        if (off >= 0) {\n            for (; off >= stopSearching; off--) {\n                archive.seek(off);\n                int curr = archive.read();\n                if (curr == -1) {\n                    break;\n                }\n                if (curr == sig[POS_0]) {\n                    curr = archive.read();\n                    if (curr == sig[POS_1]) {\n                        curr = archive.read();\n                        if (curr == sig[POS_2]) {\n                            curr = archive.read();\n                            if (curr == sig[POS_3]) {\n                                found = true;\n                                break;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        if (found) {\n            archive.seek(off);\n        }\n        return found;\n    }\n\n    /**\n     * Skips the given number of bytes or throws an EOFException if\n     * skipping failed.\n     */ \n    private void skipBytes(final int count) throws IOException {\n        int totalSkipped = 0;\n        while (totalSkipped < count) {\n            int skippedNow = archive.skipBytes(count - totalSkipped);\n            if (skippedNow <= 0) {\n                throw new EOFException();\n            }\n            totalSkipped += skippedNow;\n        }\n    }\n\n    /**\n     * Number of bytes in local file header up to the &quot;length of\n     * filename&quot; entry.\n     */\n    private static final long LFH_OFFSET_FOR_FILENAME_LENGTH =\n        /* local file header signature     */ WORD\n        /* version needed to extract       */ + SHORT\n        /* general purpose bit flag        */ + SHORT\n        /* compression method              */ + SHORT\n        /* last mod file time              */ + SHORT\n        /* last mod file date              */ + SHORT\n        /* crc-32                          */ + WORD\n        /* compressed size                 */ + WORD\n        /* uncompressed size               */ + WORD;\n\n    /**\n     * Walks through all recorded entries and adds the data available\n     * from the local file header.\n     *\n     * <p>Also records the offsets for the data to read from the\n     * entries.</p>\n     */\n    private void resolveLocalFileHeaderData(Map<ZipArchiveEntry, NameAndComment>\n                                            entriesWithoutUTF8Flag)\n        throws IOException {\n        // changing the name of a ZipArchiveEntry is going to change\n        // the hashcode - see COMPRESS-164\n        // Map needs to be reconstructed in order to keep central\n        // directory order\n        Map<ZipArchiveEntry, OffsetEntry> origMap =\n            new LinkedHashMap<ZipArchiveEntry, OffsetEntry>(entries);\n        entries.clear();\n        for (ZipArchiveEntry ze : origMap.keySet()) {\n            OffsetEntry offsetEntry = origMap.get(ze);\n            long offset = offsetEntry.headerOffset;\n            archive.seek(offset + LFH_OFFSET_FOR_FILENAME_LENGTH);\n            byte[] b = new byte[SHORT];\n            archive.readFully(b);\n            int fileNameLen = ZipShort.getValue(b);\n            archive.readFully(b);\n            int extraFieldLen = ZipShort.getValue(b);\n            int lenToSkip = fileNameLen;\n            while (lenToSkip > 0) {\n                int skipped = archive.skipBytes(lenToSkip);\n                if (skipped <= 0) {\n                    throw new RuntimeException(\"failed to skip file name in\"\n                                               + \" local file header\");\n                }\n                lenToSkip -= skipped;\n            }\n            byte[] localExtraData = new byte[extraFieldLen];\n            archive.readFully(localExtraData);\n            ze.setExtra(localExtraData);\n            offsetEntry.dataOffset = offset + LFH_OFFSET_FOR_FILENAME_LENGTH\n                + SHORT + SHORT + fileNameLen + extraFieldLen;\n\n            if (entriesWithoutUTF8Flag.containsKey(ze)) {\n                String orig = ze.getName();\n                NameAndComment nc = entriesWithoutUTF8Flag.get(ze);\n                ZipUtil.setNameAndCommentFromExtraFields(ze, nc.name,\n                                                         nc.comment);\n                if (!orig.equals(ze.getName())) {\n                    nameMap.remove(orig);\n                    nameMap.put(ze.getName(), ze);\n                }\n            }\n            entries.put(ze, offsetEntry);\n        }\n    }\n\n    /**\n     * Checks whether the archive starts with a LFH.  If it doesn't,\n     * it may be an empty archive.\n     */\n    private boolean startsWithLocalFileHeader() throws IOException {\n        archive.seek(0);\n        final byte[] start = new byte[WORD];\n        archive.readFully(start);\n        for (int i = 0; i < start.length; i++) {\n            if (start[i] != ZipArchiveOutputStream.LFH_SIG[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * InputStream that delegates requests to the underlying\n     * RandomAccessFile, making sure that only bytes from a certain\n     * range can be read.\n     */\n    private class BoundedInputStream extends InputStream {\n        private long remaining;\n        private long loc;\n        private boolean addDummyByte = false;\n\n        BoundedInputStream(long start, long remaining) {\n            this.remaining = remaining;\n            loc = start;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (remaining-- <= 0) {\n                if (addDummyByte) {\n                    addDummyByte = false;\n                    return 0;\n                }\n                return -1;\n            }\n            synchronized (archive) {\n                archive.seek(loc++);\n                return archive.read();\n            }\n        }\n\n        @Override\n        public int read(byte[] b, int off, int len) throws IOException {\n            if (remaining <= 0) {\n                if (addDummyByte) {\n                    addDummyByte = false;\n                    b[off] = 0;\n                    return 1;\n                }\n                return -1;\n            }\n\n            if (len <= 0) {\n                return 0;\n            }\n\n            if (len > remaining) {\n                len = (int) remaining;\n            }\n            int ret = -1;\n            synchronized (archive) {\n                archive.seek(loc);\n                ret = archive.read(b, off, len);\n            }\n            if (ret > 0) {\n                loc += ret;\n                remaining -= ret;\n            }\n            return ret;\n        }\n\n        /**\n         * Inflater needs an extra dummy byte for nowrap - see\n         * Inflater's javadocs.\n         */\n        void addDummy() {\n            addDummyByte = true;\n        }\n    }\n\n    private static final class NameAndComment {\n        private final byte[] name;\n        private final byte[] comment;\n        private NameAndComment(byte[] name, byte[] comment) {\n            this.name = name;\n            this.comment = comment;\n        }\n    }\n\n    /**\n     * Compares two ZipArchiveEntries based on their offset within the archive.\n     *\n     * <p>Won't return any meaningful results if one of the entries\n     * isn't part of the archive at all.</p>\n     *\n     * @since Commons Compress 1.1\n     */\n    private final Comparator<ZipArchiveEntry> OFFSET_COMPARATOR =\n        new Comparator<ZipArchiveEntry>() {\n        public int compare(ZipArchiveEntry e1, ZipArchiveEntry e2) {\n            if (e1 == e2)\n                return 0;\n\n            OffsetEntry off1 = entries.get(e1);\n            OffsetEntry off2 = entries.get(e2);\n            if (off1 == null) {\n                return 1;\n            }\n            if (off2 == null) {\n                return -1;\n            }\n            long val = (off1.headerOffset - off2.headerOffset);\n            return val == 0 ? 0 : val < 0 ? -1 : +1;\n        }\n    };\n}\n"}]}
{"project": "Compress", "bug_id": 11, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.ArchiveStreamFactory", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n\n/**\n * <p>Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order add other implementations you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).</p>\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * \n * @Immutable\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant used to identify the AR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant used to identify the CPIO archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant used to identify the Unix DUMP archive format.\n     * @since Commons Compress 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant used to identify the JAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant used to identify the ZIP archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String ZIP = \"zip\";\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\", \"dump\" or \"cpio\"\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n        \n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        \n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveInputStream(in);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveInputStream(in);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveInputStream(in);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveInputStream(in);\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            return new DumpArchiveInputStream(in);\n        }\n        \n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\" or \"cpio\"\n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveOutputStream(out);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveOutputStream(out);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveOutputStream(out);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveOutputStream(out);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = in.read(signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                return new ZipArchiveInputStream(in);\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                return new JarArchiveInputStream(in);\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                return new CpioArchiveInputStream(in);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = in.read(dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = in.read(tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            try {\n                TarArchiveInputStream tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                tais.getNextEntry();\n                return new TarArchiveInputStream(in);\n            } catch (Exception e) { // NOPMD\n                // can generate IllegalArgumentException as well as IOException\n                // autodetection, simply not a TAR\n                // ignored\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n\n/**\n * <p>Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order add other implementations you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).</p>\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * \n * @Immutable\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant used to identify the AR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant used to identify the CPIO archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant used to identify the Unix DUMP archive format.\n     * @since Commons Compress 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant used to identify the JAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant used to identify the ZIP archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String ZIP = \"zip\";\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\", \"dump\" or \"cpio\"\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n        \n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        \n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveInputStream(in);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveInputStream(in);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveInputStream(in);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveInputStream(in);\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            return new DumpArchiveInputStream(in);\n        }\n        \n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\" or \"cpio\"\n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveOutputStream(out);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveOutputStream(out);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveOutputStream(out);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveOutputStream(out);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = in.read(signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                return new ZipArchiveInputStream(in);\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                return new JarArchiveInputStream(in);\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                return new CpioArchiveInputStream(in);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = in.read(dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = in.read(tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            if (signatureLength >= 512) {\n            try {\n                TarArchiveInputStream tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                tais.getNextEntry();\n                return new TarArchiveInputStream(in);\n            } catch (Exception e) { // NOPMD\n                // can generate IllegalArgumentException as well as IOException\n                // autodetection, simply not a TAR\n                // ignored\n            }\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 12, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n    private static final int SMALL_BUFFER_SIZE = 256;\n    private static final int BUFFER_SIZE = 8 * 1024;\n\n    private boolean hasHitEOF;\n    private long entrySize;\n    private long entryOffset;\n    private byte[] readBuf;\n    protected final TarBuffer buffer;\n    private TarArchiveEntry currEntry;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this.buffer = new TarBuffer(is, blockSize, recordSize);\n        this.readBuf = null;\n        this.hasHitEOF = false;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        buffer.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returen in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    /**\n     * Skip bytes in the input buffer. This skips bytes in the\n     * current entry's data, not the entire archive, and will\n     * stop at the end of the current entry's data if the number\n     * to skip extends beyond that point.\n     *\n     * @param numToSkip The number of bytes to skip.\n     * @return the number actually skipped\n     * @throws IOException on error\n     */\n    @Override\n    public long skip(long numToSkip) throws IOException {\n        // REVIEW\n        // This is horribly inefficient, but it ensures that we\n        // properly skip over bytes via the TarBuffer...\n        //\n        byte[] skipBuf = new byte[BUFFER_SIZE];\n        long skip = numToSkip;\n        while (skip > 0) {\n            int realSkip = (int) (skip > skipBuf.length ? skipBuf.length : skip);\n            int numRead = read(skipBuf, 0, realSkip);\n            if (numRead == -1) {\n                break;\n            }\n            skip -= numRead;\n        }\n        return (numToSkip - skip);\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            long numToSkip = entrySize - entryOffset;\n\n            while (numToSkip > 0) {\n                long skipped = skip(numToSkip);\n                if (skipped <= 0) {\n                    throw new RuntimeException(\"failed to skip current tar entry\");\n                }\n                numToSkip -= skipped;\n            }\n\n            readBuf = null;\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (hasHitEOF) {\n            currEntry = null;\n            return null;\n        }\n\n        currEntry = new TarArchiveEntry(headerBuf);\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongNameEntry()) {\n            // read in the name\n            StringBuffer longName = new StringBuffer();\n            byte[] buf = new byte[SMALL_BUFFER_SIZE];\n            int length = 0;\n            while ((length = read(buf)) >= 0) {\n                longName.append(new String(buf, 0, length));\n            }\n            getNextEntry();\n            if (currEntry == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by entry\n                return null;\n            }\n            // remove trailing null terminator\n            if (longName.length() > 0\n                && longName.charAt(longName.length() - 1) == 0) {\n                longName.deleteCharAt(longName.length() - 1);\n            }\n            currEntry.setName(longName.toString());\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n        return currEntry;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        byte[] headerBuf = buffer.readRecord();\n\n        if (headerBuf == null) {\n            hasHitEOF = true;\n        } else if (buffer.isEOFRecord(headerBuf)) {\n            hasHitEOF = true;\n        }\n\n        return hasHitEOF ? null : headerBuf;\n    }\n\n    private void paxHeaders() throws IOException{\n        Reader br = new InputStreamReader(this, \"UTF-8\") {\n                @Override\n                public void close() {\n                    // make sure GC doesn't close \"this\" before we are done\n                }\n            };\n        Map<String, String> headers = null;\n        try {\n            headers = parsePaxHeaders(br);\n        } finally {\n            // NO-OP but makes FindBugs happy\n            br.close();\n        }\n\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(Reader br) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = br.read()) != -1){\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    StringBuffer sb = new StringBuffer();\n                    while((ch = br.read()) != -1){\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = sb.toString();\n                            // Get rest of entry\n                            char[] cbuf = new char[len-read];\n                            int got = br.read(cbuf);\n                            if (got != len - read){\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + (len - read)\n                                                      + \" chars, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(cbuf, 0,\n                                                      len - read - 1);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        sb.append((char) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, mtime, charset: cannot use these without changing TarArchiveEntry fields\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     * \n     * @throws IOException on error \n     * \n     * @todo Sparse files get not yet really processed. \n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (hasHitEOF) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n        int totalRead = 0;\n\n        if (entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if ((numToRead + entryOffset) > entrySize) {\n            numToRead = (int) (entrySize - entryOffset);\n        }\n\n        if (readBuf != null) {\n            int sz = (numToRead > readBuf.length) ? readBuf.length\n                : numToRead;\n\n            System.arraycopy(readBuf, 0, buf, offset, sz);\n\n            if (sz >= readBuf.length) {\n                readBuf = null;\n            } else {\n                int newLen = readBuf.length - sz;\n                byte[] newBuf = new byte[newLen];\n\n                System.arraycopy(readBuf, sz, newBuf, 0, newLen);\n\n                readBuf = newBuf;\n            }\n\n            totalRead += sz;\n            numToRead -= sz;\n            offset += sz;\n        }\n\n        while (numToRead > 0) {\n            byte[] rec = buffer.readRecord();\n\n            if (rec == null) {\n                // Unexpected EOF!\n                throw new IOException(\"unexpected EOF with \" + numToRead\n                                      + \" bytes unread. Occured at byte: \" + getBytesRead());\n            }\n            count(rec.length);\n            int sz = numToRead;\n            int recLen = rec.length;\n\n            if (recLen > sz) {\n                System.arraycopy(rec, 0, buf, offset, sz);\n\n                readBuf = new byte[recLen - sz];\n\n                System.arraycopy(rec, sz, readBuf, 0, recLen - sz);\n            } else {\n                sz = recLen;\n\n                System.arraycopy(rec, 0, buf, offset, recLen);\n            }\n\n            totalRead += sz;\n            numToRead -= sz;\n            offset += sz;\n        }\n\n        entryOffset += totalRead;\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    protected final TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n    private static final int SMALL_BUFFER_SIZE = 256;\n    private static final int BUFFER_SIZE = 8 * 1024;\n\n    private boolean hasHitEOF;\n    private long entrySize;\n    private long entryOffset;\n    private byte[] readBuf;\n    protected final TarBuffer buffer;\n    private TarArchiveEntry currEntry;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this.buffer = new TarBuffer(is, blockSize, recordSize);\n        this.readBuf = null;\n        this.hasHitEOF = false;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        buffer.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returen in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    /**\n     * Skip bytes in the input buffer. This skips bytes in the\n     * current entry's data, not the entire archive, and will\n     * stop at the end of the current entry's data if the number\n     * to skip extends beyond that point.\n     *\n     * @param numToSkip The number of bytes to skip.\n     * @return the number actually skipped\n     * @throws IOException on error\n     */\n    @Override\n    public long skip(long numToSkip) throws IOException {\n        // REVIEW\n        // This is horribly inefficient, but it ensures that we\n        // properly skip over bytes via the TarBuffer...\n        //\n        byte[] skipBuf = new byte[BUFFER_SIZE];\n        long skip = numToSkip;\n        while (skip > 0) {\n            int realSkip = (int) (skip > skipBuf.length ? skipBuf.length : skip);\n            int numRead = read(skipBuf, 0, realSkip);\n            if (numRead == -1) {\n                break;\n            }\n            skip -= numRead;\n        }\n        return (numToSkip - skip);\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            long numToSkip = entrySize - entryOffset;\n\n            while (numToSkip > 0) {\n                long skipped = skip(numToSkip);\n                if (skipped <= 0) {\n                    throw new RuntimeException(\"failed to skip current tar entry\");\n                }\n                numToSkip -= skipped;\n            }\n\n            readBuf = null;\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (hasHitEOF) {\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongNameEntry()) {\n            // read in the name\n            StringBuffer longName = new StringBuffer();\n            byte[] buf = new byte[SMALL_BUFFER_SIZE];\n            int length = 0;\n            while ((length = read(buf)) >= 0) {\n                longName.append(new String(buf, 0, length));\n            }\n            getNextEntry();\n            if (currEntry == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by entry\n                return null;\n            }\n            // remove trailing null terminator\n            if (longName.length() > 0\n                && longName.charAt(longName.length() - 1) == 0) {\n                longName.deleteCharAt(longName.length() - 1);\n            }\n            currEntry.setName(longName.toString());\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n        return currEntry;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        byte[] headerBuf = buffer.readRecord();\n\n        if (headerBuf == null) {\n            hasHitEOF = true;\n        } else if (buffer.isEOFRecord(headerBuf)) {\n            hasHitEOF = true;\n        }\n\n        return hasHitEOF ? null : headerBuf;\n    }\n\n    private void paxHeaders() throws IOException{\n        Reader br = new InputStreamReader(this, \"UTF-8\") {\n                @Override\n                public void close() {\n                    // make sure GC doesn't close \"this\" before we are done\n                }\n            };\n        Map<String, String> headers = null;\n        try {\n            headers = parsePaxHeaders(br);\n        } finally {\n            // NO-OP but makes FindBugs happy\n            br.close();\n        }\n\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(Reader br) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = br.read()) != -1){\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    StringBuffer sb = new StringBuffer();\n                    while((ch = br.read()) != -1){\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = sb.toString();\n                            // Get rest of entry\n                            char[] cbuf = new char[len-read];\n                            int got = br.read(cbuf);\n                            if (got != len - read){\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + (len - read)\n                                                      + \" chars, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(cbuf, 0,\n                                                      len - read - 1);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        sb.append((char) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, mtime, charset: cannot use these without changing TarArchiveEntry fields\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     * \n     * @throws IOException on error \n     * \n     * @todo Sparse files get not yet really processed. \n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (hasHitEOF) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n        int totalRead = 0;\n\n        if (entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if ((numToRead + entryOffset) > entrySize) {\n            numToRead = (int) (entrySize - entryOffset);\n        }\n\n        if (readBuf != null) {\n            int sz = (numToRead > readBuf.length) ? readBuf.length\n                : numToRead;\n\n            System.arraycopy(readBuf, 0, buf, offset, sz);\n\n            if (sz >= readBuf.length) {\n                readBuf = null;\n            } else {\n                int newLen = readBuf.length - sz;\n                byte[] newBuf = new byte[newLen];\n\n                System.arraycopy(readBuf, sz, newBuf, 0, newLen);\n\n                readBuf = newBuf;\n            }\n\n            totalRead += sz;\n            numToRead -= sz;\n            offset += sz;\n        }\n\n        while (numToRead > 0) {\n            byte[] rec = buffer.readRecord();\n\n            if (rec == null) {\n                // Unexpected EOF!\n                throw new IOException(\"unexpected EOF with \" + numToRead\n                                      + \" bytes unread. Occured at byte: \" + getBytesRead());\n            }\n            count(rec.length);\n            int sz = numToRead;\n            int recLen = rec.length;\n\n            if (recLen > sz) {\n                System.arraycopy(rec, 0, buf, offset, sz);\n\n                readBuf = new byte[recLen - sz];\n\n                System.arraycopy(rec, sz, readBuf, 0, recLen - sz);\n            } else {\n                sz = recLen;\n\n                System.arraycopy(rec, 0, buf, offset, recLen);\n            }\n\n            totalRead += sz;\n            numToRead -= sz;\n            offset += sz;\n        }\n\n        entryOffset += totalRead;\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    protected final TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 13, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveEntry", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * {@link <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">\n * APPNOTE.txt</a>}:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry, Cloneable {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap<ZipShort, ZipExtraField> extraFields = null;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields(true));\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     */\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields(true));\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    @Override\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n        for (int i = 0; i < fields.length; i++) {\n            if (fields[i] instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) fields[i];\n            } else {\n                extraFields.put(fields[i].getHeaderId(), fields[i]);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getExtraFields(false);\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public ZipExtraField[] getExtraFields(boolean includeUnparseable) {\n        if (extraFields == null) {\n            return !includeUnparseable || unparseableExtra == null\n                ? new ZipExtraField[0]\n                : new ZipExtraField[] { unparseableExtra };\n        }\n        List<ZipExtraField> result =\n            new ArrayList<ZipExtraField>(extraFields.values());\n        if (includeUnparseable && unparseableExtra != null) {\n            result.add(unparseableExtra);\n        }\n        return result.toArray(new ZipExtraField[0]);\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            }\n            extraFields.put(ze.getHeaderId(), ze);\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            LinkedHashMap<ZipShort, ZipExtraField> copy = extraFields;\n            extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            extraFields.put(ze.getHeaderId(), ze);\n            if (copy != null) {\n                copy.remove(ze.getHeaderId());\n                extraFields.putAll(copy);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \"\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields(true)));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields(true));\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @exception IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since Apache Commons Compress 1.2\n     */\n    protected void setName(String name, byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @since Apache Commons Compress 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since Apache Commons Compress 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since Apache Commons Compress 1.1\n     */\n    public void setGeneralPurposeBit(GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (int i = 0; i < f.length; i++) {\n                ZipExtraField existing;\n                if (f[i] instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(f[i].getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(f[i]);\n                } else {\n                    if (local) {\n                        byte[] b = f[i].getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = f[i].getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDoc} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        String myName = getName();\n        String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            if (otherComment != null) {\n                return false;\n            }\n        } else if (!myComment.equals(otherComment)) {\n            return false;\n        }\n        return getTime() == other.getTime()\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * {@link <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">\n * APPNOTE.txt</a>}:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry, Cloneable {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap<ZipShort, ZipExtraField> extraFields = null;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields(true));\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     */\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields(true));\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    @Override\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n        for (int i = 0; i < fields.length; i++) {\n            if (fields[i] instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) fields[i];\n            } else {\n                extraFields.put(fields[i].getHeaderId(), fields[i]);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getExtraFields(false);\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public ZipExtraField[] getExtraFields(boolean includeUnparseable) {\n        if (extraFields == null) {\n            return !includeUnparseable || unparseableExtra == null\n                ? new ZipExtraField[0]\n                : new ZipExtraField[] { unparseableExtra };\n        }\n        List<ZipExtraField> result =\n            new ArrayList<ZipExtraField>(extraFields.values());\n        if (includeUnparseable && unparseableExtra != null) {\n            result.add(unparseableExtra);\n        }\n        return result.toArray(new ZipExtraField[0]);\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            }\n            extraFields.put(ze.getHeaderId(), ze);\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            LinkedHashMap<ZipShort, ZipExtraField> copy = extraFields;\n            extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            extraFields.put(ze.getHeaderId(), ze);\n            if (copy != null) {\n                copy.remove(ze.getHeaderId());\n                extraFields.putAll(copy);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since Apache Commons Compress 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \"\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields(true)));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields(true));\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        if (name != null && getPlatform() == PLATFORM_FAT\n            && name.indexOf(\"/\") == -1) {\n            name = name.replace('\\\\', '/');\n        }\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @exception IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since Apache Commons Compress 1.2\n     */\n    protected void setName(String name, byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @since Apache Commons Compress 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since Apache Commons Compress 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since Apache Commons Compress 1.1\n     */\n    public void setGeneralPurposeBit(GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (int i = 0; i < f.length; i++) {\n                ZipExtraField existing;\n                if (f[i] instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(f[i].getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(f[i]);\n                } else {\n                    if (local) {\n                        byte[] b = f[i].getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = f[i].getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDoc} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        String myName = getName();\n        String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            if (otherComment != null) {\n                return false;\n            }\n        } else if (!myComment.equals(otherComment)) {\n            return false;\n        }\n        return getTime() == other.getTime()\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 14, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        boolean allNUL = true;\n        for (int i = start; i < end; i++){\n            if (buffer[i] != 0){\n                allNUL = false;\n                break;\n            }\n        }\n        if (allNUL) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Must have trailing NUL or space\n        byte trailer;\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        // May have additional NUL or space\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since Apache Commons Compress 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n\n        long val = buffer[offset] & 0x7f;\n        for (int i = 1; i < length; i++) {\n            if (val >= (1L << (63 - 8))) {\n                throw new IllegalArgumentException(\n                    \"At offset \" + offset + \", \" + length + \" byte \" +\n                    \"binary number exceeds maximum signed long value\");\n            }\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        return val;\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length);\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            byte b = buffer[i];\n            if (b == 0) { // Trailing null\n                break;\n            }\n            result.append((char) (b & 0xFF)); // Allow for sign-extension\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since Apache Commons Compress 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        if (value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        long val = value;\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n\n        if (val != 0 || (buf[offset] & 0x80) != 0) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n\n        buf[offset] |= 0x80;\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){    \n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Must have trailing NUL or space\n        byte trailer;\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        // May have additional NUL or space\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since Apache Commons Compress 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n\n        long val = buffer[offset] & 0x7f;\n        for (int i = 1; i < length; i++) {\n            if (val >= (1L << (63 - 8))) {\n                throw new IllegalArgumentException(\n                    \"At offset \" + offset + \", \" + length + \" byte \" +\n                    \"binary number exceeds maximum signed long value\");\n            }\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        return val;\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length);\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        StringBuffer result = new StringBuffer(length);\n        int          end = offset + length;\n\n        for (int i = offset; i < end; ++i) {\n            byte b = buffer[i];\n            if (b == 0) { // Trailing null\n                break;\n            }\n            result.append((char) (b & 0xFF)); // Allow for sign-extension\n        }\n\n        return result.toString();\n    }\n\n    /**\n     * Copy a name (StringBuffer) into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        int i;\n\n        // copy until end of input or output is reached.\n        for (i = 0; i < length && i < name.length(); ++i) {\n            buf[offset + i] = (byte) name.charAt(i);\n        }\n\n        // Pad any remaining output bytes with NUL\n        for (; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n        \n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since Apache Commons Compress 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        if (value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        long val = value;\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n\n        if (val != 0 || (buf[offset] & 0x80) != 0) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n\n        buf[offset] |= 0x80;\n        return offset + length;\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 15, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveEntry", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * {@link <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">\n * APPNOTE.txt</a>}:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap<ZipShort, ZipExtraField> extraFields = null;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields(true));\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     */\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields(true));\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n        for (ZipExtraField field : fields) {\n            if (field instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) field;\n            } else {\n                extraFields.put(field.getHeaderId(), field);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getExtraFields(false);\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since 1.1\n     */\n    public ZipExtraField[] getExtraFields(boolean includeUnparseable) {\n        if (extraFields == null) {\n            return !includeUnparseable || unparseableExtra == null\n                ? new ZipExtraField[0]\n                : new ZipExtraField[] { unparseableExtra };\n        }\n        List<ZipExtraField> result =\n            new ArrayList<ZipExtraField>(extraFields.values());\n        if (includeUnparseable && unparseableExtra != null) {\n            result.add(unparseableExtra);\n        }\n        return result.toArray(new ZipExtraField[0]);\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            }\n            extraFields.put(ze.getHeaderId(), ze);\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            LinkedHashMap<ZipShort, ZipExtraField> copy = extraFields;\n            extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            extraFields.put(ze.getHeaderId(), ze);\n            if (copy != null) {\n                copy.remove(ze.getHeaderId());\n                extraFields.putAll(copy);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \"\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields(true)));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields(true));\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        if (name != null && getPlatform() == PLATFORM_FAT\n            && name.indexOf(\"/\") == -1) {\n            name = name.replace('\\\\', '/');\n        }\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @exception IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since 1.2\n     */\n    protected void setName(String name, byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @since 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since 1.1\n     */\n    public void setGeneralPurposeBit(GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (ZipExtraField element : f) {\n                ZipExtraField existing;\n                if (element instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(element.getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(element);\n                } else {\n                    if (local) {\n                        byte[] b = element.getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = element.getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDoc} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        String myName = getName();\n        String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            if (otherComment != null) {\n                return false;\n            }\n        } else if (!myComment.equals(otherComment)) {\n            return false;\n        }\n        return getTime() == other.getTime()\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.zip.ZipException;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * {@link <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">\n * APPNOTE.txt</a>}:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = -1;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int platform = PLATFORM_FAT;\n    private long externalAttributes = 0;\n    private LinkedHashMap<ZipShort, ZipExtraField> extraFields = null;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(entry.getExtraFields(true));\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     */\n    public ZipArchiveEntry(File inputFile, String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getExtraFields(true));\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public void setMethod(int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(ZipExtraField[] fields) {\n        extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n        for (ZipExtraField field : fields) {\n            if (field instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) field;\n            } else {\n                extraFields.put(field.getHeaderId(), field);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getExtraFields(false);\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since 1.1\n     */\n    public ZipExtraField[] getExtraFields(boolean includeUnparseable) {\n        if (extraFields == null) {\n            return !includeUnparseable || unparseableExtra == null\n                ? new ZipExtraField[0]\n                : new ZipExtraField[] { unparseableExtra };\n        }\n        List<ZipExtraField> result =\n            new ArrayList<ZipExtraField>(extraFields.values());\n        if (includeUnparseable && unparseableExtra != null) {\n            result.add(unparseableExtra);\n        }\n        return result.toArray(new ZipExtraField[0]);\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            }\n            extraFields.put(ze.getHeaderId(), ze);\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            LinkedHashMap<ZipShort, ZipExtraField> copy = extraFields;\n            extraFields = new LinkedHashMap<ZipShort, ZipExtraField>();\n            extraFields.put(ze.getHeaderId(), ze);\n            if (copy != null) {\n                copy.remove(ze.getHeaderId());\n                extraFields.putAll(copy);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        if (extraFields.remove(type) == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(ZipShort type) {\n        if (extraFields != null) {\n            return extraFields.get(type);\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(byte[] extra) throws RuntimeException {\n        try {\n            ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \"\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getExtraFields(true)));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     */\n    public void setCentralDirectoryExtra(byte[] b) {\n        try {\n            ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (ZipException e) {\n            throw new RuntimeException(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        byte[] extra = getExtra();\n        return extra != null ? extra : new byte[0];\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getExtraFields(true));\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        if (name != null && getPlatform() == PLATFORM_FAT\n            && name.indexOf(\"/\") == -1) {\n            name = name.replace('\\\\', '/');\n        }\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @exception IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since 1.2\n     */\n    protected void setName(String name, byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @since 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @since 1.1\n     */\n    public void setGeneralPurposeBit(GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(ZipExtraField[] f, boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (ZipExtraField element : f) {\n                ZipExtraField existing;\n                if (element instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(element.getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(element);\n                } else {\n                    if (local) {\n                        byte[] b = element.getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        byte[] b = element.getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /** {@inheritDoc} */\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        String myName = getName();\n        String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            myComment = \"\";\n        }\n        if (otherComment == null) {\n            otherComment = \"\";\n        }\n        return getTime() == other.getTime()\n            && myComment.equals(otherComment)\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 16, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.ArchiveStreamFactory", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n\n/**\n * <p>Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order add other implementations you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).</p>\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * \n * @Immutable\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant used to identify the AR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant used to identify the CPIO archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant used to identify the Unix DUMP archive format.\n     * @since Commons Compress 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant used to identify the JAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant used to identify the ZIP archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String ZIP = \"zip\";\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\", \"dump\" or \"cpio\"\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n\n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveInputStream(in);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveInputStream(in);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveInputStream(in);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveInputStream(in);\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            return new DumpArchiveInputStream(in);\n        }\n\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\" or \"cpio\"\n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveOutputStream(out);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveOutputStream(out);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveOutputStream(out);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveOutputStream(out);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = in.read(signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                return new ZipArchiveInputStream(in);\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                return new JarArchiveInputStream(in);\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                return new CpioArchiveInputStream(in);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = in.read(dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = in.read(tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            if (signatureLength >= 512) {\n                try {\n                    TarArchiveInputStream tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                    // COMPRESS-191 - verify the header checksum\n                    tais.getNextEntry();\n                        return new TarArchiveInputStream(in);\n                } catch (Exception e) { // NOPMD\n                    // can generate IllegalArgumentException as well\n                    // as IOException\n                    // autodetection, simply not a TAR\n                    // ignored\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\n\n/**\n * <p>Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order add other implementations you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).</p>\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * \n * @Immutable\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant used to identify the AR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant used to identify the CPIO archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant used to identify the Unix DUMP archive format.\n     * @since Commons Compress 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant used to identify the JAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant used to identify the ZIP archive format.\n     * @since Commons Compress 1.1\n     */\n    public static final String ZIP = \"zip\";\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\", \"dump\" or \"cpio\"\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n\n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveInputStream(in);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveInputStream(in);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveInputStream(in);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveInputStream(in);\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            return new DumpArchiveInputStream(in);\n        }\n\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name, i.e. \"ar\", \"zip\", \"tar\", \"jar\" or \"cpio\"\n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            return new ZipArchiveOutputStream(out);\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            return new TarArchiveOutputStream(out);\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            return new JarArchiveOutputStream(out);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            return new CpioArchiveOutputStream(out);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = in.read(signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                return new ZipArchiveInputStream(in);\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                return new JarArchiveInputStream(in);\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                return new CpioArchiveInputStream(in);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = in.read(dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = in.read(tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            if (signatureLength >= 512) {\n                try {\n                    TarArchiveInputStream tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                    // COMPRESS-191 - verify the header checksum\n                    if (tais.getNextTarEntry().isCheckSumOK()) {\n                        return new TarArchiveInputStream(in);\n                    }\n                } catch (Exception e) { // NOPMD\n                    // can generate IllegalArgumentException as well\n                    // as IOException\n                    // autodetection, simply not a TAR\n                    // ignored\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 17, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuffer result = new StringBuffer(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Must have trailing NUL or space\n        byte trailer;\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        // May have additional NULs or spaces\n        trailer = buffer[end - 1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= ((long) Math.pow(2, (length - 1) * 8) - 1);\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length); // TODO default charset?\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuffer result = new StringBuffer(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Must have trailing NUL or space\n        byte trailer;\n        trailer = buffer[end-1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        // May have additional NULs or spaces\n        trailer = buffer[end - 1];\n        while (start < end - 1 && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= ((long) Math.pow(2, (length - 1) * 8) - 1);\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        String string = new String(buffer, offset, length); // TODO default charset?\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (int i = 0; i < buf.length; ++i) {\n            sum += BYTE_MASK & buf[i];\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 18, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.StringWriter;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\nimport java.util.Map;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    /** POSIX/PAX extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_POSIX = 3;\n\n    /** Fail if a big number (e.g. size &gt; 8GiB) is required in the archive. */\n    public static final int BIGNUMBER_ERROR = 0;\n\n    /** star/GNU tar/BSD tar extensions are used to store big number in the archive. */\n    public static final int BIGNUMBER_STAR = 1;\n\n    /** POSIX/PAX extensions are used to store big numbers in the archive. */\n    public static final int BIGNUMBER_POSIX = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n    private int       bigNumberMode = BIGNUMBER_ERROR;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished = false;\n\n    private final OutputStream out;\n\n    private final ZipEncoding encoding;\n\n    private boolean addPaxHeadersForNonAsciiNames = false;\n    private static final ZipEncoding ASCII =\n        ZipEncodingHelper.getZipEncoding(\"ASCII\");\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, String encoding) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  String encoding) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        this(os, blockSize, recordSize, null);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  int recordSize, String encoding) {\n        out = new CountingOutputStream(os);\n        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        this.buffer = new TarBuffer(out, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n    /**\n     * Set the big number mode.\n     * This can be BIGNUMBER_ERROR(0), BIGNUMBER_POSIX(1) or BIGNUMBER_STAR(2).\n     * This specifies the treatment of big files (sizes &gt; TarConstants.MAXSIZE) and other numeric values to big to fit into a traditional tar header.\n     * Default is BIGNUMBER_ERROR.\n     * @param bigNumberMode the mode to use\n     * @since 1.4\n     */\n    public void setBigNumberMode(int bigNumberMode) {\n        this.bigNumberMode = bigNumberMode;\n    }\n\n    /**\n     * Whether to add a PAX extension header for non-ASCII file names.\n     * @since 1.4\n     */\n    public void setAddPaxHeadersForNonAsciiNames(boolean b) {\n        addPaxHeadersForNonAsciiNames = b;\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesWritten();\n    }\n\n    @Override\n    public long getBytesWritten() {\n        return ((CountingOutputStream) out).getBytesWritten();\n    }\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        buffer.flushBlock();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n\n        if (!closed) {\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        Map<String, String> paxHeaders = new HashMap<String, String>();\n        final String entryName = entry.getName();\n        final ByteBuffer encodedName = encoding.encode(entryName);\n        final int nameLen = encodedName.limit() - encodedName.position();\n        boolean paxHeaderContainsPath = false;\n        if (nameLen >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_POSIX) {\n                paxHeaders.put(\"path\", entryName);\n                paxHeaderContainsPath = true;\n            } else if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                longLinkEntry.setSize(nameLen + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(encodedName.array(), encodedName.arrayOffset(), nameLen);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entryName\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        if (bigNumberMode == BIGNUMBER_POSIX) {\n            addPaxHeadersForBigNumbers(paxHeaders, entry);\n        } else if (bigNumberMode != BIGNUMBER_STAR) {\n            failForBigNumbers(entry);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath\n            && !ASCII.canEncode(entryName)) {\n            paxHeaders.put(\"path\", entryName);\n        }\n\n        if (addPaxHeadersForNonAsciiNames\n            && (entry.isLink() || entry.isSymbolicLink())\n            && !ASCII.canEncode(entry.getLinkName())) {\n            paxHeaders.put(\"linkpath\", entry.getLinkName());\n        }\n\n        if (paxHeaders.size() > 0) {\n            writePaxHeaders(entryName, paxHeaders);\n        }\n\n        entry.writeEntryHeader(recordBuf, encoding,\n                               bigNumberMode == BIGNUMBER_STAR);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entryName;\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Writes a PAX extended header with the given map as contents.\n     * @since 1.4\n     */\n    void writePaxHeaders(String entryName,\n                         Map<String, String> headers) throws IOException {\n        String name = \"./PaxHeaders.X/\" + stripTo7Bits(entryName);\n            // TarEntry's constructor would think this is a directory\n            // and not allow any data to be written\n        if (name.length() >= TarConstants.NAMELEN) {\n            name = name.substring(0, TarConstants.NAMELEN - 1);\n        }\n        TarArchiveEntry pex = new TarArchiveEntry(name,\n                                                  TarConstants.LF_PAX_EXTENDED_HEADER_LC);\n\n        StringWriter w = new StringWriter();\n        for (Map.Entry<String, String> h : headers.entrySet()) {\n            String key = h.getKey();\n            String value = h.getValue();\n            int len = key.length() + value.length()\n                + 3 /* blank, equals and newline */\n                + 2 /* guess 9 < actual length < 100 */;\n            String line = len + \" \" + key + \"=\" + value + \"\\n\";\n            int actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            while (len != actualLength) {\n                // Adjust for cases where length < 10 or > 100\n                // or where UTF-8 encoding isn't a single octet\n                // per character.\n                // Must be in loop as size may go from 99 to 100 in\n                // first pass so we'd need a second.\n                len = actualLength;\n                line = len + \" \" + key + \"=\" + value + \"\\n\";\n                actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            }\n            w.write(line);\n        }\n        byte[] data = w.toString().getBytes(CharsetNames.UTF_8);\n        pex.setSize(data.length);\n        putArchiveEntry(pex);\n        write(data);\n        closeArchiveEntry();\n    }\n\n    private String stripTo7Bits(String name) {\n        final int length = name.length();\n        StringBuffer result = new StringBuffer(length);\n        for (int i = 0; i < length; i++) {\n            char stripped = (char) (name.charAt(i) & 0x7F);\n            if (stripped != 0) { // would be read as Trailing null\n                result.append(stripped);\n            }\n        }\n        return result.toString();\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n\n    private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n                                            TarArchiveEntry entry) {\n        addPaxHeaderForBigNumber(paxHeaders, \"size\", entry.getSize(),\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"gid\", entry.getGroupId(),\n                                 TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"mtime\",\n                                 entry.getModTime().getTime() / 1000,\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"uid\", entry.getUserId(),\n                                 TarConstants.MAXID);\n        // star extensions by J\\u00f6rg Schilling\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devmajor\",\n                                 entry.getDevMajor(), TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devminor\",\n                                 entry.getDevMinor(), TarConstants.MAXID);\n        // there is no PAX header for file mode\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n    }\n\n    private void addPaxHeaderForBigNumber(Map<String, String> paxHeaders,\n                                          String header, long value,\n                                          long maxValue) {\n        if (value < 0 || value > maxValue) {\n            paxHeaders.put(header, String.valueOf(value));\n        }\n    }\n\n    private void failForBigNumbers(TarArchiveEntry entry) {\n        failForBigNumber(\"entry size\", entry.getSize(), TarConstants.MAXSIZE);\n        failForBigNumber(\"group id\", entry.getGroupId(), TarConstants.MAXID);\n        failForBigNumber(\"last modification time\",\n                         entry.getModTime().getTime() / 1000,\n                         TarConstants.MAXSIZE);\n        failForBigNumber(\"user id\", entry.getUserId(), TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n        failForBigNumber(\"major device number\", entry.getDevMajor(),\n                         TarConstants.MAXID);\n        failForBigNumber(\"minor device number\", entry.getDevMinor(),\n                         TarConstants.MAXID);\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue) {\n        if (value < 0 || value > maxValue) {\n            throw new RuntimeException(field + \" '\" + value\n                                       + \"' is too big ( > \"\n                                       + maxValue + \" )\");\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.StringWriter;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\nimport java.util.Map;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    /** POSIX/PAX extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_POSIX = 3;\n\n    /** Fail if a big number (e.g. size &gt; 8GiB) is required in the archive. */\n    public static final int BIGNUMBER_ERROR = 0;\n\n    /** star/GNU tar/BSD tar extensions are used to store big number in the archive. */\n    public static final int BIGNUMBER_STAR = 1;\n\n    /** POSIX/PAX extensions are used to store big numbers in the archive. */\n    public static final int BIGNUMBER_POSIX = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    protected final TarBuffer buffer;\n    private int       longFileMode = LONGFILE_ERROR;\n    private int       bigNumberMode = BIGNUMBER_ERROR;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished = false;\n\n    private final OutputStream out;\n\n    private final ZipEncoding encoding;\n\n    private boolean addPaxHeadersForNonAsciiNames = false;\n    private static final ZipEncoding ASCII =\n        ZipEncodingHelper.getZipEncoding(\"ASCII\");\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, String encoding) {\n        this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  String encoding) {\n        this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        this(os, blockSize, recordSize, null);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since Commons Compress 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  int recordSize, String encoding) {\n        out = new CountingOutputStream(os);\n        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        this.buffer = new TarBuffer(out, blockSize, recordSize);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n    /**\n     * Set the big number mode.\n     * This can be BIGNUMBER_ERROR(0), BIGNUMBER_POSIX(1) or BIGNUMBER_STAR(2).\n     * This specifies the treatment of big files (sizes &gt; TarConstants.MAXSIZE) and other numeric values to big to fit into a traditional tar header.\n     * Default is BIGNUMBER_ERROR.\n     * @param bigNumberMode the mode to use\n     * @since 1.4\n     */\n    public void setBigNumberMode(int bigNumberMode) {\n        this.bigNumberMode = bigNumberMode;\n    }\n\n    /**\n     * Whether to add a PAX extension header for non-ASCII file names.\n     * @since 1.4\n     */\n    public void setAddPaxHeadersForNonAsciiNames(boolean b) {\n        addPaxHeadersForNonAsciiNames = b;\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesWritten();\n    }\n\n    @Override\n    public long getBytesWritten() {\n        return ((CountingOutputStream) out).getBytesWritten();\n    }\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        buffer.flushBlock();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n\n        if (!closed) {\n            buffer.close();\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return buffer.getRecordSize();\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        Map<String, String> paxHeaders = new HashMap<String, String>();\n        final String entryName = entry.getName();\n        final ByteBuffer encodedName = encoding.encode(entryName);\n        final int nameLen = encodedName.limit() - encodedName.position();\n        boolean paxHeaderContainsPath = false;\n        if (nameLen >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_POSIX) {\n                paxHeaders.put(\"path\", entryName);\n                paxHeaderContainsPath = true;\n            } else if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the entry's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK,\n                                                                    TarConstants.LF_GNUTYPE_LONGNAME);\n\n                longLinkEntry.setSize(nameLen + 1); // +1 for NUL\n                putArchiveEntry(longLinkEntry);\n                write(encodedName.array(), encodedName.arrayOffset(), nameLen);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(\"file name '\" + entryName\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n\n        if (bigNumberMode == BIGNUMBER_POSIX) {\n            addPaxHeadersForBigNumbers(paxHeaders, entry);\n        } else if (bigNumberMode != BIGNUMBER_STAR) {\n            failForBigNumbers(entry);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath\n            && !ASCII.canEncode(entryName)) {\n            paxHeaders.put(\"path\", entryName);\n        }\n\n        if (addPaxHeadersForNonAsciiNames\n            && (entry.isLink() || entry.isSymbolicLink())\n            && !ASCII.canEncode(entry.getLinkName())) {\n            paxHeaders.put(\"linkpath\", entry.getLinkName());\n        }\n\n        if (paxHeaders.size() > 0) {\n            writePaxHeaders(entryName, paxHeaders);\n        }\n\n        entry.writeEntryHeader(recordBuf, encoding,\n                               bigNumberMode == BIGNUMBER_STAR);\n        buffer.writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entryName;\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            buffer.writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if ((currBytes + numToWrite) > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                buffer.writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            buffer.writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Writes a PAX extended header with the given map as contents.\n     * @since 1.4\n     */\n    void writePaxHeaders(String entryName,\n                         Map<String, String> headers) throws IOException {\n        String name = \"./PaxHeaders.X/\" + stripTo7Bits(entryName);\n        while (name.endsWith(\"/\")) {\n            // TarEntry's constructor would think this is a directory\n            // and not allow any data to be written\n            name = name.substring(0, name.length() - 1);\n        }\n        if (name.length() >= TarConstants.NAMELEN) {\n            name = name.substring(0, TarConstants.NAMELEN - 1);\n        }\n        TarArchiveEntry pex = new TarArchiveEntry(name,\n                                                  TarConstants.LF_PAX_EXTENDED_HEADER_LC);\n\n        StringWriter w = new StringWriter();\n        for (Map.Entry<String, String> h : headers.entrySet()) {\n            String key = h.getKey();\n            String value = h.getValue();\n            int len = key.length() + value.length()\n                + 3 /* blank, equals and newline */\n                + 2 /* guess 9 < actual length < 100 */;\n            String line = len + \" \" + key + \"=\" + value + \"\\n\";\n            int actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            while (len != actualLength) {\n                // Adjust for cases where length < 10 or > 100\n                // or where UTF-8 encoding isn't a single octet\n                // per character.\n                // Must be in loop as size may go from 99 to 100 in\n                // first pass so we'd need a second.\n                len = actualLength;\n                line = len + \" \" + key + \"=\" + value + \"\\n\";\n                actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            }\n            w.write(line);\n        }\n        byte[] data = w.toString().getBytes(CharsetNames.UTF_8);\n        pex.setSize(data.length);\n        putArchiveEntry(pex);\n        write(data);\n        closeArchiveEntry();\n    }\n\n    private String stripTo7Bits(String name) {\n        final int length = name.length();\n        StringBuffer result = new StringBuffer(length);\n        for (int i = 0; i < length; i++) {\n            char stripped = (char) (name.charAt(i) & 0x7F);\n            if (stripped != 0) { // would be read as Trailing null\n                result.append(stripped);\n            }\n        }\n        return result.toString();\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        for (int i = 0; i < recordBuf.length; ++i) {\n            recordBuf[i] = 0;\n        }\n\n        buffer.writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n\n    private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n                                            TarArchiveEntry entry) {\n        addPaxHeaderForBigNumber(paxHeaders, \"size\", entry.getSize(),\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"gid\", entry.getGroupId(),\n                                 TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"mtime\",\n                                 entry.getModTime().getTime() / 1000,\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"uid\", entry.getUserId(),\n                                 TarConstants.MAXID);\n        // star extensions by J\\u00f6rg Schilling\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devmajor\",\n                                 entry.getDevMajor(), TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devminor\",\n                                 entry.getDevMinor(), TarConstants.MAXID);\n        // there is no PAX header for file mode\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n    }\n\n    private void addPaxHeaderForBigNumber(Map<String, String> paxHeaders,\n                                          String header, long value,\n                                          long maxValue) {\n        if (value < 0 || value > maxValue) {\n            paxHeaders.put(header, String.valueOf(value));\n        }\n    }\n\n    private void failForBigNumbers(TarArchiveEntry entry) {\n        failForBigNumber(\"entry size\", entry.getSize(), TarConstants.MAXSIZE);\n        failForBigNumber(\"group id\", entry.getGroupId(), TarConstants.MAXID);\n        failForBigNumber(\"last modification time\",\n                         entry.getModTime().getTime() / 1000,\n                         TarConstants.MAXSIZE);\n        failForBigNumber(\"user id\", entry.getUserId(), TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n        failForBigNumber(\"major device number\", entry.getDevMajor(),\n                         TarConstants.MAXID);\n        failForBigNumber(\"minor device number\", entry.getDevMinor(),\n                         TarConstants.MAXID);\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue) {\n        if (value < 0 || value > maxValue) {\n            throw new RuntimeException(field + \" '\" + value\n                                       + \"' is too big ( > \"\n                                       + maxValue + \" )\");\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 19, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n\n/**\n * Holds size and other extended information for entries that use Zip64\n * features.\n *\n * <p>From {@link \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's APPNOTE.TXT\"}\n * <pre>\n * Zip64 Extended Information Extra Field (0x0001):\n *\n *          The following is the layout of the zip64 extended \n *          information \"extra\" block. If one of the size or\n *          offset fields in the Local or Central directory\n *          record is too small to hold the required data,\n *          a Zip64 extended information record is created.\n *          The order of the fields in the zip64 extended \n *          information record is fixed, but the fields will\n *          only appear if the corresponding Local or Central\n *          directory record field is set to 0xFFFF or 0xFFFFFFFF.\n *\n *          Note: all fields stored in Intel low-byte/high-byte order.\n *\n *          Value      Size       Description\n *          -----      ----       -----------\n *  (ZIP64) 0x0001     2 bytes    Tag for this \"extra\" block type\n *          Size       2 bytes    Size of this \"extra\" block\n *          Original \n *          Size       8 bytes    Original uncompressed file size\n *          Compressed\n *          Size       8 bytes    Size of compressed data\n *          Relative Header\n *          Offset     8 bytes    Offset of local header record\n *          Disk Start\n *          Number     4 bytes    Number of the disk on which\n *                                this file starts \n *\n *          This entry in the Local header must include BOTH original\n *          and compressed file size fields. If encrypting the \n *          central directory and bit 13 of the general purpose bit\n *          flag is set indicating masking, the value stored in the\n *          Local Header for the original file size will be zero.\n * </pre></p>\n *\n * <p>Currently Commons Compress doesn't support encrypting the\n * central directory so the note about masking doesn't apply.</p>\n *\n * <p>The implementation relies on data being read from the local file\n * header and assumes that both size values are always present.</p>\n *\n * @since 1.2\n * @NotThreadSafe\n */\npublic class Zip64ExtendedInformationExtraField implements ZipExtraField {\n\n    static final ZipShort HEADER_ID = new ZipShort(0x0001);\n\n    private static final String LFH_MUST_HAVE_BOTH_SIZES_MSG =\n        \"Zip64 extended information must contain\"\n        + \" both size values in the local file header.\";\n    private static final byte[] EMPTY = new byte[0];\n\n    private ZipEightByteInteger size, compressedSize, relativeHeaderOffset;\n    private ZipLong diskStart;\n\n    /**\n     * Stored in {@link #parseFromCentralDirectoryData\n     * parseFromCentralDirectoryData} so it can be reused when ZipFile\n     * calls {@link #reparseCentralDirectoryData\n     * reparseCentralDirectoryData}.\n     *\n     * <p>Not used for anything else</p>\n     *\n     * @since 1.3\n     */\n    private byte[] rawCentralDirectoryData;\n\n    /**\n     * This constructor should only be used by the code that reads\n     * archives inside of Commons Compress.\n     */\n    public Zip64ExtendedInformationExtraField() { }\n\n    /**\n     * Creates an extra field based on the original and compressed size.\n     *\n     * @param size the entry's original size\n     * @param compressedSize the entry's compressed size\n     *\n     * @throws IllegalArgumentException if size or compressedSize is null\n     */\n    public Zip64ExtendedInformationExtraField(ZipEightByteInteger size,\n                                              ZipEightByteInteger compressedSize) {\n        this(size, compressedSize, null, null);\n    }\n\n    /**\n     * Creates an extra field based on all four possible values.\n     *\n     * @param size the entry's original size\n     * @param compressedSize the entry's compressed size\n     *\n     * @throws IllegalArgumentException if size or compressedSize is null\n     */\n    public Zip64ExtendedInformationExtraField(ZipEightByteInteger size,\n                                              ZipEightByteInteger compressedSize,\n                                              ZipEightByteInteger relativeHeaderOffset,\n                                              ZipLong diskStart) {\n        this.size = size;\n        this.compressedSize = compressedSize;\n        this.relativeHeaderOffset = relativeHeaderOffset;\n        this.diskStart = diskStart;\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getLocalFileDataLength() {\n        return new ZipShort(size != null ? 2 * DWORD : 0);\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getCentralDirectoryLength() {\n        return new ZipShort((size != null ? DWORD : 0)\n                            + (compressedSize != null ? DWORD : 0)\n                            + (relativeHeaderOffset != null ? DWORD : 0)\n                            + (diskStart != null ? WORD : 0));\n    }\n\n    /** {@inheritDoc} */\n    public byte[] getLocalFileDataData() {\n        if (size != null || compressedSize != null) {\n            if (size == null || compressedSize == null) {\n                throw new IllegalArgumentException(LFH_MUST_HAVE_BOTH_SIZES_MSG);\n            }\n            byte[] data = new byte[2 * DWORD];\n            addSizes(data);\n            return data;\n        }\n        return EMPTY;\n    }\n\n    /** {@inheritDoc} */\n    public byte[] getCentralDirectoryData() {\n        byte[] data = new byte[getCentralDirectoryLength().getValue()];\n        int off = addSizes(data);\n        if (relativeHeaderOffset != null) {\n            System.arraycopy(relativeHeaderOffset.getBytes(), 0, data, off, DWORD);\n            off += DWORD;\n        }\n        if (diskStart != null) {\n            System.arraycopy(diskStart.getBytes(), 0, data, off, WORD);\n            off += WORD;\n        }\n        return data;\n    }\n\n    /** {@inheritDoc} */\n    public void parseFromLocalFileData(byte[] buffer, int offset, int length)\n        throws ZipException {\n        if (length == 0) {\n            // no local file data at all, may happen if an archive\n            // only holds a ZIP64 extended information extra field\n            // inside the central directory but not inside the local\n            // file header\n            return;\n        }\n        if (length < 2 * DWORD) {\n            throw new ZipException(LFH_MUST_HAVE_BOTH_SIZES_MSG);\n        }\n        size = new ZipEightByteInteger(buffer, offset);\n        offset += DWORD;\n        compressedSize = new ZipEightByteInteger(buffer, offset);\n        offset += DWORD;\n        int remaining = length - 2 * DWORD;\n        if (remaining >= DWORD) {\n            relativeHeaderOffset = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            remaining -= DWORD;\n        }\n        if (remaining >= WORD) {\n            diskStart = new ZipLong(buffer, offset);\n            offset += WORD;\n            remaining -= WORD;\n        }\n    }\n\n    /** {@inheritDoc} */\n    public void parseFromCentralDirectoryData(byte[] buffer, int offset,\n                                              int length)\n        throws ZipException {\n        // store for processing in reparseCentralDirectoryData\n        rawCentralDirectoryData = new byte[length];\n        System.arraycopy(buffer, offset, rawCentralDirectoryData, 0, length);\n\n        // if there is no size information in here, we are screwed and\n        // can only hope things will get resolved by LFH data later\n        // But there are some cases that can be detected\n        // * all data is there\n        // * length == 24 -> both sizes and offset\n        // * length % 8 == 4 -> at least we can identify the diskStart field\n        if (length >= 3 * DWORD + WORD) {\n            parseFromLocalFileData(buffer, offset, length);\n        } else if (length == 3 * DWORD) {\n            size = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            compressedSize = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            relativeHeaderOffset = new ZipEightByteInteger(buffer, offset);\n        } else if (length % DWORD == WORD) {\n            diskStart = new ZipLong(buffer, offset + length - WORD);\n        }\n    }\n\n    /**\n     * Parses the raw bytes read from the central directory extra\n     * field with knowledge which fields are expected to be there.\n     *\n     * <p>All four fields inside the zip64 extended information extra\n     * field are optional and must only be present if their corresponding\n     * entry inside the central directory contains the correct magic\n     * value.</p>\n     */\n    public void reparseCentralDirectoryData(boolean hasUncompressedSize,\n                                            boolean hasCompressedSize,\n                                            boolean hasRelativeHeaderOffset,\n                                            boolean hasDiskStart)\n        throws ZipException {\n        if (rawCentralDirectoryData != null) {\n            int expectedLength = (hasUncompressedSize ? DWORD : 0)\n                + (hasCompressedSize ? DWORD : 0)\n                + (hasRelativeHeaderOffset ? DWORD : 0)\n                + (hasDiskStart ? WORD : 0);\n            if (rawCentralDirectoryData.length != expectedLength) {\n                throw new ZipException(\"central directory zip64 extended\"\n                                       + \" information extra field's length\"\n                                       + \" doesn't match central directory\"\n                                       + \" data.  Expected length \"\n                                       + expectedLength + \" but is \"\n                                       + rawCentralDirectoryData.length);\n            }\n            int offset = 0;\n            if (hasUncompressedSize) {\n                size = new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasCompressedSize) {\n                compressedSize = new ZipEightByteInteger(rawCentralDirectoryData,\n                                                         offset);\n                offset += DWORD;\n            }\n            if (hasRelativeHeaderOffset) {\n                relativeHeaderOffset =\n                    new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasDiskStart) {\n                diskStart = new ZipLong(rawCentralDirectoryData, offset);\n                offset += WORD;\n            }\n        }\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public ZipEightByteInteger getSize() {\n        return size;\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public void setSize(ZipEightByteInteger size) {\n        this.size = size;\n    }\n\n    /**\n     * The compressed size stored in this extra field.\n     */\n    public ZipEightByteInteger getCompressedSize() {\n        return compressedSize;\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public void setCompressedSize(ZipEightByteInteger compressedSize) {\n        this.compressedSize = compressedSize;\n    }\n\n    /**\n     * The relative header offset stored in this extra field.\n     */\n    public ZipEightByteInteger getRelativeHeaderOffset() {\n        return relativeHeaderOffset;\n    }\n\n    /**\n     * The relative header offset stored in this extra field.\n     */\n    public void setRelativeHeaderOffset(ZipEightByteInteger rho) {\n        relativeHeaderOffset = rho;\n    }\n\n    /**\n     * The disk start number stored in this extra field.\n     */\n    public ZipLong getDiskStartNumber() {\n        return diskStart;\n    }\n\n    /**\n     * The disk start number stored in this extra field.\n     */\n    public void setDiskStartNumber(ZipLong ds) {\n        diskStart = ds;\n    }\n\n    private int addSizes(byte[] data) {\n        int off = 0;\n        if (size != null) {\n            System.arraycopy(size.getBytes(), 0, data, 0, DWORD);\n            off += DWORD;\n        }\n        if (compressedSize != null) {\n            System.arraycopy(compressedSize.getBytes(), 0, data, off, DWORD);\n            off += DWORD;\n        }\n        return off;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n\n/**\n * Holds size and other extended information for entries that use Zip64\n * features.\n *\n * <p>From {@link \"http://www.pkware.com/documents/casestudies/APPNOTE.TXT PKWARE's APPNOTE.TXT\"}\n * <pre>\n * Zip64 Extended Information Extra Field (0x0001):\n *\n *          The following is the layout of the zip64 extended \n *          information \"extra\" block. If one of the size or\n *          offset fields in the Local or Central directory\n *          record is too small to hold the required data,\n *          a Zip64 extended information record is created.\n *          The order of the fields in the zip64 extended \n *          information record is fixed, but the fields will\n *          only appear if the corresponding Local or Central\n *          directory record field is set to 0xFFFF or 0xFFFFFFFF.\n *\n *          Note: all fields stored in Intel low-byte/high-byte order.\n *\n *          Value      Size       Description\n *          -----      ----       -----------\n *  (ZIP64) 0x0001     2 bytes    Tag for this \"extra\" block type\n *          Size       2 bytes    Size of this \"extra\" block\n *          Original \n *          Size       8 bytes    Original uncompressed file size\n *          Compressed\n *          Size       8 bytes    Size of compressed data\n *          Relative Header\n *          Offset     8 bytes    Offset of local header record\n *          Disk Start\n *          Number     4 bytes    Number of the disk on which\n *                                this file starts \n *\n *          This entry in the Local header must include BOTH original\n *          and compressed file size fields. If encrypting the \n *          central directory and bit 13 of the general purpose bit\n *          flag is set indicating masking, the value stored in the\n *          Local Header for the original file size will be zero.\n * </pre></p>\n *\n * <p>Currently Commons Compress doesn't support encrypting the\n * central directory so the note about masking doesn't apply.</p>\n *\n * <p>The implementation relies on data being read from the local file\n * header and assumes that both size values are always present.</p>\n *\n * @since 1.2\n * @NotThreadSafe\n */\npublic class Zip64ExtendedInformationExtraField implements ZipExtraField {\n\n    static final ZipShort HEADER_ID = new ZipShort(0x0001);\n\n    private static final String LFH_MUST_HAVE_BOTH_SIZES_MSG =\n        \"Zip64 extended information must contain\"\n        + \" both size values in the local file header.\";\n    private static final byte[] EMPTY = new byte[0];\n\n    private ZipEightByteInteger size, compressedSize, relativeHeaderOffset;\n    private ZipLong diskStart;\n\n    /**\n     * Stored in {@link #parseFromCentralDirectoryData\n     * parseFromCentralDirectoryData} so it can be reused when ZipFile\n     * calls {@link #reparseCentralDirectoryData\n     * reparseCentralDirectoryData}.\n     *\n     * <p>Not used for anything else</p>\n     *\n     * @since 1.3\n     */\n    private byte[] rawCentralDirectoryData;\n\n    /**\n     * This constructor should only be used by the code that reads\n     * archives inside of Commons Compress.\n     */\n    public Zip64ExtendedInformationExtraField() { }\n\n    /**\n     * Creates an extra field based on the original and compressed size.\n     *\n     * @param size the entry's original size\n     * @param compressedSize the entry's compressed size\n     *\n     * @throws IllegalArgumentException if size or compressedSize is null\n     */\n    public Zip64ExtendedInformationExtraField(ZipEightByteInteger size,\n                                              ZipEightByteInteger compressedSize) {\n        this(size, compressedSize, null, null);\n    }\n\n    /**\n     * Creates an extra field based on all four possible values.\n     *\n     * @param size the entry's original size\n     * @param compressedSize the entry's compressed size\n     *\n     * @throws IllegalArgumentException if size or compressedSize is null\n     */\n    public Zip64ExtendedInformationExtraField(ZipEightByteInteger size,\n                                              ZipEightByteInteger compressedSize,\n                                              ZipEightByteInteger relativeHeaderOffset,\n                                              ZipLong diskStart) {\n        this.size = size;\n        this.compressedSize = compressedSize;\n        this.relativeHeaderOffset = relativeHeaderOffset;\n        this.diskStart = diskStart;\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getLocalFileDataLength() {\n        return new ZipShort(size != null ? 2 * DWORD : 0);\n    }\n\n    /** {@inheritDoc} */\n    public ZipShort getCentralDirectoryLength() {\n        return new ZipShort((size != null ? DWORD : 0)\n                            + (compressedSize != null ? DWORD : 0)\n                            + (relativeHeaderOffset != null ? DWORD : 0)\n                            + (diskStart != null ? WORD : 0));\n    }\n\n    /** {@inheritDoc} */\n    public byte[] getLocalFileDataData() {\n        if (size != null || compressedSize != null) {\n            if (size == null || compressedSize == null) {\n                throw new IllegalArgumentException(LFH_MUST_HAVE_BOTH_SIZES_MSG);\n            }\n            byte[] data = new byte[2 * DWORD];\n            addSizes(data);\n            return data;\n        }\n        return EMPTY;\n    }\n\n    /** {@inheritDoc} */\n    public byte[] getCentralDirectoryData() {\n        byte[] data = new byte[getCentralDirectoryLength().getValue()];\n        int off = addSizes(data);\n        if (relativeHeaderOffset != null) {\n            System.arraycopy(relativeHeaderOffset.getBytes(), 0, data, off, DWORD);\n            off += DWORD;\n        }\n        if (diskStart != null) {\n            System.arraycopy(diskStart.getBytes(), 0, data, off, WORD);\n            off += WORD;\n        }\n        return data;\n    }\n\n    /** {@inheritDoc} */\n    public void parseFromLocalFileData(byte[] buffer, int offset, int length)\n        throws ZipException {\n        if (length == 0) {\n            // no local file data at all, may happen if an archive\n            // only holds a ZIP64 extended information extra field\n            // inside the central directory but not inside the local\n            // file header\n            return;\n        }\n        if (length < 2 * DWORD) {\n            throw new ZipException(LFH_MUST_HAVE_BOTH_SIZES_MSG);\n        }\n        size = new ZipEightByteInteger(buffer, offset);\n        offset += DWORD;\n        compressedSize = new ZipEightByteInteger(buffer, offset);\n        offset += DWORD;\n        int remaining = length - 2 * DWORD;\n        if (remaining >= DWORD) {\n            relativeHeaderOffset = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            remaining -= DWORD;\n        }\n        if (remaining >= WORD) {\n            diskStart = new ZipLong(buffer, offset);\n            offset += WORD;\n            remaining -= WORD;\n        }\n    }\n\n    /** {@inheritDoc} */\n    public void parseFromCentralDirectoryData(byte[] buffer, int offset,\n                                              int length)\n        throws ZipException {\n        // store for processing in reparseCentralDirectoryData\n        rawCentralDirectoryData = new byte[length];\n        System.arraycopy(buffer, offset, rawCentralDirectoryData, 0, length);\n\n        // if there is no size information in here, we are screwed and\n        // can only hope things will get resolved by LFH data later\n        // But there are some cases that can be detected\n        // * all data is there\n        // * length == 24 -> both sizes and offset\n        // * length % 8 == 4 -> at least we can identify the diskStart field\n        if (length >= 3 * DWORD + WORD) {\n            parseFromLocalFileData(buffer, offset, length);\n        } else if (length == 3 * DWORD) {\n            size = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            compressedSize = new ZipEightByteInteger(buffer, offset);\n            offset += DWORD;\n            relativeHeaderOffset = new ZipEightByteInteger(buffer, offset);\n        } else if (length % DWORD == WORD) {\n            diskStart = new ZipLong(buffer, offset + length - WORD);\n        }\n    }\n\n    /**\n     * Parses the raw bytes read from the central directory extra\n     * field with knowledge which fields are expected to be there.\n     *\n     * <p>All four fields inside the zip64 extended information extra\n     * field are optional and must only be present if their corresponding\n     * entry inside the central directory contains the correct magic\n     * value.</p>\n     */\n    public void reparseCentralDirectoryData(boolean hasUncompressedSize,\n                                            boolean hasCompressedSize,\n                                            boolean hasRelativeHeaderOffset,\n                                            boolean hasDiskStart)\n        throws ZipException {\n        if (rawCentralDirectoryData != null) {\n            int expectedLength = (hasUncompressedSize ? DWORD : 0)\n                + (hasCompressedSize ? DWORD : 0)\n                + (hasRelativeHeaderOffset ? DWORD : 0)\n                + (hasDiskStart ? WORD : 0);\n            if (rawCentralDirectoryData.length < expectedLength) {\n                throw new ZipException(\"central directory zip64 extended\"\n                                       + \" information extra field's length\"\n                                       + \" doesn't match central directory\"\n                                       + \" data.  Expected length \"\n                                       + expectedLength + \" but is \"\n                                       + rawCentralDirectoryData.length);\n            }\n            int offset = 0;\n            if (hasUncompressedSize) {\n                size = new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasCompressedSize) {\n                compressedSize = new ZipEightByteInteger(rawCentralDirectoryData,\n                                                         offset);\n                offset += DWORD;\n            }\n            if (hasRelativeHeaderOffset) {\n                relativeHeaderOffset =\n                    new ZipEightByteInteger(rawCentralDirectoryData, offset);\n                offset += DWORD;\n            }\n            if (hasDiskStart) {\n                diskStart = new ZipLong(rawCentralDirectoryData, offset);\n                offset += WORD;\n            }\n        }\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public ZipEightByteInteger getSize() {\n        return size;\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public void setSize(ZipEightByteInteger size) {\n        this.size = size;\n    }\n\n    /**\n     * The compressed size stored in this extra field.\n     */\n    public ZipEightByteInteger getCompressedSize() {\n        return compressedSize;\n    }\n\n    /**\n     * The uncompressed size stored in this extra field.\n     */\n    public void setCompressedSize(ZipEightByteInteger compressedSize) {\n        this.compressedSize = compressedSize;\n    }\n\n    /**\n     * The relative header offset stored in this extra field.\n     */\n    public ZipEightByteInteger getRelativeHeaderOffset() {\n        return relativeHeaderOffset;\n    }\n\n    /**\n     * The relative header offset stored in this extra field.\n     */\n    public void setRelativeHeaderOffset(ZipEightByteInteger rho) {\n        relativeHeaderOffset = rho;\n    }\n\n    /**\n     * The disk start number stored in this extra field.\n     */\n    public ZipLong getDiskStartNumber() {\n        return diskStart;\n    }\n\n    /**\n     * The disk start number stored in this extra field.\n     */\n    public void setDiskStartNumber(ZipLong ds) {\n        diskStart = ds;\n    }\n\n    private int addSizes(byte[] data) {\n        int off = 0;\n        if (size != null) {\n            System.arraycopy(size.getBytes(), 0, data, 0, DWORD);\n            off += DWORD;\n        }\n        if (compressedSize != null) {\n            System.arraycopy(compressedSize.getBytes(), 0, data, off, DWORD);\n            off += DWORD;\n        }\n        return off;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 20, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * CPIOArchiveInputStream is a stream for reading cpio streams. All formats of\n * cpio are supported (old ascii, old binary, new portable format and the new\n * portable format with crc).\n * <p/>\n * <p/>\n * The stream can be read by extracting a cpio entry (containing all\n * informations about a entry) and afterwards reading from the stream the file\n * specified by the entry.\n * <p/>\n * <code><pre>\n * CPIOArchiveInputStream cpioIn = new CPIOArchiveInputStream(\n *         new FileInputStream(new File(&quot;test.cpio&quot;)));\n * CPIOArchiveEntry cpioEntry;\n * <p/>\n * while ((cpioEntry = cpioIn.getNextEntry()) != null) {\n *     System.out.println(cpioEntry.getName());\n *     int tmp;\n *     StringBuilder buf = new StringBuilder();\n *     while ((tmp = cpIn.read()) != -1) {\n *         buf.append((char) tmp);\n *     }\n *     System.out.println(buf.toString());\n * }\n * cpioIn.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered to be threadsafe.\n * \n * Based on code from the jRPM project (jrpm.sourceforge.net)\n */\n\npublic class CpioArchiveInputStream extends ArchiveInputStream implements\n        CpioConstants {\n\n    private boolean closed = false;\n\n    private CpioArchiveEntry entry;\n\n    private long entryBytesRead = 0;\n\n    private boolean entryEOF = false;\n\n    private final byte tmpbuf[] = new byte[4096];\n\n    private long crc = 0;\n\n    private final InputStream in;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] TWO_BYTES_BUF = new byte[2];\n    private final byte[] FOUR_BYTES_BUF = new byte[4];\n    private final byte[] SIX_BYTES_BUF = new byte[6];\n\n    private final int blockSize;\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     */\n    public CpioArchiveInputStream(final InputStream in) {\n        this(in, BLOCK_SIZE);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * Construct the cpio input stream.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @since 1.5\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize) {\n        this.in = in;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Returns 0 after EOF has reached for the current entry data, otherwise\n     * always return 1.\n     * <p/>\n     * Programs should not count on this method to return the actual number of\n     * bytes that could be read without blocking.\n     * \n     * @return 1 before EOF and 0 after EOF has reached for current entry.\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int available() throws IOException {\n        ensureOpen();\n        if (this.entryEOF) {\n            return 0;\n        }\n        return 1;\n    }\n\n    /**\n     * Closes the CPIO input stream.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if (!this.closed) {\n            in.close();\n            this.closed = true;\n        }\n    }\n\n    /**\n     * Closes the current CPIO entry and positions the stream for reading the\n     * next entry.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    private void closeEntry() throws IOException {\n        ensureOpen();\n        while (read(this.tmpbuf, 0, this.tmpbuf.length) != -1) { // NOPMD\n            // do nothing\n        }\n\n        this.entryEOF = true;\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Reads the next CPIO file entry and positions stream at the beginning of\n     * the entry data.\n     * \n     * @return the CPIOArchiveEntry just read\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public CpioArchiveEntry getNextCPIOEntry() throws IOException {\n        ensureOpen();\n        if (this.entry != null) {\n            closeEntry();\n        }\n        readFully(TWO_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n        if (CpioUtil.byteArray2long(TWO_BYTES_BUF, false) == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(false);\n        } else if (CpioUtil.byteArray2long(TWO_BYTES_BUF, true)\n                   == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(true);\n        } else {\n            System.arraycopy(TWO_BYTES_BUF, 0, SIX_BYTES_BUF, 0,\n                             TWO_BYTES_BUF.length);\n            readFully(SIX_BYTES_BUF, TWO_BYTES_BUF.length,\n                      FOUR_BYTES_BUF.length);\n            String magicString = ArchiveUtils.toAsciiString(SIX_BYTES_BUF);\n            if (magicString.equals(MAGIC_NEW)) {\n                this.entry = readNewEntry(false);\n            } else if (magicString.equals(MAGIC_NEW_CRC)) {\n                this.entry = readNewEntry(true);\n            } else if (magicString.equals(MAGIC_OLD_ASCII)) {\n                this.entry = readOldAsciiEntry();\n            } else {\n                throw new IOException(\"Unknown magic [\" + magicString + \"]. Occured at byte: \" + getBytesRead());\n            }\n        }\n\n        this.entryBytesRead = 0;\n        this.entryEOF = false;\n        this.crc = 0;\n\n        if (this.entry.getName().equals(CPIO_TRAILER)) {\n            this.entryEOF = true;\n            skipRemainderOfLastBlock();\n            return null;\n        }\n        return this.entry;\n    }\n\n    private void skip(int bytes) throws IOException{\n        // bytes cannot be more than 3 bytes\n        if (bytes > 0) {\n            readFully(FOUR_BYTES_BUF, 0, bytes);\n        }\n    }\n\n    /**\n     * Reads from the current CPIO entry into an array of bytes. Blocks until\n     * some input is available.\n     * \n     * @param b\n     *            the buffer into which the data is read\n     * @param off\n     *            the start offset of the data\n     * @param len\n     *            the maximum number of bytes read\n     * @return the actual number of bytes read, or -1 if the end of the entry is\n     *         reached\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n\n        if (this.entry == null || this.entryEOF) {\n            return -1;\n        }\n        if (this.entryBytesRead == this.entry.getSize()) {\n            skip(entry.getDataPadCount());\n            this.entryEOF = true;\n            if (this.entry.getFormat() == FORMAT_NEW_CRC\n                && this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error. Occured at byte: \"\n                                      + getBytesRead());\n            }\n            return -1; // EOF for this entry\n        }\n        int tmplength = (int) Math.min(len, this.entry.getSize()\n                - this.entryBytesRead);\n        if (tmplength < 0) {\n            return -1;\n        }\n\n        int tmpread = readFully(b, off, tmplength);\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < tmpread; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        this.entryBytesRead += tmpread;\n\n        return tmpread;\n    }\n\n    private final int readFully(final byte[] b, final int off, final int len)\n            throws IOException {\n        if (len < 0) {\n            throw new IndexOutOfBoundsException();\n        }\n        int n = 0;\n        while (n < len) {\n            int count = this.in.read(b, off + n, len - n);\n            count(count);\n            if (count < 0) {\n                throw new EOFException();\n            }\n            n += count;\n        }\n        return n;\n    }\n\n    private long readBinaryLong(final int length, final boolean swapHalfWord)\n            throws IOException {\n        byte tmp[] = new byte[length];\n        readFully(tmp, 0, tmp.length);\n        return CpioUtil.byteArray2long(tmp, swapHalfWord);\n    }\n\n    private long readAsciiLong(final int length, final int radix)\n            throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return Long.parseLong(ArchiveUtils.toAsciiString(tmpBuffer), radix);\n    }\n\n    private CpioArchiveEntry readNewEntry(final boolean hasCrc)\n            throws IOException {\n        CpioArchiveEntry ret;\n        if (hasCrc) {\n            ret = new CpioArchiveEntry(FORMAT_NEW_CRC);\n        } else {\n            ret = new CpioArchiveEntry(FORMAT_NEW);\n        }\n\n        ret.setInode(readAsciiLong(8, 16));\n        long mode = readAsciiLong(8, 16);\n        if (mode != 0){\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(8, 16));\n        ret.setGID(readAsciiLong(8, 16));\n        ret.setNumberOfLinks(readAsciiLong(8, 16));\n        ret.setTime(readAsciiLong(8, 16));\n        ret.setSize(readAsciiLong(8, 16));\n        ret.setDeviceMaj(readAsciiLong(8, 16));\n        ret.setDeviceMin(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMaj(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMin(readAsciiLong(8, 16));\n        long namesize = readAsciiLong(8, 16);\n        ret.setChksum(readAsciiLong(8, 16));\n        String name = readCString((int) namesize);\n        ret.setName(name);\n        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry name: \"+name + \" Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldAsciiEntry() throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_ASCII);\n\n        ret.setDevice(readAsciiLong(6, 8));\n        ret.setInode(readAsciiLong(6, 8));\n        final long mode = readAsciiLong(6, 8);\n        if (mode != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(6, 8));\n        ret.setGID(readAsciiLong(6, 8));\n        ret.setNumberOfLinks(readAsciiLong(6, 8));\n        ret.setRemoteDevice(readAsciiLong(6, 8));\n        ret.setTime(readAsciiLong(11, 8));\n        long namesize = readAsciiLong(6, 8);\n        ret.setSize(readAsciiLong(11, 8));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+ name + \" Occured at byte: \" + getBytesRead());\n        }\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldBinaryEntry(final boolean swapHalfWord)\n            throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_BINARY);\n\n        ret.setDevice(readBinaryLong(2, swapHalfWord));\n        ret.setInode(readBinaryLong(2, swapHalfWord));\n        final long mode = readBinaryLong(2, swapHalfWord);\n        if (mode != 0){\n            ret.setMode(mode);\n        }\n        ret.setUID(readBinaryLong(2, swapHalfWord));\n        ret.setGID(readBinaryLong(2, swapHalfWord));\n        ret.setNumberOfLinks(readBinaryLong(2, swapHalfWord));\n        ret.setRemoteDevice(readBinaryLong(2, swapHalfWord));\n        ret.setTime(readBinaryLong(4, swapHalfWord));\n        long namesize = readBinaryLong(2, swapHalfWord);\n        ret.setSize(readBinaryLong(4, swapHalfWord));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (mode == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+name + \"Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private String readCString(final int length) throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return new String(tmpBuffer, 0, tmpBuffer.length - 1); // TODO default charset?\n    }\n\n    /**\n     * Skips specified number of bytes in the current CPIO entry.\n     * \n     * @param n\n     *            the number of bytes to skip\n     * @return the actual number of bytes skipped\n     * @throws IOException\n     *             if an I/O error has occurred\n     * @throws IllegalArgumentException\n     *             if n < 0\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n < 0) {\n            throw new IllegalArgumentException(\"negative skip length\");\n        }\n        ensureOpen();\n        int max = (int) Math.min(n, Integer.MAX_VALUE);\n        int total = 0;\n\n        while (total < max) {\n            int len = max - total;\n            if (len > this.tmpbuf.length) {\n                len = this.tmpbuf.length;\n            }\n            len = read(this.tmpbuf, 0, len);\n            if (len == -1) {\n                this.entryEOF = true;\n                break;\n            }\n            total += len;\n        }\n        return total;\n    }\n\n    @Override\n    public CpioArchiveEntry getNextEntry() throws IOException {\n        return getNextCPIOEntry();\n    }\n\n    /**\n     * Skips the padding zeros written after the TRAILER!!! entry.\n     */\n    private void skipRemainderOfLastBlock() throws IOException {\n        long readFromLastBlock = getBytesRead() % blockSize;\n        long remainingBytes = readFromLastBlock == 0 ? 0\n            : blockSize - readFromLastBlock;\n        while (remainingBytes > 0) {\n            long skipped = skip(blockSize - readFromLastBlock);\n            if (skipped <= 0) {\n                break;\n            }\n            remainingBytes -= skipped;\n        }\n    }\n\n    /**\n     * Checks if the signature matches one of the following magic values:\n     * \n     * Strings:\n     *\n     * \"070701\" - MAGIC_NEW\n     * \"070702\" - MAGIC_NEW_CRC\n     * \"070707\" - MAGIC_OLD_ASCII\n     * \n     * Octal Binary value:\n     * \n     * 070707 - MAGIC_OLD_BINARY (held as a short) = 0x71C7 or 0xC771\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < 6) {\n            return false;\n        }\n\n        // Check binary values\n        if (signature[0] == 0x71 && (signature[1] & 0xFF) == 0xc7) {\n            return true;\n        }\n        if (signature[1] == 0x71 && (signature[0] & 0xFF) == 0xc7) {\n            return true;\n        }\n\n        // Check Ascii (String) values\n        // 3037 3037 30nn\n        if (signature[0] != 0x30) {\n            return false;\n        }\n        if (signature[1] != 0x37) {\n            return false;\n        }\n        if (signature[2] != 0x30) {\n            return false;\n        }\n        if (signature[3] != 0x37) {\n            return false;\n        }\n        if (signature[4] != 0x30) {\n            return false;\n        }\n        // Check last byte\n        if (signature[5] == 0x31) {\n            return true;\n        }\n        if (signature[5] == 0x32) {\n            return true;\n        }\n        if (signature[5] == 0x37) {\n            return true;\n        }\n\n        return false;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * CPIOArchiveInputStream is a stream for reading cpio streams. All formats of\n * cpio are supported (old ascii, old binary, new portable format and the new\n * portable format with crc).\n * <p/>\n * <p/>\n * The stream can be read by extracting a cpio entry (containing all\n * informations about a entry) and afterwards reading from the stream the file\n * specified by the entry.\n * <p/>\n * <code><pre>\n * CPIOArchiveInputStream cpioIn = new CPIOArchiveInputStream(\n *         new FileInputStream(new File(&quot;test.cpio&quot;)));\n * CPIOArchiveEntry cpioEntry;\n * <p/>\n * while ((cpioEntry = cpioIn.getNextEntry()) != null) {\n *     System.out.println(cpioEntry.getName());\n *     int tmp;\n *     StringBuilder buf = new StringBuilder();\n *     while ((tmp = cpIn.read()) != -1) {\n *         buf.append((char) tmp);\n *     }\n *     System.out.println(buf.toString());\n * }\n * cpioIn.close();\n * </pre></code>\n * <p/>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * This class uses mutable fields and is not considered to be threadsafe.\n * \n * Based on code from the jRPM project (jrpm.sourceforge.net)\n */\n\npublic class CpioArchiveInputStream extends ArchiveInputStream implements\n        CpioConstants {\n\n    private boolean closed = false;\n\n    private CpioArchiveEntry entry;\n\n    private long entryBytesRead = 0;\n\n    private boolean entryEOF = false;\n\n    private final byte tmpbuf[] = new byte[4096];\n\n    private long crc = 0;\n\n    private final InputStream in;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] TWO_BYTES_BUF = new byte[2];\n    private final byte[] FOUR_BYTES_BUF = new byte[4];\n    private final byte[] SIX_BYTES_BUF = new byte[6];\n\n    private final int blockSize;\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     */\n    public CpioArchiveInputStream(final InputStream in) {\n        this(in, BLOCK_SIZE);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * Construct the cpio input stream.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @since 1.5\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize) {\n        this.in = in;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Returns 0 after EOF has reached for the current entry data, otherwise\n     * always return 1.\n     * <p/>\n     * Programs should not count on this method to return the actual number of\n     * bytes that could be read without blocking.\n     * \n     * @return 1 before EOF and 0 after EOF has reached for current entry.\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int available() throws IOException {\n        ensureOpen();\n        if (this.entryEOF) {\n            return 0;\n        }\n        return 1;\n    }\n\n    /**\n     * Closes the CPIO input stream.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if (!this.closed) {\n            in.close();\n            this.closed = true;\n        }\n    }\n\n    /**\n     * Closes the current CPIO entry and positions the stream for reading the\n     * next entry.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    private void closeEntry() throws IOException {\n        ensureOpen();\n        while (read(this.tmpbuf, 0, this.tmpbuf.length) != -1) { // NOPMD\n            // do nothing\n        }\n\n        this.entryEOF = true;\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Reads the next CPIO file entry and positions stream at the beginning of\n     * the entry data.\n     * \n     * @return the CPIOArchiveEntry just read\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public CpioArchiveEntry getNextCPIOEntry() throws IOException {\n        ensureOpen();\n        if (this.entry != null) {\n            closeEntry();\n        }\n        readFully(TWO_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n        if (CpioUtil.byteArray2long(TWO_BYTES_BUF, false) == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(false);\n        } else if (CpioUtil.byteArray2long(TWO_BYTES_BUF, true)\n                   == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(true);\n        } else {\n            System.arraycopy(TWO_BYTES_BUF, 0, SIX_BYTES_BUF, 0,\n                             TWO_BYTES_BUF.length);\n            readFully(SIX_BYTES_BUF, TWO_BYTES_BUF.length,\n                      FOUR_BYTES_BUF.length);\n            String magicString = ArchiveUtils.toAsciiString(SIX_BYTES_BUF);\n            if (magicString.equals(MAGIC_NEW)) {\n                this.entry = readNewEntry(false);\n            } else if (magicString.equals(MAGIC_NEW_CRC)) {\n                this.entry = readNewEntry(true);\n            } else if (magicString.equals(MAGIC_OLD_ASCII)) {\n                this.entry = readOldAsciiEntry();\n            } else {\n                throw new IOException(\"Unknown magic [\" + magicString + \"]. Occured at byte: \" + getBytesRead());\n            }\n        }\n\n        this.entryBytesRead = 0;\n        this.entryEOF = false;\n        this.crc = 0;\n\n        if (this.entry.getName().equals(CPIO_TRAILER)) {\n            this.entryEOF = true;\n            skipRemainderOfLastBlock();\n            return null;\n        }\n        return this.entry;\n    }\n\n    private void skip(int bytes) throws IOException{\n        // bytes cannot be more than 3 bytes\n        if (bytes > 0) {\n            readFully(FOUR_BYTES_BUF, 0, bytes);\n        }\n    }\n\n    /**\n     * Reads from the current CPIO entry into an array of bytes. Blocks until\n     * some input is available.\n     * \n     * @param b\n     *            the buffer into which the data is read\n     * @param off\n     *            the start offset of the data\n     * @param len\n     *            the maximum number of bytes read\n     * @return the actual number of bytes read, or -1 if the end of the entry is\n     *         reached\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n\n        if (this.entry == null || this.entryEOF) {\n            return -1;\n        }\n        if (this.entryBytesRead == this.entry.getSize()) {\n            skip(entry.getDataPadCount());\n            this.entryEOF = true;\n            if (this.entry.getFormat() == FORMAT_NEW_CRC\n                && this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error. Occured at byte: \"\n                                      + getBytesRead());\n            }\n            return -1; // EOF for this entry\n        }\n        int tmplength = (int) Math.min(len, this.entry.getSize()\n                - this.entryBytesRead);\n        if (tmplength < 0) {\n            return -1;\n        }\n\n        int tmpread = readFully(b, off, tmplength);\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < tmpread; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        this.entryBytesRead += tmpread;\n\n        return tmpread;\n    }\n\n    private final int readFully(final byte[] b, final int off, final int len)\n            throws IOException {\n        if (len < 0) {\n            throw new IndexOutOfBoundsException();\n        }\n        int n = 0;\n        while (n < len) {\n            int count = this.in.read(b, off + n, len - n);\n            count(count);\n            if (count < 0) {\n                throw new EOFException();\n            }\n            n += count;\n        }\n        return n;\n    }\n\n    private long readBinaryLong(final int length, final boolean swapHalfWord)\n            throws IOException {\n        byte tmp[] = new byte[length];\n        readFully(tmp, 0, tmp.length);\n        return CpioUtil.byteArray2long(tmp, swapHalfWord);\n    }\n\n    private long readAsciiLong(final int length, final int radix)\n            throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return Long.parseLong(ArchiveUtils.toAsciiString(tmpBuffer), radix);\n    }\n\n    private CpioArchiveEntry readNewEntry(final boolean hasCrc)\n            throws IOException {\n        CpioArchiveEntry ret;\n        if (hasCrc) {\n            ret = new CpioArchiveEntry(FORMAT_NEW_CRC);\n        } else {\n            ret = new CpioArchiveEntry(FORMAT_NEW);\n        }\n\n        ret.setInode(readAsciiLong(8, 16));\n        long mode = readAsciiLong(8, 16);\n        if (CpioUtil.fileType(mode) != 0){ // mode is initialised to 0\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(8, 16));\n        ret.setGID(readAsciiLong(8, 16));\n        ret.setNumberOfLinks(readAsciiLong(8, 16));\n        ret.setTime(readAsciiLong(8, 16));\n        ret.setSize(readAsciiLong(8, 16));\n        ret.setDeviceMaj(readAsciiLong(8, 16));\n        ret.setDeviceMin(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMaj(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMin(readAsciiLong(8, 16));\n        long namesize = readAsciiLong(8, 16);\n        ret.setChksum(readAsciiLong(8, 16));\n        String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry name: \"+name + \" Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldAsciiEntry() throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_ASCII);\n\n        ret.setDevice(readAsciiLong(6, 8));\n        ret.setInode(readAsciiLong(6, 8));\n        final long mode = readAsciiLong(6, 8);\n        if (CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(6, 8));\n        ret.setGID(readAsciiLong(6, 8));\n        ret.setNumberOfLinks(readAsciiLong(6, 8));\n        ret.setRemoteDevice(readAsciiLong(6, 8));\n        ret.setTime(readAsciiLong(11, 8));\n        long namesize = readAsciiLong(6, 8);\n        ret.setSize(readAsciiLong(11, 8));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+ name + \" Occured at byte: \" + getBytesRead());\n        }\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldBinaryEntry(final boolean swapHalfWord)\n            throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_BINARY);\n\n        ret.setDevice(readBinaryLong(2, swapHalfWord));\n        ret.setInode(readBinaryLong(2, swapHalfWord));\n        final long mode = readBinaryLong(2, swapHalfWord);\n        if (CpioUtil.fileType(mode) != 0){\n            ret.setMode(mode);\n        }\n        ret.setUID(readBinaryLong(2, swapHalfWord));\n        ret.setGID(readBinaryLong(2, swapHalfWord));\n        ret.setNumberOfLinks(readBinaryLong(2, swapHalfWord));\n        ret.setRemoteDevice(readBinaryLong(2, swapHalfWord));\n        ret.setTime(readBinaryLong(4, swapHalfWord));\n        long namesize = readBinaryLong(2, swapHalfWord);\n        ret.setSize(readBinaryLong(4, swapHalfWord));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+name + \"Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private String readCString(final int length) throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return new String(tmpBuffer, 0, tmpBuffer.length - 1); // TODO default charset?\n    }\n\n    /**\n     * Skips specified number of bytes in the current CPIO entry.\n     * \n     * @param n\n     *            the number of bytes to skip\n     * @return the actual number of bytes skipped\n     * @throws IOException\n     *             if an I/O error has occurred\n     * @throws IllegalArgumentException\n     *             if n < 0\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n < 0) {\n            throw new IllegalArgumentException(\"negative skip length\");\n        }\n        ensureOpen();\n        int max = (int) Math.min(n, Integer.MAX_VALUE);\n        int total = 0;\n\n        while (total < max) {\n            int len = max - total;\n            if (len > this.tmpbuf.length) {\n                len = this.tmpbuf.length;\n            }\n            len = read(this.tmpbuf, 0, len);\n            if (len == -1) {\n                this.entryEOF = true;\n                break;\n            }\n            total += len;\n        }\n        return total;\n    }\n\n    @Override\n    public CpioArchiveEntry getNextEntry() throws IOException {\n        return getNextCPIOEntry();\n    }\n\n    /**\n     * Skips the padding zeros written after the TRAILER!!! entry.\n     */\n    private void skipRemainderOfLastBlock() throws IOException {\n        long readFromLastBlock = getBytesRead() % blockSize;\n        long remainingBytes = readFromLastBlock == 0 ? 0\n            : blockSize - readFromLastBlock;\n        while (remainingBytes > 0) {\n            long skipped = skip(blockSize - readFromLastBlock);\n            if (skipped <= 0) {\n                break;\n            }\n            remainingBytes -= skipped;\n        }\n    }\n\n    /**\n     * Checks if the signature matches one of the following magic values:\n     * \n     * Strings:\n     *\n     * \"070701\" - MAGIC_NEW\n     * \"070702\" - MAGIC_NEW_CRC\n     * \"070707\" - MAGIC_OLD_ASCII\n     * \n     * Octal Binary value:\n     * \n     * 070707 - MAGIC_OLD_BINARY (held as a short) = 0x71C7 or 0xC771\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < 6) {\n            return false;\n        }\n\n        // Check binary values\n        if (signature[0] == 0x71 && (signature[1] & 0xFF) == 0xc7) {\n            return true;\n        }\n        if (signature[1] == 0x71 && (signature[0] & 0xFF) == 0xc7) {\n            return true;\n        }\n\n        // Check Ascii (String) values\n        // 3037 3037 30nn\n        if (signature[0] != 0x30) {\n            return false;\n        }\n        if (signature[1] != 0x37) {\n            return false;\n        }\n        if (signature[2] != 0x30) {\n            return false;\n        }\n        if (signature[3] != 0x37) {\n            return false;\n        }\n        if (signature[4] != 0x30) {\n            return false;\n        }\n        // Check last byte\n        if (signature[5] == 0x31) {\n            return true;\n        }\n        if (signature[5] == 0x32) {\n            return true;\n        }\n        if (signature[5] == 0x37) {\n            return true;\n        }\n\n        return false;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 21, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.sevenz.SevenZOutputFile", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.DataOutput;\nimport java.io.DataOutputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.RandomAccessFile;\nimport java.util.ArrayList;\nimport java.util.BitSet;\nimport java.util.Date;\nimport java.util.List;\nimport java.util.zip.CRC32;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * Writes a 7z file.\n * @since 1.6\n */\npublic class SevenZOutputFile {\n    private final RandomAccessFile file;\n    private final List<SevenZArchiveEntry> files = new ArrayList<SevenZArchiveEntry>();\n    private int numNonEmptyStreams = 0;\n    private CRC32 crc32 = new CRC32();\n    private CRC32 compressedCrc32 = new CRC32();\n    private long fileBytesWritten = 0;\n    private boolean finished = false;\n    private CountingOutputStream currentOutputStream;\n    private SevenZMethod contentCompression = SevenZMethod.LZMA2;\n    \n    /**\n     * Opens file to write a 7z archive to.\n     *\n     * @param filename name of the file to write to\n     * @throws IOException if opening the file fails\n     */\n    public SevenZOutputFile(final File filename) throws IOException {\n        file = new RandomAccessFile(filename, \"rw\");\n        file.seek(SevenZFile.SIGNATURE_HEADER_SIZE);\n    }\n    \n    /**\n     * Sets the compression method to use for entry contents - the\n     * default is LZMA2.\n     *\n     * <p>Currently only {@link SevenZMethod#COPY}, {@link\n     * SevenZMethod#LZMA2}, {@link SevenZMethod#BZIP2} and {@link\n     * SevenZMethod#DEFLATE} are supported.</p>\n     */\n    public void setContentCompression(SevenZMethod method) {\n        this.contentCompression = method;\n    }\n\n    /**\n     * Closes the archive, calling {@link #finish} if necessary.\n     * \n     * @throws IOException\n     */\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n        file.close();\n    }\n    \n    /**\n     * Create an archive entry using the inputFile and entryName provided.\n     * \n     * @param inputFile\n     * @param entryName \n     * @return the ArchiveEntry set up with details from the file\n     * \n     * @throws IOException\n     */\n    public SevenZArchiveEntry createArchiveEntry(final File inputFile,\n            final String entryName) throws IOException {\n        final SevenZArchiveEntry entry = new SevenZArchiveEntry();\n        entry.setDirectory(inputFile.isDirectory());\n        entry.setName(entryName);\n        entry.setLastModifiedDate(new Date(inputFile.lastModified()));\n        return entry;\n    }\n\n    /**\n     * Records an archive entry to add.\n     *\n     * The caller must then write the content to the archive and call\n     * {@link #closeArchiveEntry()} to complete the process.\n     * \n     * @param archiveEntry describes the entry\n     * @throws IOException\n     */\n    public void putArchiveEntry(final ArchiveEntry archiveEntry) throws IOException {\n        final SevenZArchiveEntry entry = (SevenZArchiveEntry) archiveEntry;\n        files.add(entry);\n    }\n    \n    /**\n     * Closes the archive entry.\n     * @throws IOException\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (currentOutputStream != null) {\n            currentOutputStream.flush();\n            currentOutputStream.close();\n        }\n\n        final SevenZArchiveEntry entry = files.get(files.size() - 1);\n        if (fileBytesWritten > 0) {\n            entry.setHasStream(true);\n            ++numNonEmptyStreams;\n            entry.setSize(currentOutputStream.getBytesWritten());\n            entry.setCompressedSize(fileBytesWritten);\n            entry.setCrcValue(crc32.getValue());\n            entry.setCompressedCrcValue(compressedCrc32.getValue());\n            entry.setHasCrc(true);\n        } else {\n            entry.setHasStream(false);\n            entry.setSize(0);\n            entry.setCompressedSize(0);\n            entry.setHasCrc(false);\n        }\n        currentOutputStream = null;\n        crc32.reset();\n        compressedCrc32.reset();\n        fileBytesWritten = 0;\n    }\n    \n    /**\n     * Writes a byte to the current archive entry.\n     * @param b The byte to be written.\n     * @throws IOException on error\n     */\n    public void write(final int b) throws IOException {\n        getCurrentOutputStream().write(b);\n    }\n    \n    /**\n     * Writes a byte array to the current archive entry.\n     * @param b The byte array to be written.\n     * @throws IOException on error\n     */\n    public void write(final byte[] b) throws IOException {\n        write(b, 0, b.length);\n    }\n    \n    /**\n     * Writes part of a byte array to the current archive entry.\n     * @param b The byte array to be written.\n     * @param off offset into the array to start writing from\n     * @param len number of bytes to write\n     * @throws IOException on error\n     */\n    public void write(final byte[] b, final int off, final int len) throws IOException {\n        if (len > 0) {\n            getCurrentOutputStream().write(b, off, len);\n        }\n    }\n    \n    /**\n     * Finishes the addition of entries to this archive, without closing it.\n     * \n     * @throws IOException if archive is already closed.\n     */\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n        finished = true;\n        \n        final long headerPosition = file.getFilePointer();\n        \n        final ByteArrayOutputStream headerBaos = new ByteArrayOutputStream();\n        final DataOutputStream header = new DataOutputStream(headerBaos);\n        \n        writeHeader(header);\n        header.flush();\n        final byte[] headerBytes = headerBaos.toByteArray();\n        file.write(headerBytes);\n        \n        final CRC32 crc32 = new CRC32();\n        \n        // signature header\n        file.seek(0);\n        file.write(SevenZFile.sevenZSignature);\n        // version\n        file.write(0);\n        file.write(2);\n        \n        // start header\n        final ByteArrayOutputStream startHeaderBaos = new ByteArrayOutputStream();\n        final DataOutputStream startHeaderStream = new DataOutputStream(startHeaderBaos);\n        startHeaderStream.writeLong(Long.reverseBytes(headerPosition - SevenZFile.SIGNATURE_HEADER_SIZE));\n        startHeaderStream.writeLong(Long.reverseBytes(0xffffFFFFL & headerBytes.length));\n        crc32.reset();\n        crc32.update(headerBytes);\n        startHeaderStream.writeInt(Integer.reverseBytes((int)crc32.getValue()));\n        startHeaderStream.flush();\n        final byte[] startHeaderBytes = startHeaderBaos.toByteArray();\n        crc32.reset();\n        crc32.update(startHeaderBytes);\n        file.writeInt(Integer.reverseBytes((int) crc32.getValue()));\n        file.write(startHeaderBytes);\n    }\n    \n    /*\n     * Creation of output stream is deferred until data is actually\n     * written as some codecs might write header information even for\n     * empty streams and directories otherwise.\n     */\n    private OutputStream getCurrentOutputStream() throws IOException {\n        if (currentOutputStream == null) {\n            currentOutputStream = setupFileOutputStream();\n        }\n        return currentOutputStream;\n    }\n\n    private CountingOutputStream setupFileOutputStream() throws IOException {\n        OutputStream out = new OutputStreamWrapper();\n        return new CountingOutputStream(Coders\n                                        .addEncoder(out,\n                                                    contentCompression,\n                                                    null)) {\n            @Override\n            public void write(final int b) throws IOException {\n                super.write(b);\n                crc32.update(b);\n            }\n    \n            @Override\n            public void write(final byte[] b) throws IOException {\n                super.write(b);\n                crc32.update(b);\n            }\n    \n            @Override\n            public void write(final byte[] b, final int off, final int len)\n                throws IOException {\n                super.write(b, off, len);\n                crc32.update(b, off, len);\n            }\n        };\n    }\n\n    private void writeHeader(final DataOutput header) throws IOException {\n        header.write(NID.kHeader);\n        \n        header.write(NID.kMainStreamsInfo);\n        writeStreamsInfo(header);\n        writeFilesInfo(header);\n        header.write(NID.kEnd);\n    }\n    \n    private void writeStreamsInfo(final DataOutput header) throws IOException {\n        if (numNonEmptyStreams > 0) {\n            writePackInfo(header);\n            writeUnpackInfo(header);\n        }\n        \n        writeSubStreamsInfo(header);\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writePackInfo(final DataOutput header) throws IOException {\n        header.write(NID.kPackInfo);\n        \n        writeUint64(header, 0);\n        writeUint64(header, 0xffffFFFFL & numNonEmptyStreams);\n        \n        header.write(NID.kSize);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                writeUint64(header, entry.getCompressedSize());\n            }\n        }\n        \n        header.write(NID.kCRC);\n        header.write(1);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                header.writeInt(Integer.reverseBytes((int) entry.getCompressedCrcValue()));\n            }\n        }\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeUnpackInfo(final DataOutput header) throws IOException {\n        header.write(NID.kUnpackInfo);\n        \n        header.write(NID.kFolder);\n        writeUint64(header, numNonEmptyStreams);\n        header.write(0);\n        for (int i = 0; i < numNonEmptyStreams; i++) {\n            writeFolder(header);\n        }\n        \n        header.write(NID.kCodersUnpackSize);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                writeUint64(header, entry.getSize());\n            }\n        }\n        \n        header.write(NID.kCRC);\n        header.write(1);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                header.writeInt(Integer.reverseBytes((int) entry.getCrcValue()));\n            }\n        }\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeFolder(final DataOutput header) throws IOException {\n        // one coder\n        writeUint64(header, 1);\n        byte[] id = contentCompression.getId();\n        byte[] properties = contentCompression.getProperties();\n\n        int codecFlags = id.length;\n        if (properties.length > 0) {\n            codecFlags |= 0x20;\n        }\n        header.write(codecFlags);\n        header.write(id);\n\n        if (properties.length > 0) {\n            header.write(properties.length);\n            header.write(properties);\n        }\n    }\n    \n    private void writeSubStreamsInfo(final DataOutput header) throws IOException {\n        header.write(NID.kSubStreamsInfo);\n//        \n//        header.write(NID.kCRC);\n//        header.write(1);\n//        for (final SevenZArchiveEntry entry : files) {\n//            if (entry.getHasCrc()) {\n//                header.writeInt(Integer.reverseBytes(entry.getCrc()));\n//            }\n//        }\n//        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeFilesInfo(final DataOutput header) throws IOException {\n        header.write(NID.kFilesInfo);\n        \n        writeUint64(header, files.size());\n\n        writeFileEmptyStreams(header);\n        writeFileEmptyFiles(header);\n        writeFileAntiItems(header);\n        writeFileNames(header);\n        writeFileCTimes(header);\n        writeFileATimes(header);\n        writeFileMTimes(header);\n        writeFileWindowsAttributes(header);\n        header.write(0);\n    }\n    \n    private void writeFileEmptyStreams(final DataOutput header) throws IOException {\n        boolean hasEmptyStreams = false;\n        for (final SevenZArchiveEntry entry : files) {\n            if (!entry.hasStream()) {\n                hasEmptyStreams = true;\n                break;\n            }\n        }\n        if (hasEmptyStreams) {\n            header.write(NID.kEmptyStream);\n            final BitSet emptyStreams = new BitSet(files.size());\n            for (int i = 0; i < files.size(); i++) {\n                emptyStreams.set(i, !files.get(i).hasStream());\n            }\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, emptyStreams, files.size());\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileEmptyFiles(final DataOutput header) throws IOException {\n        boolean hasEmptyFiles = false;\n        int emptyStreamCounter = 0;\n        final BitSet emptyFiles = new BitSet(0);\n        for (int i = 0; i < files.size(); i++) {\n            if (!files.get(i).hasStream()) {\n                boolean isDir = files.get(i).isDirectory();\n                emptyFiles.set(emptyStreamCounter++, !isDir);\n                hasEmptyFiles |= !isDir;\n            }\n        }\n        if (hasEmptyFiles) {\n            header.write(NID.kEmptyFile);\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, emptyFiles, emptyStreamCounter);\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileAntiItems(final DataOutput header) throws IOException {\n        boolean hasAntiItems = false;\n        final BitSet antiItems = new BitSet(0);\n        int antiItemCounter = 0;\n        for (int i = 0; i < files.size(); i++) {\n            if (!files.get(i).hasStream()) {\n                boolean isAnti = files.get(i).isAntiItem();\n                antiItems.set(antiItemCounter++, isAnti);\n                hasAntiItems |= isAnti;\n            }\n        }\n        if (hasAntiItems) {\n            header.write(NID.kAnti);\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, antiItems, antiItemCounter);\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileNames(final DataOutput header) throws IOException {\n        header.write(NID.kName);\n        \n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final DataOutputStream out = new DataOutputStream(baos);\n        out.write(0);\n        for (final SevenZArchiveEntry entry : files) {\n            out.write(entry.getName().getBytes(\"UTF-16LE\"));\n            out.writeShort(0);\n        }\n        out.flush();\n        final byte[] contents = baos.toByteArray();\n        writeUint64(header, contents.length);\n        header.write(contents);\n    }\n\n    private void writeFileCTimes(final DataOutput header) throws IOException {\n        int numCreationDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasCreationDate()) {\n                ++numCreationDates;\n            }\n        }\n        if (numCreationDates > 0) {\n            header.write(NID.kCTime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numCreationDates != files.size()) {\n                out.write(0);\n                final BitSet cTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    cTimes.set(i, files.get(i).getHasCreationDate());\n                }\n                writeBits(out, cTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasCreationDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getCreationDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileATimes(final DataOutput header) throws IOException {\n        int numAccessDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasAccessDate()) {\n                ++numAccessDates;\n            }\n        }\n        if (numAccessDates > 0) {\n            header.write(NID.kATime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numAccessDates != files.size()) {\n                out.write(0);\n                final BitSet aTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    aTimes.set(i, files.get(i).getHasAccessDate());\n                }\n                writeBits(out, aTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasAccessDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getAccessDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileMTimes(final DataOutput header) throws IOException {\n        int numLastModifiedDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasLastModifiedDate()) {\n                ++numLastModifiedDates;\n            }\n        }\n        if (numLastModifiedDates > 0) {\n            header.write(NID.kMTime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numLastModifiedDates != files.size()) {\n                out.write(0);\n                final BitSet mTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    mTimes.set(i, files.get(i).getHasLastModifiedDate());\n                }\n                writeBits(out, mTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasLastModifiedDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getLastModifiedDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileWindowsAttributes(final DataOutput header) throws IOException {\n        int numWindowsAttributes = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasWindowsAttributes()) {\n                ++numWindowsAttributes;\n            }\n        }\n        if (numWindowsAttributes > 0) {\n            header.write(NID.kWinAttributes);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numWindowsAttributes != files.size()) {\n                out.write(0);\n                final BitSet attributes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    attributes.set(i, files.get(i).getHasWindowsAttributes());\n                }\n                writeBits(out, attributes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasWindowsAttributes()) {\n                    out.writeInt(Integer.reverseBytes(entry.getWindowsAttributes()));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeUint64(final DataOutput header, long value) throws IOException {\n        int firstByte = 0;\n        int mask = 0x80;\n        int i;\n        for (i = 0; i < 8; i++) {\n            if (value < ((1L << ( 7  * (i + 1))))) {\n                firstByte |= (value >>> (8 * i));\n                break;\n            }\n            firstByte |= mask;\n            mask >>>= 1;\n        }\n        header.write(firstByte);\n        for (; i > 0; i--) {\n            header.write((int) (0xff & value));\n            value >>>= 8;\n        }\n    }\n\n    private void writeBits(final DataOutput header, final BitSet bits, final int length) throws IOException {\n        int cache = 0;\n        int shift = 7;\n        for (int i = 0; i < length; i++) {\n            cache |= ((bits.get(i) ? 1 : 0) << shift);\n            --shift;\n            if (shift == 0) {\n                header.write(cache);\n                shift = 7;\n                cache = 0;\n            }\n        }\n        if (length > 0 && shift > 0) {\n            header.write(cache);\n        }\n    }\n\n    private class OutputStreamWrapper extends OutputStream {\n        @Override\n        public void write(final int b) throws IOException {\n            file.write(b);\n            compressedCrc32.update(b);\n            fileBytesWritten++;\n        }\n    \n        @Override\n        public void write(final byte[] b) throws IOException {\n            OutputStreamWrapper.this.write(b, 0, b.length);\n        }\n    \n        @Override\n        public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n            file.write(b, off, len);\n            compressedCrc32.update(b, off, len);\n            fileBytesWritten += len;\n        }\n\n        @Override\n        public void flush() throws IOException {\n            // no reason to flush a RandomAccessFile\n        }\n\n        @Override\n        public void close() throws IOException {\n            // the file will be closed by the containing class's close method\n        }\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.DataOutput;\nimport java.io.DataOutputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.RandomAccessFile;\nimport java.util.ArrayList;\nimport java.util.BitSet;\nimport java.util.Date;\nimport java.util.List;\nimport java.util.zip.CRC32;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * Writes a 7z file.\n * @since 1.6\n */\npublic class SevenZOutputFile {\n    private final RandomAccessFile file;\n    private final List<SevenZArchiveEntry> files = new ArrayList<SevenZArchiveEntry>();\n    private int numNonEmptyStreams = 0;\n    private CRC32 crc32 = new CRC32();\n    private CRC32 compressedCrc32 = new CRC32();\n    private long fileBytesWritten = 0;\n    private boolean finished = false;\n    private CountingOutputStream currentOutputStream;\n    private SevenZMethod contentCompression = SevenZMethod.LZMA2;\n    \n    /**\n     * Opens file to write a 7z archive to.\n     *\n     * @param filename name of the file to write to\n     * @throws IOException if opening the file fails\n     */\n    public SevenZOutputFile(final File filename) throws IOException {\n        file = new RandomAccessFile(filename, \"rw\");\n        file.seek(SevenZFile.SIGNATURE_HEADER_SIZE);\n    }\n    \n    /**\n     * Sets the compression method to use for entry contents - the\n     * default is LZMA2.\n     *\n     * <p>Currently only {@link SevenZMethod#COPY}, {@link\n     * SevenZMethod#LZMA2}, {@link SevenZMethod#BZIP2} and {@link\n     * SevenZMethod#DEFLATE} are supported.</p>\n     */\n    public void setContentCompression(SevenZMethod method) {\n        this.contentCompression = method;\n    }\n\n    /**\n     * Closes the archive, calling {@link #finish} if necessary.\n     * \n     * @throws IOException\n     */\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n        file.close();\n    }\n    \n    /**\n     * Create an archive entry using the inputFile and entryName provided.\n     * \n     * @param inputFile\n     * @param entryName \n     * @return the ArchiveEntry set up with details from the file\n     * \n     * @throws IOException\n     */\n    public SevenZArchiveEntry createArchiveEntry(final File inputFile,\n            final String entryName) throws IOException {\n        final SevenZArchiveEntry entry = new SevenZArchiveEntry();\n        entry.setDirectory(inputFile.isDirectory());\n        entry.setName(entryName);\n        entry.setLastModifiedDate(new Date(inputFile.lastModified()));\n        return entry;\n    }\n\n    /**\n     * Records an archive entry to add.\n     *\n     * The caller must then write the content to the archive and call\n     * {@link #closeArchiveEntry()} to complete the process.\n     * \n     * @param archiveEntry describes the entry\n     * @throws IOException\n     */\n    public void putArchiveEntry(final ArchiveEntry archiveEntry) throws IOException {\n        final SevenZArchiveEntry entry = (SevenZArchiveEntry) archiveEntry;\n        files.add(entry);\n    }\n    \n    /**\n     * Closes the archive entry.\n     * @throws IOException\n     */\n    public void closeArchiveEntry() throws IOException {\n        if (currentOutputStream != null) {\n            currentOutputStream.flush();\n            currentOutputStream.close();\n        }\n\n        final SevenZArchiveEntry entry = files.get(files.size() - 1);\n        if (fileBytesWritten > 0) {\n            entry.setHasStream(true);\n            ++numNonEmptyStreams;\n            entry.setSize(currentOutputStream.getBytesWritten());\n            entry.setCompressedSize(fileBytesWritten);\n            entry.setCrcValue(crc32.getValue());\n            entry.setCompressedCrcValue(compressedCrc32.getValue());\n            entry.setHasCrc(true);\n        } else {\n            entry.setHasStream(false);\n            entry.setSize(0);\n            entry.setCompressedSize(0);\n            entry.setHasCrc(false);\n        }\n        currentOutputStream = null;\n        crc32.reset();\n        compressedCrc32.reset();\n        fileBytesWritten = 0;\n    }\n    \n    /**\n     * Writes a byte to the current archive entry.\n     * @param b The byte to be written.\n     * @throws IOException on error\n     */\n    public void write(final int b) throws IOException {\n        getCurrentOutputStream().write(b);\n    }\n    \n    /**\n     * Writes a byte array to the current archive entry.\n     * @param b The byte array to be written.\n     * @throws IOException on error\n     */\n    public void write(final byte[] b) throws IOException {\n        write(b, 0, b.length);\n    }\n    \n    /**\n     * Writes part of a byte array to the current archive entry.\n     * @param b The byte array to be written.\n     * @param off offset into the array to start writing from\n     * @param len number of bytes to write\n     * @throws IOException on error\n     */\n    public void write(final byte[] b, final int off, final int len) throws IOException {\n        if (len > 0) {\n            getCurrentOutputStream().write(b, off, len);\n        }\n    }\n    \n    /**\n     * Finishes the addition of entries to this archive, without closing it.\n     * \n     * @throws IOException if archive is already closed.\n     */\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n        finished = true;\n        \n        final long headerPosition = file.getFilePointer();\n        \n        final ByteArrayOutputStream headerBaos = new ByteArrayOutputStream();\n        final DataOutputStream header = new DataOutputStream(headerBaos);\n        \n        writeHeader(header);\n        header.flush();\n        final byte[] headerBytes = headerBaos.toByteArray();\n        file.write(headerBytes);\n        \n        final CRC32 crc32 = new CRC32();\n        \n        // signature header\n        file.seek(0);\n        file.write(SevenZFile.sevenZSignature);\n        // version\n        file.write(0);\n        file.write(2);\n        \n        // start header\n        final ByteArrayOutputStream startHeaderBaos = new ByteArrayOutputStream();\n        final DataOutputStream startHeaderStream = new DataOutputStream(startHeaderBaos);\n        startHeaderStream.writeLong(Long.reverseBytes(headerPosition - SevenZFile.SIGNATURE_HEADER_SIZE));\n        startHeaderStream.writeLong(Long.reverseBytes(0xffffFFFFL & headerBytes.length));\n        crc32.reset();\n        crc32.update(headerBytes);\n        startHeaderStream.writeInt(Integer.reverseBytes((int)crc32.getValue()));\n        startHeaderStream.flush();\n        final byte[] startHeaderBytes = startHeaderBaos.toByteArray();\n        crc32.reset();\n        crc32.update(startHeaderBytes);\n        file.writeInt(Integer.reverseBytes((int) crc32.getValue()));\n        file.write(startHeaderBytes);\n    }\n    \n    /*\n     * Creation of output stream is deferred until data is actually\n     * written as some codecs might write header information even for\n     * empty streams and directories otherwise.\n     */\n    private OutputStream getCurrentOutputStream() throws IOException {\n        if (currentOutputStream == null) {\n            currentOutputStream = setupFileOutputStream();\n        }\n        return currentOutputStream;\n    }\n\n    private CountingOutputStream setupFileOutputStream() throws IOException {\n        OutputStream out = new OutputStreamWrapper();\n        return new CountingOutputStream(Coders\n                                        .addEncoder(out,\n                                                    contentCompression,\n                                                    null)) {\n            @Override\n            public void write(final int b) throws IOException {\n                super.write(b);\n                crc32.update(b);\n            }\n    \n            @Override\n            public void write(final byte[] b) throws IOException {\n                super.write(b);\n                crc32.update(b);\n            }\n    \n            @Override\n            public void write(final byte[] b, final int off, final int len)\n                throws IOException {\n                super.write(b, off, len);\n                crc32.update(b, off, len);\n            }\n        };\n    }\n\n    private void writeHeader(final DataOutput header) throws IOException {\n        header.write(NID.kHeader);\n        \n        header.write(NID.kMainStreamsInfo);\n        writeStreamsInfo(header);\n        writeFilesInfo(header);\n        header.write(NID.kEnd);\n    }\n    \n    private void writeStreamsInfo(final DataOutput header) throws IOException {\n        if (numNonEmptyStreams > 0) {\n            writePackInfo(header);\n            writeUnpackInfo(header);\n        }\n        \n        writeSubStreamsInfo(header);\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writePackInfo(final DataOutput header) throws IOException {\n        header.write(NID.kPackInfo);\n        \n        writeUint64(header, 0);\n        writeUint64(header, 0xffffFFFFL & numNonEmptyStreams);\n        \n        header.write(NID.kSize);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                writeUint64(header, entry.getCompressedSize());\n            }\n        }\n        \n        header.write(NID.kCRC);\n        header.write(1);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                header.writeInt(Integer.reverseBytes((int) entry.getCompressedCrcValue()));\n            }\n        }\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeUnpackInfo(final DataOutput header) throws IOException {\n        header.write(NID.kUnpackInfo);\n        \n        header.write(NID.kFolder);\n        writeUint64(header, numNonEmptyStreams);\n        header.write(0);\n        for (int i = 0; i < numNonEmptyStreams; i++) {\n            writeFolder(header);\n        }\n        \n        header.write(NID.kCodersUnpackSize);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                writeUint64(header, entry.getSize());\n            }\n        }\n        \n        header.write(NID.kCRC);\n        header.write(1);\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.hasStream()) {\n                header.writeInt(Integer.reverseBytes((int) entry.getCrcValue()));\n            }\n        }\n        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeFolder(final DataOutput header) throws IOException {\n        // one coder\n        writeUint64(header, 1);\n        byte[] id = contentCompression.getId();\n        byte[] properties = contentCompression.getProperties();\n\n        int codecFlags = id.length;\n        if (properties.length > 0) {\n            codecFlags |= 0x20;\n        }\n        header.write(codecFlags);\n        header.write(id);\n\n        if (properties.length > 0) {\n            header.write(properties.length);\n            header.write(properties);\n        }\n    }\n    \n    private void writeSubStreamsInfo(final DataOutput header) throws IOException {\n        header.write(NID.kSubStreamsInfo);\n//        \n//        header.write(NID.kCRC);\n//        header.write(1);\n//        for (final SevenZArchiveEntry entry : files) {\n//            if (entry.getHasCrc()) {\n//                header.writeInt(Integer.reverseBytes(entry.getCrc()));\n//            }\n//        }\n//        \n        header.write(NID.kEnd);\n    }\n    \n    private void writeFilesInfo(final DataOutput header) throws IOException {\n        header.write(NID.kFilesInfo);\n        \n        writeUint64(header, files.size());\n\n        writeFileEmptyStreams(header);\n        writeFileEmptyFiles(header);\n        writeFileAntiItems(header);\n        writeFileNames(header);\n        writeFileCTimes(header);\n        writeFileATimes(header);\n        writeFileMTimes(header);\n        writeFileWindowsAttributes(header);\n        header.write(0);\n    }\n    \n    private void writeFileEmptyStreams(final DataOutput header) throws IOException {\n        boolean hasEmptyStreams = false;\n        for (final SevenZArchiveEntry entry : files) {\n            if (!entry.hasStream()) {\n                hasEmptyStreams = true;\n                break;\n            }\n        }\n        if (hasEmptyStreams) {\n            header.write(NID.kEmptyStream);\n            final BitSet emptyStreams = new BitSet(files.size());\n            for (int i = 0; i < files.size(); i++) {\n                emptyStreams.set(i, !files.get(i).hasStream());\n            }\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, emptyStreams, files.size());\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileEmptyFiles(final DataOutput header) throws IOException {\n        boolean hasEmptyFiles = false;\n        int emptyStreamCounter = 0;\n        final BitSet emptyFiles = new BitSet(0);\n        for (int i = 0; i < files.size(); i++) {\n            if (!files.get(i).hasStream()) {\n                boolean isDir = files.get(i).isDirectory();\n                emptyFiles.set(emptyStreamCounter++, !isDir);\n                hasEmptyFiles |= !isDir;\n            }\n        }\n        if (hasEmptyFiles) {\n            header.write(NID.kEmptyFile);\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, emptyFiles, emptyStreamCounter);\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileAntiItems(final DataOutput header) throws IOException {\n        boolean hasAntiItems = false;\n        final BitSet antiItems = new BitSet(0);\n        int antiItemCounter = 0;\n        for (int i = 0; i < files.size(); i++) {\n            if (!files.get(i).hasStream()) {\n                boolean isAnti = files.get(i).isAntiItem();\n                antiItems.set(antiItemCounter++, isAnti);\n                hasAntiItems |= isAnti;\n            }\n        }\n        if (hasAntiItems) {\n            header.write(NID.kAnti);\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            writeBits(out, antiItems, antiItemCounter);\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n    \n    private void writeFileNames(final DataOutput header) throws IOException {\n        header.write(NID.kName);\n        \n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final DataOutputStream out = new DataOutputStream(baos);\n        out.write(0);\n        for (final SevenZArchiveEntry entry : files) {\n            out.write(entry.getName().getBytes(\"UTF-16LE\"));\n            out.writeShort(0);\n        }\n        out.flush();\n        final byte[] contents = baos.toByteArray();\n        writeUint64(header, contents.length);\n        header.write(contents);\n    }\n\n    private void writeFileCTimes(final DataOutput header) throws IOException {\n        int numCreationDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasCreationDate()) {\n                ++numCreationDates;\n            }\n        }\n        if (numCreationDates > 0) {\n            header.write(NID.kCTime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numCreationDates != files.size()) {\n                out.write(0);\n                final BitSet cTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    cTimes.set(i, files.get(i).getHasCreationDate());\n                }\n                writeBits(out, cTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasCreationDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getCreationDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileATimes(final DataOutput header) throws IOException {\n        int numAccessDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasAccessDate()) {\n                ++numAccessDates;\n            }\n        }\n        if (numAccessDates > 0) {\n            header.write(NID.kATime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numAccessDates != files.size()) {\n                out.write(0);\n                final BitSet aTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    aTimes.set(i, files.get(i).getHasAccessDate());\n                }\n                writeBits(out, aTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasAccessDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getAccessDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileMTimes(final DataOutput header) throws IOException {\n        int numLastModifiedDates = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasLastModifiedDate()) {\n                ++numLastModifiedDates;\n            }\n        }\n        if (numLastModifiedDates > 0) {\n            header.write(NID.kMTime);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numLastModifiedDates != files.size()) {\n                out.write(0);\n                final BitSet mTimes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    mTimes.set(i, files.get(i).getHasLastModifiedDate());\n                }\n                writeBits(out, mTimes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasLastModifiedDate()) {\n                    out.writeLong(Long.reverseBytes(\n                            SevenZArchiveEntry.javaTimeToNtfsTime(entry.getLastModifiedDate())));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeFileWindowsAttributes(final DataOutput header) throws IOException {\n        int numWindowsAttributes = 0;\n        for (final SevenZArchiveEntry entry : files) {\n            if (entry.getHasWindowsAttributes()) {\n                ++numWindowsAttributes;\n            }\n        }\n        if (numWindowsAttributes > 0) {\n            header.write(NID.kWinAttributes);\n\n            final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            final DataOutputStream out = new DataOutputStream(baos);\n            if (numWindowsAttributes != files.size()) {\n                out.write(0);\n                final BitSet attributes = new BitSet(files.size());\n                for (int i = 0; i < files.size(); i++) {\n                    attributes.set(i, files.get(i).getHasWindowsAttributes());\n                }\n                writeBits(out, attributes, files.size());\n            } else {\n                out.write(1);\n            }\n            out.write(0);\n            for (final SevenZArchiveEntry entry : files) {\n                if (entry.getHasWindowsAttributes()) {\n                    out.writeInt(Integer.reverseBytes(entry.getWindowsAttributes()));\n                }\n            }\n            out.flush();\n            final byte[] contents = baos.toByteArray();\n            writeUint64(header, contents.length);\n            header.write(contents);\n        }\n    }\n\n    private void writeUint64(final DataOutput header, long value) throws IOException {\n        int firstByte = 0;\n        int mask = 0x80;\n        int i;\n        for (i = 0; i < 8; i++) {\n            if (value < ((1L << ( 7  * (i + 1))))) {\n                firstByte |= (value >>> (8 * i));\n                break;\n            }\n            firstByte |= mask;\n            mask >>>= 1;\n        }\n        header.write(firstByte);\n        for (; i > 0; i--) {\n            header.write((int) (0xff & value));\n            value >>>= 8;\n        }\n    }\n\n    private void writeBits(final DataOutput header, final BitSet bits, final int length) throws IOException {\n        int cache = 0;\n        int shift = 7;\n        for (int i = 0; i < length; i++) {\n            cache |= ((bits.get(i) ? 1 : 0) << shift);\n            if (--shift < 0) {\n                header.write(cache);\n                shift = 7;\n                cache = 0;\n            }\n        }\n        if (shift != 7) {\n            header.write(cache);\n        }\n    }\n\n    private class OutputStreamWrapper extends OutputStream {\n        @Override\n        public void write(final int b) throws IOException {\n            file.write(b);\n            compressedCrc32.update(b);\n            fileBytesWritten++;\n        }\n    \n        @Override\n        public void write(final byte[] b) throws IOException {\n            OutputStreamWrapper.this.write(b, 0, b.length);\n        }\n    \n        @Override\n        public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n            file.write(b, off, len);\n            compressedCrc32.update(b, off, len);\n            fileBytesWritten += len;\n        }\n\n        @Override\n        public void flush() throws IOException {\n            // no reason to flush a RandomAccessFile\n        }\n\n        @Override\n        public void close() throws IOException {\n            // the file will be closed by the containing class's close method\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 22, "classes_modified": [{"class_name": "org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*\n * This package is based on the work done by Keiron Liddle, Aftex Software\n * <keiron@aftexsw.com> to whom the Ant project is very grateful for his\n * great code.\n */\npackage org.apache.commons.compress.compressors.bzip2;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * An input stream that decompresses from the BZip2 format to be read as any other stream.\n * \n * @NotThreadSafe\n */\npublic class BZip2CompressorInputStream extends CompressorInputStream implements\n                                                                          BZip2Constants {\n\n    /**\n     * Index of the last char in the block, so the block size == last + 1.\n     */\n    private int last;\n\n    /**\n     * Index in zptr[] of original string after sorting.\n     */\n    private int origPtr;\n\n    /**\n     * always: in the range 0 .. 9. The current block size is 100000 * this\n     * number.\n     */\n    private int blockSize100k;\n\n    private boolean blockRandomised;\n\n    private int bsBuff;\n    private int bsLive;\n    private final CRC crc = new CRC();\n\n    private int nInUse;\n\n    private InputStream in;\n    private final boolean decompressConcatenated;\n\n    private int currentChar = -1;\n    private static final int EOF = 0;\n    private static final int START_BLOCK_STATE = 1;\n    private static final int RAND_PART_A_STATE = 2;\n    private static final int RAND_PART_B_STATE = 3;\n    private static final int RAND_PART_C_STATE = 4;\n    private static final int NO_RAND_PART_A_STATE = 5;\n    private static final int NO_RAND_PART_B_STATE = 6;\n    private static final int NO_RAND_PART_C_STATE = 7;\n\n    private int currentState = START_BLOCK_STATE;\n\n    private int storedBlockCRC, storedCombinedCRC;\n    private int computedBlockCRC, computedCombinedCRC;\n\n    // Variables used by setup* methods exclusively\n\n    private int su_count;\n    private int su_ch2;\n    private int su_chPrev;\n    private int su_i2;\n    private int su_j2;\n    private int su_rNToGo;\n    private int su_rTPos;\n    private int su_tPos;\n    private char su_z;\n\n    /**\n     * All memory intensive stuff. This field is initialized by initBlock().\n     */\n    private BZip2CompressorInputStream.Data data;\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream. This doesn't suppprt decompressing\n     * concatenated .bz2 files.\n     * \n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if <tt>in == null</tt>\n     */\n    public BZip2CompressorInputStream(final InputStream in) throws IOException {\n        this(in, false);\n    }\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream.\n     *\n     * @param in the InputStream from which this object should be created\n     * @param decompressConcatenated\n     *                     if true, decompress until the end of the input;\n     *                     if false, stop after the first .bz2 stream and\n     *                     leave the input position to point to the next\n     *                     byte after the .bz2 stream\n     *\n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if <tt>in == null</tt>\n     */\n    public BZip2CompressorInputStream(final InputStream in, final boolean decompressConcatenated) throws IOException {\n        this.in = in;\n        this.decompressConcatenated = decompressConcatenated;\n\n        init(true);\n        initBlock();\n        setupBlock();\n    }\n\n    @Override\n    public int read() throws IOException {\n        if (this.in != null) {\n            int r = read0();\n            count(r < 0 ? -1 : 1);\n            return r;\n        } else {\n            throw new IOException(\"stream closed\");\n        }\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.InputStream#read(byte[], int, int)\n     */\n    @Override\n    public int read(final byte[] dest, final int offs, final int len)\n        throws IOException {\n        if (offs < 0) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") < 0.\");\n        }\n        if (len < 0) {\n            throw new IndexOutOfBoundsException(\"len(\" + len + \") < 0.\");\n        }\n        if (offs + len > dest.length) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") + len(\"\n                                                + len + \") > dest.length(\" + dest.length + \").\");\n        }\n        if (this.in == null) {\n            throw new IOException(\"stream closed\");\n        }\n\n        final int hi = offs + len;\n        int destOffs = offs;\n        int b;\n        while (destOffs < hi && ((b = read0()) >= 0)) {\n            dest[destOffs++] = (byte) b;\n            count(1);\n        }\n\n        int c = (destOffs == offs) ? -1 : (destOffs - offs);\n        return c;\n    }\n\n    private void makeMaps() {\n        final boolean[] inUse = this.data.inUse;\n        final byte[] seqToUnseq = this.data.seqToUnseq;\n\n        int nInUseShadow = 0;\n\n        for (int i = 0; i < 256; i++) {\n            if (inUse[i]) {\n                seqToUnseq[nInUseShadow++] = (byte) i;\n            }\n        }\n\n        this.nInUse = nInUseShadow;\n    }\n\n    private int read0() throws IOException {\n        final int retChar = this.currentChar;\n        switch (currentState) {\n        case EOF:\n            return -1;\n\n        case START_BLOCK_STATE:\n            throw new IllegalStateException();\n\n        case RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case RAND_PART_B_STATE:\n            setupRandPartB();\n            break;\n\n        case RAND_PART_C_STATE:\n            setupRandPartC();\n            break;\n\n        case NO_RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case NO_RAND_PART_B_STATE:\n            setupNoRandPartB();\n            break;\n\n        case NO_RAND_PART_C_STATE:\n            setupNoRandPartC();\n            break;\n\n        default:\n            throw new IllegalStateException();\n        }\n        return retChar;\n    }\n\n    private boolean init(boolean isFirstStream) throws IOException {\n        if (null == in) {\n            throw new IOException(\"No InputStream\");\n        }\n\n        int magic0 = this.in.read();\n        if (magic0 == -1 && !isFirstStream) {\n            return false;\n        }\n        int magic1 = this.in.read();\n        int magic2 = this.in.read();\n\n        if (magic0 != 'B' || magic1 != 'Z' || magic2 != 'h') {\n            throw new IOException(isFirstStream\n                    ? \"Stream is not in the BZip2 format\"\n                    : \"Garbage after a valid BZip2 stream\");\n        }\n\n        int blockSize = this.in.read();\n        if ((blockSize < '1') || (blockSize > '9')) {\n            throw new IOException(\"BZip2 block size is invalid\");\n        }\n\n        this.blockSize100k = blockSize - '0';\n\n        this.bsLive = 0;\n        this.computedCombinedCRC = 0;\n\n        return true;\n    }\n\n    private void initBlock() throws IOException {\n        char magic0;\n        char magic1;\n        char magic2;\n        char magic3;\n        char magic4;\n        char magic5;\n\n        while (true) {\n            // Get the block magic bytes.\n            magic0 = bsGetUByte();\n            magic1 = bsGetUByte();\n            magic2 = bsGetUByte();\n            magic3 = bsGetUByte();\n            magic4 = bsGetUByte();\n            magic5 = bsGetUByte();\n\n            // If isn't end of stream magic, break out of the loop.\n            if (magic0 != 0x17 || magic1 != 0x72 || magic2 != 0x45\n                    || magic3 != 0x38 || magic4 != 0x50 || magic5 != 0x90) {\n                break;\n            }\n\n            // End of stream was reached. Check the combined CRC and\n            // advance to the next .bz2 stream if decoding concatenated\n            // streams.\n            if (complete()) {\n                return;\n            }\n        }\n\n        if (magic0 != 0x31 || // '1'\n            magic1 != 0x41 || // ')'\n            magic2 != 0x59 || // 'Y'\n            magic3 != 0x26 || // '&'\n            magic4 != 0x53 || // 'S'\n            magic5 != 0x59 // 'Y'\n            ) {\n            this.currentState = EOF;\n            throw new IOException(\"bad block header\");\n        } else {\n            this.storedBlockCRC = bsGetInt();\n            this.blockRandomised = bsR(1) == 1;\n\n            /**\n             * Allocate data here instead in constructor, so we do not allocate\n             * it if the input file is empty.\n             */\n            if (this.data == null) {\n                this.data = new Data(this.blockSize100k);\n            }\n\n            // currBlockNo++;\n            getAndMoveToFrontDecode();\n\n            this.crc.initialiseCRC();\n            this.currentState = START_BLOCK_STATE;\n        }\n    }\n\n    private void endBlock() throws IOException {\n        this.computedBlockCRC = this.crc.getFinalCRC();\n\n        // A bad CRC is considered a fatal error.\n        if (this.storedBlockCRC != this.computedBlockCRC) {\n            // make next blocks readable without error\n            // (repair feature, not yet documented, not tested)\n            this.computedCombinedCRC = (this.storedCombinedCRC << 1)\n                | (this.storedCombinedCRC >>> 31);\n            this.computedCombinedCRC ^= this.storedBlockCRC;\n\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        this.computedCombinedCRC = (this.computedCombinedCRC << 1)\n            | (this.computedCombinedCRC >>> 31);\n        this.computedCombinedCRC ^= this.computedBlockCRC;\n    }\n\n    private boolean complete() throws IOException {\n        this.storedCombinedCRC = bsGetInt();\n        this.currentState = EOF;\n        this.data = null;\n\n        if (this.storedCombinedCRC != this.computedCombinedCRC) {\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        // Look for the next .bz2 stream if decompressing\n        // concatenated files.\n        return !decompressConcatenated || !init(false);\n    }\n\n    @Override\n    public void close() throws IOException {\n        InputStream inShadow = this.in;\n        if (inShadow != null) {\n            try {\n                if (inShadow != System.in) {\n                    inShadow.close();\n                }\n            } finally {\n                this.data = null;\n                this.in = null;\n            }\n        }\n    }\n\n    private int bsR(final int n) throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < n) {\n            final InputStream inShadow = this.in;\n            do {\n                int thech = inShadow.read();\n\n                if (thech < 0) {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n\n                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                bsLiveShadow += 8;\n            } while (bsLiveShadow < n);\n\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - n;\n        return (bsBuffShadow >> (bsLiveShadow - n)) & ((1 << n) - 1);\n    }\n\n    private boolean bsGetBit() throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < 1) {\n            int thech = this.in.read();\n\n            if (thech < 0) {\n                throw new IOException(\"unexpected end of stream\");\n            }\n\n            bsBuffShadow = (bsBuffShadow << 8) | thech;\n            bsLiveShadow += 8;\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - 1;\n        return ((bsBuffShadow >> (bsLiveShadow - 1)) & 1) != 0;\n    }\n\n    private char bsGetUByte() throws IOException {\n        return (char) bsR(8);\n    }\n\n    private int bsGetInt() throws IOException {\n        return (((((bsR(8) << 8) | bsR(8)) << 8) | bsR(8)) << 8) | bsR(8);\n    }\n\n    /**\n     * Called by createHuffmanDecodingTables() exclusively.\n     */\n    private static void hbCreateDecodeTables(final int[] limit,\n                                             final int[] base, final int[] perm, final char[] length,\n                                             final int minLen, final int maxLen, final int alphaSize) {\n        for (int i = minLen, pp = 0; i <= maxLen; i++) {\n            for (int j = 0; j < alphaSize; j++) {\n                if (length[j] == i) {\n                    perm[pp++] = j;\n                }\n            }\n        }\n\n        for (int i = MAX_CODE_LEN; --i > 0;) {\n            base[i] = 0;\n            limit[i] = 0;\n        }\n\n        for (int i = 0; i < alphaSize; i++) {\n            base[length[i] + 1]++;\n        }\n\n        for (int i = 1, b = base[0]; i < MAX_CODE_LEN; i++) {\n            b += base[i];\n            base[i] = b;\n        }\n\n        for (int i = minLen, vec = 0, b = base[i]; i <= maxLen; i++) {\n            final int nb = base[i + 1];\n            vec += nb - b;\n            b = nb;\n            limit[i] = vec - 1;\n            vec <<= 1;\n        }\n\n        for (int i = minLen + 1; i <= maxLen; i++) {\n            base[i] = ((limit[i - 1] + 1) << 1) - base[i];\n        }\n    }\n\n    private void recvDecodingTables() throws IOException {\n        final Data dataShadow = this.data;\n        final boolean[] inUse = dataShadow.inUse;\n        final byte[] pos = dataShadow.recvDecodingTables_pos;\n        final byte[] selector = dataShadow.selector;\n        final byte[] selectorMtf = dataShadow.selectorMtf;\n\n        int inUse16 = 0;\n\n        /* Receive the mapping table */\n        for (int i = 0; i < 16; i++) {\n            if (bsGetBit()) {\n                inUse16 |= 1 << i;\n            }\n        }\n\n        for (int i = 256; --i >= 0;) {\n            inUse[i] = false;\n        }\n\n        for (int i = 0; i < 16; i++) {\n            if ((inUse16 & (1 << i)) != 0) {\n                final int i16 = i << 4;\n                for (int j = 0; j < 16; j++) {\n                    if (bsGetBit()) {\n                        inUse[i16 + j] = true;\n                    }\n                }\n            }\n        }\n\n        makeMaps();\n        final int alphaSize = this.nInUse + 2;\n\n        /* Now the selectors */\n        final int nGroups = bsR(3);\n        final int nSelectors = bsR(15);\n\n        for (int i = 0; i < nSelectors; i++) {\n            int j = 0;\n            while (bsGetBit()) {\n                j++;\n            }\n            selectorMtf[i] = (byte) j;\n        }\n\n        /* Undo the MTF values for the selectors. */\n        for (int v = nGroups; --v >= 0;) {\n            pos[v] = (byte) v;\n        }\n\n        for (int i = 0; i < nSelectors; i++) {\n            int v = selectorMtf[i] & 0xff;\n            final byte tmp = pos[v];\n            while (v > 0) {\n                // nearly all times v is zero, 4 in most other cases\n                pos[v] = pos[v - 1];\n                v--;\n            }\n            pos[0] = tmp;\n            selector[i] = tmp;\n        }\n\n        final char[][] len = dataShadow.temp_charArray2d;\n\n        /* Now the coding tables */\n        for (int t = 0; t < nGroups; t++) {\n            int curr = bsR(5);\n            final char[] len_t = len[t];\n            for (int i = 0; i < alphaSize; i++) {\n                while (bsGetBit()) {\n                    curr += bsGetBit() ? -1 : 1;\n                }\n                len_t[i] = (char) curr;\n            }\n        }\n\n        // finally create the Huffman tables\n        createHuffmanDecodingTables(alphaSize, nGroups);\n    }\n\n    /**\n     * Called by recvDecodingTables() exclusively.\n     */\n    private void createHuffmanDecodingTables(final int alphaSize,\n                                             final int nGroups) {\n        final Data dataShadow = this.data;\n        final char[][] len = dataShadow.temp_charArray2d;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n\n        for (int t = 0; t < nGroups; t++) {\n            int minLen = 32;\n            int maxLen = 0;\n            final char[] len_t = len[t];\n            for (int i = alphaSize; --i >= 0;) {\n                final char lent = len_t[i];\n                if (lent > maxLen) {\n                    maxLen = lent;\n                }\n                if (lent < minLen) {\n                    minLen = lent;\n                }\n            }\n            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,\n                                 maxLen, alphaSize);\n            minLens[t] = minLen;\n        }\n    }\n\n    private void getAndMoveToFrontDecode() throws IOException {\n        this.origPtr = bsR(24);\n        recvDecodingTables();\n\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final byte[] ll8 = dataShadow.ll8;\n        final int[] unzftab = dataShadow.unzftab;\n        final byte[] selector = dataShadow.selector;\n        final byte[] seqToUnseq = dataShadow.seqToUnseq;\n        final char[] yy = dataShadow.getAndMoveToFrontDecode_yy;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n        final int limitLast = this.blockSize100k * 100000;\n\n        /*\n         * Setting up the unzftab entries here is not strictly necessary, but it\n         * does save having to do it later in a separate pass, and so saves a\n         * block's worth of cache misses.\n         */\n        for (int i = 256; --i >= 0;) {\n            yy[i] = (char) i;\n            unzftab[i] = 0;\n        }\n\n        int groupNo = 0;\n        int groupPos = G_SIZE - 1;\n        final int eob = this.nInUse + 1;\n        int nextSym = getAndMoveToFrontDecode0(0);\n        int bsBuffShadow = this.bsBuff;\n        int bsLiveShadow = this.bsLive;\n        int lastShadow = -1;\n        int zt = selector[groupNo] & 0xff;\n        int[] base_zt = base[zt];\n        int[] limit_zt = limit[zt];\n        int[] perm_zt = perm[zt];\n        int minLens_zt = minLens[zt];\n\n        while (nextSym != eob) {\n            if ((nextSym == RUNA) || (nextSym == RUNB)) {\n                int s = -1;\n\n                for (int n = 1; true; n <<= 1) {\n                    if (nextSym == RUNA) {\n                        s += n;\n                    } else if (nextSym == RUNB) {\n                        s += n << 1;\n                    } else {\n                        break;\n                    }\n\n                    if (groupPos == 0) {\n                        groupPos = G_SIZE - 1;\n                        zt = selector[++groupNo] & 0xff;\n                        base_zt = base[zt];\n                        limit_zt = limit[zt];\n                        perm_zt = perm[zt];\n                        minLens_zt = minLens[zt];\n                    } else {\n                        groupPos--;\n                    }\n\n                    int zn = minLens_zt;\n\n                    // Inlined:\n                    // int zvec = bsR(zn);\n                    while (bsLiveShadow < zn) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                        & ((1 << zn) - 1);\n                    bsLiveShadow -= zn;\n\n                    while (zvec > limit_zt[zn]) {\n                        zn++;\n                        while (bsLiveShadow < 1) {\n                            final int thech = inShadow.read();\n                            if (thech >= 0) {\n                                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                                bsLiveShadow += 8;\n                                continue;\n                            } else {\n                                throw new IOException(\n                                                      \"unexpected end of stream\");\n                            }\n                        }\n                        bsLiveShadow--;\n                        zvec = (zvec << 1)\n                            | ((bsBuffShadow >> bsLiveShadow) & 1);\n                    }\n                    nextSym = perm_zt[zvec - base_zt[zn]];\n                }\n\n                final byte ch = seqToUnseq[yy[0]];\n                unzftab[ch & 0xff] += s + 1;\n\n                while (s-- >= 0) {\n                    ll8[++lastShadow] = ch;\n                }\n\n                if (lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n            } else {\n                if (++lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n\n                final char tmp = yy[nextSym - 1];\n                unzftab[seqToUnseq[tmp] & 0xff]++;\n                ll8[lastShadow] = seqToUnseq[tmp];\n\n                /*\n                 * This loop is hammered during decompression, hence avoid\n                 * native method call overhead of System.arraycopy for very\n                 * small ranges to copy.\n                 */\n                if (nextSym <= 16) {\n                    for (int j = nextSym - 1; j > 0;) {\n                        yy[j] = yy[--j];\n                    }\n                } else {\n                    System.arraycopy(yy, 0, yy, 1, nextSym - 1);\n                }\n\n                yy[0] = tmp;\n\n                if (groupPos == 0) {\n                    groupPos = G_SIZE - 1;\n                    zt = selector[++groupNo] & 0xff;\n                    base_zt = base[zt];\n                    limit_zt = limit[zt];\n                    perm_zt = perm[zt];\n                    minLens_zt = minLens[zt];\n                } else {\n                    groupPos--;\n                }\n\n                int zn = minLens_zt;\n\n                // Inlined:\n                // int zvec = bsR(zn);\n                while (bsLiveShadow < zn) {\n                    final int thech = inShadow.read();\n                    if (thech >= 0) {\n                        bsBuffShadow = (bsBuffShadow << 8) | thech;\n                        bsLiveShadow += 8;\n                        continue;\n                    } else {\n                        throw new IOException(\"unexpected end of stream\");\n                    }\n                }\n                int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                    & ((1 << zn) - 1);\n                bsLiveShadow -= zn;\n\n                while (zvec > limit_zt[zn]) {\n                    zn++;\n                    while (bsLiveShadow < 1) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    bsLiveShadow--;\n                    zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n                }\n                nextSym = perm_zt[zvec - base_zt[zn]];\n            }\n        }\n\n        this.last = lastShadow;\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n    }\n\n    private int getAndMoveToFrontDecode0(final int groupNo) throws IOException {\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final int zt = dataShadow.selector[groupNo] & 0xff;\n        final int[] limit_zt = dataShadow.limit[zt];\n        int zn = dataShadow.minLens[zt];\n        int zvec = bsR(zn);\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        while (zvec > limit_zt[zn]) {\n            zn++;\n            while (bsLiveShadow < 1) {\n                final int thech = inShadow.read();\n\n                if (thech >= 0) {\n                    bsBuffShadow = (bsBuffShadow << 8) | thech;\n                    bsLiveShadow += 8;\n                    continue;\n                } else {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n            }\n            bsLiveShadow--;\n            zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n        }\n\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n\n        return dataShadow.perm[zt][zvec - dataShadow.base[zt][zn]];\n    }\n\n    private int setupBlock() throws IOException {\n        if (currentState == EOF || this.data == null) {\n            return -1;\n        }\n\n        final int[] cftab = this.data.cftab;\n        final int[] tt = this.data.initTT(this.last + 1);\n        final byte[] ll8 = this.data.ll8;\n        cftab[0] = 0;\n        System.arraycopy(this.data.unzftab, 0, cftab, 1, 256);\n\n        for (int i = 1, c = cftab[0]; i <= 256; i++) {\n            c += cftab[i];\n            cftab[i] = c;\n        }\n\n        for (int i = 0, lastShadow = this.last; i <= lastShadow; i++) {\n            tt[cftab[ll8[i] & 0xff]++] = i;\n        }\n\n        if ((this.origPtr < 0) || (this.origPtr >= tt.length)) {\n            throw new IOException(\"stream corrupted\");\n        }\n\n        this.su_tPos = tt[this.origPtr];\n        this.su_count = 0;\n        this.su_i2 = 0;\n        this.su_ch2 = 256; /* not a char and not EOF */\n\n        if (this.blockRandomised) {\n            this.su_rNToGo = 0;\n            this.su_rTPos = 0;\n            return setupRandPartA();\n        }\n        return setupNoRandPartA();\n    }\n\n    private int setupRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_ch2 = su_ch2Shadow ^= (this.su_rNToGo == 1) ? 1 : 0;\n            this.su_i2++;\n            this.currentChar = su_ch2Shadow;\n            this.currentState = RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupNoRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_ch2 = su_ch2Shadow;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_i2++;\n            this.currentChar = su_ch2Shadow;\n            this.currentState = NO_RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            this.currentState = NO_RAND_PART_A_STATE;\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_count = 1;\n            return setupRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_j2 = 0;\n            this.currentState = RAND_PART_C_STATE;\n            if (this.su_rNToGo == 1) {\n                this.su_z ^= 1;\n            }\n            return setupRandPartC();\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            this.currentChar = this.su_ch2;\n            this.crc.updateCRC(this.su_ch2);\n            this.su_j2++;\n            return this.su_ch2;\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_i2++;\n            this.su_count = 0;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupNoRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.su_count = 1;\n            return setupNoRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_j2 = 0;\n            return setupNoRandPartC();\n        } else {\n            return setupNoRandPartA();\n        }\n    }\n\n    private int setupNoRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            int su_ch2Shadow = this.su_ch2;\n            this.currentChar = su_ch2Shadow;\n            this.crc.updateCRC(su_ch2Shadow);\n            this.su_j2++;\n            this.currentState = NO_RAND_PART_C_STATE;\n            return su_ch2Shadow;\n        } else {\n            this.su_i2++;\n            this.su_count = 0;\n            return setupNoRandPartA();\n        }\n    }\n\n    private static final class Data extends Object {\n\n        // (with blockSize 900k)\n        final boolean[] inUse = new boolean[256]; // 256 byte\n\n        final byte[] seqToUnseq = new byte[256]; // 256 byte\n        final byte[] selector = new byte[MAX_SELECTORS]; // 18002 byte\n        final byte[] selectorMtf = new byte[MAX_SELECTORS]; // 18002 byte\n\n        /**\n         * Freq table collected to save a pass over the data during\n         * decompression.\n         */\n        final int[] unzftab = new int[256]; // 1024 byte\n\n        final int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[] minLens = new int[N_GROUPS]; // 24 byte\n\n        final int[] cftab = new int[257]; // 1028 byte\n        final char[] getAndMoveToFrontDecode_yy = new char[256]; // 512 byte\n        final char[][] temp_charArray2d = new char[N_GROUPS][MAX_ALPHA_SIZE]; // 3096\n        // byte\n        final byte[] recvDecodingTables_pos = new byte[N_GROUPS]; // 6 byte\n        // ---------------\n        // 60798 byte\n\n        int[] tt; // 3600000 byte\n        byte[] ll8; // 900000 byte\n\n        // ---------------\n        // 4560782 byte\n        // ===============\n\n        Data(int blockSize100k) {\n            this.ll8 = new byte[blockSize100k * BZip2Constants.BASEBLOCKSIZE];\n        }\n\n        /**\n         * Initializes the {@link #tt} array.\n         * \n         * This method is called when the required length of the array is known.\n         * I don't initialize it at construction time to avoid unneccessary\n         * memory allocation when compressing small files.\n         */\n        int[] initTT(int length) {\n            int[] ttShadow = this.tt;\n\n            // tt.length should always be >= length, but theoretically\n            // it can happen, if the compressor mixed small and large\n            // blocks. Normally only the last block will be smaller\n            // than others.\n            if ((ttShadow == null) || (ttShadow.length < length)) {\n                this.tt = ttShadow = new int[length];\n            }\n\n            return ttShadow;\n        }\n\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a bzip2 file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a bzip2 compressed stream, false otherwise\n     * \n     * @since 1.1\n     */\n    public static boolean matches(byte[] signature, int length) {\n\n        if (length < 3) {\n            return false;\n        }\n\n        if (signature[0] != 'B') {\n            return false;\n        }\n\n        if (signature[1] != 'Z') {\n            return false;\n        }\n\n        if (signature[2] != 'h') {\n            return false;\n        }\n\n        return true;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*\n * This package is based on the work done by Keiron Liddle, Aftex Software\n * <keiron@aftexsw.com> to whom the Ant project is very grateful for his\n * great code.\n */\npackage org.apache.commons.compress.compressors.bzip2;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * An input stream that decompresses from the BZip2 format to be read as any other stream.\n * \n * @NotThreadSafe\n */\npublic class BZip2CompressorInputStream extends CompressorInputStream implements\n                                                                          BZip2Constants {\n\n    /**\n     * Index of the last char in the block, so the block size == last + 1.\n     */\n    private int last;\n\n    /**\n     * Index in zptr[] of original string after sorting.\n     */\n    private int origPtr;\n\n    /**\n     * always: in the range 0 .. 9. The current block size is 100000 * this\n     * number.\n     */\n    private int blockSize100k;\n\n    private boolean blockRandomised;\n\n    private int bsBuff;\n    private int bsLive;\n    private final CRC crc = new CRC();\n\n    private int nInUse;\n\n    private InputStream in;\n    private final boolean decompressConcatenated;\n\n    private static final int EOF = 0;\n    private static final int START_BLOCK_STATE = 1;\n    private static final int RAND_PART_A_STATE = 2;\n    private static final int RAND_PART_B_STATE = 3;\n    private static final int RAND_PART_C_STATE = 4;\n    private static final int NO_RAND_PART_A_STATE = 5;\n    private static final int NO_RAND_PART_B_STATE = 6;\n    private static final int NO_RAND_PART_C_STATE = 7;\n\n    private int currentState = START_BLOCK_STATE;\n\n    private int storedBlockCRC, storedCombinedCRC;\n    private int computedBlockCRC, computedCombinedCRC;\n\n    // Variables used by setup* methods exclusively\n\n    private int su_count;\n    private int su_ch2;\n    private int su_chPrev;\n    private int su_i2;\n    private int su_j2;\n    private int su_rNToGo;\n    private int su_rTPos;\n    private int su_tPos;\n    private char su_z;\n\n    /**\n     * All memory intensive stuff. This field is initialized by initBlock().\n     */\n    private BZip2CompressorInputStream.Data data;\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream. This doesn't suppprt decompressing\n     * concatenated .bz2 files.\n     * \n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if <tt>in == null</tt>\n     */\n    public BZip2CompressorInputStream(final InputStream in) throws IOException {\n        this(in, false);\n    }\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream.\n     *\n     * @param in the InputStream from which this object should be created\n     * @param decompressConcatenated\n     *                     if true, decompress until the end of the input;\n     *                     if false, stop after the first .bz2 stream and\n     *                     leave the input position to point to the next\n     *                     byte after the .bz2 stream\n     *\n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if <tt>in == null</tt>\n     */\n    public BZip2CompressorInputStream(final InputStream in, final boolean decompressConcatenated) throws IOException {\n        this.in = in;\n        this.decompressConcatenated = decompressConcatenated;\n\n        init(true);\n        initBlock();\n    }\n\n    @Override\n    public int read() throws IOException {\n        if (this.in != null) {\n            int r = read0();\n            count(r < 0 ? -1 : 1);\n            return r;\n        } else {\n            throw new IOException(\"stream closed\");\n        }\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.InputStream#read(byte[], int, int)\n     */\n    @Override\n    public int read(final byte[] dest, final int offs, final int len)\n        throws IOException {\n        if (offs < 0) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") < 0.\");\n        }\n        if (len < 0) {\n            throw new IndexOutOfBoundsException(\"len(\" + len + \") < 0.\");\n        }\n        if (offs + len > dest.length) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") + len(\"\n                                                + len + \") > dest.length(\" + dest.length + \").\");\n        }\n        if (this.in == null) {\n            throw new IOException(\"stream closed\");\n        }\n\n        final int hi = offs + len;\n        int destOffs = offs;\n        int b;\n        while (destOffs < hi && ((b = read0()) >= 0)) {\n            dest[destOffs++] = (byte) b;\n            count(1);\n        }\n\n        int c = (destOffs == offs) ? -1 : (destOffs - offs);\n        return c;\n    }\n\n    private void makeMaps() {\n        final boolean[] inUse = this.data.inUse;\n        final byte[] seqToUnseq = this.data.seqToUnseq;\n\n        int nInUseShadow = 0;\n\n        for (int i = 0; i < 256; i++) {\n            if (inUse[i]) {\n                seqToUnseq[nInUseShadow++] = (byte) i;\n            }\n        }\n\n        this.nInUse = nInUseShadow;\n    }\n\n    private int read0() throws IOException {\n        switch (currentState) {\n        case EOF:\n            return -1;\n\n        case START_BLOCK_STATE:\n            return setupBlock();\n\n        case RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case RAND_PART_B_STATE:\n            return setupRandPartB();\n\n        case RAND_PART_C_STATE:\n            return setupRandPartC();\n\n        case NO_RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case NO_RAND_PART_B_STATE:\n            return setupNoRandPartB();\n\n        case NO_RAND_PART_C_STATE:\n            return setupNoRandPartC();\n\n        default:\n            throw new IllegalStateException();\n        }\n    }\n\n    private boolean init(boolean isFirstStream) throws IOException {\n        if (null == in) {\n            throw new IOException(\"No InputStream\");\n        }\n\n        int magic0 = this.in.read();\n        if (magic0 == -1 && !isFirstStream) {\n            return false;\n        }\n        int magic1 = this.in.read();\n        int magic2 = this.in.read();\n\n        if (magic0 != 'B' || magic1 != 'Z' || magic2 != 'h') {\n            throw new IOException(isFirstStream\n                    ? \"Stream is not in the BZip2 format\"\n                    : \"Garbage after a valid BZip2 stream\");\n        }\n\n        int blockSize = this.in.read();\n        if ((blockSize < '1') || (blockSize > '9')) {\n            throw new IOException(\"BZip2 block size is invalid\");\n        }\n\n        this.blockSize100k = blockSize - '0';\n\n        this.bsLive = 0;\n        this.computedCombinedCRC = 0;\n\n        return true;\n    }\n\n    private void initBlock() throws IOException {\n        char magic0;\n        char magic1;\n        char magic2;\n        char magic3;\n        char magic4;\n        char magic5;\n\n        while (true) {\n            // Get the block magic bytes.\n            magic0 = bsGetUByte();\n            magic1 = bsGetUByte();\n            magic2 = bsGetUByte();\n            magic3 = bsGetUByte();\n            magic4 = bsGetUByte();\n            magic5 = bsGetUByte();\n\n            // If isn't end of stream magic, break out of the loop.\n            if (magic0 != 0x17 || magic1 != 0x72 || magic2 != 0x45\n                    || magic3 != 0x38 || magic4 != 0x50 || magic5 != 0x90) {\n                break;\n            }\n\n            // End of stream was reached. Check the combined CRC and\n            // advance to the next .bz2 stream if decoding concatenated\n            // streams.\n            if (complete()) {\n                return;\n            }\n        }\n\n        if (magic0 != 0x31 || // '1'\n            magic1 != 0x41 || // ')'\n            magic2 != 0x59 || // 'Y'\n            magic3 != 0x26 || // '&'\n            magic4 != 0x53 || // 'S'\n            magic5 != 0x59 // 'Y'\n            ) {\n            this.currentState = EOF;\n            throw new IOException(\"bad block header\");\n        } else {\n            this.storedBlockCRC = bsGetInt();\n            this.blockRandomised = bsR(1) == 1;\n\n            /**\n             * Allocate data here instead in constructor, so we do not allocate\n             * it if the input file is empty.\n             */\n            if (this.data == null) {\n                this.data = new Data(this.blockSize100k);\n            }\n\n            // currBlockNo++;\n            getAndMoveToFrontDecode();\n\n            this.crc.initialiseCRC();\n            this.currentState = START_BLOCK_STATE;\n        }\n    }\n\n    private void endBlock() throws IOException {\n        this.computedBlockCRC = this.crc.getFinalCRC();\n\n        // A bad CRC is considered a fatal error.\n        if (this.storedBlockCRC != this.computedBlockCRC) {\n            // make next blocks readable without error\n            // (repair feature, not yet documented, not tested)\n            this.computedCombinedCRC = (this.storedCombinedCRC << 1)\n                | (this.storedCombinedCRC >>> 31);\n            this.computedCombinedCRC ^= this.storedBlockCRC;\n\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        this.computedCombinedCRC = (this.computedCombinedCRC << 1)\n            | (this.computedCombinedCRC >>> 31);\n        this.computedCombinedCRC ^= this.computedBlockCRC;\n    }\n\n    private boolean complete() throws IOException {\n        this.storedCombinedCRC = bsGetInt();\n        this.currentState = EOF;\n        this.data = null;\n\n        if (this.storedCombinedCRC != this.computedCombinedCRC) {\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        // Look for the next .bz2 stream if decompressing\n        // concatenated files.\n        return !decompressConcatenated || !init(false);\n    }\n\n    @Override\n    public void close() throws IOException {\n        InputStream inShadow = this.in;\n        if (inShadow != null) {\n            try {\n                if (inShadow != System.in) {\n                    inShadow.close();\n                }\n            } finally {\n                this.data = null;\n                this.in = null;\n            }\n        }\n    }\n\n    private int bsR(final int n) throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < n) {\n            final InputStream inShadow = this.in;\n            do {\n                int thech = inShadow.read();\n\n                if (thech < 0) {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n\n                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                bsLiveShadow += 8;\n            } while (bsLiveShadow < n);\n\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - n;\n        return (bsBuffShadow >> (bsLiveShadow - n)) & ((1 << n) - 1);\n    }\n\n    private boolean bsGetBit() throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < 1) {\n            int thech = this.in.read();\n\n            if (thech < 0) {\n                throw new IOException(\"unexpected end of stream\");\n            }\n\n            bsBuffShadow = (bsBuffShadow << 8) | thech;\n            bsLiveShadow += 8;\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - 1;\n        return ((bsBuffShadow >> (bsLiveShadow - 1)) & 1) != 0;\n    }\n\n    private char bsGetUByte() throws IOException {\n        return (char) bsR(8);\n    }\n\n    private int bsGetInt() throws IOException {\n        return (((((bsR(8) << 8) | bsR(8)) << 8) | bsR(8)) << 8) | bsR(8);\n    }\n\n    /**\n     * Called by createHuffmanDecodingTables() exclusively.\n     */\n    private static void hbCreateDecodeTables(final int[] limit,\n                                             final int[] base, final int[] perm, final char[] length,\n                                             final int minLen, final int maxLen, final int alphaSize) {\n        for (int i = minLen, pp = 0; i <= maxLen; i++) {\n            for (int j = 0; j < alphaSize; j++) {\n                if (length[j] == i) {\n                    perm[pp++] = j;\n                }\n            }\n        }\n\n        for (int i = MAX_CODE_LEN; --i > 0;) {\n            base[i] = 0;\n            limit[i] = 0;\n        }\n\n        for (int i = 0; i < alphaSize; i++) {\n            base[length[i] + 1]++;\n        }\n\n        for (int i = 1, b = base[0]; i < MAX_CODE_LEN; i++) {\n            b += base[i];\n            base[i] = b;\n        }\n\n        for (int i = minLen, vec = 0, b = base[i]; i <= maxLen; i++) {\n            final int nb = base[i + 1];\n            vec += nb - b;\n            b = nb;\n            limit[i] = vec - 1;\n            vec <<= 1;\n        }\n\n        for (int i = minLen + 1; i <= maxLen; i++) {\n            base[i] = ((limit[i - 1] + 1) << 1) - base[i];\n        }\n    }\n\n    private void recvDecodingTables() throws IOException {\n        final Data dataShadow = this.data;\n        final boolean[] inUse = dataShadow.inUse;\n        final byte[] pos = dataShadow.recvDecodingTables_pos;\n        final byte[] selector = dataShadow.selector;\n        final byte[] selectorMtf = dataShadow.selectorMtf;\n\n        int inUse16 = 0;\n\n        /* Receive the mapping table */\n        for (int i = 0; i < 16; i++) {\n            if (bsGetBit()) {\n                inUse16 |= 1 << i;\n            }\n        }\n\n        for (int i = 256; --i >= 0;) {\n            inUse[i] = false;\n        }\n\n        for (int i = 0; i < 16; i++) {\n            if ((inUse16 & (1 << i)) != 0) {\n                final int i16 = i << 4;\n                for (int j = 0; j < 16; j++) {\n                    if (bsGetBit()) {\n                        inUse[i16 + j] = true;\n                    }\n                }\n            }\n        }\n\n        makeMaps();\n        final int alphaSize = this.nInUse + 2;\n\n        /* Now the selectors */\n        final int nGroups = bsR(3);\n        final int nSelectors = bsR(15);\n\n        for (int i = 0; i < nSelectors; i++) {\n            int j = 0;\n            while (bsGetBit()) {\n                j++;\n            }\n            selectorMtf[i] = (byte) j;\n        }\n\n        /* Undo the MTF values for the selectors. */\n        for (int v = nGroups; --v >= 0;) {\n            pos[v] = (byte) v;\n        }\n\n        for (int i = 0; i < nSelectors; i++) {\n            int v = selectorMtf[i] & 0xff;\n            final byte tmp = pos[v];\n            while (v > 0) {\n                // nearly all times v is zero, 4 in most other cases\n                pos[v] = pos[v - 1];\n                v--;\n            }\n            pos[0] = tmp;\n            selector[i] = tmp;\n        }\n\n        final char[][] len = dataShadow.temp_charArray2d;\n\n        /* Now the coding tables */\n        for (int t = 0; t < nGroups; t++) {\n            int curr = bsR(5);\n            final char[] len_t = len[t];\n            for (int i = 0; i < alphaSize; i++) {\n                while (bsGetBit()) {\n                    curr += bsGetBit() ? -1 : 1;\n                }\n                len_t[i] = (char) curr;\n            }\n        }\n\n        // finally create the Huffman tables\n        createHuffmanDecodingTables(alphaSize, nGroups);\n    }\n\n    /**\n     * Called by recvDecodingTables() exclusively.\n     */\n    private void createHuffmanDecodingTables(final int alphaSize,\n                                             final int nGroups) {\n        final Data dataShadow = this.data;\n        final char[][] len = dataShadow.temp_charArray2d;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n\n        for (int t = 0; t < nGroups; t++) {\n            int minLen = 32;\n            int maxLen = 0;\n            final char[] len_t = len[t];\n            for (int i = alphaSize; --i >= 0;) {\n                final char lent = len_t[i];\n                if (lent > maxLen) {\n                    maxLen = lent;\n                }\n                if (lent < minLen) {\n                    minLen = lent;\n                }\n            }\n            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,\n                                 maxLen, alphaSize);\n            minLens[t] = minLen;\n        }\n    }\n\n    private void getAndMoveToFrontDecode() throws IOException {\n        this.origPtr = bsR(24);\n        recvDecodingTables();\n\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final byte[] ll8 = dataShadow.ll8;\n        final int[] unzftab = dataShadow.unzftab;\n        final byte[] selector = dataShadow.selector;\n        final byte[] seqToUnseq = dataShadow.seqToUnseq;\n        final char[] yy = dataShadow.getAndMoveToFrontDecode_yy;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n        final int limitLast = this.blockSize100k * 100000;\n\n        /*\n         * Setting up the unzftab entries here is not strictly necessary, but it\n         * does save having to do it later in a separate pass, and so saves a\n         * block's worth of cache misses.\n         */\n        for (int i = 256; --i >= 0;) {\n            yy[i] = (char) i;\n            unzftab[i] = 0;\n        }\n\n        int groupNo = 0;\n        int groupPos = G_SIZE - 1;\n        final int eob = this.nInUse + 1;\n        int nextSym = getAndMoveToFrontDecode0(0);\n        int bsBuffShadow = this.bsBuff;\n        int bsLiveShadow = this.bsLive;\n        int lastShadow = -1;\n        int zt = selector[groupNo] & 0xff;\n        int[] base_zt = base[zt];\n        int[] limit_zt = limit[zt];\n        int[] perm_zt = perm[zt];\n        int minLens_zt = minLens[zt];\n\n        while (nextSym != eob) {\n            if ((nextSym == RUNA) || (nextSym == RUNB)) {\n                int s = -1;\n\n                for (int n = 1; true; n <<= 1) {\n                    if (nextSym == RUNA) {\n                        s += n;\n                    } else if (nextSym == RUNB) {\n                        s += n << 1;\n                    } else {\n                        break;\n                    }\n\n                    if (groupPos == 0) {\n                        groupPos = G_SIZE - 1;\n                        zt = selector[++groupNo] & 0xff;\n                        base_zt = base[zt];\n                        limit_zt = limit[zt];\n                        perm_zt = perm[zt];\n                        minLens_zt = minLens[zt];\n                    } else {\n                        groupPos--;\n                    }\n\n                    int zn = minLens_zt;\n\n                    // Inlined:\n                    // int zvec = bsR(zn);\n                    while (bsLiveShadow < zn) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                        & ((1 << zn) - 1);\n                    bsLiveShadow -= zn;\n\n                    while (zvec > limit_zt[zn]) {\n                        zn++;\n                        while (bsLiveShadow < 1) {\n                            final int thech = inShadow.read();\n                            if (thech >= 0) {\n                                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                                bsLiveShadow += 8;\n                                continue;\n                            } else {\n                                throw new IOException(\n                                                      \"unexpected end of stream\");\n                            }\n                        }\n                        bsLiveShadow--;\n                        zvec = (zvec << 1)\n                            | ((bsBuffShadow >> bsLiveShadow) & 1);\n                    }\n                    nextSym = perm_zt[zvec - base_zt[zn]];\n                }\n\n                final byte ch = seqToUnseq[yy[0]];\n                unzftab[ch & 0xff] += s + 1;\n\n                while (s-- >= 0) {\n                    ll8[++lastShadow] = ch;\n                }\n\n                if (lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n            } else {\n                if (++lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n\n                final char tmp = yy[nextSym - 1];\n                unzftab[seqToUnseq[tmp] & 0xff]++;\n                ll8[lastShadow] = seqToUnseq[tmp];\n\n                /*\n                 * This loop is hammered during decompression, hence avoid\n                 * native method call overhead of System.arraycopy for very\n                 * small ranges to copy.\n                 */\n                if (nextSym <= 16) {\n                    for (int j = nextSym - 1; j > 0;) {\n                        yy[j] = yy[--j];\n                    }\n                } else {\n                    System.arraycopy(yy, 0, yy, 1, nextSym - 1);\n                }\n\n                yy[0] = tmp;\n\n                if (groupPos == 0) {\n                    groupPos = G_SIZE - 1;\n                    zt = selector[++groupNo] & 0xff;\n                    base_zt = base[zt];\n                    limit_zt = limit[zt];\n                    perm_zt = perm[zt];\n                    minLens_zt = minLens[zt];\n                } else {\n                    groupPos--;\n                }\n\n                int zn = minLens_zt;\n\n                // Inlined:\n                // int zvec = bsR(zn);\n                while (bsLiveShadow < zn) {\n                    final int thech = inShadow.read();\n                    if (thech >= 0) {\n                        bsBuffShadow = (bsBuffShadow << 8) | thech;\n                        bsLiveShadow += 8;\n                        continue;\n                    } else {\n                        throw new IOException(\"unexpected end of stream\");\n                    }\n                }\n                int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                    & ((1 << zn) - 1);\n                bsLiveShadow -= zn;\n\n                while (zvec > limit_zt[zn]) {\n                    zn++;\n                    while (bsLiveShadow < 1) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    bsLiveShadow--;\n                    zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n                }\n                nextSym = perm_zt[zvec - base_zt[zn]];\n            }\n        }\n\n        this.last = lastShadow;\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n    }\n\n    private int getAndMoveToFrontDecode0(final int groupNo) throws IOException {\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final int zt = dataShadow.selector[groupNo] & 0xff;\n        final int[] limit_zt = dataShadow.limit[zt];\n        int zn = dataShadow.minLens[zt];\n        int zvec = bsR(zn);\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        while (zvec > limit_zt[zn]) {\n            zn++;\n            while (bsLiveShadow < 1) {\n                final int thech = inShadow.read();\n\n                if (thech >= 0) {\n                    bsBuffShadow = (bsBuffShadow << 8) | thech;\n                    bsLiveShadow += 8;\n                    continue;\n                } else {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n            }\n            bsLiveShadow--;\n            zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n        }\n\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n\n        return dataShadow.perm[zt][zvec - dataShadow.base[zt][zn]];\n    }\n\n    private int setupBlock() throws IOException {\n        if (currentState == EOF || this.data == null) {\n            return -1;\n        }\n\n        final int[] cftab = this.data.cftab;\n        final int[] tt = this.data.initTT(this.last + 1);\n        final byte[] ll8 = this.data.ll8;\n        cftab[0] = 0;\n        System.arraycopy(this.data.unzftab, 0, cftab, 1, 256);\n\n        for (int i = 1, c = cftab[0]; i <= 256; i++) {\n            c += cftab[i];\n            cftab[i] = c;\n        }\n\n        for (int i = 0, lastShadow = this.last; i <= lastShadow; i++) {\n            tt[cftab[ll8[i] & 0xff]++] = i;\n        }\n\n        if ((this.origPtr < 0) || (this.origPtr >= tt.length)) {\n            throw new IOException(\"stream corrupted\");\n        }\n\n        this.su_tPos = tt[this.origPtr];\n        this.su_count = 0;\n        this.su_i2 = 0;\n        this.su_ch2 = 256; /* not a char and not EOF */\n\n        if (this.blockRandomised) {\n            this.su_rNToGo = 0;\n            this.su_rTPos = 0;\n            return setupRandPartA();\n        }\n        return setupNoRandPartA();\n    }\n\n    private int setupRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_ch2 = su_ch2Shadow ^= (this.su_rNToGo == 1) ? 1 : 0;\n            this.su_i2++;\n            this.currentState = RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupNoRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_ch2 = su_ch2Shadow;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_i2++;\n            this.currentState = NO_RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            this.currentState = NO_RAND_PART_A_STATE;\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_count = 1;\n            return setupRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_j2 = 0;\n            this.currentState = RAND_PART_C_STATE;\n            if (this.su_rNToGo == 1) {\n                this.su_z ^= 1;\n            }\n            return setupRandPartC();\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            this.crc.updateCRC(this.su_ch2);\n            this.su_j2++;\n            return this.su_ch2;\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_i2++;\n            this.su_count = 0;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupNoRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.su_count = 1;\n            return setupNoRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_j2 = 0;\n            return setupNoRandPartC();\n        } else {\n            return setupNoRandPartA();\n        }\n    }\n\n    private int setupNoRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            int su_ch2Shadow = this.su_ch2;\n            this.crc.updateCRC(su_ch2Shadow);\n            this.su_j2++;\n            this.currentState = NO_RAND_PART_C_STATE;\n            return su_ch2Shadow;\n        } else {\n            this.su_i2++;\n            this.su_count = 0;\n            return setupNoRandPartA();\n        }\n    }\n\n    private static final class Data extends Object {\n\n        // (with blockSize 900k)\n        final boolean[] inUse = new boolean[256]; // 256 byte\n\n        final byte[] seqToUnseq = new byte[256]; // 256 byte\n        final byte[] selector = new byte[MAX_SELECTORS]; // 18002 byte\n        final byte[] selectorMtf = new byte[MAX_SELECTORS]; // 18002 byte\n\n        /**\n         * Freq table collected to save a pass over the data during\n         * decompression.\n         */\n        final int[] unzftab = new int[256]; // 1024 byte\n\n        final int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[] minLens = new int[N_GROUPS]; // 24 byte\n\n        final int[] cftab = new int[257]; // 1028 byte\n        final char[] getAndMoveToFrontDecode_yy = new char[256]; // 512 byte\n        final char[][] temp_charArray2d = new char[N_GROUPS][MAX_ALPHA_SIZE]; // 3096\n        // byte\n        final byte[] recvDecodingTables_pos = new byte[N_GROUPS]; // 6 byte\n        // ---------------\n        // 60798 byte\n\n        int[] tt; // 3600000 byte\n        byte[] ll8; // 900000 byte\n\n        // ---------------\n        // 4560782 byte\n        // ===============\n\n        Data(int blockSize100k) {\n            this.ll8 = new byte[blockSize100k * BZip2Constants.BASEBLOCKSIZE];\n        }\n\n        /**\n         * Initializes the {@link #tt} array.\n         * \n         * This method is called when the required length of the array is known.\n         * I don't initialize it at construction time to avoid unneccessary\n         * memory allocation when compressing small files.\n         */\n        int[] initTT(int length) {\n            int[] ttShadow = this.tt;\n\n            // tt.length should always be >= length, but theoretically\n            // it can happen, if the compressor mixed small and large\n            // blocks. Normally only the last block will be smaller\n            // than others.\n            if ((ttShadow == null) || (ttShadow.length < length)) {\n                this.tt = ttShadow = new int[length];\n            }\n\n            return ttShadow;\n        }\n\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a bzip2 file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a bzip2 compressed stream, false otherwise\n     * \n     * @since 1.1\n     */\n    public static boolean matches(byte[] signature, int length) {\n\n        if (length < 3) {\n            return false;\n        }\n\n        if (signature[0] != 'B') {\n            return false;\n        }\n\n        if (signature[1] != 'Z') {\n            return false;\n        }\n\n        if (signature[2] != 'h') {\n            return false;\n        }\n\n        return true;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 23, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.sevenz.Coders", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.FilterInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.security.GeneralSecurityException;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Arrays;\nimport java.util.zip.Deflater;\nimport java.util.zip.DeflaterOutputStream;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\n\nimport javax.crypto.Cipher;\nimport javax.crypto.CipherInputStream;\nimport javax.crypto.SecretKey;\nimport javax.crypto.spec.IvParameterSpec;\nimport javax.crypto.spec.SecretKeySpec;\n\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\nimport org.tukaani.xz.LZMAInputStream;\n\nclass Coders {\n    static InputStream addDecoder(final InputStream is,\n            final Coder coder, final byte[] password) throws IOException {\n        for (final CoderId coderId : coderTable) {\n            if (Arrays.equals(coderId.method.getId(), coder.decompressionMethodId)) {\n                return coderId.coder.decode(is, coder, password);\n            }\n        }\n        throw new IOException(\"Unsupported compression method \" +\n                Arrays.toString(coder.decompressionMethodId));\n    }\n    \n    static OutputStream addEncoder(final OutputStream out, final SevenZMethod method,\n                                   final byte[] password) throws IOException {\n        for (final CoderId coderId : coderTable) {\n            if (coderId.method.equals(method)) {\n                return coderId.coder.encode(out, password);\n            }\n        }\n        throw new IOException(\"Unsupported compression method \" + method);\n    }\n\n    static CoderId[] coderTable = new CoderId[] {\n        new CoderId(SevenZMethod.COPY, new CopyDecoder()),\n        new CoderId(SevenZMethod.LZMA, new LZMADecoder()),\n        new CoderId(SevenZMethod.LZMA2, new LZMA2Decoder()),\n        new CoderId(SevenZMethod.DEFLATE, new DeflateDecoder()),\n        new CoderId(SevenZMethod.BZIP2, new BZIP2Decoder()),\n        new CoderId(SevenZMethod.AES256SHA256, new AES256SHA256Decoder())\n    };\n    \n    static class CoderId {\n        CoderId(SevenZMethod method, final CoderBase coder) {\n            this.method = method;\n            this.coder = coder;\n        }\n\n        final SevenZMethod method;\n        final CoderBase coder;\n    }\n    \n    static abstract class CoderBase {\n        abstract InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException;\n        OutputStream encode(final OutputStream out, final byte[] password)\n            throws IOException {\n            throw new UnsupportedOperationException(\"method doesn't support writing\");\n        }\n    }\n    \n    static class CopyDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            return in; \n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return out;\n        }\n    }\n\n    static class LZMADecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            byte propsByte = coder.properties[0];\n            long dictSize = coder.properties[1];\n            for (int i = 1; i < 4; i++) {\n                dictSize |= (coder.properties[i + 1] << (8 * i));\n            }\n            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n            }\n            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n        }\n    }\n    \n    static class DeflateDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n            throws IOException {\n            return new InflaterInputStream(new DummyByteAddingInputStream(in),\n                                           new Inflater(true));\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return new DeflaterOutputStream(out, new Deflater(9, true));\n        }\n    }\n\n    static class BZIP2Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorInputStream(in);\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorOutputStream(out);\n        }\n    }\n\n    static class AES256SHA256Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                final byte[] passwordBytes) throws IOException {\n            return new InputStream() {\n                private boolean isInitialized = false;\n                private CipherInputStream cipherInputStream = null;\n                \n                private CipherInputStream init() throws IOException {\n                    if (isInitialized) {\n                        return cipherInputStream;\n                    }\n                    final int byte0 = 0xff & coder.properties[0];\n                    final int numCyclesPower = byte0 & 0x3f;\n                    final int byte1 = 0xff & coder.properties[1];\n                    final int ivSize = ((byte0 >> 6) & 1) + (byte1 & 0x0f);\n                    final int saltSize = ((byte0 >> 7) & 1) + (byte1 >> 4);\n                    if (2 + saltSize + ivSize > coder.properties.length) {\n                        throw new IOException(\"Salt size + IV size too long\");\n                    }\n                    final byte[] salt = new byte[saltSize];\n                    System.arraycopy(coder.properties, 2, salt, 0, saltSize);\n                    final byte[] iv = new byte[16];\n                    System.arraycopy(coder.properties, 2 + saltSize, iv, 0, ivSize);\n                    \n                    if (passwordBytes == null) {\n                        throw new IOException(\"Cannot read encrypted files without a password\");\n                    }\n                    final byte[] aesKeyBytes;\n                    if (numCyclesPower == 0x3f) {\n                        aesKeyBytes = new byte[32];\n                        System.arraycopy(salt, 0, aesKeyBytes, 0, saltSize);\n                        System.arraycopy(passwordBytes, 0, aesKeyBytes, saltSize,\n                                Math.min(passwordBytes.length, aesKeyBytes.length - saltSize));\n                    } else {\n                        final MessageDigest digest;\n                        try {\n                            digest = MessageDigest.getInstance(\"SHA-256\");\n                        } catch (NoSuchAlgorithmException noSuchAlgorithmException) {\n                            IOException ioe = new IOException(\"SHA-256 is unsupported by your Java implementation\");\n                            ioe.initCause(noSuchAlgorithmException);\n                            throw ioe;\n        // TODO: simplify when Compress requires Java 1.6                \n//                            throw new IOException(\"SHA-256 is unsupported by your Java implementation\",\n//                                    noSuchAlgorithmException);\n                        }\n                        final byte[] extra = new byte[8];\n                        for (long j = 0; j < (1L << numCyclesPower); j++) {\n                            digest.update(salt);\n                            digest.update(passwordBytes);\n                            digest.update(extra);\n                            for (int k = 0; k < extra.length; k++) {\n                                ++extra[k];\n                                if (extra[k] != 0) {\n                                    break;\n                                }\n                            }\n                        }\n                        aesKeyBytes = digest.digest();\n                    }\n                    \n                    final SecretKey aesKey = new SecretKeySpec(aesKeyBytes, \"AES\");\n                    try {\n                        final Cipher cipher = Cipher.getInstance(\"AES/CBC/NoPadding\");\n                        cipher.init(Cipher.DECRYPT_MODE, aesKey, new IvParameterSpec(iv));\n                        cipherInputStream = new CipherInputStream(in, cipher);\n                        isInitialized = true;\n                        return cipherInputStream;\n                    } catch (GeneralSecurityException generalSecurityException) {\n                        IOException ioe = new IOException(\"Decryption error \" +\n                                \"(do you have the JCE Unlimited Strength Jurisdiction Policy Files installed?)\");\n                        ioe.initCause(generalSecurityException);\n                        throw ioe;\n        // TODO: simplify when Compress requires Java 1.6                \n//                        throw new IOException(\"Decryption error \" +\n//                                \"(do you have the JCE Unlimited Strength Jurisdiction Policy Files installed?)\",\n//                                generalSecurityException);\n                    }\n                }\n                \n                @Override\n                public int read() throws IOException {\n                    return init().read();\n                }\n                \n                @Override\n                public int read(byte[] b, int off, int len) throws IOException {\n                    return init().read(b, off, len);\n                }\n                \n                @Override\n                public void close() {\n                }\n            };\n        }\n    }\n\n    /**\n     * ZLIB requires an extra dummy byte.\n     *\n     * @see java.util.zip.Inflater#Inflater(boolean)\n     * @see org.apache.commons.compress.archivers.zip.ZipFile.BoundedInputStream\n     */\n    private static class DummyByteAddingInputStream extends FilterInputStream {\n        private boolean addDummyByte = true;\n\n        private DummyByteAddingInputStream(InputStream in) {\n            super(in);\n        }\n\n        @Override\n        public int read() throws IOException {\n            int result = super.read();\n            if (result == -1 && addDummyByte) {\n                addDummyByte = false;\n                result = 0;\n            }\n            return result;\n        }\n\n        @Override\n        public int read(byte[] b, int off, int len) throws IOException {\n            int result = super.read(b, off, len);\n            if (result == -1 && addDummyByte) {\n                addDummyByte = false;\n                b[off] = 0;\n                return 1;\n            }\n            return result;\n        }\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.FilterInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.security.GeneralSecurityException;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Arrays;\nimport java.util.zip.Deflater;\nimport java.util.zip.DeflaterOutputStream;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\n\nimport javax.crypto.Cipher;\nimport javax.crypto.CipherInputStream;\nimport javax.crypto.SecretKey;\nimport javax.crypto.spec.IvParameterSpec;\nimport javax.crypto.spec.SecretKeySpec;\n\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\nimport org.tukaani.xz.LZMAInputStream;\n\nclass Coders {\n    static InputStream addDecoder(final InputStream is,\n            final Coder coder, final byte[] password) throws IOException {\n        for (final CoderId coderId : coderTable) {\n            if (Arrays.equals(coderId.method.getId(), coder.decompressionMethodId)) {\n                return coderId.coder.decode(is, coder, password);\n            }\n        }\n        throw new IOException(\"Unsupported compression method \" +\n                Arrays.toString(coder.decompressionMethodId));\n    }\n    \n    static OutputStream addEncoder(final OutputStream out, final SevenZMethod method,\n                                   final byte[] password) throws IOException {\n        for (final CoderId coderId : coderTable) {\n            if (coderId.method.equals(method)) {\n                return coderId.coder.encode(out, password);\n            }\n        }\n        throw new IOException(\"Unsupported compression method \" + method);\n    }\n\n    static CoderId[] coderTable = new CoderId[] {\n        new CoderId(SevenZMethod.COPY, new CopyDecoder()),\n        new CoderId(SevenZMethod.LZMA, new LZMADecoder()),\n        new CoderId(SevenZMethod.LZMA2, new LZMA2Decoder()),\n        new CoderId(SevenZMethod.DEFLATE, new DeflateDecoder()),\n        new CoderId(SevenZMethod.BZIP2, new BZIP2Decoder()),\n        new CoderId(SevenZMethod.AES256SHA256, new AES256SHA256Decoder())\n    };\n    \n    static class CoderId {\n        CoderId(SevenZMethod method, final CoderBase coder) {\n            this.method = method;\n            this.coder = coder;\n        }\n\n        final SevenZMethod method;\n        final CoderBase coder;\n    }\n    \n    static abstract class CoderBase {\n        abstract InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException;\n        OutputStream encode(final OutputStream out, final byte[] password)\n            throws IOException {\n            throw new UnsupportedOperationException(\"method doesn't support writing\");\n        }\n    }\n    \n    static class CopyDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            return in; \n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return out;\n        }\n    }\n\n    static class LZMADecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                byte[] password) throws IOException {\n            byte propsByte = coder.properties[0];\n            long dictSize = coder.properties[1];\n            for (int i = 1; i < 4; i++) {\n                dictSize |= (coder.properties[i + 1] & 0xffl) << (8 * i);\n            }\n            if (dictSize > LZMAInputStream.DICT_SIZE_MAX) {\n                throw new IOException(\"Dictionary larger than 4GiB maximum size\");\n            }\n            return new LZMAInputStream(in, -1, propsByte, (int) dictSize);\n        }\n    }\n    \n    static class DeflateDecoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n            throws IOException {\n            return new InflaterInputStream(new DummyByteAddingInputStream(in),\n                                           new Inflater(true));\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password) {\n            return new DeflaterOutputStream(out, new Deflater(9, true));\n        }\n    }\n\n    static class BZIP2Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorInputStream(in);\n        }\n        @Override\n        OutputStream encode(final OutputStream out, final byte[] password)\n                throws IOException {\n            return new BZip2CompressorOutputStream(out);\n        }\n    }\n\n    static class AES256SHA256Decoder extends CoderBase {\n        @Override\n        InputStream decode(final InputStream in, final Coder coder,\n                final byte[] passwordBytes) throws IOException {\n            return new InputStream() {\n                private boolean isInitialized = false;\n                private CipherInputStream cipherInputStream = null;\n                \n                private CipherInputStream init() throws IOException {\n                    if (isInitialized) {\n                        return cipherInputStream;\n                    }\n                    final int byte0 = 0xff & coder.properties[0];\n                    final int numCyclesPower = byte0 & 0x3f;\n                    final int byte1 = 0xff & coder.properties[1];\n                    final int ivSize = ((byte0 >> 6) & 1) + (byte1 & 0x0f);\n                    final int saltSize = ((byte0 >> 7) & 1) + (byte1 >> 4);\n                    if (2 + saltSize + ivSize > coder.properties.length) {\n                        throw new IOException(\"Salt size + IV size too long\");\n                    }\n                    final byte[] salt = new byte[saltSize];\n                    System.arraycopy(coder.properties, 2, salt, 0, saltSize);\n                    final byte[] iv = new byte[16];\n                    System.arraycopy(coder.properties, 2 + saltSize, iv, 0, ivSize);\n                    \n                    if (passwordBytes == null) {\n                        throw new IOException(\"Cannot read encrypted files without a password\");\n                    }\n                    final byte[] aesKeyBytes;\n                    if (numCyclesPower == 0x3f) {\n                        aesKeyBytes = new byte[32];\n                        System.arraycopy(salt, 0, aesKeyBytes, 0, saltSize);\n                        System.arraycopy(passwordBytes, 0, aesKeyBytes, saltSize,\n                                Math.min(passwordBytes.length, aesKeyBytes.length - saltSize));\n                    } else {\n                        final MessageDigest digest;\n                        try {\n                            digest = MessageDigest.getInstance(\"SHA-256\");\n                        } catch (NoSuchAlgorithmException noSuchAlgorithmException) {\n                            IOException ioe = new IOException(\"SHA-256 is unsupported by your Java implementation\");\n                            ioe.initCause(noSuchAlgorithmException);\n                            throw ioe;\n        // TODO: simplify when Compress requires Java 1.6                \n//                            throw new IOException(\"SHA-256 is unsupported by your Java implementation\",\n//                                    noSuchAlgorithmException);\n                        }\n                        final byte[] extra = new byte[8];\n                        for (long j = 0; j < (1L << numCyclesPower); j++) {\n                            digest.update(salt);\n                            digest.update(passwordBytes);\n                            digest.update(extra);\n                            for (int k = 0; k < extra.length; k++) {\n                                ++extra[k];\n                                if (extra[k] != 0) {\n                                    break;\n                                }\n                            }\n                        }\n                        aesKeyBytes = digest.digest();\n                    }\n                    \n                    final SecretKey aesKey = new SecretKeySpec(aesKeyBytes, \"AES\");\n                    try {\n                        final Cipher cipher = Cipher.getInstance(\"AES/CBC/NoPadding\");\n                        cipher.init(Cipher.DECRYPT_MODE, aesKey, new IvParameterSpec(iv));\n                        cipherInputStream = new CipherInputStream(in, cipher);\n                        isInitialized = true;\n                        return cipherInputStream;\n                    } catch (GeneralSecurityException generalSecurityException) {\n                        IOException ioe = new IOException(\"Decryption error \" +\n                                \"(do you have the JCE Unlimited Strength Jurisdiction Policy Files installed?)\");\n                        ioe.initCause(generalSecurityException);\n                        throw ioe;\n        // TODO: simplify when Compress requires Java 1.6                \n//                        throw new IOException(\"Decryption error \" +\n//                                \"(do you have the JCE Unlimited Strength Jurisdiction Policy Files installed?)\",\n//                                generalSecurityException);\n                    }\n                }\n                \n                @Override\n                public int read() throws IOException {\n                    return init().read();\n                }\n                \n                @Override\n                public int read(byte[] b, int off, int len) throws IOException {\n                    return init().read(b, off, len);\n                }\n                \n                @Override\n                public void close() {\n                }\n            };\n        }\n    }\n\n    /**\n     * ZLIB requires an extra dummy byte.\n     *\n     * @see java.util.zip.Inflater#Inflater(boolean)\n     * @see org.apache.commons.compress.archivers.zip.ZipFile.BoundedInputStream\n     */\n    private static class DummyByteAddingInputStream extends FilterInputStream {\n        private boolean addDummyByte = true;\n\n        private DummyByteAddingInputStream(InputStream in) {\n            super(in);\n        }\n\n        @Override\n        public int read() throws IOException {\n            int result = super.read();\n            if (result == -1 && addDummyByte) {\n                addDummyByte = false;\n                result = 0;\n            }\n            return result;\n        }\n\n        @Override\n        public int read(byte[] b, int off, int len) throws IOException {\n            int result = super.read(b, off, len);\n            if (result == -1 && addDummyByte) {\n                addDummyByte = false;\n                b[off] = 0;\n                return 1;\n            }\n            return result;\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 24, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        if (trailer == 0 || trailer == ' '){\n            end--;\n        } else {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, end-1, trailer));\n        }\n        trailer = buffer[end - 1];\n        while (start < end - 1 && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n        if (start == end) {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, start, trailer));\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 25, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n * DEFLATE algorithm is used, as the size information is not available\n * from the header.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != -1) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(buf.limit());\n            current.bytesReadFromStream += buf.limit();\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(byte[] buffer, int offset, int length) throws IOException {\n        int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(byte[] buffer, int offset, int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data decsriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(ByteArrayOutputStream bos, int offset, int lastRead, int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(ByteArrayOutputStream bos, int offset, int lastRead, int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n * DEFLATE algorithm is used, as the size information is not available\n * from the header.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != -1) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(buf.limit());\n            current.bytesReadFromStream += buf.limit();\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(byte[] buffer, int offset, int length) throws IOException {\n        int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(byte[] buffer, int offset, int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data decsriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(ByteArrayOutputStream bos, int offset, int lastRead, int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(ByteArrayOutputStream bos, int offset, int lastRead, int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 26, "classes_modified": [{"class_name": "org.apache.commons.compress.utils.IOUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\n/**\n * Utility functions\n * @Immutable\n */\npublic final class IOUtils {\n\n    private static final int COPY_BUF_SIZE = 8024;\n    private static final int SKIP_BUF_SIZE = 4096;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private IOUtils(){\n    }\n\n    /**\n     * Copies the content of a InputStream into an OutputStream.\n     * Uses a default buffer size of 8024 bytes.\n     *\n     * @param input\n     *            the InputStream to copy\n     * @param output\n     *            the target Stream\n     * @throws IOException\n     *             if an error occurs\n     */\n    public static long copy(final InputStream input, final OutputStream output) throws IOException {\n        return copy(input, output, COPY_BUF_SIZE);\n    }\n\n    /**\n     * Copies the content of a InputStream into an OutputStream\n     *\n     * @param input\n     *            the InputStream to copy\n     * @param output\n     *            the target Stream\n     * @param buffersize\n     *            the buffer size to use\n     * @throws IOException\n     *             if an error occurs\n     */\n    public static long copy(final InputStream input, final OutputStream output, int buffersize) throws IOException {\n        final byte[] buffer = new byte[buffersize];\n        int n = 0;\n        long count=0;\n        while (-1 != (n = input.read(buffer))) {\n            output.write(buffer, 0, n);\n            count += n;\n        }\n        return count;\n    }\n    \n    /**\n     * Skips the given number of bytes by repeatedly invoking skip on\n     * the given input stream if necessary.\n     *\n     * <p>In a case where the stream's skip() method returns 0 before\n     * the requested number of bytes has been skip this implementation\n     * will fall back to using the read() method.</p>\n     *\n     * <p>This method will only skip less than the requested number of\n     * bytes if the end of the input stream has been reached.</p>\n     *\n     * @param input stream to skip bytes in\n     * @param numToSkip the number of bytes to skip\n     * @return the number of bytes actually skipped\n     * @throws IOException\n     */\n    public static long skip(InputStream input, long numToSkip) throws IOException {\n        long available = numToSkip;\n        while (numToSkip > 0) {\n            long skipped = input.skip(numToSkip);\n            if (skipped == 0) {\n                break;\n            }\n            numToSkip -= skipped;\n        }\n            \n        return available - numToSkip;\n    }\n\n    /**\n     * Reads as much from input as possible to fill the given array.\n     *\n     * <p>This method may invoke read repeatedly to fill the array and\n     * only read less bytes than the length of the array if the end of\n     * the stream has been reached.</p>\n     *\n     * @param input stream to read from\n     * @param b buffer to fill\n     * @return the number of bytes actually read\n     * @throws IOException\n     */\n    public static int readFully(InputStream input, byte[] b) throws IOException {\n        return readFully(input, b, 0, b.length);\n    }\n\n    /**\n     * Reads as much from input as possible to fill the given array\n     * with the given amount of bytes.\n     *\n     * <p>This method may invoke read repeatedly to read the bytes and\n     * only read less bytes than the requested length if the end of\n     * the stream has been reached.</p>\n     *\n     * @param input stream to read from\n     * @param b buffer to fill\n     * @param offset offset into the buffer to start filling at\n     * @param len of bytes to read\n     * @return the number of bytes actually read\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public static int readFully(InputStream input, byte[] b, int offset, int len)\n        throws IOException {\n        if (len < 0 || offset < 0 || len + offset > b.length) {\n            throw new IndexOutOfBoundsException();\n        }\n        int count = 0, x = 0;\n        while (count != len) {\n            x = input.read(b, offset + count, len - count);\n            if (x == -1) {\n                break;\n            }\n            count += x;\n        }\n        return count;\n    }\n\n    // toByteArray(InputStream) copied from:\n    // commons/proper/io/trunk/src/main/java/org/apache/commons/io/IOUtils.java?revision=1428941\n    // January 8th, 2013\n    //\n    // Assuming our copy() works just as well as theirs!  :-)\n\n    /**\n     * Gets the contents of an <code>InputStream</code> as a <code>byte[]</code>.\n     * <p>\n     * This method buffers the input internally, so there is no need to use a\n     * <code>BufferedInputStream</code>.\n     *\n     * @param input  the <code>InputStream</code> to read from\n     * @return the requested byte array\n     * @throws NullPointerException if the input is null\n     * @throws IOException if an I/O error occurs\n     * @since 1.5\n     */\n    public static byte[] toByteArray(final InputStream input) throws IOException {\n        final ByteArrayOutputStream output = new ByteArrayOutputStream();\n        copy(input, output);\n        return output.toByteArray();\n    }\n\n    /**\n     * Closes the given Closeable and swallows any IOException that may occur.\n     * @param c Closeable to close, can be null\n     * @since 1.7\n     */\n    public static void closeQuietly(Closeable c) {\n        if (c != null) {\n            try {\n                c.close();\n            } catch (IOException ignored) { // NOPMD\n            }\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\n/**\n * Utility functions\n * @Immutable\n */\npublic final class IOUtils {\n\n    private static final int COPY_BUF_SIZE = 8024;\n    private static final int SKIP_BUF_SIZE = 4096;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private IOUtils(){\n    }\n\n    /**\n     * Copies the content of a InputStream into an OutputStream.\n     * Uses a default buffer size of 8024 bytes.\n     *\n     * @param input\n     *            the InputStream to copy\n     * @param output\n     *            the target Stream\n     * @throws IOException\n     *             if an error occurs\n     */\n    public static long copy(final InputStream input, final OutputStream output) throws IOException {\n        return copy(input, output, COPY_BUF_SIZE);\n    }\n\n    /**\n     * Copies the content of a InputStream into an OutputStream\n     *\n     * @param input\n     *            the InputStream to copy\n     * @param output\n     *            the target Stream\n     * @param buffersize\n     *            the buffer size to use\n     * @throws IOException\n     *             if an error occurs\n     */\n    public static long copy(final InputStream input, final OutputStream output, int buffersize) throws IOException {\n        final byte[] buffer = new byte[buffersize];\n        int n = 0;\n        long count=0;\n        while (-1 != (n = input.read(buffer))) {\n            output.write(buffer, 0, n);\n            count += n;\n        }\n        return count;\n    }\n    \n    /**\n     * Skips the given number of bytes by repeatedly invoking skip on\n     * the given input stream if necessary.\n     *\n     * <p>In a case where the stream's skip() method returns 0 before\n     * the requested number of bytes has been skip this implementation\n     * will fall back to using the read() method.</p>\n     *\n     * <p>This method will only skip less than the requested number of\n     * bytes if the end of the input stream has been reached.</p>\n     *\n     * @param input stream to skip bytes in\n     * @param numToSkip the number of bytes to skip\n     * @return the number of bytes actually skipped\n     * @throws IOException\n     */\n    public static long skip(InputStream input, long numToSkip) throws IOException {\n        long available = numToSkip;\n        while (numToSkip > 0) {\n            long skipped = input.skip(numToSkip);\n            if (skipped == 0) {\n                break;\n            }\n            numToSkip -= skipped;\n        }\n            \n        if (numToSkip > 0) {\n            byte[] skipBuf = new byte[SKIP_BUF_SIZE];\n            while (numToSkip > 0) {\n                int read = readFully(input, skipBuf, 0,\n                                     (int) Math.min(numToSkip, SKIP_BUF_SIZE));\n                if (read < 1) {\n                    break;\n                }\n                numToSkip -= read;\n            }\n        }\n        return available - numToSkip;\n    }\n\n    /**\n     * Reads as much from input as possible to fill the given array.\n     *\n     * <p>This method may invoke read repeatedly to fill the array and\n     * only read less bytes than the length of the array if the end of\n     * the stream has been reached.</p>\n     *\n     * @param input stream to read from\n     * @param b buffer to fill\n     * @return the number of bytes actually read\n     * @throws IOException\n     */\n    public static int readFully(InputStream input, byte[] b) throws IOException {\n        return readFully(input, b, 0, b.length);\n    }\n\n    /**\n     * Reads as much from input as possible to fill the given array\n     * with the given amount of bytes.\n     *\n     * <p>This method may invoke read repeatedly to read the bytes and\n     * only read less bytes than the requested length if the end of\n     * the stream has been reached.</p>\n     *\n     * @param input stream to read from\n     * @param b buffer to fill\n     * @param offset offset into the buffer to start filling at\n     * @param len of bytes to read\n     * @return the number of bytes actually read\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public static int readFully(InputStream input, byte[] b, int offset, int len)\n        throws IOException {\n        if (len < 0 || offset < 0 || len + offset > b.length) {\n            throw new IndexOutOfBoundsException();\n        }\n        int count = 0, x = 0;\n        while (count != len) {\n            x = input.read(b, offset + count, len - count);\n            if (x == -1) {\n                break;\n            }\n            count += x;\n        }\n        return count;\n    }\n\n    // toByteArray(InputStream) copied from:\n    // commons/proper/io/trunk/src/main/java/org/apache/commons/io/IOUtils.java?revision=1428941\n    // January 8th, 2013\n    //\n    // Assuming our copy() works just as well as theirs!  :-)\n\n    /**\n     * Gets the contents of an <code>InputStream</code> as a <code>byte[]</code>.\n     * <p>\n     * This method buffers the input internally, so there is no need to use a\n     * <code>BufferedInputStream</code>.\n     *\n     * @param input  the <code>InputStream</code> to read from\n     * @return the requested byte array\n     * @throws NullPointerException if the input is null\n     * @throws IOException if an I/O error occurs\n     * @since 1.5\n     */\n    public static byte[] toByteArray(final InputStream input) throws IOException {\n        final ByteArrayOutputStream output = new ByteArrayOutputStream();\n        copy(input, output);\n        return output.toByteArray();\n    }\n\n    /**\n     * Closes the given Closeable and swallows any IOException that may occur.\n     * @param c Closeable to close, can be null\n     * @since 1.7\n     */\n    public static void closeQuietly(Closeable c) {\n        if (c != null) {\n            try {\n                c.close();\n            } catch (IOException ignored) { // NOPMD\n            }\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 27, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n        if (start == end) {\n            throw new IllegalArgumentException(\n                    exceptionMessage(buffer, offset, length, start, trailer));\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (int i = 0; i < length; ++i) {\n                    byte b = buffer[i];\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 28, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    /**\n     * Skip bytes in the input buffer. This skips bytes in the\n     * current entry's data, not the entire archive, and will\n     * stop at the end of the current entry's data if the number\n     * to skip extends beyond that point.\n     *\n     * @param numToSkip The number of bytes to skip.\n     * @return the number actually skipped\n     * @throws IOException on error\n     */\n    @Override\n    public long skip(long numToSkip) throws IOException {\n\n        long available = entrySize - entryOffset;\n        numToSkip = Math.min(numToSkip, available);\n\n        long skipped = IOUtils.skip(is, numToSkip); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            skip(Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, encoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(encoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(encoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            byte[] rest = new byte[len - read];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != len - read){\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + (len - read)\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      len - read - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        count(totalRead);\n        \n        if (totalRead == -1) {\n            hasHitEOF = true;\n        } else {\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    /**\n     * Skip bytes in the input buffer. This skips bytes in the\n     * current entry's data, not the entire archive, and will\n     * stop at the end of the current entry's data if the number\n     * to skip extends beyond that point.\n     *\n     * @param numToSkip The number of bytes to skip.\n     * @return the number actually skipped\n     * @throws IOException on error\n     */\n    @Override\n    public long skip(long numToSkip) throws IOException {\n\n        long available = entrySize - entryOffset;\n        numToSkip = Math.min(numToSkip, available);\n\n        long skipped = IOUtils.skip(is, numToSkip); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            skip(Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, encoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(encoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(encoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            byte[] rest = new byte[len - read];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != len - read){\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + (len - read)\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      len - read - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 29, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.ArchiveStreamFactory", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.arj.ArjArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.sevenz.SevenZFile;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order to add other implementations, you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * @Immutable provided that the deprecated method setEntryEncoding is not used.\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant (value {@value}) used to identify the AR archive format.\n     * @since 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant (value {@value}) used to identify the ARJ archive format.\n     * Not supported as an output stream type.\n     * @since 1.6\n     */\n    public static final String ARJ = \"arj\";\n    /**\n     * Constant (value {@value}) used to identify the CPIO archive format.\n     * @since 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant (value {@value}) used to identify the Unix DUMP archive format.\n     * Not supported as an output stream type.\n     * @since 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant (value {@value}) used to identify the JAR archive format.\n     * @since 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant (value {@value}) used to identify the ZIP archive format.\n     * @since 1.1\n     */\n    public static final String ZIP = \"zip\";\n    /**\n     * Constant (value {@value}) used to identify the 7z archive format.\n     * @since 1.8\n     */\n    public static final String SEVEN_Z = \"7z\";\n\n    /**\n     * Entry encoding, null for the platform default.\n     */\n    private final String encoding;\n\n    /**\n     * Entry encoding, null for the default.\n     */\n    private volatile String entryEncoding = null;\n\n    /**\n     * Create an instance using the platform default encoding.\n     */\n    public ArchiveStreamFactory() {\n        this(null);\n    }\n\n    /**\n     * Create an instance using the specified encoding.\n     *\n     * @param encoding the encoding to be used.\n     *\n     * @since 1.10\n     */\n    public ArchiveStreamFactory(String encoding) {\n        super();\n        this.encoding = encoding;\n        // Also set the original field so can continue to use it.\n        this.entryEncoding = encoding;\n    }\n\n    /**\n     * Returns the encoding to use for arj, jar, zip, dump, cpio and tar\n     * files, or null for the archiver default.\n     *\n     * @return entry encoding, or null for the archiver default\n     * @since 1.5\n     */\n    public String getEntryEncoding() {\n        return entryEncoding;\n    }\n\n    /**\n     * Sets the encoding to use for arj, jar, zip, dump, cpio and tar files. Use null for the archiver default.\n     * \n     * @param entryEncoding the entry encoding, null uses the archiver default.\n     * @since 1.5\n     * @deprecated 1.10 use {@link #ArchiveStreamFactory(String)} to specify the encoding\n     * @throws IllegalStateException if the constructor {@link #ArchiveStreamFactory(String)} \n     * was used to specify the factory encoding.\n     */\n    @Deprecated\n    public void setEntryEncoding(String entryEncoding) {\n        // Note: this does not detect new ArchiveStreamFactory(null) but that does not set the encoding anyway\n        if (encoding != null) {\n            throw new IllegalStateException(\"Cannot overide encoding set by the constructor\");\n        }\n        this.entryEncoding = entryEncoding;\n    }\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name,\n     * i.e. {@value #AR}, {@value #ARJ}, {@value #ZIP}, {@value #TAR}, {@value #JAR}, {@value #CPIO}, {@value #DUMP} or {@value #SEVEN_Z}\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * read from a stream\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n\n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ARJ.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new ArjArchiveInputStream(in, entryEncoding);\n            } else {\n                return new ArjArchiveInputStream(in);\n            }\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new ZipArchiveInputStream(in, entryEncoding);\n            } else {\n                return new ZipArchiveInputStream(in);\n            }\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new TarArchiveInputStream(in, entryEncoding);\n            } else {\n                return new TarArchiveInputStream(in);\n            }\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new JarArchiveInputStream(in, entryEncoding);\n            } else {\n                return new JarArchiveInputStream(in);\n            }\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new CpioArchiveInputStream(in, entryEncoding);\n            } else {\n                return new CpioArchiveInputStream(in);\n            }\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new DumpArchiveInputStream(in, entryEncoding);\n            } else {\n                return new DumpArchiveInputStream(in);\n            }\n        }\n        if (SEVEN_Z.equalsIgnoreCase(archiverName)) {\n            throw new StreamingNotSupportedException(SEVEN_Z);\n        }\n\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an output stream.\n     * \n     * @param archiverName the archive name,\n     * i.e. {@value #AR}, {@value #ZIP}, {@value #TAR}, {@value #JAR} or {@value #CPIO} \n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * written to a stream\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            ZipArchiveOutputStream zip = new ZipArchiveOutputStream(out);\n            if (entryEncoding != null) {\n                zip.setEncoding(entryEncoding);\n            }\n            return zip;\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new TarArchiveOutputStream(out, entryEncoding);\n            } else {\n                return new TarArchiveOutputStream(out);\n            }\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n                return new JarArchiveOutputStream(out);\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new CpioArchiveOutputStream(out, entryEncoding);\n            } else {\n                return new CpioArchiveOutputStream(out);\n            }\n        }\n        if (SEVEN_Z.equalsIgnoreCase(archiverName)) {\n            throw new StreamingNotSupportedException(SEVEN_Z);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * read from a stream\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = IOUtils.readFully(in, signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new ZipArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new ZipArchiveInputStream(in);\n                }\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new JarArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new JarArchiveInputStream(in);\n                }\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new CpioArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new CpioArchiveInputStream(in);\n                }\n            } else if (ArjArchiveInputStream.matches(signature, signatureLength)) {\n                    return new ArjArchiveInputStream(in);\n            } else if (SevenZFile.matches(signature, signatureLength)) {\n                throw new StreamingNotSupportedException(SEVEN_Z);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = IOUtils.readFully(in, dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in, entryEncoding);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = IOUtils.readFully(in, tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in, entryEncoding);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            if (signatureLength >= 512) {\n                TarArchiveInputStream tais = null;\n                try {\n                    tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                    // COMPRESS-191 - verify the header checksum\n                    if (tais.getNextTarEntry().isCheckSumOK()) {\n                        return new TarArchiveInputStream(in, encoding);\n                    }\n                } catch (Exception e) { // NOPMD\n                    // can generate IllegalArgumentException as well\n                    // as IOException\n                    // autodetection, simply not a TAR\n                    // ignored\n                } finally {\n                    IOUtils.closeQuietly(tais);\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.archivers.ar.ArArchiveInputStream;\nimport org.apache.commons.compress.archivers.ar.ArArchiveOutputStream;\nimport org.apache.commons.compress.archivers.arj.ArjArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;\nimport org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream;\nimport org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveInputStream;\nimport org.apache.commons.compress.archivers.jar.JarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.sevenz.SevenZFile;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Factory to create Archive[In|Out]putStreams from names or the first bytes of\n * the InputStream. In order to add other implementations, you should extend\n * ArchiveStreamFactory and override the appropriate methods (and call their\n * implementation from super of course).\n * \n * Compressing a ZIP-File:\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * ArchiveOutputStream os = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.ZIP, out);\n * \n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test1.xml\"));\n * IOUtils.copy(new FileInputStream(file1), os);\n * os.closeArchiveEntry();\n *\n * os.putArchiveEntry(new ZipArchiveEntry(\"testdata/test2.xml\"));\n * IOUtils.copy(new FileInputStream(file2), os);\n * os.closeArchiveEntry();\n * os.close();\n * </pre>\n * \n * Decompressing a ZIP-File:\n * \n * <pre>\n * final InputStream is = new FileInputStream(input); \n * ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(ArchiveStreamFactory.ZIP, is);\n * ZipArchiveEntry entry = (ZipArchiveEntry)in.getNextEntry();\n * OutputStream out = new FileOutputStream(new File(dir, entry.getName()));\n * IOUtils.copy(in, out);\n * out.close();\n * in.close();\n * </pre>\n * @Immutable provided that the deprecated method setEntryEncoding is not used.\n */\npublic class ArchiveStreamFactory {\n\n    /**\n     * Constant (value {@value}) used to identify the AR archive format.\n     * @since 1.1\n     */\n    public static final String AR = \"ar\";\n    /**\n     * Constant (value {@value}) used to identify the ARJ archive format.\n     * Not supported as an output stream type.\n     * @since 1.6\n     */\n    public static final String ARJ = \"arj\";\n    /**\n     * Constant (value {@value}) used to identify the CPIO archive format.\n     * @since 1.1\n     */\n    public static final String CPIO = \"cpio\";\n    /**\n     * Constant (value {@value}) used to identify the Unix DUMP archive format.\n     * Not supported as an output stream type.\n     * @since 1.3\n     */\n    public static final String DUMP = \"dump\";\n    /**\n     * Constant (value {@value}) used to identify the JAR archive format.\n     * @since 1.1\n     */\n    public static final String JAR = \"jar\";\n    /**\n     * Constant used to identify the TAR archive format.\n     * @since 1.1\n     */\n    public static final String TAR = \"tar\";\n    /**\n     * Constant (value {@value}) used to identify the ZIP archive format.\n     * @since 1.1\n     */\n    public static final String ZIP = \"zip\";\n    /**\n     * Constant (value {@value}) used to identify the 7z archive format.\n     * @since 1.8\n     */\n    public static final String SEVEN_Z = \"7z\";\n\n    /**\n     * Entry encoding, null for the platform default.\n     */\n    private final String encoding;\n\n    /**\n     * Entry encoding, null for the default.\n     */\n    private volatile String entryEncoding = null;\n\n    /**\n     * Create an instance using the platform default encoding.\n     */\n    public ArchiveStreamFactory() {\n        this(null);\n    }\n\n    /**\n     * Create an instance using the specified encoding.\n     *\n     * @param encoding the encoding to be used.\n     *\n     * @since 1.10\n     */\n    public ArchiveStreamFactory(String encoding) {\n        super();\n        this.encoding = encoding;\n        // Also set the original field so can continue to use it.\n        this.entryEncoding = encoding;\n    }\n\n    /**\n     * Returns the encoding to use for arj, jar, zip, dump, cpio and tar\n     * files, or null for the archiver default.\n     *\n     * @return entry encoding, or null for the archiver default\n     * @since 1.5\n     */\n    public String getEntryEncoding() {\n        return entryEncoding;\n    }\n\n    /**\n     * Sets the encoding to use for arj, jar, zip, dump, cpio and tar files. Use null for the archiver default.\n     * \n     * @param entryEncoding the entry encoding, null uses the archiver default.\n     * @since 1.5\n     * @deprecated 1.10 use {@link #ArchiveStreamFactory(String)} to specify the encoding\n     * @throws IllegalStateException if the constructor {@link #ArchiveStreamFactory(String)} \n     * was used to specify the factory encoding.\n     */\n    @Deprecated\n    public void setEntryEncoding(String entryEncoding) {\n        // Note: this does not detect new ArchiveStreamFactory(null) but that does not set the encoding anyway\n        if (encoding != null) {\n            throw new IllegalStateException(\"Cannot overide encoding set by the constructor\");\n        }\n        this.entryEncoding = entryEncoding;\n    }\n\n    /**\n     * Create an archive input stream from an archiver name and an input stream.\n     * \n     * @param archiverName the archive name,\n     * i.e. {@value #AR}, {@value #ARJ}, {@value #ZIP}, {@value #TAR}, {@value #JAR}, {@value #CPIO}, {@value #DUMP} or {@value #SEVEN_Z}\n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * read from a stream\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveInputStream createArchiveInputStream(\n            final String archiverName, final InputStream in)\n            throws ArchiveException {\n\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n\n        if (in == null) {\n            throw new IllegalArgumentException(\"InputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveInputStream(in);\n        }\n        if (ARJ.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new ArjArchiveInputStream(in, entryEncoding);\n            } else {\n                return new ArjArchiveInputStream(in);\n            }\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new ZipArchiveInputStream(in, entryEncoding);\n            } else {\n                return new ZipArchiveInputStream(in);\n            }\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new TarArchiveInputStream(in, entryEncoding);\n            } else {\n                return new TarArchiveInputStream(in);\n            }\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new JarArchiveInputStream(in, entryEncoding);\n            } else {\n                return new JarArchiveInputStream(in);\n            }\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new CpioArchiveInputStream(in, entryEncoding);\n            } else {\n                return new CpioArchiveInputStream(in);\n            }\n        }\n        if (DUMP.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new DumpArchiveInputStream(in, entryEncoding);\n            } else {\n                return new DumpArchiveInputStream(in);\n            }\n        }\n        if (SEVEN_Z.equalsIgnoreCase(archiverName)) {\n            throw new StreamingNotSupportedException(SEVEN_Z);\n        }\n\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive output stream from an archiver name and an output stream.\n     * \n     * @param archiverName the archive name,\n     * i.e. {@value #AR}, {@value #ZIP}, {@value #TAR}, {@value #JAR} or {@value #CPIO} \n     * @param out the output stream\n     * @return the archive output stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * written to a stream\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public ArchiveOutputStream createArchiveOutputStream(\n            final String archiverName, final OutputStream out)\n            throws ArchiveException {\n        if (archiverName == null) {\n            throw new IllegalArgumentException(\"Archivername must not be null.\");\n        }\n        if (out == null) {\n            throw new IllegalArgumentException(\"OutputStream must not be null.\");\n        }\n\n        if (AR.equalsIgnoreCase(archiverName)) {\n            return new ArArchiveOutputStream(out);\n        }\n        if (ZIP.equalsIgnoreCase(archiverName)) {\n            ZipArchiveOutputStream zip = new ZipArchiveOutputStream(out);\n            if (entryEncoding != null) {\n                zip.setEncoding(entryEncoding);\n            }\n            return zip;\n        }\n        if (TAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new TarArchiveOutputStream(out, entryEncoding);\n            } else {\n                return new TarArchiveOutputStream(out);\n            }\n        }\n        if (JAR.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new JarArchiveOutputStream(out, entryEncoding);\n            } else {\n                return new JarArchiveOutputStream(out);\n            }\n        }\n        if (CPIO.equalsIgnoreCase(archiverName)) {\n            if (entryEncoding != null) {\n                return new CpioArchiveOutputStream(out, entryEncoding);\n            } else {\n                return new CpioArchiveOutputStream(out);\n            }\n        }\n        if (SEVEN_Z.equalsIgnoreCase(archiverName)) {\n            throw new StreamingNotSupportedException(SEVEN_Z);\n        }\n        throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n    }\n\n    /**\n     * Create an archive input stream from an input stream, autodetecting\n     * the archive type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the archive input stream\n     * @throws ArchiveException if the archiver name is not known\n     * @throws StreamingNotSupportedException if the format cannot be\n     * read from a stream\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     */\n    public ArchiveInputStream createArchiveInputStream(final InputStream in)\n            throws ArchiveException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = IOUtils.readFully(in, signature);\n            in.reset();\n            if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new ZipArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new ZipArchiveInputStream(in);\n                }\n            } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new JarArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new JarArchiveInputStream(in);\n                }\n            } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n                return new ArArchiveInputStream(in);\n            } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new CpioArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new CpioArchiveInputStream(in);\n                }\n            } else if (ArjArchiveInputStream.matches(signature, signatureLength)) {\n                if (entryEncoding != null) {\n                    return new ArjArchiveInputStream(in, entryEncoding);\n                } else {\n                    return new ArjArchiveInputStream(in);\n                }\n            } else if (SevenZFile.matches(signature, signatureLength)) {\n                throw new StreamingNotSupportedException(SEVEN_Z);\n            }\n\n            // Dump needs a bigger buffer to check the signature;\n            final byte[] dumpsig = new byte[32];\n            in.mark(dumpsig.length);\n            signatureLength = IOUtils.readFully(in, dumpsig);\n            in.reset();\n            if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n                return new DumpArchiveInputStream(in, entryEncoding);\n            }\n\n            // Tar needs an even bigger buffer to check the signature; read the first block\n            final byte[] tarheader = new byte[512];\n            in.mark(tarheader.length);\n            signatureLength = IOUtils.readFully(in, tarheader);\n            in.reset();\n            if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n                return new TarArchiveInputStream(in, entryEncoding);\n            }\n            // COMPRESS-117 - improve auto-recognition\n            if (signatureLength >= 512) {\n                TarArchiveInputStream tais = null;\n                try {\n                    tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                    // COMPRESS-191 - verify the header checksum\n                    if (tais.getNextTarEntry().isCheckSumOK()) {\n                        return new TarArchiveInputStream(in, encoding);\n                    }\n                } catch (Exception e) { // NOPMD\n                    // can generate IllegalArgumentException as well\n                    // as IOException\n                    // autodetection, simply not a TAR\n                    // ignored\n                } finally {\n                    IOUtils.closeQuietly(tais);\n                }\n            }\n        } catch (IOException e) {\n            throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n        }\n\n        throw new ArchiveException(\"No Archiver found for the stream signature\");\n    }\n\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * CPIOArchiveInputStream is a stream for reading cpio streams. All formats of\n * cpio are supported (old ascii, old binary, new portable format and the new\n * portable format with crc).\n *\n * <p>\n * The stream can be read by extracting a cpio entry (containing all\n * informations about a entry) and afterwards reading from the stream the file\n * specified by the entry.\n * </p>\n * <pre>\n * CPIOArchiveInputStream cpioIn = new CPIOArchiveInputStream(\n *         new FileInputStream(new File(&quot;test.cpio&quot;)));\n * CPIOArchiveEntry cpioEntry;\n *\n * while ((cpioEntry = cpioIn.getNextEntry()) != null) {\n *     System.out.println(cpioEntry.getName());\n *     int tmp;\n *     StringBuilder buf = new StringBuilder();\n *     while ((tmp = cpIn.read()) != -1) {\n *         buf.append((char) tmp);\n *     }\n *     System.out.println(buf.toString());\n * }\n * cpioIn.close();\n * </pre>\n * <p>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * <p>This class uses mutable fields and is not considered to be threadsafe.\n * \n * <p>Based on code from the jRPM project (jrpm.sourceforge.net)\n */\n\npublic class CpioArchiveInputStream extends ArchiveInputStream implements\n        CpioConstants {\n\n    private boolean closed = false;\n\n    private CpioArchiveEntry entry;\n\n    private long entryBytesRead = 0;\n\n    private boolean entryEOF = false;\n\n    private final byte tmpbuf[] = new byte[4096];\n\n    private long crc = 0;\n\n    private final InputStream in;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] TWO_BYTES_BUF = new byte[2];\n    private final byte[] FOUR_BYTES_BUF = new byte[4];\n    private final byte[] SIX_BYTES_BUF = new byte[6];\n\n    private final int blockSize;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} and expecting ASCII file\n     * names.\n     * \n     * @param in\n     *            The cpio stream\n     */\n    public CpioArchiveInputStream(final InputStream in) {\n        this(in, BLOCK_SIZE, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     * @param encoding\n     *            The encoding of file names to expect - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveInputStream(final InputStream in, String encoding) {\n        this(in, BLOCK_SIZE, encoding);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} expecting ASCII file\n     * names.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @since 1.5\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize) {\n        this(in, blockSize, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @param encoding\n     *            The encoding of file names to expect - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize, String encoding) {\n        this.in = in;\n        this.blockSize = blockSize;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    /**\n     * Returns 0 after EOF has reached for the current entry data, otherwise\n     * always return 1.\n     * <p>\n     * Programs should not count on this method to return the actual number of\n     * bytes that could be read without blocking.\n     * \n     * @return 1 before EOF and 0 after EOF has reached for current entry.\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int available() throws IOException {\n        ensureOpen();\n        if (this.entryEOF) {\n            return 0;\n        }\n        return 1;\n    }\n\n    /**\n     * Closes the CPIO input stream.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if (!this.closed) {\n            in.close();\n            this.closed = true;\n        }\n    }\n\n    /**\n     * Closes the current CPIO entry and positions the stream for reading the\n     * next entry.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    private void closeEntry() throws IOException {\n        // the skip implementation of this class will not skip more\n        // than Integer.MAX_VALUE bytes\n        while (skip((long) Integer.MAX_VALUE) == Integer.MAX_VALUE) { // NOPMD\n            // do nothing\n        }\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Reads the next CPIO file entry and positions stream at the beginning of\n     * the entry data.\n     * \n     * @return the CPIOArchiveEntry just read\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public CpioArchiveEntry getNextCPIOEntry() throws IOException {\n        ensureOpen();\n        if (this.entry != null) {\n            closeEntry();\n        }\n        readFully(TWO_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n        if (CpioUtil.byteArray2long(TWO_BYTES_BUF, false) == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(false);\n        } else if (CpioUtil.byteArray2long(TWO_BYTES_BUF, true)\n                   == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(true);\n        } else {\n            System.arraycopy(TWO_BYTES_BUF, 0, SIX_BYTES_BUF, 0,\n                             TWO_BYTES_BUF.length);\n            readFully(SIX_BYTES_BUF, TWO_BYTES_BUF.length,\n                      FOUR_BYTES_BUF.length);\n            String magicString = ArchiveUtils.toAsciiString(SIX_BYTES_BUF);\n            if (magicString.equals(MAGIC_NEW)) {\n                this.entry = readNewEntry(false);\n            } else if (magicString.equals(MAGIC_NEW_CRC)) {\n                this.entry = readNewEntry(true);\n            } else if (magicString.equals(MAGIC_OLD_ASCII)) {\n                this.entry = readOldAsciiEntry();\n            } else {\n                throw new IOException(\"Unknown magic [\" + magicString + \"]. Occured at byte: \" + getBytesRead());\n            }\n        }\n\n        this.entryBytesRead = 0;\n        this.entryEOF = false;\n        this.crc = 0;\n\n        if (this.entry.getName().equals(CPIO_TRAILER)) {\n            this.entryEOF = true;\n            skipRemainderOfLastBlock();\n            return null;\n        }\n        return this.entry;\n    }\n\n    private void skip(int bytes) throws IOException{\n        // bytes cannot be more than 3 bytes\n        if (bytes > 0) {\n            readFully(FOUR_BYTES_BUF, 0, bytes);\n        }\n    }\n\n    /**\n     * Reads from the current CPIO entry into an array of bytes. Blocks until\n     * some input is available.\n     * \n     * @param b\n     *            the buffer into which the data is read\n     * @param off\n     *            the start offset of the data\n     * @param len\n     *            the maximum number of bytes read\n     * @return the actual number of bytes read, or -1 if the end of the entry is\n     *         reached\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n\n        if (this.entry == null || this.entryEOF) {\n            return -1;\n        }\n        if (this.entryBytesRead == this.entry.getSize()) {\n            skip(entry.getDataPadCount());\n            this.entryEOF = true;\n            if (this.entry.getFormat() == FORMAT_NEW_CRC\n                && this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error. Occured at byte: \"\n                                      + getBytesRead());\n            }\n            return -1; // EOF for this entry\n        }\n        int tmplength = (int) Math.min(len, this.entry.getSize()\n                - this.entryBytesRead);\n        if (tmplength < 0) {\n            return -1;\n        }\n\n        int tmpread = readFully(b, off, tmplength);\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < tmpread; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        this.entryBytesRead += tmpread;\n\n        return tmpread;\n    }\n\n    private final int readFully(final byte[] b, final int off, final int len)\n            throws IOException {\n        int count = IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new EOFException();\n        }\n        return count;\n    }\n\n    private long readBinaryLong(final int length, final boolean swapHalfWord)\n            throws IOException {\n        byte tmp[] = new byte[length];\n        readFully(tmp, 0, tmp.length);\n        return CpioUtil.byteArray2long(tmp, swapHalfWord);\n    }\n\n    private long readAsciiLong(final int length, final int radix)\n            throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return Long.parseLong(ArchiveUtils.toAsciiString(tmpBuffer), radix);\n    }\n\n    private CpioArchiveEntry readNewEntry(final boolean hasCrc)\n            throws IOException {\n        CpioArchiveEntry ret;\n        if (hasCrc) {\n            ret = new CpioArchiveEntry(FORMAT_NEW_CRC);\n        } else {\n            ret = new CpioArchiveEntry(FORMAT_NEW);\n        }\n\n        ret.setInode(readAsciiLong(8, 16));\n        long mode = readAsciiLong(8, 16);\n        if (CpioUtil.fileType(mode) != 0){ // mode is initialised to 0\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(8, 16));\n        ret.setGID(readAsciiLong(8, 16));\n        ret.setNumberOfLinks(readAsciiLong(8, 16));\n        ret.setTime(readAsciiLong(8, 16));\n        ret.setSize(readAsciiLong(8, 16));\n        ret.setDeviceMaj(readAsciiLong(8, 16));\n        ret.setDeviceMin(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMaj(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMin(readAsciiLong(8, 16));\n        long namesize = readAsciiLong(8, 16);\n        ret.setChksum(readAsciiLong(8, 16));\n        String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry name: \"+name + \" Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldAsciiEntry() throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_ASCII);\n\n        ret.setDevice(readAsciiLong(6, 8));\n        ret.setInode(readAsciiLong(6, 8));\n        final long mode = readAsciiLong(6, 8);\n        if (CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(6, 8));\n        ret.setGID(readAsciiLong(6, 8));\n        ret.setNumberOfLinks(readAsciiLong(6, 8));\n        ret.setRemoteDevice(readAsciiLong(6, 8));\n        ret.setTime(readAsciiLong(11, 8));\n        long namesize = readAsciiLong(6, 8);\n        ret.setSize(readAsciiLong(11, 8));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+ name + \" Occured at byte: \" + getBytesRead());\n        }\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldBinaryEntry(final boolean swapHalfWord)\n            throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_BINARY);\n\n        ret.setDevice(readBinaryLong(2, swapHalfWord));\n        ret.setInode(readBinaryLong(2, swapHalfWord));\n        final long mode = readBinaryLong(2, swapHalfWord);\n        if (CpioUtil.fileType(mode) != 0){\n            ret.setMode(mode);\n        }\n        ret.setUID(readBinaryLong(2, swapHalfWord));\n        ret.setGID(readBinaryLong(2, swapHalfWord));\n        ret.setNumberOfLinks(readBinaryLong(2, swapHalfWord));\n        ret.setRemoteDevice(readBinaryLong(2, swapHalfWord));\n        ret.setTime(readBinaryLong(4, swapHalfWord));\n        long namesize = readBinaryLong(2, swapHalfWord);\n        ret.setSize(readBinaryLong(4, swapHalfWord));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+name + \"Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private String readCString(final int length) throws IOException {\n        // don't include trailing NUL in file name to decode\n        byte tmpBuffer[] = new byte[length - 1];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        this.in.read();\n        return zipEncoding.decode(tmpBuffer);\n    }\n\n    /**\n     * Skips specified number of bytes in the current CPIO entry.\n     * \n     * @param n\n     *            the number of bytes to skip\n     * @return the actual number of bytes skipped\n     * @throws IOException\n     *             if an I/O error has occurred\n     * @throws IllegalArgumentException\n     *             if n &lt; 0\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n < 0) {\n            throw new IllegalArgumentException(\"negative skip length\");\n        }\n        ensureOpen();\n        int max = (int) Math.min(n, Integer.MAX_VALUE);\n        int total = 0;\n\n        while (total < max) {\n            int len = max - total;\n            if (len > this.tmpbuf.length) {\n                len = this.tmpbuf.length;\n            }\n            len = read(this.tmpbuf, 0, len);\n            if (len == -1) {\n                this.entryEOF = true;\n                break;\n            }\n            total += len;\n        }\n        return total;\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextCPIOEntry();\n    }\n\n    /**\n     * Skips the padding zeros written after the TRAILER!!! entry.\n     */\n    private void skipRemainderOfLastBlock() throws IOException {\n        long readFromLastBlock = getBytesRead() % blockSize;\n        long remainingBytes = readFromLastBlock == 0 ? 0\n            : blockSize - readFromLastBlock;\n        while (remainingBytes > 0) {\n            long skipped = skip(blockSize - readFromLastBlock);\n            if (skipped <= 0) {\n                break;\n            }\n            remainingBytes -= skipped;\n        }\n    }\n\n    /**\n     * Checks if the signature matches one of the following magic values:\n     * \n     * Strings:\n     *\n     * \"070701\" - MAGIC_NEW\n     * \"070702\" - MAGIC_NEW_CRC\n     * \"070707\" - MAGIC_OLD_ASCII\n     * \n     * Octal Binary value:\n     * \n     * 070707 - MAGIC_OLD_BINARY (held as a short) = 0x71C7 or 0xC771\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < 6) {\n            return false;\n        }\n\n        // Check binary values\n        if (signature[0] == 0x71 && (signature[1] & 0xFF) == 0xc7) {\n            return true;\n        }\n        if (signature[1] == 0x71 && (signature[0] & 0xFF) == 0xc7) {\n            return true;\n        }\n\n        // Check Ascii (String) values\n        // 3037 3037 30nn\n        if (signature[0] != 0x30) {\n            return false;\n        }\n        if (signature[1] != 0x37) {\n            return false;\n        }\n        if (signature[2] != 0x30) {\n            return false;\n        }\n        if (signature[3] != 0x37) {\n            return false;\n        }\n        if (signature[4] != 0x30) {\n            return false;\n        }\n        // Check last byte\n        if (signature[5] == 0x31) {\n            return true;\n        }\n        if (signature[5] == 0x32) {\n            return true;\n        }\n        if (signature[5] == 0x37) {\n            return true;\n        }\n\n        return false;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * CPIOArchiveInputStream is a stream for reading cpio streams. All formats of\n * cpio are supported (old ascii, old binary, new portable format and the new\n * portable format with crc).\n *\n * <p>\n * The stream can be read by extracting a cpio entry (containing all\n * informations about a entry) and afterwards reading from the stream the file\n * specified by the entry.\n * </p>\n * <pre>\n * CPIOArchiveInputStream cpioIn = new CPIOArchiveInputStream(\n *         new FileInputStream(new File(&quot;test.cpio&quot;)));\n * CPIOArchiveEntry cpioEntry;\n *\n * while ((cpioEntry = cpioIn.getNextEntry()) != null) {\n *     System.out.println(cpioEntry.getName());\n *     int tmp;\n *     StringBuilder buf = new StringBuilder();\n *     while ((tmp = cpIn.read()) != -1) {\n *         buf.append((char) tmp);\n *     }\n *     System.out.println(buf.toString());\n * }\n * cpioIn.close();\n * </pre>\n * <p>\n * Note: This implementation should be compatible to cpio 2.5\n * \n * <p>This class uses mutable fields and is not considered to be threadsafe.\n * \n * <p>Based on code from the jRPM project (jrpm.sourceforge.net)\n */\n\npublic class CpioArchiveInputStream extends ArchiveInputStream implements\n        CpioConstants {\n\n    private boolean closed = false;\n\n    private CpioArchiveEntry entry;\n\n    private long entryBytesRead = 0;\n\n    private boolean entryEOF = false;\n\n    private final byte tmpbuf[] = new byte[4096];\n\n    private long crc = 0;\n\n    private final InputStream in;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] TWO_BYTES_BUF = new byte[2];\n    private final byte[] FOUR_BYTES_BUF = new byte[4];\n    private final byte[] SIX_BYTES_BUF = new byte[6];\n\n    private final int blockSize;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} and expecting ASCII file\n     * names.\n     * \n     * @param in\n     *            The cpio stream\n     */\n    public CpioArchiveInputStream(final InputStream in) {\n        this(in, BLOCK_SIZE, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     * @param encoding\n     *            The encoding of file names to expect - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveInputStream(final InputStream in, String encoding) {\n        this(in, BLOCK_SIZE, encoding);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link\n     * CpioConstants#BLOCK_SIZE BLOCK_SIZE} expecting ASCII file\n     * names.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @since 1.5\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize) {\n        this(in, blockSize, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio input stream with a blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE}.\n     * \n     * @param in\n     *            The cpio stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @param encoding\n     *            The encoding of file names to expect - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveInputStream(final InputStream in, int blockSize, String encoding) {\n        this.in = in;\n        this.blockSize = blockSize;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    /**\n     * Returns 0 after EOF has reached for the current entry data, otherwise\n     * always return 1.\n     * <p>\n     * Programs should not count on this method to return the actual number of\n     * bytes that could be read without blocking.\n     * \n     * @return 1 before EOF and 0 after EOF has reached for current entry.\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int available() throws IOException {\n        ensureOpen();\n        if (this.entryEOF) {\n            return 0;\n        }\n        return 1;\n    }\n\n    /**\n     * Closes the CPIO input stream.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if (!this.closed) {\n            in.close();\n            this.closed = true;\n        }\n    }\n\n    /**\n     * Closes the current CPIO entry and positions the stream for reading the\n     * next entry.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    private void closeEntry() throws IOException {\n        // the skip implementation of this class will not skip more\n        // than Integer.MAX_VALUE bytes\n        while (skip((long) Integer.MAX_VALUE) == Integer.MAX_VALUE) { // NOPMD\n            // do nothing\n        }\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Reads the next CPIO file entry and positions stream at the beginning of\n     * the entry data.\n     * \n     * @return the CPIOArchiveEntry just read\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    public CpioArchiveEntry getNextCPIOEntry() throws IOException {\n        ensureOpen();\n        if (this.entry != null) {\n            closeEntry();\n        }\n        readFully(TWO_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n        if (CpioUtil.byteArray2long(TWO_BYTES_BUF, false) == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(false);\n        } else if (CpioUtil.byteArray2long(TWO_BYTES_BUF, true)\n                   == MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(true);\n        } else {\n            System.arraycopy(TWO_BYTES_BUF, 0, SIX_BYTES_BUF, 0,\n                             TWO_BYTES_BUF.length);\n            readFully(SIX_BYTES_BUF, TWO_BYTES_BUF.length,\n                      FOUR_BYTES_BUF.length);\n            String magicString = ArchiveUtils.toAsciiString(SIX_BYTES_BUF);\n            if (magicString.equals(MAGIC_NEW)) {\n                this.entry = readNewEntry(false);\n            } else if (magicString.equals(MAGIC_NEW_CRC)) {\n                this.entry = readNewEntry(true);\n            } else if (magicString.equals(MAGIC_OLD_ASCII)) {\n                this.entry = readOldAsciiEntry();\n            } else {\n                throw new IOException(\"Unknown magic [\" + magicString + \"]. Occured at byte: \" + getBytesRead());\n            }\n        }\n\n        this.entryBytesRead = 0;\n        this.entryEOF = false;\n        this.crc = 0;\n\n        if (this.entry.getName().equals(CPIO_TRAILER)) {\n            this.entryEOF = true;\n            skipRemainderOfLastBlock();\n            return null;\n        }\n        return this.entry;\n    }\n\n    private void skip(int bytes) throws IOException{\n        // bytes cannot be more than 3 bytes\n        if (bytes > 0) {\n            readFully(FOUR_BYTES_BUF, 0, bytes);\n        }\n    }\n\n    /**\n     * Reads from the current CPIO entry into an array of bytes. Blocks until\n     * some input is available.\n     * \n     * @param b\n     *            the buffer into which the data is read\n     * @param off\n     *            the start offset of the data\n     * @param len\n     *            the maximum number of bytes read\n     * @return the actual number of bytes read, or -1 if the end of the entry is\n     *         reached\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n\n        if (this.entry == null || this.entryEOF) {\n            return -1;\n        }\n        if (this.entryBytesRead == this.entry.getSize()) {\n            skip(entry.getDataPadCount());\n            this.entryEOF = true;\n            if (this.entry.getFormat() == FORMAT_NEW_CRC\n                && this.crc != this.entry.getChksum()) {\n                throw new IOException(\"CRC Error. Occured at byte: \"\n                                      + getBytesRead());\n            }\n            return -1; // EOF for this entry\n        }\n        int tmplength = (int) Math.min(len, this.entry.getSize()\n                - this.entryBytesRead);\n        if (tmplength < 0) {\n            return -1;\n        }\n\n        int tmpread = readFully(b, off, tmplength);\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < tmpread; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        this.entryBytesRead += tmpread;\n\n        return tmpread;\n    }\n\n    private final int readFully(final byte[] b, final int off, final int len)\n            throws IOException {\n        int count = IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new EOFException();\n        }\n        return count;\n    }\n\n    private long readBinaryLong(final int length, final boolean swapHalfWord)\n            throws IOException {\n        byte tmp[] = new byte[length];\n        readFully(tmp, 0, tmp.length);\n        return CpioUtil.byteArray2long(tmp, swapHalfWord);\n    }\n\n    private long readAsciiLong(final int length, final int radix)\n            throws IOException {\n        byte tmpBuffer[] = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return Long.parseLong(ArchiveUtils.toAsciiString(tmpBuffer), radix);\n    }\n\n    private CpioArchiveEntry readNewEntry(final boolean hasCrc)\n            throws IOException {\n        CpioArchiveEntry ret;\n        if (hasCrc) {\n            ret = new CpioArchiveEntry(FORMAT_NEW_CRC);\n        } else {\n            ret = new CpioArchiveEntry(FORMAT_NEW);\n        }\n\n        ret.setInode(readAsciiLong(8, 16));\n        long mode = readAsciiLong(8, 16);\n        if (CpioUtil.fileType(mode) != 0){ // mode is initialised to 0\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(8, 16));\n        ret.setGID(readAsciiLong(8, 16));\n        ret.setNumberOfLinks(readAsciiLong(8, 16));\n        ret.setTime(readAsciiLong(8, 16));\n        ret.setSize(readAsciiLong(8, 16));\n        ret.setDeviceMaj(readAsciiLong(8, 16));\n        ret.setDeviceMin(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMaj(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMin(readAsciiLong(8, 16));\n        long namesize = readAsciiLong(8, 16);\n        ret.setChksum(readAsciiLong(8, 16));\n        String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry name: \"+name + \" Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldAsciiEntry() throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_ASCII);\n\n        ret.setDevice(readAsciiLong(6, 8));\n        ret.setInode(readAsciiLong(6, 8));\n        final long mode = readAsciiLong(6, 8);\n        if (CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(6, 8));\n        ret.setGID(readAsciiLong(6, 8));\n        ret.setNumberOfLinks(readAsciiLong(6, 8));\n        ret.setRemoteDevice(readAsciiLong(6, 8));\n        ret.setTime(readAsciiLong(11, 8));\n        long namesize = readAsciiLong(6, 8);\n        ret.setSize(readAsciiLong(11, 8));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+ name + \" Occured at byte: \" + getBytesRead());\n        }\n\n        return ret;\n    }\n\n    private CpioArchiveEntry readOldBinaryEntry(final boolean swapHalfWord)\n            throws IOException {\n        CpioArchiveEntry ret = new CpioArchiveEntry(FORMAT_OLD_BINARY);\n\n        ret.setDevice(readBinaryLong(2, swapHalfWord));\n        ret.setInode(readBinaryLong(2, swapHalfWord));\n        final long mode = readBinaryLong(2, swapHalfWord);\n        if (CpioUtil.fileType(mode) != 0){\n            ret.setMode(mode);\n        }\n        ret.setUID(readBinaryLong(2, swapHalfWord));\n        ret.setGID(readBinaryLong(2, swapHalfWord));\n        ret.setNumberOfLinks(readBinaryLong(2, swapHalfWord));\n        ret.setRemoteDevice(readBinaryLong(2, swapHalfWord));\n        ret.setTime(readBinaryLong(4, swapHalfWord));\n        long namesize = readBinaryLong(2, swapHalfWord);\n        ret.setSize(readBinaryLong(4, swapHalfWord));\n        final String name = readCString((int) namesize);\n        ret.setName(name);\n        if (CpioUtil.fileType(mode) == 0 && !name.equals(CPIO_TRAILER)){\n            throw new IOException(\"Mode 0 only allowed in the trailer. Found entry: \"+name + \"Occured at byte: \" + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n\n        return ret;\n    }\n\n    private String readCString(final int length) throws IOException {\n        // don't include trailing NUL in file name to decode\n        byte tmpBuffer[] = new byte[length - 1];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        this.in.read();\n        return zipEncoding.decode(tmpBuffer);\n    }\n\n    /**\n     * Skips specified number of bytes in the current CPIO entry.\n     * \n     * @param n\n     *            the number of bytes to skip\n     * @return the actual number of bytes skipped\n     * @throws IOException\n     *             if an I/O error has occurred\n     * @throws IllegalArgumentException\n     *             if n &lt; 0\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n < 0) {\n            throw new IllegalArgumentException(\"negative skip length\");\n        }\n        ensureOpen();\n        int max = (int) Math.min(n, Integer.MAX_VALUE);\n        int total = 0;\n\n        while (total < max) {\n            int len = max - total;\n            if (len > this.tmpbuf.length) {\n                len = this.tmpbuf.length;\n            }\n            len = read(this.tmpbuf, 0, len);\n            if (len == -1) {\n                this.entryEOF = true;\n                break;\n            }\n            total += len;\n        }\n        return total;\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextCPIOEntry();\n    }\n\n    /**\n     * Skips the padding zeros written after the TRAILER!!! entry.\n     */\n    private void skipRemainderOfLastBlock() throws IOException {\n        long readFromLastBlock = getBytesRead() % blockSize;\n        long remainingBytes = readFromLastBlock == 0 ? 0\n            : blockSize - readFromLastBlock;\n        while (remainingBytes > 0) {\n            long skipped = skip(blockSize - readFromLastBlock);\n            if (skipped <= 0) {\n                break;\n            }\n            remainingBytes -= skipped;\n        }\n    }\n\n    /**\n     * Checks if the signature matches one of the following magic values:\n     * \n     * Strings:\n     *\n     * \"070701\" - MAGIC_NEW\n     * \"070702\" - MAGIC_NEW_CRC\n     * \"070707\" - MAGIC_OLD_ASCII\n     * \n     * Octal Binary value:\n     * \n     * 070707 - MAGIC_OLD_BINARY (held as a short) = 0x71C7 or 0xC771\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < 6) {\n            return false;\n        }\n\n        // Check binary values\n        if (signature[0] == 0x71 && (signature[1] & 0xFF) == 0xc7) {\n            return true;\n        }\n        if (signature[1] == 0x71 && (signature[0] & 0xFF) == 0xc7) {\n            return true;\n        }\n\n        // Check Ascii (String) values\n        // 3037 3037 30nn\n        if (signature[0] != 0x30) {\n            return false;\n        }\n        if (signature[1] != 0x37) {\n            return false;\n        }\n        if (signature[2] != 0x30) {\n            return false;\n        }\n        if (signature[3] != 0x37) {\n            return false;\n        }\n        if (signature[4] != 0x30) {\n            return false;\n        }\n        // Check last byte\n        if (signature[5] == 0x31) {\n            return true;\n        }\n        if (signature[5] == 0x32) {\n            return true;\n        }\n        if (signature[5] == 0x37) {\n            return true;\n        }\n\n        return false;\n    }\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n *\n * <p>An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.</p>\n *\n * <pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(\"testfile\");\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * entry.setMode(CpioConstants.C_ISREG); // regular file\n * ... set other attributes, e.g. time, number of links\n * out.putArchiveEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre>\n *\n * <p>Note: This implementation should be compatible to cpio 2.5</p>\n * \n * <p>This class uses mutable fields and is not considered threadsafe.</p>\n * \n * <p>based on code from the jRPM project (jrpm.sourceforge.net)</p>\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry entry;\n\n    private boolean closed = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished;\n\n    /**\n     * See {@link CpioArchiveEntry#setFormat(short)} for possible values.\n     */\n    private final short entryFormat;\n\n    private final HashMap<String, CpioArchiveEntry> names =\n        new HashMap<String, CpioArchiveEntry>();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    private final int blockSize;\n\n    private long nextArtificalDeviceAndInode = 1;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    /**\n     * Construct the cpio output stream with a specified format, a\n     * blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE} and\n     * using ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this(out, format, BLOCK_SIZE, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio output stream with a specified format using\n     * ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     * @param blockSize\n     *            The block size of the archive.\n     * \n     * @since 1.1\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format,\n                                   final int blockSize) {\n        this(out, format, blockSize, CharsetNames.US_ASCII);\n    }        \n\n    /**\n     * Construct the cpio output stream with a specified format using\n     * ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @param encoding\n     *            The encoding of file names to write - use null for\n     *            the platform's default.\n     * \n     * @since 1.6\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format,\n                                   final int blockSize, final String encoding) {\n        this.out = out;\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown format: \"+format);\n\n        }\n        this.entryFormat = format;\n        this.blockSize = blockSize;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format using ASCII encoding for file names\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format.\n     * \n     * @param out\n     *            The cpio stream\n     * @param encoding\n     *            The encoding of file names to write - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveOutputStream(final OutputStream out, String encoding) {\n        this(out, FORMAT_NEW, BLOCK_SIZE, encoding);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param entry\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     * @throws ClassCastException if entry is not an instance of CpioArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        CpioArchiveEntry e = (CpioArchiveEntry) entry;\n        ensureOpen();\n        if (this.entry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis() / 1000);\n        }\n\n        final short format = e.getFormat();\n        if (format != this.entryFormat){\n            throw new IOException(\"Header format: \"+format+\" does not match existing format: \"+this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.entry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW));\n            count(6);\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW_CRC));\n            count(6);\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_OLD_ASCII));\n            count(6);\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        default:\n            throw new IOException(\"unknown format \" + e.getFormat());\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        long inode = entry.getInode();\n        long devMin = entry.getDeviceMin();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = devMin = 0;\n        } else {\n            if (inode == 0 && devMin == 0) {\n                inode = nextArtificalDeviceAndInode & 0xFFFFFFFF;\n                devMin = (nextArtificalDeviceAndInode++ >> 32) & 0xFFFFFFFF;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 0x100000000L * devMin) + 1;\n            }\n        }\n\n        writeAsciiLong(inode, 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(devMin, 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else {\n            if (inode == 0 && device == 0) {\n                inode = nextArtificalDeviceAndInode & 0777777;\n                device = (nextArtificalDeviceAndInode++ >> 18) & 0777777;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 01000000 * device) + 1;\n            }\n        }\n\n        writeAsciiLong(device, 6, 8);\n        writeAsciiLong(inode, 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else {\n            if (inode == 0 && device == 0) {\n                inode = nextArtificalDeviceAndInode & 0xFFFF;\n                device = (nextArtificalDeviceAndInode++ >> 16) & 0xFFFF;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 0x10000 * device) + 1;\n            }\n        }\n\n        writeBinaryLong(device, 2, swapHalfWord);\n        writeBinaryLong(inode, 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        ensureOpen();\n\n        if (entry == null) {\n            throw new IOException(\"Trying to close non-existent entry\");\n        }\n\n        if (this.entry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.entry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        pad(this.entry.getDataPadCount());\n        if (this.entry.getFormat() == FORMAT_NEW_CRC\n            && this.crc != this.entry.getChksum()) {\n            throw new IOException(\"CRC Error\");\n        }\n        this.entry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.entry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.entry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        count(len);\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void finish() throws IOException {\n        ensureOpen();\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (this.entry != null) {\n            throw new IOException(\"This archive contains unclosed entries.\");\n        }\n        this.entry = new CpioArchiveEntry(this.entryFormat);\n        this.entry.setName(CPIO_TRAILER);\n        this.entry.setNumberOfLinks(1);\n        writeHeader(this.entry);\n        closeArchiveEntry();\n\n        int lengthOfLastBlock = (int) (getBytesWritten() % blockSize);\n        if (lengthOfLastBlock != 0) {\n            pad(blockSize - lengthOfLastBlock);\n        }\n\n        finished = true;\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n\n        if (!this.closed) {\n            out.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(int count) throws IOException{\n        if (count > 0){\n            byte buff[] = new byte[count];\n            out.write(buff);\n            count(count);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n        count(tmp.length);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuilder tmp = new StringBuilder();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        byte[] b = ArchiveUtils.toAsciiBytes(tmpStr);\n        out.write(b);\n        count(b.length);\n    }\n\n    /**\n     * Writes an ASCII string to the stream followed by \\0\n     * @param str the String to write\n     * @throws IOException if the string couldn't be written\n     */\n    private void writeCString(final String str) throws IOException {\n        ByteBuffer buf = zipEncoding.encode(str);\n        final int len = buf.limit() - buf.position();\n        out.write(buf.array(), buf.arrayOffset(), len);\n        out.write('\\0');\n        count(len + 1);\n    }\n\n    /**\n     * Creates a new ArchiveEntry. The entryName must be an ASCII encoded string.\n     * \n     * @see org.apache.commons.compress.archivers.ArchiveOutputStream#createArchiveEntry(java.io.File, java.lang.String)\n     */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new CpioArchiveEntry(inputFile, entryName);\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.cpio;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.nio.ByteBuffer;\nimport java.util.HashMap;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\n\n/**\n * CPIOArchiveOutputStream is a stream for writing CPIO streams. All formats of\n * CPIO are supported (old ASCII, old binary, new portable format and the new\n * portable format with CRC).\n *\n * <p>An entry can be written by creating an instance of CpioArchiveEntry and fill\n * it with the necessary values and put it into the CPIO stream. Afterwards\n * write the contents of the file into the CPIO stream. Either close the stream\n * by calling finish() or put a next entry into the cpio stream.</p>\n *\n * <pre>\n * CpioArchiveOutputStream out = new CpioArchiveOutputStream(\n *         new FileOutputStream(new File(\"test.cpio\")));\n * CpioArchiveEntry entry = new CpioArchiveEntry();\n * entry.setName(\"testfile\");\n * String contents = &quot;12345&quot;;\n * entry.setFileSize(contents.length());\n * entry.setMode(CpioConstants.C_ISREG); // regular file\n * ... set other attributes, e.g. time, number of links\n * out.putArchiveEntry(entry);\n * out.write(testContents.getBytes());\n * out.close();\n * </pre>\n *\n * <p>Note: This implementation should be compatible to cpio 2.5</p>\n * \n * <p>This class uses mutable fields and is not considered threadsafe.</p>\n * \n * <p>based on code from the jRPM project (jrpm.sourceforge.net)</p>\n */\npublic class CpioArchiveOutputStream extends ArchiveOutputStream implements\n        CpioConstants {\n\n    private CpioArchiveEntry entry;\n\n    private boolean closed = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished;\n\n    /**\n     * See {@link CpioArchiveEntry#setFormat(short)} for possible values.\n     */\n    private final short entryFormat;\n\n    private final HashMap<String, CpioArchiveEntry> names =\n        new HashMap<String, CpioArchiveEntry>();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final OutputStream out;\n\n    private final int blockSize;\n\n    private long nextArtificalDeviceAndInode = 1;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Construct the cpio output stream with a specified format, a\n     * blocksize of {@link CpioConstants#BLOCK_SIZE BLOCK_SIZE} and\n     * using ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format) {\n        this(out, format, BLOCK_SIZE, CharsetNames.US_ASCII);\n    }\n\n    /**\n     * Construct the cpio output stream with a specified format using\n     * ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     * @param blockSize\n     *            The block size of the archive.\n     * \n     * @since 1.1\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format,\n                                   final int blockSize) {\n        this(out, format, blockSize, CharsetNames.US_ASCII);\n    }        \n\n    /**\n     * Construct the cpio output stream with a specified format using\n     * ASCII as the file name encoding.\n     * \n     * @param out\n     *            The cpio stream\n     * @param format\n     *            The format of the stream\n     * @param blockSize\n     *            The block size of the archive.\n     * @param encoding\n     *            The encoding of file names to write - use null for\n     *            the platform's default.\n     * \n     * @since 1.6\n     */\n    public CpioArchiveOutputStream(final OutputStream out, final short format,\n                                   final int blockSize, final String encoding) {\n        this.out = out;\n        switch (format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown format: \"+format);\n\n        }\n        this.entryFormat = format;\n        this.blockSize = blockSize;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format using ASCII encoding for file names\n     * \n     * @param out\n     *            The cpio stream\n     */\n    public CpioArchiveOutputStream(final OutputStream out) {\n        this(out, FORMAT_NEW);\n    }\n\n    /**\n     * Construct the cpio output stream. The format for this CPIO stream is the\n     * \"new\" format.\n     * \n     * @param out\n     *            The cpio stream\n     * @param encoding\n     *            The encoding of file names to write - use null for\n     *            the platform's default.\n     * @since 1.6\n     */\n    public CpioArchiveOutputStream(final OutputStream out, String encoding) {\n        this(out, FORMAT_NEW, BLOCK_SIZE, encoding);\n    }\n\n    /**\n     * Check to make sure that this stream has not been closed\n     * \n     * @throws IOException\n     *             if the stream is already closed\n     */\n    private void ensureOpen() throws IOException {\n        if (this.closed) {\n            throw new IOException(\"Stream closed\");\n        }\n    }\n\n    /**\n     * Begins writing a new CPIO file entry and positions the stream to the\n     * start of the entry data. Closes the current entry if still active. The\n     * current time will be used if the entry has no set modification time and\n     * the default header format will be used if no other format is specified in\n     * the entry.\n     * \n     * @param entry\n     *            the CPIO cpioEntry to be written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     * @throws ClassCastException if entry is not an instance of CpioArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry entry) throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        CpioArchiveEntry e = (CpioArchiveEntry) entry;\n        ensureOpen();\n        if (this.entry != null) {\n            closeArchiveEntry(); // close previous entry\n        }\n        if (e.getTime() == -1) {\n            e.setTime(System.currentTimeMillis() / 1000);\n        }\n\n        final short format = e.getFormat();\n        if (format != this.entryFormat){\n            throw new IOException(\"Header format: \"+format+\" does not match existing format: \"+this.entryFormat);\n        }\n\n        if (this.names.put(e.getName(), e) != null) {\n            throw new IOException(\"duplicate entry: \" + e.getName());\n        }\n\n        writeHeader(e);\n        this.entry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final CpioArchiveEntry e) throws IOException {\n        switch (e.getFormat()) {\n        case FORMAT_NEW:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW));\n            count(6);\n            writeNewEntry(e);\n            break;\n        case FORMAT_NEW_CRC:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_NEW_CRC));\n            count(6);\n            writeNewEntry(e);\n            break;\n        case FORMAT_OLD_ASCII:\n            out.write(ArchiveUtils.toAsciiBytes(MAGIC_OLD_ASCII));\n            count(6);\n            writeOldAsciiEntry(e);\n            break;\n        case FORMAT_OLD_BINARY:\n            boolean swapHalfWord = true;\n            writeBinaryLong(MAGIC_OLD_BINARY, 2, swapHalfWord);\n            writeOldBinaryEntry(e, swapHalfWord);\n            break;\n        default:\n            throw new IOException(\"unknown format \" + e.getFormat());\n        }\n    }\n\n    private void writeNewEntry(final CpioArchiveEntry entry) throws IOException {\n        long inode = entry.getInode();\n        long devMin = entry.getDeviceMin();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = devMin = 0;\n        } else {\n            if (inode == 0 && devMin == 0) {\n                inode = nextArtificalDeviceAndInode & 0xFFFFFFFF;\n                devMin = (nextArtificalDeviceAndInode++ >> 32) & 0xFFFFFFFF;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 0x100000000L * devMin) + 1;\n            }\n        }\n\n        writeAsciiLong(inode, 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(devMin, 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    private void writeOldAsciiEntry(final CpioArchiveEntry entry)\n            throws IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else {\n            if (inode == 0 && device == 0) {\n                inode = nextArtificalDeviceAndInode & 0777777;\n                device = (nextArtificalDeviceAndInode++ >> 18) & 0777777;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 01000000 * device) + 1;\n            }\n        }\n\n        writeAsciiLong(device, 6, 8);\n        writeAsciiLong(inode, 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final CpioArchiveEntry entry,\n            final boolean swapHalfWord) throws IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else {\n            if (inode == 0 && device == 0) {\n                inode = nextArtificalDeviceAndInode & 0xFFFF;\n                device = (nextArtificalDeviceAndInode++ >> 16) & 0xFFFF;\n            } else {\n                nextArtificalDeviceAndInode =\n                    Math.max(nextArtificalDeviceAndInode,\n                             inode + 0x10000 * device) + 1;\n            }\n        }\n\n        writeBinaryLong(device, 2, swapHalfWord);\n        writeBinaryLong(inode, 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    /*(non-Javadoc)\n     * \n     * @see\n     * org.apache.commons.compress.archivers.ArchiveOutputStream#closeArchiveEntry\n     * ()\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        ensureOpen();\n\n        if (entry == null) {\n            throw new IOException(\"Trying to close non-existent entry\");\n        }\n\n        if (this.entry.getSize() != this.written) {\n            throw new IOException(\"invalid entry size (expected \"\n                    + this.entry.getSize() + \" but got \" + this.written\n                    + \" bytes)\");\n        }\n        pad(this.entry.getDataPadCount());\n        if (this.entry.getFormat() == FORMAT_NEW_CRC\n            && this.crc != this.entry.getChksum()) {\n            throw new IOException(\"CRC Error\");\n        }\n        this.entry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    /**\n     * Writes an array of bytes to the current CPIO entry data. This method will\n     * block until all the bytes are written.\n     * \n     * @param b\n     *            the data to be written\n     * @param off\n     *            the start offset in the data\n     * @param len\n     *            the number of bytes that are written\n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void write(final byte[] b, final int off, final int len)\n            throws IOException {\n        ensureOpen();\n        if (off < 0 || len < 0 || off > b.length - len) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n\n        if (this.entry == null) {\n            throw new IOException(\"no current CPIO entry\");\n        }\n        if (this.written + len > this.entry.getSize()) {\n            throw new IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if (this.entry.getFormat() == FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xFF;\n            }\n        }\n        count(len);\n    }\n\n    /**\n     * Finishes writing the contents of the CPIO output stream without closing\n     * the underlying stream. Use this method when applying multiple filters in\n     * succession to the same output stream.\n     * \n     * @throws IOException\n     *             if an I/O exception has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void finish() throws IOException {\n        ensureOpen();\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (this.entry != null) {\n            throw new IOException(\"This archive contains unclosed entries.\");\n        }\n        this.entry = new CpioArchiveEntry(this.entryFormat);\n        this.entry.setName(CPIO_TRAILER);\n        this.entry.setNumberOfLinks(1);\n        writeHeader(this.entry);\n        closeArchiveEntry();\n\n        int lengthOfLastBlock = (int) (getBytesWritten() % blockSize);\n        if (lengthOfLastBlock != 0) {\n            pad(blockSize - lengthOfLastBlock);\n        }\n\n        finished = true;\n    }\n\n    /**\n     * Closes the CPIO output stream as well as the stream being filtered.\n     * \n     * @throws IOException\n     *             if an I/O error has occurred or if a CPIO file error has\n     *             occurred\n     */\n    @Override\n    public void close() throws IOException {\n        if(!finished) {\n            finish();\n        }\n\n        if (!this.closed) {\n            out.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(int count) throws IOException{\n        if (count > 0){\n            byte buff[] = new byte[count];\n            out.write(buff);\n            count(count);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length,\n            final boolean swapHalfWord) throws IOException {\n        byte tmp[] = CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n        count(tmp.length);\n    }\n\n    private void writeAsciiLong(final long number, final int length,\n            final int radix) throws IOException {\n        StringBuilder tmp = new StringBuilder();\n        String tmpStr;\n        if (radix == 16) {\n            tmp.append(Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(Long.toOctalString(number));\n        } else {\n            tmp.append(Long.toString(number));\n        }\n\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        byte[] b = ArchiveUtils.toAsciiBytes(tmpStr);\n        out.write(b);\n        count(b.length);\n    }\n\n    /**\n     * Writes an ASCII string to the stream followed by \\0\n     * @param str the String to write\n     * @throws IOException if the string couldn't be written\n     */\n    private void writeCString(final String str) throws IOException {\n        ByteBuffer buf = zipEncoding.encode(str);\n        final int len = buf.limit() - buf.position();\n        out.write(buf.array(), buf.arrayOffset(), len);\n        out.write('\\0');\n        count(len + 1);\n    }\n\n    /**\n     * Creates a new ArchiveEntry. The entryName must be an ASCII encoded string.\n     * \n     * @see org.apache.commons.compress.archivers.ArchiveOutputStream#createArchiveEntry(java.io.File, java.lang.String)\n     */\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new CpioArchiveEntry(inputFile, entryName);\n    }\n\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.dump.DumpArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.dump;\n\nimport org.apache.commons.compress.archivers.ArchiveException;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport java.util.Arrays;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.PriorityQueue;\nimport java.util.Queue;\nimport java.util.Stack;\n\n/**\n * The DumpArchiveInputStream reads a UNIX dump archive as an InputStream.\n * Methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n *\n * There doesn't seem to exist a hint on the encoding of string values\n * in any piece documentation.  Given the main purpose of dump/restore\n * is backing up a system it seems very likely the format uses the\n * current default encoding of the system.\n *\n * @NotThreadSafe\n */\npublic class DumpArchiveInputStream extends ArchiveInputStream {\n    private DumpArchiveSummary summary;\n    private DumpArchiveEntry active;\n    private boolean isClosed;\n    private boolean hasHitEOF;\n    private long entrySize;\n    private long entryOffset;\n    private int readIdx;\n    private final byte[] readBuf = new byte[DumpArchiveConstants.TP_SIZE];\n    private byte[] blockBuffer;\n    private int recordOffset;\n    private long filepos;\n    protected TapeInputStream raw;\n\n    // map of ino -> dirent entry. We can use this to reconstruct full paths.\n    private final Map<Integer, Dirent> names = new HashMap<Integer, Dirent>();\n\n    // map of ino -> (directory) entry when we're missing one or more elements in the path.\n    private final Map<Integer, DumpArchiveEntry> pending = new HashMap<Integer, DumpArchiveEntry>();\n\n    // queue of (directory) entries where we now have the full path.\n    private Queue<DumpArchiveEntry> queue;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    /**\n     * Constructor using the platform's default encoding for file\n     * names.\n     *\n     * @param is\n     * @throws ArchiveException\n     */\n    public DumpArchiveInputStream(InputStream is) throws ArchiveException {\n        this(is, null);\n    }\n\n    /**\n     * Constructor.\n     *\n     * @param is\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.6\n     */\n    public DumpArchiveInputStream(InputStream is, String encoding)\n        throws ArchiveException {\n        this.raw = new TapeInputStream(is);\n        this.hasHitEOF = false;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        try {\n            // read header, verify it's a dump archive.\n            byte[] headerBytes = raw.readRecord();\n\n            if (!DumpArchiveUtil.verify(headerBytes)) {\n                throw new UnrecognizedFormatException();\n            }\n\n            // get summary information\n            summary = new DumpArchiveSummary(headerBytes, this.zipEncoding);\n\n            // reset buffer with actual block size.\n            raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n\n            // allocate our read buffer.\n            blockBuffer = new byte[4 * DumpArchiveConstants.TP_SIZE];\n\n            // skip past CLRI and BITS segments since we don't handle them yet.\n            readCLRI();\n            readBITS();\n        } catch (IOException ex) {\n            throw new ArchiveException(ex.getMessage(), ex);\n        }\n\n        // put in a dummy record for the root node.\n        Dirent root = new Dirent(2, 2, 4, \".\");\n        names.put(2, root);\n\n        // use priority based on queue to ensure parent directories are\n        // released first.\n        queue = new PriorityQueue<DumpArchiveEntry>(10,\n                new Comparator<DumpArchiveEntry>() {\n                    public int compare(DumpArchiveEntry p, DumpArchiveEntry q) {\n                        if (p.getOriginalName() == null || q.getOriginalName() == null) {\n                            return Integer.MAX_VALUE;\n                        }\n\n                        return p.getOriginalName().compareTo(q.getOriginalName());\n                    }\n                });\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesRead();\n    }\n\n    @Override\n    public long getBytesRead() {\n        return raw.getBytesRead();\n    }\n\n    /**\n     * Return the archive summary information.\n     */\n    public DumpArchiveSummary getSummary() {\n        return summary;\n    }\n\n    /**\n     * Read CLRI (deleted inode) segment.\n     */\n    private void readCLRI() throws IOException {\n        byte[] buffer = raw.readRecord();\n\n        if (!DumpArchiveUtil.verify(buffer)) {\n            throw new InvalidFormatException();\n        }\n\n        active = DumpArchiveEntry.parse(buffer);\n\n        if (DumpArchiveConstants.SEGMENT_TYPE.CLRI != active.getHeaderType()) {\n            throw new InvalidFormatException();\n        }\n\n        // we don't do anything with this yet.\n        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n            == -1) {\n            throw new EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    /**\n     * Read BITS segment.\n     */\n    private void readBITS() throws IOException {\n        byte[] buffer = raw.readRecord();\n\n        if (!DumpArchiveUtil.verify(buffer)) {\n            throw new InvalidFormatException();\n        }\n\n        active = DumpArchiveEntry.parse(buffer);\n\n        if (DumpArchiveConstants.SEGMENT_TYPE.BITS != active.getHeaderType()) {\n            throw new InvalidFormatException();\n        }\n\n        // we don't do anything with this yet.\n        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n            == -1) {\n            throw new EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    /**\n     * Read the next entry.\n     */\n    public DumpArchiveEntry getNextDumpEntry() throws IOException {\n        return getNextEntry();\n    }\n\n    /**\n     * Read the next entry.\n     */\n    @Override\n    public DumpArchiveEntry getNextEntry() throws IOException {\n        DumpArchiveEntry entry = null;\n        String path = null;\n\n        // is there anything in the queue?\n        if (!queue.isEmpty()) {\n            return queue.remove();\n        }\n\n        while (entry == null) {\n            if (hasHitEOF) {\n                return null;\n            }\n\n            // skip any remaining records in this segment for prior file.\n            // we might still have holes... easiest to do it\n            // block by block. We may want to revisit this if\n            // the unnecessary decompression time adds up.\n            while (readIdx < active.getHeaderCount()) {\n                if (!active.isSparseRecord(readIdx++)\n                    && raw.skip(DumpArchiveConstants.TP_SIZE) == -1) {\n                    throw new EOFException();\n                }\n            }\n\n            readIdx = 0;\n            filepos = raw.getBytesRead();\n\n            byte[] headerBytes = raw.readRecord();\n\n            if (!DumpArchiveUtil.verify(headerBytes)) {\n                throw new InvalidFormatException();\n            }\n\n            active = DumpArchiveEntry.parse(headerBytes);\n\n            // skip any remaining segments for prior file.\n            while (DumpArchiveConstants.SEGMENT_TYPE.ADDR == active.getHeaderType()) {\n                if (raw.skip(DumpArchiveConstants.TP_SIZE\n                             * (active.getHeaderCount()\n                                - active.getHeaderHoles())) == -1) {\n                    throw new EOFException();\n                }\n\n                filepos = raw.getBytesRead();\n                headerBytes = raw.readRecord();\n\n                if (!DumpArchiveUtil.verify(headerBytes)) {\n                    throw new InvalidFormatException();\n                }\n\n                active = DumpArchiveEntry.parse(headerBytes);\n            }\n\n            // check if this is an end-of-volume marker.\n            if (DumpArchiveConstants.SEGMENT_TYPE.END == active.getHeaderType()) {\n                hasHitEOF = true;\n\n                return null;\n            }\n\n            entry = active;\n\n            if (entry.isDirectory()) {\n                readDirectoryEntry(active);\n\n                // now we create an empty InputStream.\n                entryOffset = 0;\n                entrySize = 0;\n                readIdx = active.getHeaderCount();\n            } else {\n                entryOffset = 0;\n                entrySize = active.getEntrySize();\n                readIdx = 0;\n            }\n\n            recordOffset = readBuf.length;\n\n            path = getPath(entry);\n\n            if (path == null) {\n                entry = null;\n            }\n        }\n\n        entry.setName(path);\n        entry.setSimpleName(names.get(entry.getIno()).getName());\n        entry.setOffset(filepos);\n\n        return entry;\n    }\n\n    /**\n     * Read directory entry.\n     */\n    private void readDirectoryEntry(DumpArchiveEntry entry)\n        throws IOException {\n        long size = entry.getEntrySize();\n        boolean first = true;\n\n        while (first ||\n                DumpArchiveConstants.SEGMENT_TYPE.ADDR == entry.getHeaderType()) {\n            // read the header that we just peeked at.\n            if (!first) {\n                raw.readRecord();\n            }\n\n            if (!names.containsKey(entry.getIno()) &&\n                    DumpArchiveConstants.SEGMENT_TYPE.INODE == entry.getHeaderType()) {\n                pending.put(entry.getIno(), entry);\n            }\n\n            int datalen = DumpArchiveConstants.TP_SIZE * entry.getHeaderCount();\n\n            if (blockBuffer.length < datalen) {\n                blockBuffer = new byte[datalen];\n            }\n\n            if (raw.read(blockBuffer, 0, datalen) != datalen) {\n                throw new EOFException();\n            }\n\n            int reclen = 0;\n\n            for (int i = 0; i < datalen - 8 && i < size - 8;\n                    i += reclen) {\n                int ino = DumpArchiveUtil.convert32(blockBuffer, i);\n                reclen = DumpArchiveUtil.convert16(blockBuffer, i + 4);\n\n                byte type = blockBuffer[i + 6];\n\n                String name = DumpArchiveUtil.decode(zipEncoding, blockBuffer, i + 8, blockBuffer[i + 7]);\n\n                if (\".\".equals(name) || \"..\".equals(name)) {\n                    // do nothing...\n                    continue;\n                }\n\n                Dirent d = new Dirent(ino, entry.getIno(), type, name);\n\n                /*\n                if ((type == 4) && names.containsKey(ino)) {\n                    System.out.println(\"we already have ino: \" +\n                                       names.get(ino));\n                }\n                */\n\n                names.put(ino, d);\n\n                // check whether this allows us to fill anything in the pending list.\n                for (Map.Entry<Integer, DumpArchiveEntry> e : pending.entrySet()) {\n                    String path = getPath(e.getValue());\n\n                    if (path != null) {\n                        e.getValue().setName(path);\n                        e.getValue()\n                         .setSimpleName(names.get(e.getKey()).getName());\n                        queue.add(e.getValue());\n                    }\n                }\n\n                // remove anything that we found. (We can't do it earlier\n                // because of concurrent modification exceptions.)\n                for (DumpArchiveEntry e : queue) {\n                    pending.remove(e.getIno());\n                }\n            }\n\n            byte[] peekBytes = raw.peek();\n\n            if (!DumpArchiveUtil.verify(peekBytes)) {\n                throw new InvalidFormatException();\n            }\n\n            entry = DumpArchiveEntry.parse(peekBytes);\n            first = false;\n            size -= DumpArchiveConstants.TP_SIZE;\n        }\n    }\n\n    /**\n     * Get full path for specified archive entry, or null if there's a gap.\n     *\n     * @param entry\n     * @return  full path for specified archive entry, or null if there's a gap.\n     */\n    private String getPath(DumpArchiveEntry entry) {\n        // build the stack of elements. It's possible that we're \n        // still missing an intermediate value and if so we\n        Stack<String> elements = new Stack<String>();\n        Dirent dirent = null;\n\n        for (int i = entry.getIno();; i = dirent.getParentIno()) {\n            if (!names.containsKey(i)) {\n                elements.clear();\n                break;\n            }\n\n            dirent = names.get(i);\n            elements.push(dirent.getName());\n\n            if (dirent.getIno() == dirent.getParentIno()) {\n                break;\n            }\n        }\n\n        // if an element is missing defer the work and read next entry.\n        if (elements.isEmpty()) {\n            pending.put(entry.getIno(), entry);\n\n            return null;\n        }\n\n        // generate full path from stack of elements.\n        StringBuilder sb = new StringBuilder(elements.pop());\n\n        while (!elements.isEmpty()) {\n            sb.append('/');\n            sb.append(elements.pop());\n        }\n\n        return sb.toString();\n    }\n\n    /**\n     * Reads bytes from the current dump archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param off The offset at which to place bytes read.\n     * @param len The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        int totalRead = 0;\n\n        if (hasHitEOF || isClosed || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (active == null) {\n            throw new IllegalStateException(\"No current dump entry\");\n        }\n\n        if (len + entryOffset > entrySize) {\n            len = (int) (entrySize - entryOffset);\n        }\n\n        while (len > 0) {\n            int sz = len > readBuf.length - recordOffset\n                ? readBuf.length - recordOffset : len;\n\n            // copy any data we have\n            if (recordOffset + sz <= readBuf.length) {\n                System.arraycopy(readBuf, recordOffset, buf, off, sz);\n                totalRead += sz;\n                recordOffset += sz;\n                len -= sz;\n                off += sz;\n            }\n\n            // load next block if necessary.\n            if (len > 0) {\n                if (readIdx >= 512) {\n                    byte[] headerBytes = raw.readRecord();\n\n                    if (!DumpArchiveUtil.verify(headerBytes)) {\n                        throw new InvalidFormatException();\n                    }\n\n                    active = DumpArchiveEntry.parse(headerBytes);\n                    readIdx = 0;\n                }\n\n                if (!active.isSparseRecord(readIdx++)) {\n                    int r = raw.read(readBuf, 0, readBuf.length);\n                    if (r != readBuf.length) {\n                        throw new EOFException();\n                    }\n                } else {\n                    Arrays.fill(readBuf, (byte) 0);\n                }\n\n                recordOffset = 0;\n            }\n        }\n\n        entryOffset += totalRead;\n\n        return totalRead;\n    }\n\n    /**\n     * Closes the stream for this entry.\n     */\n    @Override\n    public void close() throws IOException {\n        if (!isClosed) {\n            isClosed = true;\n            raw.close();\n        }\n    }\n\n    /**\n     * Look at the first few bytes of the file to decide if it's a dump\n     * archive. With 32 bytes we can look at the magic value, with a full\n     * 1k we can verify the checksum.\n     */\n    public static boolean matches(byte[] buffer, int length) {\n        // do we have enough of the header?\n        if (length < 32) {\n            return false;\n        }\n\n        // this is the best test\n        if (length >= DumpArchiveConstants.TP_SIZE) {\n            return DumpArchiveUtil.verify(buffer);\n        }\n\n        // this will work in a pinch.\n        return DumpArchiveConstants.NFS_MAGIC == DumpArchiveUtil.convert32(buffer,\n            24);\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.dump;\n\nimport org.apache.commons.compress.archivers.ArchiveException;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport java.util.Arrays;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.PriorityQueue;\nimport java.util.Queue;\nimport java.util.Stack;\n\n/**\n * The DumpArchiveInputStream reads a UNIX dump archive as an InputStream.\n * Methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n *\n * There doesn't seem to exist a hint on the encoding of string values\n * in any piece documentation.  Given the main purpose of dump/restore\n * is backing up a system it seems very likely the format uses the\n * current default encoding of the system.\n *\n * @NotThreadSafe\n */\npublic class DumpArchiveInputStream extends ArchiveInputStream {\n    private DumpArchiveSummary summary;\n    private DumpArchiveEntry active;\n    private boolean isClosed;\n    private boolean hasHitEOF;\n    private long entrySize;\n    private long entryOffset;\n    private int readIdx;\n    private final byte[] readBuf = new byte[DumpArchiveConstants.TP_SIZE];\n    private byte[] blockBuffer;\n    private int recordOffset;\n    private long filepos;\n    protected TapeInputStream raw;\n\n    // map of ino -> dirent entry. We can use this to reconstruct full paths.\n    private final Map<Integer, Dirent> names = new HashMap<Integer, Dirent>();\n\n    // map of ino -> (directory) entry when we're missing one or more elements in the path.\n    private final Map<Integer, DumpArchiveEntry> pending = new HashMap<Integer, DumpArchiveEntry>();\n\n    // queue of (directory) entries where we now have the full path.\n    private Queue<DumpArchiveEntry> queue;\n\n    /**\n     * The encoding to use for filenames and labels.\n     */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Constructor using the platform's default encoding for file\n     * names.\n     *\n     * @param is\n     * @throws ArchiveException\n     */\n    public DumpArchiveInputStream(InputStream is) throws ArchiveException {\n        this(is, null);\n    }\n\n    /**\n     * Constructor.\n     *\n     * @param is\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.6\n     */\n    public DumpArchiveInputStream(InputStream is, String encoding)\n        throws ArchiveException {\n        this.raw = new TapeInputStream(is);\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        try {\n            // read header, verify it's a dump archive.\n            byte[] headerBytes = raw.readRecord();\n\n            if (!DumpArchiveUtil.verify(headerBytes)) {\n                throw new UnrecognizedFormatException();\n            }\n\n            // get summary information\n            summary = new DumpArchiveSummary(headerBytes, this.zipEncoding);\n\n            // reset buffer with actual block size.\n            raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n\n            // allocate our read buffer.\n            blockBuffer = new byte[4 * DumpArchiveConstants.TP_SIZE];\n\n            // skip past CLRI and BITS segments since we don't handle them yet.\n            readCLRI();\n            readBITS();\n        } catch (IOException ex) {\n            throw new ArchiveException(ex.getMessage(), ex);\n        }\n\n        // put in a dummy record for the root node.\n        Dirent root = new Dirent(2, 2, 4, \".\");\n        names.put(2, root);\n\n        // use priority based on queue to ensure parent directories are\n        // released first.\n        queue = new PriorityQueue<DumpArchiveEntry>(10,\n                new Comparator<DumpArchiveEntry>() {\n                    public int compare(DumpArchiveEntry p, DumpArchiveEntry q) {\n                        if (p.getOriginalName() == null || q.getOriginalName() == null) {\n                            return Integer.MAX_VALUE;\n                        }\n\n                        return p.getOriginalName().compareTo(q.getOriginalName());\n                    }\n                });\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesRead();\n    }\n\n    @Override\n    public long getBytesRead() {\n        return raw.getBytesRead();\n    }\n\n    /**\n     * Return the archive summary information.\n     */\n    public DumpArchiveSummary getSummary() {\n        return summary;\n    }\n\n    /**\n     * Read CLRI (deleted inode) segment.\n     */\n    private void readCLRI() throws IOException {\n        byte[] buffer = raw.readRecord();\n\n        if (!DumpArchiveUtil.verify(buffer)) {\n            throw new InvalidFormatException();\n        }\n\n        active = DumpArchiveEntry.parse(buffer);\n\n        if (DumpArchiveConstants.SEGMENT_TYPE.CLRI != active.getHeaderType()) {\n            throw new InvalidFormatException();\n        }\n\n        // we don't do anything with this yet.\n        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n            == -1) {\n            throw new EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    /**\n     * Read BITS segment.\n     */\n    private void readBITS() throws IOException {\n        byte[] buffer = raw.readRecord();\n\n        if (!DumpArchiveUtil.verify(buffer)) {\n            throw new InvalidFormatException();\n        }\n\n        active = DumpArchiveEntry.parse(buffer);\n\n        if (DumpArchiveConstants.SEGMENT_TYPE.BITS != active.getHeaderType()) {\n            throw new InvalidFormatException();\n        }\n\n        // we don't do anything with this yet.\n        if (raw.skip(DumpArchiveConstants.TP_SIZE * active.getHeaderCount())\n            == -1) {\n            throw new EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    /**\n     * Read the next entry.\n     */\n    public DumpArchiveEntry getNextDumpEntry() throws IOException {\n        return getNextEntry();\n    }\n\n    /**\n     * Read the next entry.\n     */\n    @Override\n    public DumpArchiveEntry getNextEntry() throws IOException {\n        DumpArchiveEntry entry = null;\n        String path = null;\n\n        // is there anything in the queue?\n        if (!queue.isEmpty()) {\n            return queue.remove();\n        }\n\n        while (entry == null) {\n            if (hasHitEOF) {\n                return null;\n            }\n\n            // skip any remaining records in this segment for prior file.\n            // we might still have holes... easiest to do it\n            // block by block. We may want to revisit this if\n            // the unnecessary decompression time adds up.\n            while (readIdx < active.getHeaderCount()) {\n                if (!active.isSparseRecord(readIdx++)\n                    && raw.skip(DumpArchiveConstants.TP_SIZE) == -1) {\n                    throw new EOFException();\n                }\n            }\n\n            readIdx = 0;\n            filepos = raw.getBytesRead();\n\n            byte[] headerBytes = raw.readRecord();\n\n            if (!DumpArchiveUtil.verify(headerBytes)) {\n                throw new InvalidFormatException();\n            }\n\n            active = DumpArchiveEntry.parse(headerBytes);\n\n            // skip any remaining segments for prior file.\n            while (DumpArchiveConstants.SEGMENT_TYPE.ADDR == active.getHeaderType()) {\n                if (raw.skip(DumpArchiveConstants.TP_SIZE\n                             * (active.getHeaderCount()\n                                - active.getHeaderHoles())) == -1) {\n                    throw new EOFException();\n                }\n\n                filepos = raw.getBytesRead();\n                headerBytes = raw.readRecord();\n\n                if (!DumpArchiveUtil.verify(headerBytes)) {\n                    throw new InvalidFormatException();\n                }\n\n                active = DumpArchiveEntry.parse(headerBytes);\n            }\n\n            // check if this is an end-of-volume marker.\n            if (DumpArchiveConstants.SEGMENT_TYPE.END == active.getHeaderType()) {\n                hasHitEOF = true;\n\n                return null;\n            }\n\n            entry = active;\n\n            if (entry.isDirectory()) {\n                readDirectoryEntry(active);\n\n                // now we create an empty InputStream.\n                entryOffset = 0;\n                entrySize = 0;\n                readIdx = active.getHeaderCount();\n            } else {\n                entryOffset = 0;\n                entrySize = active.getEntrySize();\n                readIdx = 0;\n            }\n\n            recordOffset = readBuf.length;\n\n            path = getPath(entry);\n\n            if (path == null) {\n                entry = null;\n            }\n        }\n\n        entry.setName(path);\n        entry.setSimpleName(names.get(entry.getIno()).getName());\n        entry.setOffset(filepos);\n\n        return entry;\n    }\n\n    /**\n     * Read directory entry.\n     */\n    private void readDirectoryEntry(DumpArchiveEntry entry)\n        throws IOException {\n        long size = entry.getEntrySize();\n        boolean first = true;\n\n        while (first ||\n                DumpArchiveConstants.SEGMENT_TYPE.ADDR == entry.getHeaderType()) {\n            // read the header that we just peeked at.\n            if (!first) {\n                raw.readRecord();\n            }\n\n            if (!names.containsKey(entry.getIno()) &&\n                    DumpArchiveConstants.SEGMENT_TYPE.INODE == entry.getHeaderType()) {\n                pending.put(entry.getIno(), entry);\n            }\n\n            int datalen = DumpArchiveConstants.TP_SIZE * entry.getHeaderCount();\n\n            if (blockBuffer.length < datalen) {\n                blockBuffer = new byte[datalen];\n            }\n\n            if (raw.read(blockBuffer, 0, datalen) != datalen) {\n                throw new EOFException();\n            }\n\n            int reclen = 0;\n\n            for (int i = 0; i < datalen - 8 && i < size - 8;\n                    i += reclen) {\n                int ino = DumpArchiveUtil.convert32(blockBuffer, i);\n                reclen = DumpArchiveUtil.convert16(blockBuffer, i + 4);\n\n                byte type = blockBuffer[i + 6];\n\n                String name = DumpArchiveUtil.decode(zipEncoding, blockBuffer, i + 8, blockBuffer[i + 7]);\n\n                if (\".\".equals(name) || \"..\".equals(name)) {\n                    // do nothing...\n                    continue;\n                }\n\n                Dirent d = new Dirent(ino, entry.getIno(), type, name);\n\n                /*\n                if ((type == 4) && names.containsKey(ino)) {\n                    System.out.println(\"we already have ino: \" +\n                                       names.get(ino));\n                }\n                */\n\n                names.put(ino, d);\n\n                // check whether this allows us to fill anything in the pending list.\n                for (Map.Entry<Integer, DumpArchiveEntry> e : pending.entrySet()) {\n                    String path = getPath(e.getValue());\n\n                    if (path != null) {\n                        e.getValue().setName(path);\n                        e.getValue()\n                         .setSimpleName(names.get(e.getKey()).getName());\n                        queue.add(e.getValue());\n                    }\n                }\n\n                // remove anything that we found. (We can't do it earlier\n                // because of concurrent modification exceptions.)\n                for (DumpArchiveEntry e : queue) {\n                    pending.remove(e.getIno());\n                }\n            }\n\n            byte[] peekBytes = raw.peek();\n\n            if (!DumpArchiveUtil.verify(peekBytes)) {\n                throw new InvalidFormatException();\n            }\n\n            entry = DumpArchiveEntry.parse(peekBytes);\n            first = false;\n            size -= DumpArchiveConstants.TP_SIZE;\n        }\n    }\n\n    /**\n     * Get full path for specified archive entry, or null if there's a gap.\n     *\n     * @param entry\n     * @return  full path for specified archive entry, or null if there's a gap.\n     */\n    private String getPath(DumpArchiveEntry entry) {\n        // build the stack of elements. It's possible that we're \n        // still missing an intermediate value and if so we\n        Stack<String> elements = new Stack<String>();\n        Dirent dirent = null;\n\n        for (int i = entry.getIno();; i = dirent.getParentIno()) {\n            if (!names.containsKey(i)) {\n                elements.clear();\n                break;\n            }\n\n            dirent = names.get(i);\n            elements.push(dirent.getName());\n\n            if (dirent.getIno() == dirent.getParentIno()) {\n                break;\n            }\n        }\n\n        // if an element is missing defer the work and read next entry.\n        if (elements.isEmpty()) {\n            pending.put(entry.getIno(), entry);\n\n            return null;\n        }\n\n        // generate full path from stack of elements.\n        StringBuilder sb = new StringBuilder(elements.pop());\n\n        while (!elements.isEmpty()) {\n            sb.append('/');\n            sb.append(elements.pop());\n        }\n\n        return sb.toString();\n    }\n\n    /**\n     * Reads bytes from the current dump archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param off The offset at which to place bytes read.\n     * @param len The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        int totalRead = 0;\n\n        if (hasHitEOF || isClosed || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (active == null) {\n            throw new IllegalStateException(\"No current dump entry\");\n        }\n\n        if (len + entryOffset > entrySize) {\n            len = (int) (entrySize - entryOffset);\n        }\n\n        while (len > 0) {\n            int sz = len > readBuf.length - recordOffset\n                ? readBuf.length - recordOffset : len;\n\n            // copy any data we have\n            if (recordOffset + sz <= readBuf.length) {\n                System.arraycopy(readBuf, recordOffset, buf, off, sz);\n                totalRead += sz;\n                recordOffset += sz;\n                len -= sz;\n                off += sz;\n            }\n\n            // load next block if necessary.\n            if (len > 0) {\n                if (readIdx >= 512) {\n                    byte[] headerBytes = raw.readRecord();\n\n                    if (!DumpArchiveUtil.verify(headerBytes)) {\n                        throw new InvalidFormatException();\n                    }\n\n                    active = DumpArchiveEntry.parse(headerBytes);\n                    readIdx = 0;\n                }\n\n                if (!active.isSparseRecord(readIdx++)) {\n                    int r = raw.read(readBuf, 0, readBuf.length);\n                    if (r != readBuf.length) {\n                        throw new EOFException();\n                    }\n                } else {\n                    Arrays.fill(readBuf, (byte) 0);\n                }\n\n                recordOffset = 0;\n            }\n        }\n\n        entryOffset += totalRead;\n\n        return totalRead;\n    }\n\n    /**\n     * Closes the stream for this entry.\n     */\n    @Override\n    public void close() throws IOException {\n        if (!isClosed) {\n            isClosed = true;\n            raw.close();\n        }\n    }\n\n    /**\n     * Look at the first few bytes of the file to decide if it's a dump\n     * archive. With 32 bytes we can look at the magic value, with a full\n     * 1k we can verify the checksum.\n     */\n    public static boolean matches(byte[] buffer, int length) {\n        // do we have enough of the header?\n        if (length < 32) {\n            return false;\n        }\n\n        // this is the best test\n        if (length >= DumpArchiveConstants.TP_SIZE) {\n            return DumpArchiveUtil.verify(buffer);\n        }\n\n        // this will work in a pinch.\n        return DumpArchiveConstants.NFS_MAGIC == DumpArchiveUtil.convert32(buffer,\n            24);\n    }\n\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            byte[] rest = new byte[restLen];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != restLen) {\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + restLen\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      restLen - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            byte[] rest = new byte[restLen];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != restLen) {\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + restLen\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      restLen - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.StringWriter;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.Map;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    /** POSIX/PAX extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_POSIX = 3;\n\n    /** Fail if a big number (e.g. size &gt; 8GiB) is required in the archive. */\n    public static final int BIGNUMBER_ERROR = 0;\n\n    /** star/GNU tar/BSD tar extensions are used to store big number in the archive. */\n    public static final int BIGNUMBER_STAR = 1;\n\n    /** POSIX/PAX extensions are used to store big numbers in the archive. */\n    public static final int BIGNUMBER_POSIX = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    private int       longFileMode = LONGFILE_ERROR;\n    private int       bigNumberMode = BIGNUMBER_ERROR;\n    private int recordsWritten;\n    private final int recordsPerBlock;\n    private final int recordSize;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished = false;\n\n    private final OutputStream out;\n\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    private boolean addPaxHeadersForNonAsciiNames = false;\n    private static final ZipEncoding ASCII =\n        ZipEncodingHelper.getZipEncoding(\"ASCII\");\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, String encoding) {\n        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  String encoding) {\n        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        this(os, blockSize, recordSize, null);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  int recordSize, String encoding) {\n        out = new CountingOutputStream(os);\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n        this.recordSize = recordSize;\n        this.recordsPerBlock = blockSize / recordSize;\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names &gt;= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n    /**\n     * Set the big number mode.\n     * This can be BIGNUMBER_ERROR(0), BIGNUMBER_POSIX(1) or BIGNUMBER_STAR(2).\n     * This specifies the treatment of big files (sizes &gt; TarConstants.MAXSIZE) and other numeric values to big to fit into a traditional tar header.\n     * Default is BIGNUMBER_ERROR.\n     * @param bigNumberMode the mode to use\n     * @since 1.4\n     */\n    public void setBigNumberMode(int bigNumberMode) {\n        this.bigNumberMode = bigNumberMode;\n    }\n\n    /**\n     * Whether to add a PAX extension header for non-ASCII file names.\n     * @since 1.4\n     */\n    public void setAddPaxHeadersForNonAsciiNames(boolean b) {\n        addPaxHeadersForNonAsciiNames = b;\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesWritten();\n    }\n\n    @Override\n    public long getBytesWritten() {\n        return ((CountingOutputStream) out).getBytesWritten();\n    }\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        padAsNeeded();\n        out.flush();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n\n        if (!closed) {\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return this.recordSize;\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        Map<String, String> paxHeaders = new HashMap<String, String>();\n        final String entryName = entry.getName();\n        boolean paxHeaderContainsPath = handleLongName(entry, entryName, paxHeaders, \"path\",\n                                                       TarConstants.LF_GNUTYPE_LONGNAME, \"file name\");\n\n        final String linkName = entry.getLinkName();\n        boolean paxHeaderContainsLinkPath = linkName != null && linkName.length() > 0\n            && handleLongName(entry, linkName, paxHeaders, \"linkpath\",\n                              TarConstants.LF_GNUTYPE_LONGLINK, \"link name\");\n\n        if (bigNumberMode == BIGNUMBER_POSIX) {\n            addPaxHeadersForBigNumbers(paxHeaders, entry);\n        } else if (bigNumberMode != BIGNUMBER_STAR) {\n            failForBigNumbers(entry);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath\n            && !ASCII.canEncode(entryName)) {\n            paxHeaders.put(\"path\", entryName);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsLinkPath\n            && (entry.isLink() || entry.isSymbolicLink())\n            && !ASCII.canEncode(linkName)) {\n            paxHeaders.put(\"linkpath\", linkName);\n        }\n\n        if (paxHeaders.size() > 0) {\n            writePaxHeaders(entry, entryName, paxHeaders);\n        }\n\n        entry.writeEntryHeader(recordBuf, zipEncoding,\n                               bigNumberMode == BIGNUMBER_STAR);\n        writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entryName;\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if (!haveUnclosedEntry) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n        if (currBytes + numToWrite > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if (assemLen + numToWrite >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Writes a PAX extended header with the given map as contents.\n     * @since 1.4\n     */\n    void writePaxHeaders(TarArchiveEntry entry,\n                         String entryName,\n                         Map<String, String> headers) throws IOException {\n        String name = \"./PaxHeaders.X/\" + stripTo7Bits(entryName);\n        if (name.length() >= TarConstants.NAMELEN) {\n            name = name.substring(0, TarConstants.NAMELEN - 1);\n        }\n        TarArchiveEntry pex = new TarArchiveEntry(name,\n                                                  TarConstants.LF_PAX_EXTENDED_HEADER_LC);\n        transferModTime(entry, pex);\n\n        StringWriter w = new StringWriter();\n        for (Map.Entry<String, String> h : headers.entrySet()) {\n            String key = h.getKey();\n            String value = h.getValue();\n            int len = key.length() + value.length()\n                + 3 /* blank, equals and newline */\n                + 2 /* guess 9 < actual length < 100 */;\n            String line = len + \" \" + key + \"=\" + value + \"\\n\";\n            int actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            while (len != actualLength) {\n                // Adjust for cases where length < 10 or > 100\n                // or where UTF-8 encoding isn't a single octet\n                // per character.\n                // Must be in loop as size may go from 99 to 100 in\n                // first pass so we'd need a second.\n                len = actualLength;\n                line = len + \" \" + key + \"=\" + value + \"\\n\";\n                actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            }\n            w.write(line);\n        }\n        byte[] data = w.toString().getBytes(CharsetNames.UTF_8);\n        pex.setSize(data.length);\n        putArchiveEntry(pex);\n        write(data);\n        closeArchiveEntry();\n    }\n\n    private String stripTo7Bits(String name) {\n        final int length = name.length();\n        StringBuilder result = new StringBuilder(length);\n        for (int i = 0; i < length; i++) {\n            char stripped = (char) (name.charAt(i) & 0x7F);\n            if (shouldBeReplaced(stripped)) {\n                result.append(\"_\");\n            } else {\n                result.append(stripped);\n            }\n        }\n        return result.toString();\n    }\n\n    /**\n     * @return true if the character could lead to problems when used\n     * inside a TarArchiveEntry name for a PAX header.\n     */\n    private boolean shouldBeReplaced(char c) {\n        return c == 0 // would be read as Trailing null\n            || c == '/' // when used as last character TAE will consider the PAX header a directory\n            || c == '\\\\'; // same as '/' as slashes get \"normalized\" on Windows\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        Arrays.fill(recordBuf, (byte) 0);\n        writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n    \n    /**\n     * Write an archive record to the archive.\n     *\n     * @param record The record data to write to the archive.\n     * @throws IOException on error\n     */\n    private void writeRecord(byte[] record) throws IOException {\n        if (record.length != recordSize) {\n            throw new IOException(\"record to write has length '\"\n                                  + record.length\n                                  + \"' which is not the record size of '\"\n                                  + recordSize + \"'\");\n        }\n\n        out.write(record);\n        recordsWritten++;\n    }\n    \n    /**\n     * Write an archive record to the archive, where the record may be\n     * inside of a larger array buffer. The buffer must be \"offset plus\n     * record size\" long.\n     *\n     * @param buf The buffer containing the record data to write.\n     * @param offset The offset of the record data within buf.\n     * @throws IOException on error\n     */\n    private void writeRecord(byte[] buf, int offset) throws IOException {\n \n        if (offset + recordSize > buf.length) {\n            throw new IOException(\"record has length '\" + buf.length\n                                  + \"' with offset '\" + offset\n                                  + \"' which is less than the record size of '\"\n                                  + recordSize + \"'\");\n        }\n\n        out.write(buf, offset, recordSize);\n        recordsWritten++;\n    }\n\n    private void padAsNeeded() throws IOException {\n        int start = recordsWritten % recordsPerBlock;\n        if (start != 0) {\n            for (int i = start; i < recordsPerBlock; i++) {\n                writeEOFRecord();\n            }\n        }\n    }\n\n    private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n                                            TarArchiveEntry entry) {\n        addPaxHeaderForBigNumber(paxHeaders, \"size\", entry.getSize(),\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"gid\", entry.getGroupId(),\n                                 TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"mtime\",\n                                 entry.getModTime().getTime() / 1000,\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"uid\", entry.getUserId(),\n                                 TarConstants.MAXID);\n        // star extensions by J\\u00f6rg Schilling\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devmajor\",\n                                 entry.getDevMajor(), TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devminor\",\n                                 entry.getDevMinor(), TarConstants.MAXID);\n        // there is no PAX header for file mode\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n    }\n\n    private void addPaxHeaderForBigNumber(Map<String, String> paxHeaders,\n                                          String header, long value,\n                                          long maxValue) {\n        if (value < 0 || value > maxValue) {\n            paxHeaders.put(header, String.valueOf(value));\n        }\n    }\n\n    private void failForBigNumbers(TarArchiveEntry entry) {\n        failForBigNumber(\"entry size\", entry.getSize(), TarConstants.MAXSIZE);\n        failForBigNumberWithPosixMessage(\"group id\", entry.getGroupId(), TarConstants.MAXID);\n        failForBigNumber(\"last modification time\",\n                         entry.getModTime().getTime() / 1000,\n                         TarConstants.MAXSIZE);\n        failForBigNumber(\"user id\", entry.getUserId(), TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n        failForBigNumber(\"major device number\", entry.getDevMajor(),\n                         TarConstants.MAXID);\n        failForBigNumber(\"minor device number\", entry.getDevMinor(),\n                         TarConstants.MAXID);\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \"\");\n    }\n\n    private void failForBigNumberWithPosixMessage(String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \" Use STAR or POSIX extensions to overcome this limit\");\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue, String additionalMsg) {\n        if (value < 0 || value > maxValue) {\n            throw new RuntimeException(field + \" '\" + value\n                    + \"' is too big ( > \"\n                    + maxValue + \" ).\" + additionalMsg);\n        }\n    }\n\n    /**\n     * Handles long file or link names according to the longFileMode setting.\n     *\n     * <p>I.e. if the given name is too long to be written to a plain\n     * tar header then\n     * <ul>\n     *   <li>it creates a pax header who's name is given by the\n     *   paxHeaderName parameter if longFileMode is POSIX</li>\n     *   <li>it creates a GNU longlink entry who's type is given by\n     *   the linkType parameter if longFileMode is GNU</li>\n     *   <li>it throws an exception if longFileMode is ERROR</li>\n     *   <li>it truncates the name if longFileMode is TRUNCATE</li>\n     * </ul></p>\n     *\n     * @param entry entry the name belongs to\n     * @param name the name to write\n     * @param paxHeaders current map of pax headers\n     * @param paxHeaderName name of the pax header to write\n     * @param linkType type of the GNU entry to write\n     * @param fieldName the name of the field\n     * @return whether a pax header has been written.\n     */\n    private boolean handleLongName(TarArchiveEntry entry , String name,\n                                   Map<String, String> paxHeaders,\n                                   String paxHeaderName, byte linkType, String fieldName)\n        throws IOException {\n        final ByteBuffer encodedName = zipEncoding.encode(name);\n        final int len = encodedName.limit() - encodedName.position();\n        if (len >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_POSIX) {\n                paxHeaders.put(paxHeaderName, name);\n                return true;\n            } else if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the link's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, linkType);\n\n                longLinkEntry.setSize(len + 1); // +1 for NUL\n                transferModTime(entry, longLinkEntry);\n                putArchiveEntry(longLinkEntry);\n                write(encodedName.array(), encodedName.arrayOffset(), len);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(fieldName + \" '\" + name\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n        return false;\n    }\n\n    private void transferModTime(TarArchiveEntry from, TarArchiveEntry to) {\n        Date fromModTime = from.getModTime();\n        long fromModTimeSeconds = fromModTime.getTime() / 1000;\n        if (fromModTimeSeconds < 0 || fromModTimeSeconds > TarConstants.MAXSIZE) {\n            fromModTime = new Date(0);\n        }\n        to.setModTime(fromModTime);\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.StringWriter;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.Map;\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.CountingOutputStream;\n\n/**\n * The TarOutputStream writes a UNIX tar archive as an OutputStream.\n * Methods are provided to put entries, and then write their contents\n * by writing to this stream using write().\n * @NotThreadSafe\n */\npublic class TarArchiveOutputStream extends ArchiveOutputStream {\n    /** Fail if a long file name is required in the archive. */\n    public static final int LONGFILE_ERROR = 0;\n\n    /** Long paths will be truncated in the archive. */\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    /** GNU tar extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_GNU = 2;\n\n    /** POSIX/PAX extensions are used to store long file names in the archive. */\n    public static final int LONGFILE_POSIX = 3;\n\n    /** Fail if a big number (e.g. size &gt; 8GiB) is required in the archive. */\n    public static final int BIGNUMBER_ERROR = 0;\n\n    /** star/GNU tar/BSD tar extensions are used to store big number in the archive. */\n    public static final int BIGNUMBER_STAR = 1;\n\n    /** POSIX/PAX extensions are used to store big numbers in the archive. */\n    public static final int BIGNUMBER_POSIX = 2;\n\n    private long      currSize;\n    private String    currName;\n    private long      currBytes;\n    private final byte[]    recordBuf;\n    private int       assemLen;\n    private final byte[]    assemBuf;\n    private int       longFileMode = LONGFILE_ERROR;\n    private int       bigNumberMode = BIGNUMBER_ERROR;\n    private int recordsWritten;\n    private final int recordsPerBlock;\n    private final int recordSize;\n\n    private boolean closed = false;\n\n    /** Indicates if putArchiveEntry has been called without closeArchiveEntry */\n    private boolean haveUnclosedEntry = false;\n\n    /** indicates if this archive is finished */\n    private boolean finished = false;\n\n    private final OutputStream out;\n\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    private boolean addPaxHeadersForNonAsciiNames = false;\n    private static final ZipEncoding ASCII =\n        ZipEncodingHelper.getZipEncoding(\"ASCII\");\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     */\n    public TarArchiveOutputStream(OutputStream os) {\n        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, String encoding) {\n        this(os, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize) {\n        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  String encoding) {\n        this(os, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize) {\n        this(os, blockSize, recordSize, null);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param os the output stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveOutputStream(OutputStream os, int blockSize,\n                                  int recordSize, String encoding) {\n        out = new CountingOutputStream(os);\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n        this.recordSize = recordSize;\n        this.recordsPerBlock = blockSize / recordSize;\n    }\n\n    /**\n     * Set the long file mode.\n     * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).\n     * This specifies the treatment of long file names (names &gt;= TarConstants.NAMELEN).\n     * Default is LONGFILE_ERROR.\n     * @param longFileMode the mode to use\n     */\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n    /**\n     * Set the big number mode.\n     * This can be BIGNUMBER_ERROR(0), BIGNUMBER_POSIX(1) or BIGNUMBER_STAR(2).\n     * This specifies the treatment of big files (sizes &gt; TarConstants.MAXSIZE) and other numeric values to big to fit into a traditional tar header.\n     * Default is BIGNUMBER_ERROR.\n     * @param bigNumberMode the mode to use\n     * @since 1.4\n     */\n    public void setBigNumberMode(int bigNumberMode) {\n        this.bigNumberMode = bigNumberMode;\n    }\n\n    /**\n     * Whether to add a PAX extension header for non-ASCII file names.\n     * @since 1.4\n     */\n    public void setAddPaxHeadersForNonAsciiNames(boolean b) {\n        addPaxHeadersForNonAsciiNames = b;\n    }\n\n    @Deprecated\n    @Override\n    public int getCount() {\n        return (int) getBytesWritten();\n    }\n\n    @Override\n    public long getBytesWritten() {\n        return ((CountingOutputStream) out).getBytesWritten();\n    }\n\n    /**\n     * Ends the TAR archive without closing the underlying OutputStream.\n     * \n     * An archive consists of a series of file entries terminated by an\n     * end-of-archive entry, which consists of two 512 blocks of zero bytes. \n     * POSIX.1 requires two EOF records, like some other implementations.\n     * \n     * @throws IOException on error\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (haveUnclosedEntry) {\n            throw new IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        padAsNeeded();\n        out.flush();\n        finished = true;\n    }\n\n    /**\n     * Closes the underlying OutputStream.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n\n        if (!closed) {\n            out.close();\n            closed = true;\n        }\n    }\n\n    /**\n     * Get the record size being used by this stream's TarBuffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return this.recordSize;\n    }\n\n    /**\n     * Put an entry on the output stream. This writes the entry's\n     * header record and positions the output stream for writing\n     * the contents of the entry. Once this method is called, the\n     * stream is ready for calls to write() to write the entry's\n     * contents. Once the contents are written, closeArchiveEntry()\n     * <B>MUST</B> be called to ensure that all buffered data\n     * is completely written to the output stream.\n     *\n     * @param archiveEntry The TarEntry to be written to the archive.\n     * @throws IOException on error\n     * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry\n     */\n    @Override\n    public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;\n        Map<String, String> paxHeaders = new HashMap<String, String>();\n        final String entryName = entry.getName();\n        boolean paxHeaderContainsPath = handleLongName(entry, entryName, paxHeaders, \"path\",\n                                                       TarConstants.LF_GNUTYPE_LONGNAME, \"file name\");\n\n        final String linkName = entry.getLinkName();\n        boolean paxHeaderContainsLinkPath = linkName != null && linkName.length() > 0\n            && handleLongName(entry, linkName, paxHeaders, \"linkpath\",\n                              TarConstants.LF_GNUTYPE_LONGLINK, \"link name\");\n\n        if (bigNumberMode == BIGNUMBER_POSIX) {\n            addPaxHeadersForBigNumbers(paxHeaders, entry);\n        } else if (bigNumberMode != BIGNUMBER_STAR) {\n            failForBigNumbers(entry);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath\n            && !ASCII.canEncode(entryName)) {\n            paxHeaders.put(\"path\", entryName);\n        }\n\n        if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsLinkPath\n            && (entry.isLink() || entry.isSymbolicLink())\n            && !ASCII.canEncode(linkName)) {\n            paxHeaders.put(\"linkpath\", linkName);\n        }\n\n        if (paxHeaders.size() > 0) {\n            writePaxHeaders(entry, entryName, paxHeaders);\n        }\n\n        entry.writeEntryHeader(recordBuf, zipEncoding,\n                               bigNumberMode == BIGNUMBER_STAR);\n        writeRecord(recordBuf);\n\n        currBytes = 0;\n\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entryName;\n        haveUnclosedEntry = true;\n    }\n\n    /**\n     * Close an entry. This method MUST be called for all file\n     * entries that contain data. The reason is that we must\n     * buffer data written to the stream in order to satisfy\n     * the buffer's record based writes. Thus, there may be\n     * data fragments still being assembled that must be written\n     * to the output stream before this entry is closed and the\n     * next entry written.\n     * @throws IOException on error\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry){\n            throw new IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n\n            writeRecord(assemBuf);\n\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n\n        if (currBytes < currSize) {\n            throw new IOException(\"entry '\" + currName + \"' closed at '\"\n                                  + currBytes\n                                  + \"' before the '\" + currSize\n                                  + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    /**\n     * Writes bytes to the current tar archive entry. This method\n     * is aware of the current entry and will throw an exception if\n     * you attempt to write bytes past the length specified for the\n     * current entry. The method is also (painfully) aware of the\n     * record buffering required by TarBuffer, and manages buffers\n     * that are not a multiple of recordsize in length, including\n     * assembling records from small buffers.\n     *\n     * @param wBuf The buffer to write to the archive.\n     * @param wOffset The offset in the buffer from which to get bytes.\n     * @param numToWrite The number of bytes to write.\n     * @throws IOException on error\n     */\n    @Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {\n        if (!haveUnclosedEntry) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n        if (currBytes + numToWrite > currSize) {\n            throw new IOException(\"request to write '\" + numToWrite\n                                  + \"' bytes exceeds size in header of '\"\n                                  + currSize + \"' bytes for entry '\"\n                                  + currName + \"'\");\n\n            //\n            // We have to deal with assembly!!!\n            // The programmer can be writing little 32 byte chunks for all\n            // we know, and we must assemble complete records for writing.\n            // REVIEW Maybe this should be in TarBuffer? Could that help to\n            // eliminate some of the buffer copying.\n            //\n        }\n\n        if (assemLen > 0) {\n            if (assemLen + numToWrite >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n\n                System.arraycopy(assemBuf, 0, recordBuf, 0,\n                                 assemLen);\n                System.arraycopy(wBuf, wOffset, recordBuf,\n                                 assemLen, aLen);\n                writeRecord(recordBuf);\n\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n\n        //\n        // When we get here we have EITHER:\n        // o An empty \"assemble\" buffer.\n        // o No bytes to write (numToWrite == 0)\n        //\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                System.arraycopy(wBuf, wOffset, assemBuf, assemLen,\n                                 numToWrite);\n\n                assemLen += numToWrite;\n\n                break;\n            }\n\n            writeRecord(wBuf, wOffset);\n\n            int num = recordBuf.length;\n\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        }\n    }\n\n    /**\n     * Writes a PAX extended header with the given map as contents.\n     * @since 1.4\n     */\n    void writePaxHeaders(TarArchiveEntry entry,\n                         String entryName,\n                         Map<String, String> headers) throws IOException {\n        String name = \"./PaxHeaders.X/\" + stripTo7Bits(entryName);\n        if (name.length() >= TarConstants.NAMELEN) {\n            name = name.substring(0, TarConstants.NAMELEN - 1);\n        }\n        TarArchiveEntry pex = new TarArchiveEntry(name,\n                                                  TarConstants.LF_PAX_EXTENDED_HEADER_LC);\n        transferModTime(entry, pex);\n\n        StringWriter w = new StringWriter();\n        for (Map.Entry<String, String> h : headers.entrySet()) {\n            String key = h.getKey();\n            String value = h.getValue();\n            int len = key.length() + value.length()\n                + 3 /* blank, equals and newline */\n                + 2 /* guess 9 < actual length < 100 */;\n            String line = len + \" \" + key + \"=\" + value + \"\\n\";\n            int actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            while (len != actualLength) {\n                // Adjust for cases where length < 10 or > 100\n                // or where UTF-8 encoding isn't a single octet\n                // per character.\n                // Must be in loop as size may go from 99 to 100 in\n                // first pass so we'd need a second.\n                len = actualLength;\n                line = len + \" \" + key + \"=\" + value + \"\\n\";\n                actualLength = line.getBytes(CharsetNames.UTF_8).length;\n            }\n            w.write(line);\n        }\n        byte[] data = w.toString().getBytes(CharsetNames.UTF_8);\n        pex.setSize(data.length);\n        putArchiveEntry(pex);\n        write(data);\n        closeArchiveEntry();\n    }\n\n    private String stripTo7Bits(String name) {\n        final int length = name.length();\n        StringBuilder result = new StringBuilder(length);\n        for (int i = 0; i < length; i++) {\n            char stripped = (char) (name.charAt(i) & 0x7F);\n            if (shouldBeReplaced(stripped)) {\n                result.append(\"_\");\n            } else {\n                result.append(stripped);\n            }\n        }\n        return result.toString();\n    }\n\n    /**\n     * @return true if the character could lead to problems when used\n     * inside a TarArchiveEntry name for a PAX header.\n     */\n    private boolean shouldBeReplaced(char c) {\n        return c == 0 // would be read as Trailing null\n            || c == '/' // when used as last character TAE will consider the PAX header a directory\n            || c == '\\\\'; // same as '/' as slashes get \"normalized\" on Windows\n    }\n\n    /**\n     * Write an EOF (end of archive) record to the tar archive.\n     * An EOF record consists of a record of all zeros.\n     */\n    private void writeEOFRecord() throws IOException {\n        Arrays.fill(recordBuf, (byte) 0);\n        writeRecord(recordBuf);\n    }\n\n    @Override\n    public void flush() throws IOException {\n        out.flush();\n    }\n\n    @Override\n    public ArchiveEntry createArchiveEntry(File inputFile, String entryName)\n            throws IOException {\n        if(finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new TarArchiveEntry(inputFile, entryName);\n    }\n    \n    /**\n     * Write an archive record to the archive.\n     *\n     * @param record The record data to write to the archive.\n     * @throws IOException on error\n     */\n    private void writeRecord(byte[] record) throws IOException {\n        if (record.length != recordSize) {\n            throw new IOException(\"record to write has length '\"\n                                  + record.length\n                                  + \"' which is not the record size of '\"\n                                  + recordSize + \"'\");\n        }\n\n        out.write(record);\n        recordsWritten++;\n    }\n    \n    /**\n     * Write an archive record to the archive, where the record may be\n     * inside of a larger array buffer. The buffer must be \"offset plus\n     * record size\" long.\n     *\n     * @param buf The buffer containing the record data to write.\n     * @param offset The offset of the record data within buf.\n     * @throws IOException on error\n     */\n    private void writeRecord(byte[] buf, int offset) throws IOException {\n \n        if (offset + recordSize > buf.length) {\n            throw new IOException(\"record has length '\" + buf.length\n                                  + \"' with offset '\" + offset\n                                  + \"' which is less than the record size of '\"\n                                  + recordSize + \"'\");\n        }\n\n        out.write(buf, offset, recordSize);\n        recordsWritten++;\n    }\n\n    private void padAsNeeded() throws IOException {\n        int start = recordsWritten % recordsPerBlock;\n        if (start != 0) {\n            for (int i = start; i < recordsPerBlock; i++) {\n                writeEOFRecord();\n            }\n        }\n    }\n\n    private void addPaxHeadersForBigNumbers(Map<String, String> paxHeaders,\n                                            TarArchiveEntry entry) {\n        addPaxHeaderForBigNumber(paxHeaders, \"size\", entry.getSize(),\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"gid\", entry.getGroupId(),\n                                 TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"mtime\",\n                                 entry.getModTime().getTime() / 1000,\n                                 TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"uid\", entry.getUserId(),\n                                 TarConstants.MAXID);\n        // star extensions by J\\u00f6rg Schilling\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devmajor\",\n                                 entry.getDevMajor(), TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devminor\",\n                                 entry.getDevMinor(), TarConstants.MAXID);\n        // there is no PAX header for file mode\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n    }\n\n    private void addPaxHeaderForBigNumber(Map<String, String> paxHeaders,\n                                          String header, long value,\n                                          long maxValue) {\n        if (value < 0 || value > maxValue) {\n            paxHeaders.put(header, String.valueOf(value));\n        }\n    }\n\n    private void failForBigNumbers(TarArchiveEntry entry) {\n        failForBigNumber(\"entry size\", entry.getSize(), TarConstants.MAXSIZE);\n        failForBigNumberWithPosixMessage(\"group id\", entry.getGroupId(), TarConstants.MAXID);\n        failForBigNumber(\"last modification time\",\n                         entry.getModTime().getTime() / 1000,\n                         TarConstants.MAXSIZE);\n        failForBigNumber(\"user id\", entry.getUserId(), TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), TarConstants.MAXID);\n        failForBigNumber(\"major device number\", entry.getDevMajor(),\n                         TarConstants.MAXID);\n        failForBigNumber(\"minor device number\", entry.getDevMinor(),\n                         TarConstants.MAXID);\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \"\");\n    }\n\n    private void failForBigNumberWithPosixMessage(String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \" Use STAR or POSIX extensions to overcome this limit\");\n    }\n\n    private void failForBigNumber(String field, long value, long maxValue, String additionalMsg) {\n        if (value < 0 || value > maxValue) {\n            throw new RuntimeException(field + \" '\" + value\n                    + \"' is too big ( > \"\n                    + maxValue + \" ).\" + additionalMsg);\n        }\n    }\n\n    /**\n     * Handles long file or link names according to the longFileMode setting.\n     *\n     * <p>I.e. if the given name is too long to be written to a plain\n     * tar header then\n     * <ul>\n     *   <li>it creates a pax header who's name is given by the\n     *   paxHeaderName parameter if longFileMode is POSIX</li>\n     *   <li>it creates a GNU longlink entry who's type is given by\n     *   the linkType parameter if longFileMode is GNU</li>\n     *   <li>it throws an exception if longFileMode is ERROR</li>\n     *   <li>it truncates the name if longFileMode is TRUNCATE</li>\n     * </ul></p>\n     *\n     * @param entry entry the name belongs to\n     * @param name the name to write\n     * @param paxHeaders current map of pax headers\n     * @param paxHeaderName name of the pax header to write\n     * @param linkType type of the GNU entry to write\n     * @param fieldName the name of the field\n     * @return whether a pax header has been written.\n     */\n    private boolean handleLongName(TarArchiveEntry entry , String name,\n                                   Map<String, String> paxHeaders,\n                                   String paxHeaderName, byte linkType, String fieldName)\n        throws IOException {\n        final ByteBuffer encodedName = zipEncoding.encode(name);\n        final int len = encodedName.limit() - encodedName.position();\n        if (len >= TarConstants.NAMELEN) {\n\n            if (longFileMode == LONGFILE_POSIX) {\n                paxHeaders.put(paxHeaderName, name);\n                return true;\n            } else if (longFileMode == LONGFILE_GNU) {\n                // create a TarEntry for the LongLink, the contents\n                // of which are the link's name\n                TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, linkType);\n\n                longLinkEntry.setSize(len + 1); // +1 for NUL\n                transferModTime(entry, longLinkEntry);\n                putArchiveEntry(longLinkEntry);\n                write(encodedName.array(), encodedName.arrayOffset(), len);\n                write(0); // NUL terminator\n                closeArchiveEntry();\n            } else if (longFileMode != LONGFILE_TRUNCATE) {\n                throw new RuntimeException(fieldName + \" '\" + name\n                                           + \"' is too long ( > \"\n                                           + TarConstants.NAMELEN + \" bytes)\");\n            }\n        }\n        return false;\n    }\n\n    private void transferModTime(TarArchiveEntry from, TarArchiveEntry to) {\n        Date fromModTime = from.getModTime();\n        long fromModTimeSeconds = fromModTime.getTime() / 1000;\n        if (fromModTimeSeconds < 0 || fromModTimeSeconds > TarConstants.MAXSIZE) {\n            fromModTime = new Date(0);\n        }\n        to.setModTime(fromModTime);\n    }\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n * DEFLATE algorithm is used, as the size information is not available\n * from the header.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != ZipArchiveEntry.SIZE_UNKNOWN) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(byte[] buffer, int offset, int length) throws IOException {\n        int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(byte[] buffer, int offset, int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(ByteArrayOutputStream bos, int offset, int lastRead, int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(ByteArrayOutputStream bos, int offset, int lastRead, int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n * DEFLATE algorithm is used, as the size information is not available\n * from the header.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != ZipArchiveEntry.SIZE_UNKNOWN) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(byte[] buffer, int offset, int length) throws IOException {\n        int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(byte[] buffer, int offset, int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(ByteArrayOutputStream bos, int offset, int lastRead, int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(ByteArrayOutputStream bos, int offset, int lastRead, int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 30, "classes_modified": [{"class_name": "org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*\n * This package is based on the work done by Keiron Liddle, Aftex Software\n * <keiron@aftexsw.com> to whom the Ant project is very grateful for his\n * great code.\n */\npackage org.apache.commons.compress.compressors.bzip2;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * An input stream that decompresses from the BZip2 format to be read as any other stream.\n * \n * @NotThreadSafe\n */\npublic class BZip2CompressorInputStream extends CompressorInputStream implements\n                                                                          BZip2Constants {\n\n    /**\n     * Index of the last char in the block, so the block size == last + 1.\n     */\n    private int last;\n\n    /**\n     * Index in zptr[] of original string after sorting.\n     */\n    private int origPtr;\n\n    /**\n     * always: in the range 0 .. 9. The current block size is 100000 * this\n     * number.\n     */\n    private int blockSize100k;\n\n    private boolean blockRandomised;\n\n    private int bsBuff;\n    private int bsLive;\n    private final CRC crc = new CRC();\n\n    private int nInUse;\n\n    private InputStream in;\n    private final boolean decompressConcatenated;\n\n    private static final int EOF = 0;\n    private static final int START_BLOCK_STATE = 1;\n    private static final int RAND_PART_A_STATE = 2;\n    private static final int RAND_PART_B_STATE = 3;\n    private static final int RAND_PART_C_STATE = 4;\n    private static final int NO_RAND_PART_A_STATE = 5;\n    private static final int NO_RAND_PART_B_STATE = 6;\n    private static final int NO_RAND_PART_C_STATE = 7;\n\n    private int currentState = START_BLOCK_STATE;\n\n    private int storedBlockCRC, storedCombinedCRC;\n    private int computedBlockCRC, computedCombinedCRC;\n\n    // Variables used by setup* methods exclusively\n\n    private int su_count;\n    private int su_ch2;\n    private int su_chPrev;\n    private int su_i2;\n    private int su_j2;\n    private int su_rNToGo;\n    private int su_rTPos;\n    private int su_tPos;\n    private char su_z;\n\n    /**\n     * All memory intensive stuff. This field is initialized by initBlock().\n     */\n    private BZip2CompressorInputStream.Data data;\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream. This doesn't suppprt decompressing\n     * concatenated .bz2 files.\n     * \n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if {@code in == null}\n     */\n    public BZip2CompressorInputStream(final InputStream in) throws IOException {\n        this(in, false);\n    }\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream.\n     *\n     * @param in the InputStream from which this object should be created\n     * @param decompressConcatenated\n     *                     if true, decompress until the end of the input;\n     *                     if false, stop after the first .bz2 stream and\n     *                     leave the input position to point to the next\n     *                     byte after the .bz2 stream\n     *\n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if {@code in == null}\n     */\n    public BZip2CompressorInputStream(final InputStream in, final boolean decompressConcatenated) throws IOException {\n        this.in = in;\n        this.decompressConcatenated = decompressConcatenated;\n\n        init(true);\n        initBlock();\n    }\n\n    @Override\n    public int read() throws IOException {\n        if (this.in != null) {\n            int r = read0();\n            count(r < 0 ? -1 : 1);\n            return r;\n        } else {\n            throw new IOException(\"stream closed\");\n        }\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.InputStream#read(byte[], int, int)\n     */\n    @Override\n    public int read(final byte[] dest, final int offs, final int len)\n        throws IOException {\n        if (offs < 0) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") < 0.\");\n        }\n        if (len < 0) {\n            throw new IndexOutOfBoundsException(\"len(\" + len + \") < 0.\");\n        }\n        if (offs + len > dest.length) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") + len(\"\n                                                + len + \") > dest.length(\" + dest.length + \").\");\n        }\n        if (this.in == null) {\n            throw new IOException(\"stream closed\");\n        }\n\n        final int hi = offs + len;\n        int destOffs = offs;\n        int b;\n        while (destOffs < hi && ((b = read0()) >= 0)) {\n            dest[destOffs++] = (byte) b;\n            count(1);\n        }\n\n        int c = (destOffs == offs) ? -1 : (destOffs - offs);\n        return c;\n    }\n\n    private void makeMaps() {\n        final boolean[] inUse = this.data.inUse;\n        final byte[] seqToUnseq = this.data.seqToUnseq;\n\n        int nInUseShadow = 0;\n\n        for (int i = 0; i < 256; i++) {\n            if (inUse[i]) {\n                seqToUnseq[nInUseShadow++] = (byte) i;\n            }\n        }\n\n        this.nInUse = nInUseShadow;\n    }\n\n    private int read0() throws IOException {\n        switch (currentState) {\n        case EOF:\n            return -1;\n\n        case START_BLOCK_STATE:\n            return setupBlock();\n\n        case RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case RAND_PART_B_STATE:\n            return setupRandPartB();\n\n        case RAND_PART_C_STATE:\n            return setupRandPartC();\n\n        case NO_RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case NO_RAND_PART_B_STATE:\n            return setupNoRandPartB();\n\n        case NO_RAND_PART_C_STATE:\n            return setupNoRandPartC();\n\n        default:\n            throw new IllegalStateException();\n        }\n    }\n\n    private boolean init(boolean isFirstStream) throws IOException {\n        if (null == in) {\n            throw new IOException(\"No InputStream\");\n        }\n\n        int magic0 = this.in.read();\n        if (magic0 == -1 && !isFirstStream) {\n            return false;\n        }\n        int magic1 = this.in.read();\n        int magic2 = this.in.read();\n\n        if (magic0 != 'B' || magic1 != 'Z' || magic2 != 'h') {\n            throw new IOException(isFirstStream\n                    ? \"Stream is not in the BZip2 format\"\n                    : \"Garbage after a valid BZip2 stream\");\n        }\n\n        int blockSize = this.in.read();\n        if ((blockSize < '1') || (blockSize > '9')) {\n            throw new IOException(\"BZip2 block size is invalid\");\n        }\n\n        this.blockSize100k = blockSize - '0';\n\n        this.bsLive = 0;\n        this.computedCombinedCRC = 0;\n\n        return true;\n    }\n\n    private void initBlock() throws IOException {\n        char magic0;\n        char magic1;\n        char magic2;\n        char magic3;\n        char magic4;\n        char magic5;\n\n        while (true) {\n            // Get the block magic bytes.\n            magic0 = bsGetUByte();\n            magic1 = bsGetUByte();\n            magic2 = bsGetUByte();\n            magic3 = bsGetUByte();\n            magic4 = bsGetUByte();\n            magic5 = bsGetUByte();\n\n            // If isn't end of stream magic, break out of the loop.\n            if (magic0 != 0x17 || magic1 != 0x72 || magic2 != 0x45\n                    || magic3 != 0x38 || magic4 != 0x50 || magic5 != 0x90) {\n                break;\n            }\n\n            // End of stream was reached. Check the combined CRC and\n            // advance to the next .bz2 stream if decoding concatenated\n            // streams.\n            if (complete()) {\n                return;\n            }\n        }\n\n        if (magic0 != 0x31 || // '1'\n            magic1 != 0x41 || // ')'\n            magic2 != 0x59 || // 'Y'\n            magic3 != 0x26 || // '&'\n            magic4 != 0x53 || // 'S'\n            magic5 != 0x59 // 'Y'\n            ) {\n            this.currentState = EOF;\n            throw new IOException(\"bad block header\");\n        } else {\n            this.storedBlockCRC = bsGetInt();\n            this.blockRandomised = bsR(1) == 1;\n\n            /**\n             * Allocate data here instead in constructor, so we do not allocate\n             * it if the input file is empty.\n             */\n            if (this.data == null) {\n                this.data = new Data(this.blockSize100k);\n            }\n\n            // currBlockNo++;\n            getAndMoveToFrontDecode();\n\n            this.crc.initialiseCRC();\n            this.currentState = START_BLOCK_STATE;\n        }\n    }\n\n    private void endBlock() throws IOException {\n        this.computedBlockCRC = this.crc.getFinalCRC();\n\n        // A bad CRC is considered a fatal error.\n        if (this.storedBlockCRC != this.computedBlockCRC) {\n            // make next blocks readable without error\n            // (repair feature, not yet documented, not tested)\n            this.computedCombinedCRC = (this.storedCombinedCRC << 1)\n                | (this.storedCombinedCRC >>> 31);\n            this.computedCombinedCRC ^= this.storedBlockCRC;\n\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        this.computedCombinedCRC = (this.computedCombinedCRC << 1)\n            | (this.computedCombinedCRC >>> 31);\n        this.computedCombinedCRC ^= this.computedBlockCRC;\n    }\n\n    private boolean complete() throws IOException {\n        this.storedCombinedCRC = bsGetInt();\n        this.currentState = EOF;\n        this.data = null;\n\n        if (this.storedCombinedCRC != this.computedCombinedCRC) {\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        // Look for the next .bz2 stream if decompressing\n        // concatenated files.\n        return !decompressConcatenated || !init(false);\n    }\n\n    @Override\n    public void close() throws IOException {\n        InputStream inShadow = this.in;\n        if (inShadow != null) {\n            try {\n                if (inShadow != System.in) {\n                    inShadow.close();\n                }\n            } finally {\n                this.data = null;\n                this.in = null;\n            }\n        }\n    }\n\n    private int bsR(final int n) throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < n) {\n            final InputStream inShadow = this.in;\n            do {\n                int thech = inShadow.read();\n\n                if (thech < 0) {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n\n                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                bsLiveShadow += 8;\n            } while (bsLiveShadow < n);\n\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - n;\n        return (bsBuffShadow >> (bsLiveShadow - n)) & ((1 << n) - 1);\n    }\n\n    private boolean bsGetBit() throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < 1) {\n            int thech = this.in.read();\n\n            if (thech < 0) {\n                throw new IOException(\"unexpected end of stream\");\n            }\n\n            bsBuffShadow = (bsBuffShadow << 8) | thech;\n            bsLiveShadow += 8;\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - 1;\n        return ((bsBuffShadow >> (bsLiveShadow - 1)) & 1) != 0;\n    }\n\n    private char bsGetUByte() throws IOException {\n        return (char) bsR(8);\n    }\n\n    private int bsGetInt() throws IOException {\n        return (((((bsR(8) << 8) | bsR(8)) << 8) | bsR(8)) << 8) | bsR(8);\n    }\n\n    /**\n     * Called by createHuffmanDecodingTables() exclusively.\n     */\n    private static void hbCreateDecodeTables(final int[] limit,\n                                             final int[] base, final int[] perm, final char[] length,\n                                             final int minLen, final int maxLen, final int alphaSize) {\n        for (int i = minLen, pp = 0; i <= maxLen; i++) {\n            for (int j = 0; j < alphaSize; j++) {\n                if (length[j] == i) {\n                    perm[pp++] = j;\n                }\n            }\n        }\n\n        for (int i = MAX_CODE_LEN; --i > 0;) {\n            base[i] = 0;\n            limit[i] = 0;\n        }\n\n        for (int i = 0; i < alphaSize; i++) {\n            base[length[i] + 1]++;\n        }\n\n        for (int i = 1, b = base[0]; i < MAX_CODE_LEN; i++) {\n            b += base[i];\n            base[i] = b;\n        }\n\n        for (int i = minLen, vec = 0, b = base[i]; i <= maxLen; i++) {\n            final int nb = base[i + 1];\n            vec += nb - b;\n            b = nb;\n            limit[i] = vec - 1;\n            vec <<= 1;\n        }\n\n        for (int i = minLen + 1; i <= maxLen; i++) {\n            base[i] = ((limit[i - 1] + 1) << 1) - base[i];\n        }\n    }\n\n    private void recvDecodingTables() throws IOException {\n        final Data dataShadow = this.data;\n        final boolean[] inUse = dataShadow.inUse;\n        final byte[] pos = dataShadow.recvDecodingTables_pos;\n        final byte[] selector = dataShadow.selector;\n        final byte[] selectorMtf = dataShadow.selectorMtf;\n\n        int inUse16 = 0;\n\n        /* Receive the mapping table */\n        for (int i = 0; i < 16; i++) {\n            if (bsGetBit()) {\n                inUse16 |= 1 << i;\n            }\n        }\n\n        for (int i = 256; --i >= 0;) {\n            inUse[i] = false;\n        }\n\n        for (int i = 0; i < 16; i++) {\n            if ((inUse16 & (1 << i)) != 0) {\n                final int i16 = i << 4;\n                for (int j = 0; j < 16; j++) {\n                    if (bsGetBit()) {\n                        inUse[i16 + j] = true;\n                    }\n                }\n            }\n        }\n\n        makeMaps();\n        final int alphaSize = this.nInUse + 2;\n\n        /* Now the selectors */\n        final int nGroups = bsR(3);\n        final int nSelectors = bsR(15);\n\n        for (int i = 0; i < nSelectors; i++) {\n            int j = 0;\n            while (bsGetBit()) {\n                j++;\n            }\n            selectorMtf[i] = (byte) j;\n        }\n\n        /* Undo the MTF values for the selectors. */\n        for (int v = nGroups; --v >= 0;) {\n            pos[v] = (byte) v;\n        }\n\n        for (int i = 0; i < nSelectors; i++) {\n            int v = selectorMtf[i] & 0xff;\n            final byte tmp = pos[v];\n            while (v > 0) {\n                // nearly all times v is zero, 4 in most other cases\n                pos[v] = pos[v - 1];\n                v--;\n            }\n            pos[0] = tmp;\n            selector[i] = tmp;\n        }\n\n        final char[][] len = dataShadow.temp_charArray2d;\n\n        /* Now the coding tables */\n        for (int t = 0; t < nGroups; t++) {\n            int curr = bsR(5);\n            final char[] len_t = len[t];\n            for (int i = 0; i < alphaSize; i++) {\n                while (bsGetBit()) {\n                    curr += bsGetBit() ? -1 : 1;\n                }\n                len_t[i] = (char) curr;\n            }\n        }\n\n        // finally create the Huffman tables\n        createHuffmanDecodingTables(alphaSize, nGroups);\n    }\n\n    /**\n     * Called by recvDecodingTables() exclusively.\n     */\n    private void createHuffmanDecodingTables(final int alphaSize,\n                                             final int nGroups) {\n        final Data dataShadow = this.data;\n        final char[][] len = dataShadow.temp_charArray2d;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n\n        for (int t = 0; t < nGroups; t++) {\n            int minLen = 32;\n            int maxLen = 0;\n            final char[] len_t = len[t];\n            for (int i = alphaSize; --i >= 0;) {\n                final char lent = len_t[i];\n                if (lent > maxLen) {\n                    maxLen = lent;\n                }\n                if (lent < minLen) {\n                    minLen = lent;\n                }\n            }\n            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,\n                                 maxLen, alphaSize);\n            minLens[t] = minLen;\n        }\n    }\n\n    private void getAndMoveToFrontDecode() throws IOException {\n        this.origPtr = bsR(24);\n        recvDecodingTables();\n\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final byte[] ll8 = dataShadow.ll8;\n        final int[] unzftab = dataShadow.unzftab;\n        final byte[] selector = dataShadow.selector;\n        final byte[] seqToUnseq = dataShadow.seqToUnseq;\n        final char[] yy = dataShadow.getAndMoveToFrontDecode_yy;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n        final int limitLast = this.blockSize100k * 100000;\n\n        /*\n         * Setting up the unzftab entries here is not strictly necessary, but it\n         * does save having to do it later in a separate pass, and so saves a\n         * block's worth of cache misses.\n         */\n        for (int i = 256; --i >= 0;) {\n            yy[i] = (char) i;\n            unzftab[i] = 0;\n        }\n\n        int groupNo = 0;\n        int groupPos = G_SIZE - 1;\n        final int eob = this.nInUse + 1;\n        int nextSym = getAndMoveToFrontDecode0(0);\n        int bsBuffShadow = this.bsBuff;\n        int bsLiveShadow = this.bsLive;\n        int lastShadow = -1;\n        int zt = selector[groupNo] & 0xff;\n        int[] base_zt = base[zt];\n        int[] limit_zt = limit[zt];\n        int[] perm_zt = perm[zt];\n        int minLens_zt = minLens[zt];\n\n        while (nextSym != eob) {\n            if ((nextSym == RUNA) || (nextSym == RUNB)) {\n                int s = -1;\n\n                for (int n = 1; true; n <<= 1) {\n                    if (nextSym == RUNA) {\n                        s += n;\n                    } else if (nextSym == RUNB) {\n                        s += n << 1;\n                    } else {\n                        break;\n                    }\n\n                    if (groupPos == 0) {\n                        groupPos = G_SIZE - 1;\n                        zt = selector[++groupNo] & 0xff;\n                        base_zt = base[zt];\n                        limit_zt = limit[zt];\n                        perm_zt = perm[zt];\n                        minLens_zt = minLens[zt];\n                    } else {\n                        groupPos--;\n                    }\n\n                    int zn = minLens_zt;\n\n                    // Inlined:\n                    // int zvec = bsR(zn);\n                    while (bsLiveShadow < zn) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                        & ((1 << zn) - 1);\n                    bsLiveShadow -= zn;\n\n                    while (zvec > limit_zt[zn]) {\n                        zn++;\n                        while (bsLiveShadow < 1) {\n                            final int thech = inShadow.read();\n                            if (thech >= 0) {\n                                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                                bsLiveShadow += 8;\n                                continue;\n                            } else {\n                                throw new IOException(\n                                                      \"unexpected end of stream\");\n                            }\n                        }\n                        bsLiveShadow--;\n                        zvec = (zvec << 1)\n                            | ((bsBuffShadow >> bsLiveShadow) & 1);\n                    }\n                    nextSym = perm_zt[zvec - base_zt[zn]];\n                }\n\n                final byte ch = seqToUnseq[yy[0]];\n                unzftab[ch & 0xff] += s + 1;\n\n                while (s-- >= 0) {\n                    ll8[++lastShadow] = ch;\n                }\n\n                if (lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n            } else {\n                if (++lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n\n                final char tmp = yy[nextSym - 1];\n                unzftab[seqToUnseq[tmp] & 0xff]++;\n                ll8[lastShadow] = seqToUnseq[tmp];\n\n                /*\n                 * This loop is hammered during decompression, hence avoid\n                 * native method call overhead of System.arraycopy for very\n                 * small ranges to copy.\n                 */\n                if (nextSym <= 16) {\n                    for (int j = nextSym - 1; j > 0;) {\n                        yy[j] = yy[--j];\n                    }\n                } else {\n                    System.arraycopy(yy, 0, yy, 1, nextSym - 1);\n                }\n\n                yy[0] = tmp;\n\n                if (groupPos == 0) {\n                    groupPos = G_SIZE - 1;\n                    zt = selector[++groupNo] & 0xff;\n                    base_zt = base[zt];\n                    limit_zt = limit[zt];\n                    perm_zt = perm[zt];\n                    minLens_zt = minLens[zt];\n                } else {\n                    groupPos--;\n                }\n\n                int zn = minLens_zt;\n\n                // Inlined:\n                // int zvec = bsR(zn);\n                while (bsLiveShadow < zn) {\n                    final int thech = inShadow.read();\n                    if (thech >= 0) {\n                        bsBuffShadow = (bsBuffShadow << 8) | thech;\n                        bsLiveShadow += 8;\n                        continue;\n                    } else {\n                        throw new IOException(\"unexpected end of stream\");\n                    }\n                }\n                int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                    & ((1 << zn) - 1);\n                bsLiveShadow -= zn;\n\n                while (zvec > limit_zt[zn]) {\n                    zn++;\n                    while (bsLiveShadow < 1) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    bsLiveShadow--;\n                    zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n                }\n                nextSym = perm_zt[zvec - base_zt[zn]];\n            }\n        }\n\n        this.last = lastShadow;\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n    }\n\n    private int getAndMoveToFrontDecode0(final int groupNo) throws IOException {\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final int zt = dataShadow.selector[groupNo] & 0xff;\n        final int[] limit_zt = dataShadow.limit[zt];\n        int zn = dataShadow.minLens[zt];\n        int zvec = bsR(zn);\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        while (zvec > limit_zt[zn]) {\n            zn++;\n            while (bsLiveShadow < 1) {\n                final int thech = inShadow.read();\n\n                if (thech >= 0) {\n                    bsBuffShadow = (bsBuffShadow << 8) | thech;\n                    bsLiveShadow += 8;\n                    continue;\n                } else {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n            }\n            bsLiveShadow--;\n            zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n        }\n\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n\n        return dataShadow.perm[zt][zvec - dataShadow.base[zt][zn]];\n    }\n\n    private int setupBlock() throws IOException {\n        if (currentState == EOF || this.data == null) {\n            return -1;\n        }\n\n        final int[] cftab = this.data.cftab;\n        final int[] tt = this.data.initTT(this.last + 1);\n        final byte[] ll8 = this.data.ll8;\n        cftab[0] = 0;\n        System.arraycopy(this.data.unzftab, 0, cftab, 1, 256);\n\n        for (int i = 1, c = cftab[0]; i <= 256; i++) {\n            c += cftab[i];\n            cftab[i] = c;\n        }\n\n        for (int i = 0, lastShadow = this.last; i <= lastShadow; i++) {\n            tt[cftab[ll8[i] & 0xff]++] = i;\n        }\n\n        if ((this.origPtr < 0) || (this.origPtr >= tt.length)) {\n            throw new IOException(\"stream corrupted\");\n        }\n\n        this.su_tPos = tt[this.origPtr];\n        this.su_count = 0;\n        this.su_i2 = 0;\n        this.su_ch2 = 256; /* not a char and not EOF */\n\n        if (this.blockRandomised) {\n            this.su_rNToGo = 0;\n            this.su_rTPos = 0;\n            return setupRandPartA();\n        }\n        return setupNoRandPartA();\n    }\n\n    private int setupRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_ch2 = su_ch2Shadow ^= (this.su_rNToGo == 1) ? 1 : 0;\n            this.su_i2++;\n            this.currentState = RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupNoRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_ch2 = su_ch2Shadow;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_i2++;\n            this.currentState = NO_RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            this.currentState = NO_RAND_PART_A_STATE;\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_count = 1;\n            return setupRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_j2 = 0;\n            this.currentState = RAND_PART_C_STATE;\n            if (this.su_rNToGo == 1) {\n                this.su_z ^= 1;\n            }\n            return setupRandPartC();\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            this.crc.updateCRC(this.su_ch2);\n            this.su_j2++;\n            return this.su_ch2;\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_i2++;\n            this.su_count = 0;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupNoRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.su_count = 1;\n            return setupNoRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_j2 = 0;\n            return setupNoRandPartC();\n        } else {\n            return setupNoRandPartA();\n        }\n    }\n\n    private int setupNoRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            int su_ch2Shadow = this.su_ch2;\n            this.crc.updateCRC(su_ch2Shadow);\n            this.su_j2++;\n            this.currentState = NO_RAND_PART_C_STATE;\n            return su_ch2Shadow;\n        } else {\n            this.su_i2++;\n            this.su_count = 0;\n            return setupNoRandPartA();\n        }\n    }\n\n    private static final class Data {\n\n        // (with blockSize 900k)\n        final boolean[] inUse = new boolean[256]; // 256 byte\n\n        final byte[] seqToUnseq = new byte[256]; // 256 byte\n        final byte[] selector = new byte[MAX_SELECTORS]; // 18002 byte\n        final byte[] selectorMtf = new byte[MAX_SELECTORS]; // 18002 byte\n\n        /**\n         * Freq table collected to save a pass over the data during\n         * decompression.\n         */\n        final int[] unzftab = new int[256]; // 1024 byte\n\n        final int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[] minLens = new int[N_GROUPS]; // 24 byte\n\n        final int[] cftab = new int[257]; // 1028 byte\n        final char[] getAndMoveToFrontDecode_yy = new char[256]; // 512 byte\n        final char[][] temp_charArray2d = new char[N_GROUPS][MAX_ALPHA_SIZE]; // 3096\n        // byte\n        final byte[] recvDecodingTables_pos = new byte[N_GROUPS]; // 6 byte\n        // ---------------\n        // 60798 byte\n\n        int[] tt; // 3600000 byte\n        byte[] ll8; // 900000 byte\n\n        // ---------------\n        // 4560782 byte\n        // ===============\n\n        Data(int blockSize100k) {\n            this.ll8 = new byte[blockSize100k * BZip2Constants.BASEBLOCKSIZE];\n        }\n\n        /**\n         * Initializes the {@link #tt} array.\n         * \n         * This method is called when the required length of the array is known.\n         * I don't initialize it at construction time to avoid unneccessary\n         * memory allocation when compressing small files.\n         */\n        int[] initTT(int length) {\n            int[] ttShadow = this.tt;\n\n            // tt.length should always be >= length, but theoretically\n            // it can happen, if the compressor mixed small and large\n            // blocks. Normally only the last block will be smaller\n            // than others.\n            if ((ttShadow == null) || (ttShadow.length < length)) {\n                this.tt = ttShadow = new int[length];\n            }\n\n            return ttShadow;\n        }\n\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a bzip2 file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a bzip2 compressed stream, false otherwise\n     * \n     * @since 1.1\n     */\n    public static boolean matches(byte[] signature, int length) {\n\n        if (length < 3) {\n            return false;\n        }\n\n        if (signature[0] != 'B') {\n            return false;\n        }\n\n        if (signature[1] != 'Z') {\n            return false;\n        }\n\n        if (signature[2] != 'h') {\n            return false;\n        }\n\n        return true;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*\n * This package is based on the work done by Keiron Liddle, Aftex Software\n * <keiron@aftexsw.com> to whom the Ant project is very grateful for his\n * great code.\n */\npackage org.apache.commons.compress.compressors.bzip2;\n\nimport java.io.IOException;\nimport java.io.InputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * An input stream that decompresses from the BZip2 format to be read as any other stream.\n * \n * @NotThreadSafe\n */\npublic class BZip2CompressorInputStream extends CompressorInputStream implements\n                                                                          BZip2Constants {\n\n    /**\n     * Index of the last char in the block, so the block size == last + 1.\n     */\n    private int last;\n\n    /**\n     * Index in zptr[] of original string after sorting.\n     */\n    private int origPtr;\n\n    /**\n     * always: in the range 0 .. 9. The current block size is 100000 * this\n     * number.\n     */\n    private int blockSize100k;\n\n    private boolean blockRandomised;\n\n    private int bsBuff;\n    private int bsLive;\n    private final CRC crc = new CRC();\n\n    private int nInUse;\n\n    private InputStream in;\n    private final boolean decompressConcatenated;\n\n    private static final int EOF = 0;\n    private static final int START_BLOCK_STATE = 1;\n    private static final int RAND_PART_A_STATE = 2;\n    private static final int RAND_PART_B_STATE = 3;\n    private static final int RAND_PART_C_STATE = 4;\n    private static final int NO_RAND_PART_A_STATE = 5;\n    private static final int NO_RAND_PART_B_STATE = 6;\n    private static final int NO_RAND_PART_C_STATE = 7;\n\n    private int currentState = START_BLOCK_STATE;\n\n    private int storedBlockCRC, storedCombinedCRC;\n    private int computedBlockCRC, computedCombinedCRC;\n\n    // Variables used by setup* methods exclusively\n\n    private int su_count;\n    private int su_ch2;\n    private int su_chPrev;\n    private int su_i2;\n    private int su_j2;\n    private int su_rNToGo;\n    private int su_rTPos;\n    private int su_tPos;\n    private char su_z;\n\n    /**\n     * All memory intensive stuff. This field is initialized by initBlock().\n     */\n    private BZip2CompressorInputStream.Data data;\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream. This doesn't suppprt decompressing\n     * concatenated .bz2 files.\n     * \n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if {@code in == null}\n     */\n    public BZip2CompressorInputStream(final InputStream in) throws IOException {\n        this(in, false);\n    }\n\n    /**\n     * Constructs a new BZip2CompressorInputStream which decompresses bytes\n     * read from the specified stream.\n     *\n     * @param in the InputStream from which this object should be created\n     * @param decompressConcatenated\n     *                     if true, decompress until the end of the input;\n     *                     if false, stop after the first .bz2 stream and\n     *                     leave the input position to point to the next\n     *                     byte after the .bz2 stream\n     *\n     * @throws IOException\n     *             if the stream content is malformed or an I/O error occurs.\n     * @throws NullPointerException\n     *             if {@code in == null}\n     */\n    public BZip2CompressorInputStream(final InputStream in, final boolean decompressConcatenated) throws IOException {\n        this.in = in;\n        this.decompressConcatenated = decompressConcatenated;\n\n        init(true);\n        initBlock();\n    }\n\n    @Override\n    public int read() throws IOException {\n        if (this.in != null) {\n            int r = read0();\n            count(r < 0 ? -1 : 1);\n            return r;\n        } else {\n            throw new IOException(\"stream closed\");\n        }\n    }\n\n    /*\n     * (non-Javadoc)\n     * \n     * @see java.io.InputStream#read(byte[], int, int)\n     */\n    @Override\n    public int read(final byte[] dest, final int offs, final int len)\n        throws IOException {\n        if (offs < 0) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") < 0.\");\n        }\n        if (len < 0) {\n            throw new IndexOutOfBoundsException(\"len(\" + len + \") < 0.\");\n        }\n        if (offs + len > dest.length) {\n            throw new IndexOutOfBoundsException(\"offs(\" + offs + \") + len(\"\n                                                + len + \") > dest.length(\" + dest.length + \").\");\n        }\n        if (this.in == null) {\n            throw new IOException(\"stream closed\");\n        }\n        if (len == 0) {\n            return 0;\n        }\n\n        final int hi = offs + len;\n        int destOffs = offs;\n        int b;\n        while (destOffs < hi && ((b = read0()) >= 0)) {\n            dest[destOffs++] = (byte) b;\n            count(1);\n        }\n\n        int c = (destOffs == offs) ? -1 : (destOffs - offs);\n        return c;\n    }\n\n    private void makeMaps() {\n        final boolean[] inUse = this.data.inUse;\n        final byte[] seqToUnseq = this.data.seqToUnseq;\n\n        int nInUseShadow = 0;\n\n        for (int i = 0; i < 256; i++) {\n            if (inUse[i]) {\n                seqToUnseq[nInUseShadow++] = (byte) i;\n            }\n        }\n\n        this.nInUse = nInUseShadow;\n    }\n\n    private int read0() throws IOException {\n        switch (currentState) {\n        case EOF:\n            return -1;\n\n        case START_BLOCK_STATE:\n            return setupBlock();\n\n        case RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case RAND_PART_B_STATE:\n            return setupRandPartB();\n\n        case RAND_PART_C_STATE:\n            return setupRandPartC();\n\n        case NO_RAND_PART_A_STATE:\n            throw new IllegalStateException();\n\n        case NO_RAND_PART_B_STATE:\n            return setupNoRandPartB();\n\n        case NO_RAND_PART_C_STATE:\n            return setupNoRandPartC();\n\n        default:\n            throw new IllegalStateException();\n        }\n    }\n\n    private boolean init(boolean isFirstStream) throws IOException {\n        if (null == in) {\n            throw new IOException(\"No InputStream\");\n        }\n\n        int magic0 = this.in.read();\n        if (magic0 == -1 && !isFirstStream) {\n            return false;\n        }\n        int magic1 = this.in.read();\n        int magic2 = this.in.read();\n\n        if (magic0 != 'B' || magic1 != 'Z' || magic2 != 'h') {\n            throw new IOException(isFirstStream\n                    ? \"Stream is not in the BZip2 format\"\n                    : \"Garbage after a valid BZip2 stream\");\n        }\n\n        int blockSize = this.in.read();\n        if ((blockSize < '1') || (blockSize > '9')) {\n            throw new IOException(\"BZip2 block size is invalid\");\n        }\n\n        this.blockSize100k = blockSize - '0';\n\n        this.bsLive = 0;\n        this.computedCombinedCRC = 0;\n\n        return true;\n    }\n\n    private void initBlock() throws IOException {\n        char magic0;\n        char magic1;\n        char magic2;\n        char magic3;\n        char magic4;\n        char magic5;\n\n        while (true) {\n            // Get the block magic bytes.\n            magic0 = bsGetUByte();\n            magic1 = bsGetUByte();\n            magic2 = bsGetUByte();\n            magic3 = bsGetUByte();\n            magic4 = bsGetUByte();\n            magic5 = bsGetUByte();\n\n            // If isn't end of stream magic, break out of the loop.\n            if (magic0 != 0x17 || magic1 != 0x72 || magic2 != 0x45\n                    || magic3 != 0x38 || magic4 != 0x50 || magic5 != 0x90) {\n                break;\n            }\n\n            // End of stream was reached. Check the combined CRC and\n            // advance to the next .bz2 stream if decoding concatenated\n            // streams.\n            if (complete()) {\n                return;\n            }\n        }\n\n        if (magic0 != 0x31 || // '1'\n            magic1 != 0x41 || // ')'\n            magic2 != 0x59 || // 'Y'\n            magic3 != 0x26 || // '&'\n            magic4 != 0x53 || // 'S'\n            magic5 != 0x59 // 'Y'\n            ) {\n            this.currentState = EOF;\n            throw new IOException(\"bad block header\");\n        } else {\n            this.storedBlockCRC = bsGetInt();\n            this.blockRandomised = bsR(1) == 1;\n\n            /**\n             * Allocate data here instead in constructor, so we do not allocate\n             * it if the input file is empty.\n             */\n            if (this.data == null) {\n                this.data = new Data(this.blockSize100k);\n            }\n\n            // currBlockNo++;\n            getAndMoveToFrontDecode();\n\n            this.crc.initialiseCRC();\n            this.currentState = START_BLOCK_STATE;\n        }\n    }\n\n    private void endBlock() throws IOException {\n        this.computedBlockCRC = this.crc.getFinalCRC();\n\n        // A bad CRC is considered a fatal error.\n        if (this.storedBlockCRC != this.computedBlockCRC) {\n            // make next blocks readable without error\n            // (repair feature, not yet documented, not tested)\n            this.computedCombinedCRC = (this.storedCombinedCRC << 1)\n                | (this.storedCombinedCRC >>> 31);\n            this.computedCombinedCRC ^= this.storedBlockCRC;\n\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        this.computedCombinedCRC = (this.computedCombinedCRC << 1)\n            | (this.computedCombinedCRC >>> 31);\n        this.computedCombinedCRC ^= this.computedBlockCRC;\n    }\n\n    private boolean complete() throws IOException {\n        this.storedCombinedCRC = bsGetInt();\n        this.currentState = EOF;\n        this.data = null;\n\n        if (this.storedCombinedCRC != this.computedCombinedCRC) {\n            throw new IOException(\"BZip2 CRC error\");\n        }\n\n        // Look for the next .bz2 stream if decompressing\n        // concatenated files.\n        return !decompressConcatenated || !init(false);\n    }\n\n    @Override\n    public void close() throws IOException {\n        InputStream inShadow = this.in;\n        if (inShadow != null) {\n            try {\n                if (inShadow != System.in) {\n                    inShadow.close();\n                }\n            } finally {\n                this.data = null;\n                this.in = null;\n            }\n        }\n    }\n\n    private int bsR(final int n) throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < n) {\n            final InputStream inShadow = this.in;\n            do {\n                int thech = inShadow.read();\n\n                if (thech < 0) {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n\n                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                bsLiveShadow += 8;\n            } while (bsLiveShadow < n);\n\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - n;\n        return (bsBuffShadow >> (bsLiveShadow - n)) & ((1 << n) - 1);\n    }\n\n    private boolean bsGetBit() throws IOException {\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        if (bsLiveShadow < 1) {\n            int thech = this.in.read();\n\n            if (thech < 0) {\n                throw new IOException(\"unexpected end of stream\");\n            }\n\n            bsBuffShadow = (bsBuffShadow << 8) | thech;\n            bsLiveShadow += 8;\n            this.bsBuff = bsBuffShadow;\n        }\n\n        this.bsLive = bsLiveShadow - 1;\n        return ((bsBuffShadow >> (bsLiveShadow - 1)) & 1) != 0;\n    }\n\n    private char bsGetUByte() throws IOException {\n        return (char) bsR(8);\n    }\n\n    private int bsGetInt() throws IOException {\n        return (((((bsR(8) << 8) | bsR(8)) << 8) | bsR(8)) << 8) | bsR(8);\n    }\n\n    /**\n     * Called by createHuffmanDecodingTables() exclusively.\n     */\n    private static void hbCreateDecodeTables(final int[] limit,\n                                             final int[] base, final int[] perm, final char[] length,\n                                             final int minLen, final int maxLen, final int alphaSize) {\n        for (int i = minLen, pp = 0; i <= maxLen; i++) {\n            for (int j = 0; j < alphaSize; j++) {\n                if (length[j] == i) {\n                    perm[pp++] = j;\n                }\n            }\n        }\n\n        for (int i = MAX_CODE_LEN; --i > 0;) {\n            base[i] = 0;\n            limit[i] = 0;\n        }\n\n        for (int i = 0; i < alphaSize; i++) {\n            base[length[i] + 1]++;\n        }\n\n        for (int i = 1, b = base[0]; i < MAX_CODE_LEN; i++) {\n            b += base[i];\n            base[i] = b;\n        }\n\n        for (int i = minLen, vec = 0, b = base[i]; i <= maxLen; i++) {\n            final int nb = base[i + 1];\n            vec += nb - b;\n            b = nb;\n            limit[i] = vec - 1;\n            vec <<= 1;\n        }\n\n        for (int i = minLen + 1; i <= maxLen; i++) {\n            base[i] = ((limit[i - 1] + 1) << 1) - base[i];\n        }\n    }\n\n    private void recvDecodingTables() throws IOException {\n        final Data dataShadow = this.data;\n        final boolean[] inUse = dataShadow.inUse;\n        final byte[] pos = dataShadow.recvDecodingTables_pos;\n        final byte[] selector = dataShadow.selector;\n        final byte[] selectorMtf = dataShadow.selectorMtf;\n\n        int inUse16 = 0;\n\n        /* Receive the mapping table */\n        for (int i = 0; i < 16; i++) {\n            if (bsGetBit()) {\n                inUse16 |= 1 << i;\n            }\n        }\n\n        for (int i = 256; --i >= 0;) {\n            inUse[i] = false;\n        }\n\n        for (int i = 0; i < 16; i++) {\n            if ((inUse16 & (1 << i)) != 0) {\n                final int i16 = i << 4;\n                for (int j = 0; j < 16; j++) {\n                    if (bsGetBit()) {\n                        inUse[i16 + j] = true;\n                    }\n                }\n            }\n        }\n\n        makeMaps();\n        final int alphaSize = this.nInUse + 2;\n\n        /* Now the selectors */\n        final int nGroups = bsR(3);\n        final int nSelectors = bsR(15);\n\n        for (int i = 0; i < nSelectors; i++) {\n            int j = 0;\n            while (bsGetBit()) {\n                j++;\n            }\n            selectorMtf[i] = (byte) j;\n        }\n\n        /* Undo the MTF values for the selectors. */\n        for (int v = nGroups; --v >= 0;) {\n            pos[v] = (byte) v;\n        }\n\n        for (int i = 0; i < nSelectors; i++) {\n            int v = selectorMtf[i] & 0xff;\n            final byte tmp = pos[v];\n            while (v > 0) {\n                // nearly all times v is zero, 4 in most other cases\n                pos[v] = pos[v - 1];\n                v--;\n            }\n            pos[0] = tmp;\n            selector[i] = tmp;\n        }\n\n        final char[][] len = dataShadow.temp_charArray2d;\n\n        /* Now the coding tables */\n        for (int t = 0; t < nGroups; t++) {\n            int curr = bsR(5);\n            final char[] len_t = len[t];\n            for (int i = 0; i < alphaSize; i++) {\n                while (bsGetBit()) {\n                    curr += bsGetBit() ? -1 : 1;\n                }\n                len_t[i] = (char) curr;\n            }\n        }\n\n        // finally create the Huffman tables\n        createHuffmanDecodingTables(alphaSize, nGroups);\n    }\n\n    /**\n     * Called by recvDecodingTables() exclusively.\n     */\n    private void createHuffmanDecodingTables(final int alphaSize,\n                                             final int nGroups) {\n        final Data dataShadow = this.data;\n        final char[][] len = dataShadow.temp_charArray2d;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n\n        for (int t = 0; t < nGroups; t++) {\n            int minLen = 32;\n            int maxLen = 0;\n            final char[] len_t = len[t];\n            for (int i = alphaSize; --i >= 0;) {\n                final char lent = len_t[i];\n                if (lent > maxLen) {\n                    maxLen = lent;\n                }\n                if (lent < minLen) {\n                    minLen = lent;\n                }\n            }\n            hbCreateDecodeTables(limit[t], base[t], perm[t], len[t], minLen,\n                                 maxLen, alphaSize);\n            minLens[t] = minLen;\n        }\n    }\n\n    private void getAndMoveToFrontDecode() throws IOException {\n        this.origPtr = bsR(24);\n        recvDecodingTables();\n\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final byte[] ll8 = dataShadow.ll8;\n        final int[] unzftab = dataShadow.unzftab;\n        final byte[] selector = dataShadow.selector;\n        final byte[] seqToUnseq = dataShadow.seqToUnseq;\n        final char[] yy = dataShadow.getAndMoveToFrontDecode_yy;\n        final int[] minLens = dataShadow.minLens;\n        final int[][] limit = dataShadow.limit;\n        final int[][] base = dataShadow.base;\n        final int[][] perm = dataShadow.perm;\n        final int limitLast = this.blockSize100k * 100000;\n\n        /*\n         * Setting up the unzftab entries here is not strictly necessary, but it\n         * does save having to do it later in a separate pass, and so saves a\n         * block's worth of cache misses.\n         */\n        for (int i = 256; --i >= 0;) {\n            yy[i] = (char) i;\n            unzftab[i] = 0;\n        }\n\n        int groupNo = 0;\n        int groupPos = G_SIZE - 1;\n        final int eob = this.nInUse + 1;\n        int nextSym = getAndMoveToFrontDecode0(0);\n        int bsBuffShadow = this.bsBuff;\n        int bsLiveShadow = this.bsLive;\n        int lastShadow = -1;\n        int zt = selector[groupNo] & 0xff;\n        int[] base_zt = base[zt];\n        int[] limit_zt = limit[zt];\n        int[] perm_zt = perm[zt];\n        int minLens_zt = minLens[zt];\n\n        while (nextSym != eob) {\n            if ((nextSym == RUNA) || (nextSym == RUNB)) {\n                int s = -1;\n\n                for (int n = 1; true; n <<= 1) {\n                    if (nextSym == RUNA) {\n                        s += n;\n                    } else if (nextSym == RUNB) {\n                        s += n << 1;\n                    } else {\n                        break;\n                    }\n\n                    if (groupPos == 0) {\n                        groupPos = G_SIZE - 1;\n                        zt = selector[++groupNo] & 0xff;\n                        base_zt = base[zt];\n                        limit_zt = limit[zt];\n                        perm_zt = perm[zt];\n                        minLens_zt = minLens[zt];\n                    } else {\n                        groupPos--;\n                    }\n\n                    int zn = minLens_zt;\n\n                    // Inlined:\n                    // int zvec = bsR(zn);\n                    while (bsLiveShadow < zn) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                        & ((1 << zn) - 1);\n                    bsLiveShadow -= zn;\n\n                    while (zvec > limit_zt[zn]) {\n                        zn++;\n                        while (bsLiveShadow < 1) {\n                            final int thech = inShadow.read();\n                            if (thech >= 0) {\n                                bsBuffShadow = (bsBuffShadow << 8) | thech;\n                                bsLiveShadow += 8;\n                                continue;\n                            } else {\n                                throw new IOException(\n                                                      \"unexpected end of stream\");\n                            }\n                        }\n                        bsLiveShadow--;\n                        zvec = (zvec << 1)\n                            | ((bsBuffShadow >> bsLiveShadow) & 1);\n                    }\n                    nextSym = perm_zt[zvec - base_zt[zn]];\n                }\n\n                final byte ch = seqToUnseq[yy[0]];\n                unzftab[ch & 0xff] += s + 1;\n\n                while (s-- >= 0) {\n                    ll8[++lastShadow] = ch;\n                }\n\n                if (lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n            } else {\n                if (++lastShadow >= limitLast) {\n                    throw new IOException(\"block overrun\");\n                }\n\n                final char tmp = yy[nextSym - 1];\n                unzftab[seqToUnseq[tmp] & 0xff]++;\n                ll8[lastShadow] = seqToUnseq[tmp];\n\n                /*\n                 * This loop is hammered during decompression, hence avoid\n                 * native method call overhead of System.arraycopy for very\n                 * small ranges to copy.\n                 */\n                if (nextSym <= 16) {\n                    for (int j = nextSym - 1; j > 0;) {\n                        yy[j] = yy[--j];\n                    }\n                } else {\n                    System.arraycopy(yy, 0, yy, 1, nextSym - 1);\n                }\n\n                yy[0] = tmp;\n\n                if (groupPos == 0) {\n                    groupPos = G_SIZE - 1;\n                    zt = selector[++groupNo] & 0xff;\n                    base_zt = base[zt];\n                    limit_zt = limit[zt];\n                    perm_zt = perm[zt];\n                    minLens_zt = minLens[zt];\n                } else {\n                    groupPos--;\n                }\n\n                int zn = minLens_zt;\n\n                // Inlined:\n                // int zvec = bsR(zn);\n                while (bsLiveShadow < zn) {\n                    final int thech = inShadow.read();\n                    if (thech >= 0) {\n                        bsBuffShadow = (bsBuffShadow << 8) | thech;\n                        bsLiveShadow += 8;\n                        continue;\n                    } else {\n                        throw new IOException(\"unexpected end of stream\");\n                    }\n                }\n                int zvec = (bsBuffShadow >> (bsLiveShadow - zn))\n                    & ((1 << zn) - 1);\n                bsLiveShadow -= zn;\n\n                while (zvec > limit_zt[zn]) {\n                    zn++;\n                    while (bsLiveShadow < 1) {\n                        final int thech = inShadow.read();\n                        if (thech >= 0) {\n                            bsBuffShadow = (bsBuffShadow << 8) | thech;\n                            bsLiveShadow += 8;\n                            continue;\n                        } else {\n                            throw new IOException(\"unexpected end of stream\");\n                        }\n                    }\n                    bsLiveShadow--;\n                    zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n                }\n                nextSym = perm_zt[zvec - base_zt[zn]];\n            }\n        }\n\n        this.last = lastShadow;\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n    }\n\n    private int getAndMoveToFrontDecode0(final int groupNo) throws IOException {\n        final InputStream inShadow = this.in;\n        final Data dataShadow = this.data;\n        final int zt = dataShadow.selector[groupNo] & 0xff;\n        final int[] limit_zt = dataShadow.limit[zt];\n        int zn = dataShadow.minLens[zt];\n        int zvec = bsR(zn);\n        int bsLiveShadow = this.bsLive;\n        int bsBuffShadow = this.bsBuff;\n\n        while (zvec > limit_zt[zn]) {\n            zn++;\n            while (bsLiveShadow < 1) {\n                final int thech = inShadow.read();\n\n                if (thech >= 0) {\n                    bsBuffShadow = (bsBuffShadow << 8) | thech;\n                    bsLiveShadow += 8;\n                    continue;\n                } else {\n                    throw new IOException(\"unexpected end of stream\");\n                }\n            }\n            bsLiveShadow--;\n            zvec = (zvec << 1) | ((bsBuffShadow >> bsLiveShadow) & 1);\n        }\n\n        this.bsLive = bsLiveShadow;\n        this.bsBuff = bsBuffShadow;\n\n        return dataShadow.perm[zt][zvec - dataShadow.base[zt][zn]];\n    }\n\n    private int setupBlock() throws IOException {\n        if (currentState == EOF || this.data == null) {\n            return -1;\n        }\n\n        final int[] cftab = this.data.cftab;\n        final int[] tt = this.data.initTT(this.last + 1);\n        final byte[] ll8 = this.data.ll8;\n        cftab[0] = 0;\n        System.arraycopy(this.data.unzftab, 0, cftab, 1, 256);\n\n        for (int i = 1, c = cftab[0]; i <= 256; i++) {\n            c += cftab[i];\n            cftab[i] = c;\n        }\n\n        for (int i = 0, lastShadow = this.last; i <= lastShadow; i++) {\n            tt[cftab[ll8[i] & 0xff]++] = i;\n        }\n\n        if ((this.origPtr < 0) || (this.origPtr >= tt.length)) {\n            throw new IOException(\"stream corrupted\");\n        }\n\n        this.su_tPos = tt[this.origPtr];\n        this.su_count = 0;\n        this.su_i2 = 0;\n        this.su_ch2 = 256; /* not a char and not EOF */\n\n        if (this.blockRandomised) {\n            this.su_rNToGo = 0;\n            this.su_rTPos = 0;\n            return setupRandPartA();\n        }\n        return setupNoRandPartA();\n    }\n\n    private int setupRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_ch2 = su_ch2Shadow ^= (this.su_rNToGo == 1) ? 1 : 0;\n            this.su_i2++;\n            this.currentState = RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupNoRandPartA() throws IOException {\n        if (this.su_i2 <= this.last) {\n            this.su_chPrev = this.su_ch2;\n            int su_ch2Shadow = this.data.ll8[this.su_tPos] & 0xff;\n            this.su_ch2 = su_ch2Shadow;\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_i2++;\n            this.currentState = NO_RAND_PART_B_STATE;\n            this.crc.updateCRC(su_ch2Shadow);\n            return su_ch2Shadow;\n        } else {\n            this.currentState = NO_RAND_PART_A_STATE;\n            endBlock();\n            initBlock();\n            return setupBlock();\n        }\n    }\n\n    private int setupRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_count = 1;\n            return setupRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            if (this.su_rNToGo == 0) {\n                this.su_rNToGo = Rand.rNums(this.su_rTPos) - 1;\n                if (++this.su_rTPos == 512) {\n                    this.su_rTPos = 0;\n                }\n            } else {\n                this.su_rNToGo--;\n            }\n            this.su_j2 = 0;\n            this.currentState = RAND_PART_C_STATE;\n            if (this.su_rNToGo == 1) {\n                this.su_z ^= 1;\n            }\n            return setupRandPartC();\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            this.crc.updateCRC(this.su_ch2);\n            this.su_j2++;\n            return this.su_ch2;\n        } else {\n            this.currentState = RAND_PART_A_STATE;\n            this.su_i2++;\n            this.su_count = 0;\n            return setupRandPartA();\n        }\n    }\n\n    private int setupNoRandPartB() throws IOException {\n        if (this.su_ch2 != this.su_chPrev) {\n            this.su_count = 1;\n            return setupNoRandPartA();\n        } else if (++this.su_count >= 4) {\n            this.su_z = (char) (this.data.ll8[this.su_tPos] & 0xff);\n            this.su_tPos = this.data.tt[this.su_tPos];\n            this.su_j2 = 0;\n            return setupNoRandPartC();\n        } else {\n            return setupNoRandPartA();\n        }\n    }\n\n    private int setupNoRandPartC() throws IOException {\n        if (this.su_j2 < this.su_z) {\n            int su_ch2Shadow = this.su_ch2;\n            this.crc.updateCRC(su_ch2Shadow);\n            this.su_j2++;\n            this.currentState = NO_RAND_PART_C_STATE;\n            return su_ch2Shadow;\n        } else {\n            this.su_i2++;\n            this.su_count = 0;\n            return setupNoRandPartA();\n        }\n    }\n\n    private static final class Data {\n\n        // (with blockSize 900k)\n        final boolean[] inUse = new boolean[256]; // 256 byte\n\n        final byte[] seqToUnseq = new byte[256]; // 256 byte\n        final byte[] selector = new byte[MAX_SELECTORS]; // 18002 byte\n        final byte[] selectorMtf = new byte[MAX_SELECTORS]; // 18002 byte\n\n        /**\n         * Freq table collected to save a pass over the data during\n         * decompression.\n         */\n        final int[] unzftab = new int[256]; // 1024 byte\n\n        final int[][] limit = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] base = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[][] perm = new int[N_GROUPS][MAX_ALPHA_SIZE]; // 6192 byte\n        final int[] minLens = new int[N_GROUPS]; // 24 byte\n\n        final int[] cftab = new int[257]; // 1028 byte\n        final char[] getAndMoveToFrontDecode_yy = new char[256]; // 512 byte\n        final char[][] temp_charArray2d = new char[N_GROUPS][MAX_ALPHA_SIZE]; // 3096\n        // byte\n        final byte[] recvDecodingTables_pos = new byte[N_GROUPS]; // 6 byte\n        // ---------------\n        // 60798 byte\n\n        int[] tt; // 3600000 byte\n        byte[] ll8; // 900000 byte\n\n        // ---------------\n        // 4560782 byte\n        // ===============\n\n        Data(int blockSize100k) {\n            this.ll8 = new byte[blockSize100k * BZip2Constants.BASEBLOCKSIZE];\n        }\n\n        /**\n         * Initializes the {@link #tt} array.\n         * \n         * This method is called when the required length of the array is known.\n         * I don't initialize it at construction time to avoid unneccessary\n         * memory allocation when compressing small files.\n         */\n        int[] initTT(int length) {\n            int[] ttShadow = this.tt;\n\n            // tt.length should always be >= length, but theoretically\n            // it can happen, if the compressor mixed small and large\n            // blocks. Normally only the last block will be smaller\n            // than others.\n            if ((ttShadow == null) || (ttShadow.length < length)) {\n                this.tt = ttShadow = new int[length];\n            }\n\n            return ttShadow;\n        }\n\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a bzip2 file.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a bzip2 compressed stream, false otherwise\n     * \n     * @since 1.1\n     */\n    public static boolean matches(byte[] signature, int length) {\n\n        if (length < 3) {\n            return false;\n        }\n\n        if (signature[0] != 'B') {\n            return false;\n        }\n\n        if (signature[1] != 'Z') {\n            return false;\n        }\n\n        if (signature[2] != 'h') {\n            return false;\n        }\n\n        return true;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 31, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            if (currentByte == 0) {\n                break;\n            }\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * In addition there are\n     * <a href=\"https://issues.apache.org/jira/browse/COMPRESS-117\">some tar files</a>\n     * that seem to have parts of their header cleared to zero (no detectable\n     * magic bytes, etc.) but still have a reasonable-looking checksum field\n     * present. It looks like we can detect such cases reasonably well by\n     * checking whether the stored checksum is <em>greater than</em> the\n     * computed unsigned checksum. That check is unlikely to pass on some\n     * random file header, as it would need to have a valid sequence of\n     * octal digits in just the right place.\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6; // only look at the first octal digit sequence\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n\n        return storedSum == unsignedSum || storedSum == signedSum\n                || storedSum > unsignedSum; // COMPRESS-177\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 32, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            byte[] rest = new byte[restLen];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != restLen) {\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + restLen\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      restLen - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize,\n                                 String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(InputStream is, int blockSize, int recordSize,\n                                 String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (IllegalArgumentException e) {\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        }\n\n        if (currEntry.isGNUSparse()){ // Process sparse files\n            readGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        byte[] record = new byte[recordSize];\n\n        int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void paxHeaders() throws IOException{\n        Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    Map<String, String> parsePaxHeaders(InputStream i) throws IOException {\n        Map<String, String> headers = new HashMap<String, String>();\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){ // End of length string\n                    // Get keyword\n                    ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            byte[] rest = new byte[restLen];\n                            int got = IOUtils.readFully(i, rest);\n                            if (got != restLen) {\n                                throw new IOException(\"Failed to read \"\n                                                      + \"Paxheader. Expected \"\n                                                      + restLen\n                                                      + \" bytes, read \"\n                                                      + got);\n                            }\n                            // Drop trailing NL\n                            String value = new String(rest, 0,\n                                                      restLen - 1, CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         */\n        for (Entry<String, String> ent : headers.entrySet()){\n            String key = ent.getKey();\n            String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Long.parseLong(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Long.parseLong(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(byte[] buf, int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 33, "classes_modified": [{"class_name": "org.apache.commons.compress.compressors.CompressorStreamFactory", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.compressors;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\nimport org.apache.commons.compress.compressors.deflate.DeflateCompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate.DeflateCompressorOutputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;\nimport org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\nimport org.apache.commons.compress.compressors.lzma.LZMAUtils;\nimport org.apache.commons.compress.compressors.xz.XZCompressorInputStream;\nimport org.apache.commons.compress.compressors.xz.XZCompressorOutputStream;\nimport org.apache.commons.compress.compressors.xz.XZUtils;\nimport org.apache.commons.compress.compressors.pack200.Pack200CompressorInputStream;\nimport org.apache.commons.compress.compressors.pack200.Pack200CompressorOutputStream;\nimport org.apache.commons.compress.compressors.snappy.FramedSnappyCompressorInputStream;\nimport org.apache.commons.compress.compressors.snappy.SnappyCompressorInputStream;\nimport org.apache.commons.compress.compressors.z.ZCompressorInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * <p>Factory to create Compressor[In|Out]putStreams from names. To add other\n * implementations you should extend CompressorStreamFactory and override the\n * appropriate methods (and call their implementation from super of course).</p>\n * \n * Example (Compressing a file):\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * CompressorOutputStream cos = \n *      new CompressorStreamFactory().createCompressorOutputStream(CompressorStreamFactory.BZIP2, out);\n * IOUtils.copy(new FileInputStream(input), cos);\n * cos.close();\n * </pre>\n * \n * Example (Decompressing a file):\n * <pre>\n * final InputStream is = new FileInputStream(input); \n * CompressorInputStream in = \n *      new CompressorStreamFactory().createCompressorInputStream(CompressorStreamFactory.BZIP2, is);\n * IOUtils.copy(in, new FileOutputStream(output));\n * in.close();\n * </pre>\n * @Immutable provided that the deprecated method setDecompressConcatenated is not used.\n * @ThreadSafe even if the deprecated method setDecompressConcatenated is used\n */\npublic class CompressorStreamFactory {\n\n    /**\n     * Constant (value {@value}) used to identify the BZIP2 compression algorithm.\n     * @since 1.1\n     */\n    public static final String BZIP2 = \"bzip2\";\n\n    /**\n     * Constant (value {@value}) used to identify the GZIP compression algorithm.\n     * Not supported as an output stream type.\n     * @since 1.1\n     */\n    public static final String GZIP = \"gz\";\n    /**\n     * Constant (value {@value}) used to identify the PACK200 compression algorithm.\n     * @since 1.3\n     */\n    public static final String PACK200 = \"pack200\";\n\n    /**\n     * Constant (value {@value}) used to identify the XZ compression method.\n     * @since 1.4\n     */\n    public static final String XZ = \"xz\";\n\n    /**\n     * Constant (value {@value}) used to identify the LZMA compression method.\n     * Not supported as an output stream type.\n     * @since 1.6\n     */\n    public static final String LZMA = \"lzma\";\n\n    /**\n     * Constant (value {@value}) used to identify the \"framed\" Snappy compression method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String SNAPPY_FRAMED = \"snappy-framed\";\n\n    /**\n     * Constant (value {@value}) used to identify the \"raw\" Snappy compression method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String SNAPPY_RAW = \"snappy-raw\";\n\n    /**\n     * Constant (value {@value}) used to identify the traditional Unix compress method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String Z = \"z\";\n\n    /**\n     * Constant (value {@value}) used to identify the Deflate compress method.\n     * @since 1.9\n     */\n    public static final String DEFLATE = \"deflate\";\n\n    /**\n     * If true, decompress until the end of the input.\n     * If false, stop after the first stream and leave the \n     * input position to point to the next byte after the stream\n     */\n    private final Boolean decompressUntilEOF;\n    // This is Boolean so setDecompressConcatenated can determine whether it has been set by the ctor\n    // once the setDecompressConcatenated method has been removed, it can revert to boolean\n\n    /**\n     * If true, decompress until the end of the input.\n     * If false, stop after the first stream and leave the \n     * input position to point to the next byte after the stream\n     */\n\n    private volatile boolean decompressConcatenated = false;\n\n    /**\n     * Create an instance with the decompress Concatenated option set to false.\n     */\n    public CompressorStreamFactory() {\n        this.decompressUntilEOF = null;  \n    }\n\n    /**\n     * Create an instance with the provided decompress Concatenated option.\n     * @param       decompressUntilEOF\n     *                          if true, decompress until the end of the\n     *                          input; if false, stop after the first\n     *                          stream and leave the input position to point\n     *                          to the next byte after the stream.\n     *           This setting applies to the gzip, bzip2 and xz formats only.\n     * @since 1.10\n     */\n    public CompressorStreamFactory(boolean decompressUntilEOF) {\n        this.decompressUntilEOF = Boolean.valueOf(decompressUntilEOF);\n        // Also copy to existing variable so can continue to use that as the current value\n        this.decompressConcatenated = decompressUntilEOF;\n    }\n\n    /**\n     * Whether to decompress the full input or only the first stream\n     * in formats supporting multiple concatenated input streams.\n     *\n     * <p>This setting applies to the gzip, bzip2 and xz formats only.</p>\n     *\n     * @param       decompressConcatenated\n     *                          if true, decompress until the end of the\n     *                          input; if false, stop after the first\n     *                          stream and leave the input position to point\n     *                          to the next byte after the stream\n     * @since 1.5\n     * @deprecated 1.10 use the {@link #CompressorStreamFactory(boolean)} constructor instead\n     * @throws IllegalStateException if the constructor {@link #CompressorStreamFactory(boolean)} \n     * was used to create the factory\n     */\n    @Deprecated\n    public void setDecompressConcatenated(boolean decompressConcatenated) {\n        if (this.decompressUntilEOF != null) {\n            throw new IllegalStateException(\"Cannot override the setting defined by the constructor\");\n        }\n        this.decompressConcatenated = decompressConcatenated;\n    }\n\n    /**\n     * Create an compressor input stream from an input stream, autodetecting\n     * the compressor type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the compressor input stream\n     * @throws CompressorException if the compressor name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     * @since 1.1\n     */\n    public CompressorInputStream createCompressorInputStream(final InputStream in)\n            throws CompressorException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = IOUtils.readFully(in, signature);\n            in.reset();\n\n            if (BZip2CompressorInputStream.matches(signature, signatureLength)) {\n                return new BZip2CompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (GzipCompressorInputStream.matches(signature, signatureLength)) {\n                return new GzipCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (Pack200CompressorInputStream.matches(signature, signatureLength)) {\n                return new Pack200CompressorInputStream(in);\n            }\n\n            if (FramedSnappyCompressorInputStream.matches(signature, signatureLength)) {\n                return new FramedSnappyCompressorInputStream(in);\n            }\n\n            if (ZCompressorInputStream.matches(signature, signatureLength)) {\n                return new ZCompressorInputStream(in);\n            }\n\n\n            if (XZUtils.matches(signature, signatureLength) &&\n                XZUtils.isXZCompressionAvailable()) {\n                return new XZCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (LZMAUtils.matches(signature, signatureLength) &&\n                LZMAUtils.isLZMACompressionAvailable()) {\n                return new LZMACompressorInputStream(in);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\"Failed to detect Compressor from InputStream.\", e);\n        }\n\n        throw new CompressorException(\"No Compressor found for the stream signature.\");\n    }\n\n    /**\n     * Create a compressor input stream from a compressor name and an input stream.\n     * \n     * @param name of the compressor,\n     * i.e. {@value #GZIP}, {@value #BZIP2}, {@value #XZ}, {@value #LZMA},\n     * {@value #PACK200}, {@value #SNAPPY_RAW}, {@value #SNAPPY_FRAMED}, \n     * {@value #Z} or {@value #DEFLATE} \n     * @param in the input stream\n     * @return compressor input stream\n     * @throws CompressorException if the compressor name is not known\n     * @throws IllegalArgumentException if the name or input stream is null\n     */\n    public CompressorInputStream createCompressorInputStream(final String name,\n            final InputStream in) throws CompressorException {\n        if (name == null || in == null) {\n            throw new IllegalArgumentException(\n                    \"Compressor name and stream must not be null.\");\n        }\n\n        try {\n\n            if (GZIP.equalsIgnoreCase(name)) {\n                return new GzipCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (BZIP2.equalsIgnoreCase(name)) {\n                return new BZip2CompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (XZ.equalsIgnoreCase(name)) {\n                return new XZCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (LZMA.equalsIgnoreCase(name)) {\n                return new LZMACompressorInputStream(in);\n            }\n\n            if (PACK200.equalsIgnoreCase(name)) {\n                return new Pack200CompressorInputStream(in);\n            }\n\n            if (SNAPPY_RAW.equalsIgnoreCase(name)) {\n                return new SnappyCompressorInputStream(in);\n            }\n\n            if (SNAPPY_FRAMED.equalsIgnoreCase(name)) {\n                return new FramedSnappyCompressorInputStream(in);\n            }\n\n            if (Z.equalsIgnoreCase(name)) {\n                return new ZCompressorInputStream(in);\n            }\n\n            if (DEFLATE.equalsIgnoreCase(name)) {\n                return new DeflateCompressorInputStream(in);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\n                    \"Could not create CompressorInputStream.\", e);\n        }\n        throw new CompressorException(\"Compressor: \" + name + \" not found.\");\n    }\n\n    /**\n     * Create an compressor output stream from an compressor name and an output stream.\n     * \n     * @param name the compressor name,\n     * i.e. {@value #GZIP}, {@value #BZIP2}, {@value #XZ},\n     * {@value #PACK200} or {@value #DEFLATE} \n     * @param out the output stream\n     * @return the compressor output stream\n     * @throws CompressorException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public CompressorOutputStream createCompressorOutputStream(\n            final String name, final OutputStream out)\n            throws CompressorException {\n        if (name == null || out == null) {\n            throw new IllegalArgumentException(\n                    \"Compressor name and stream must not be null.\");\n        }\n\n        try {\n\n            if (GZIP.equalsIgnoreCase(name)) {\n                return new GzipCompressorOutputStream(out);\n            }\n\n            if (BZIP2.equalsIgnoreCase(name)) {\n                return new BZip2CompressorOutputStream(out);\n            }\n\n            if (XZ.equalsIgnoreCase(name)) {\n                return new XZCompressorOutputStream(out);\n            }\n\n            if (PACK200.equalsIgnoreCase(name)) {\n                return new Pack200CompressorOutputStream(out);\n            }\n\n            if (DEFLATE.equalsIgnoreCase(name)) {\n                return new DeflateCompressorOutputStream(out);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\n                    \"Could not create CompressorOutputStream\", e);\n        }\n        throw new CompressorException(\"Compressor: \" + name + \" not found.\");\n    }\n\n    // For Unit tests\n    boolean getDecompressConcatenated() {\n        return decompressConcatenated;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.compressors;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream;\nimport org.apache.commons.compress.compressors.deflate.DeflateCompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate.DeflateCompressorOutputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream;\nimport org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream;\nimport org.apache.commons.compress.compressors.lzma.LZMAUtils;\nimport org.apache.commons.compress.compressors.xz.XZCompressorInputStream;\nimport org.apache.commons.compress.compressors.xz.XZCompressorOutputStream;\nimport org.apache.commons.compress.compressors.xz.XZUtils;\nimport org.apache.commons.compress.compressors.pack200.Pack200CompressorInputStream;\nimport org.apache.commons.compress.compressors.pack200.Pack200CompressorOutputStream;\nimport org.apache.commons.compress.compressors.snappy.FramedSnappyCompressorInputStream;\nimport org.apache.commons.compress.compressors.snappy.SnappyCompressorInputStream;\nimport org.apache.commons.compress.compressors.z.ZCompressorInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * <p>Factory to create Compressor[In|Out]putStreams from names. To add other\n * implementations you should extend CompressorStreamFactory and override the\n * appropriate methods (and call their implementation from super of course).</p>\n * \n * Example (Compressing a file):\n * \n * <pre>\n * final OutputStream out = new FileOutputStream(output); \n * CompressorOutputStream cos = \n *      new CompressorStreamFactory().createCompressorOutputStream(CompressorStreamFactory.BZIP2, out);\n * IOUtils.copy(new FileInputStream(input), cos);\n * cos.close();\n * </pre>\n * \n * Example (Decompressing a file):\n * <pre>\n * final InputStream is = new FileInputStream(input); \n * CompressorInputStream in = \n *      new CompressorStreamFactory().createCompressorInputStream(CompressorStreamFactory.BZIP2, is);\n * IOUtils.copy(in, new FileOutputStream(output));\n * in.close();\n * </pre>\n * @Immutable provided that the deprecated method setDecompressConcatenated is not used.\n * @ThreadSafe even if the deprecated method setDecompressConcatenated is used\n */\npublic class CompressorStreamFactory {\n\n    /**\n     * Constant (value {@value}) used to identify the BZIP2 compression algorithm.\n     * @since 1.1\n     */\n    public static final String BZIP2 = \"bzip2\";\n\n    /**\n     * Constant (value {@value}) used to identify the GZIP compression algorithm.\n     * Not supported as an output stream type.\n     * @since 1.1\n     */\n    public static final String GZIP = \"gz\";\n    /**\n     * Constant (value {@value}) used to identify the PACK200 compression algorithm.\n     * @since 1.3\n     */\n    public static final String PACK200 = \"pack200\";\n\n    /**\n     * Constant (value {@value}) used to identify the XZ compression method.\n     * @since 1.4\n     */\n    public static final String XZ = \"xz\";\n\n    /**\n     * Constant (value {@value}) used to identify the LZMA compression method.\n     * Not supported as an output stream type.\n     * @since 1.6\n     */\n    public static final String LZMA = \"lzma\";\n\n    /**\n     * Constant (value {@value}) used to identify the \"framed\" Snappy compression method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String SNAPPY_FRAMED = \"snappy-framed\";\n\n    /**\n     * Constant (value {@value}) used to identify the \"raw\" Snappy compression method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String SNAPPY_RAW = \"snappy-raw\";\n\n    /**\n     * Constant (value {@value}) used to identify the traditional Unix compress method.\n     * Not supported as an output stream type.\n     * @since 1.7\n     */\n    public static final String Z = \"z\";\n\n    /**\n     * Constant (value {@value}) used to identify the Deflate compress method.\n     * @since 1.9\n     */\n    public static final String DEFLATE = \"deflate\";\n\n    /**\n     * If true, decompress until the end of the input.\n     * If false, stop after the first stream and leave the \n     * input position to point to the next byte after the stream\n     */\n    private final Boolean decompressUntilEOF;\n    // This is Boolean so setDecompressConcatenated can determine whether it has been set by the ctor\n    // once the setDecompressConcatenated method has been removed, it can revert to boolean\n\n    /**\n     * If true, decompress until the end of the input.\n     * If false, stop after the first stream and leave the \n     * input position to point to the next byte after the stream\n     */\n\n    private volatile boolean decompressConcatenated = false;\n\n    /**\n     * Create an instance with the decompress Concatenated option set to false.\n     */\n    public CompressorStreamFactory() {\n        this.decompressUntilEOF = null;  \n    }\n\n    /**\n     * Create an instance with the provided decompress Concatenated option.\n     * @param       decompressUntilEOF\n     *                          if true, decompress until the end of the\n     *                          input; if false, stop after the first\n     *                          stream and leave the input position to point\n     *                          to the next byte after the stream.\n     *           This setting applies to the gzip, bzip2 and xz formats only.\n     * @since 1.10\n     */\n    public CompressorStreamFactory(boolean decompressUntilEOF) {\n        this.decompressUntilEOF = Boolean.valueOf(decompressUntilEOF);\n        // Also copy to existing variable so can continue to use that as the current value\n        this.decompressConcatenated = decompressUntilEOF;\n    }\n\n    /**\n     * Whether to decompress the full input or only the first stream\n     * in formats supporting multiple concatenated input streams.\n     *\n     * <p>This setting applies to the gzip, bzip2 and xz formats only.</p>\n     *\n     * @param       decompressConcatenated\n     *                          if true, decompress until the end of the\n     *                          input; if false, stop after the first\n     *                          stream and leave the input position to point\n     *                          to the next byte after the stream\n     * @since 1.5\n     * @deprecated 1.10 use the {@link #CompressorStreamFactory(boolean)} constructor instead\n     * @throws IllegalStateException if the constructor {@link #CompressorStreamFactory(boolean)} \n     * was used to create the factory\n     */\n    @Deprecated\n    public void setDecompressConcatenated(boolean decompressConcatenated) {\n        if (this.decompressUntilEOF != null) {\n            throw new IllegalStateException(\"Cannot override the setting defined by the constructor\");\n        }\n        this.decompressConcatenated = decompressConcatenated;\n    }\n\n    /**\n     * Create an compressor input stream from an input stream, autodetecting\n     * the compressor type from the first few bytes of the stream. The InputStream\n     * must support marks, like BufferedInputStream.\n     * \n     * @param in the input stream\n     * @return the compressor input stream\n     * @throws CompressorException if the compressor name is not known\n     * @throws IllegalArgumentException if the stream is null or does not support mark\n     * @since 1.1\n     */\n    public CompressorInputStream createCompressorInputStream(final InputStream in)\n            throws CompressorException {\n        if (in == null) {\n            throw new IllegalArgumentException(\"Stream must not be null.\");\n        }\n\n        if (!in.markSupported()) {\n            throw new IllegalArgumentException(\"Mark is not supported.\");\n        }\n\n        final byte[] signature = new byte[12];\n        in.mark(signature.length);\n        try {\n            int signatureLength = IOUtils.readFully(in, signature);\n            in.reset();\n\n            if (BZip2CompressorInputStream.matches(signature, signatureLength)) {\n                return new BZip2CompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (GzipCompressorInputStream.matches(signature, signatureLength)) {\n                return new GzipCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (Pack200CompressorInputStream.matches(signature, signatureLength)) {\n                return new Pack200CompressorInputStream(in);\n            }\n\n            if (FramedSnappyCompressorInputStream.matches(signature, signatureLength)) {\n                return new FramedSnappyCompressorInputStream(in);\n            }\n\n            if (ZCompressorInputStream.matches(signature, signatureLength)) {\n                return new ZCompressorInputStream(in);\n            }\n\n            if (DeflateCompressorInputStream.matches(signature, signatureLength)) {\n                return new DeflateCompressorInputStream(in);\n            }\n\n            if (XZUtils.matches(signature, signatureLength) &&\n                XZUtils.isXZCompressionAvailable()) {\n                return new XZCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (LZMAUtils.matches(signature, signatureLength) &&\n                LZMAUtils.isLZMACompressionAvailable()) {\n                return new LZMACompressorInputStream(in);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\"Failed to detect Compressor from InputStream.\", e);\n        }\n\n        throw new CompressorException(\"No Compressor found for the stream signature.\");\n    }\n\n    /**\n     * Create a compressor input stream from a compressor name and an input stream.\n     * \n     * @param name of the compressor,\n     * i.e. {@value #GZIP}, {@value #BZIP2}, {@value #XZ}, {@value #LZMA},\n     * {@value #PACK200}, {@value #SNAPPY_RAW}, {@value #SNAPPY_FRAMED}, \n     * {@value #Z} or {@value #DEFLATE} \n     * @param in the input stream\n     * @return compressor input stream\n     * @throws CompressorException if the compressor name is not known\n     * @throws IllegalArgumentException if the name or input stream is null\n     */\n    public CompressorInputStream createCompressorInputStream(final String name,\n            final InputStream in) throws CompressorException {\n        if (name == null || in == null) {\n            throw new IllegalArgumentException(\n                    \"Compressor name and stream must not be null.\");\n        }\n\n        try {\n\n            if (GZIP.equalsIgnoreCase(name)) {\n                return new GzipCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (BZIP2.equalsIgnoreCase(name)) {\n                return new BZip2CompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (XZ.equalsIgnoreCase(name)) {\n                return new XZCompressorInputStream(in, decompressConcatenated);\n            }\n\n            if (LZMA.equalsIgnoreCase(name)) {\n                return new LZMACompressorInputStream(in);\n            }\n\n            if (PACK200.equalsIgnoreCase(name)) {\n                return new Pack200CompressorInputStream(in);\n            }\n\n            if (SNAPPY_RAW.equalsIgnoreCase(name)) {\n                return new SnappyCompressorInputStream(in);\n            }\n\n            if (SNAPPY_FRAMED.equalsIgnoreCase(name)) {\n                return new FramedSnappyCompressorInputStream(in);\n            }\n\n            if (Z.equalsIgnoreCase(name)) {\n                return new ZCompressorInputStream(in);\n            }\n\n            if (DEFLATE.equalsIgnoreCase(name)) {\n                return new DeflateCompressorInputStream(in);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\n                    \"Could not create CompressorInputStream.\", e);\n        }\n        throw new CompressorException(\"Compressor: \" + name + \" not found.\");\n    }\n\n    /**\n     * Create an compressor output stream from an compressor name and an output stream.\n     * \n     * @param name the compressor name,\n     * i.e. {@value #GZIP}, {@value #BZIP2}, {@value #XZ},\n     * {@value #PACK200} or {@value #DEFLATE} \n     * @param out the output stream\n     * @return the compressor output stream\n     * @throws CompressorException if the archiver name is not known\n     * @throws IllegalArgumentException if the archiver name or stream is null\n     */\n    public CompressorOutputStream createCompressorOutputStream(\n            final String name, final OutputStream out)\n            throws CompressorException {\n        if (name == null || out == null) {\n            throw new IllegalArgumentException(\n                    \"Compressor name and stream must not be null.\");\n        }\n\n        try {\n\n            if (GZIP.equalsIgnoreCase(name)) {\n                return new GzipCompressorOutputStream(out);\n            }\n\n            if (BZIP2.equalsIgnoreCase(name)) {\n                return new BZip2CompressorOutputStream(out);\n            }\n\n            if (XZ.equalsIgnoreCase(name)) {\n                return new XZCompressorOutputStream(out);\n            }\n\n            if (PACK200.equalsIgnoreCase(name)) {\n                return new Pack200CompressorOutputStream(out);\n            }\n\n            if (DEFLATE.equalsIgnoreCase(name)) {\n                return new DeflateCompressorOutputStream(out);\n            }\n\n        } catch (IOException e) {\n            throw new CompressorException(\n                    \"Could not create CompressorOutputStream\", e);\n        }\n        throw new CompressorException(\"Compressor: \" + name + \" not found.\");\n    }\n\n    // For Unit tests\n    boolean getDecompressConcatenated() {\n        return decompressConcatenated;\n    }\n}\n"}, {"class_name": "org.apache.commons.compress.compressors.deflate.DeflateCompressorInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.compressors.deflate;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * Deflate decompressor.\n * @since 1.9\n */\npublic class DeflateCompressorInputStream extends CompressorInputStream {\n    \n    private final InputStream in;\n\n    /**\n     * Creates a new input stream that decompresses Deflate-compressed data\n     * from the specified input stream.\n     *\n     * @param       inputStream where to read the compressed data\n     *\n     */\n    public DeflateCompressorInputStream(InputStream inputStream) {\n        this(inputStream, new DeflateParameters());\n    }\n\n    /**\n     * Creates a new input stream that decompresses Deflate-compressed data\n     * from the specified input stream.\n     *\n     * @param       inputStream where to read the compressed data\n     * @param       parameters parameters\n     */\n    public DeflateCompressorInputStream(InputStream inputStream,\n                                        DeflateParameters parameters) {\n        in = new InflaterInputStream(inputStream, new Inflater(!parameters.withZlibHeader()));\n    }\n    \n    /** {@inheritDoc} */\n    @Override\n    public int read() throws IOException {\n        int ret = in.read();\n        count(ret == -1 ? 0 : 1);\n        return ret;\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        int ret = in.read(buf, off, len);\n        count(ret);\n        return ret;\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public long skip(long n) throws IOException {\n        return in.skip(n);\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public int available() throws IOException {\n        return in.available();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n    \n    /**\n     * Checks if the signature matches what is expected for a zlib / deflated file\n     *  with the zlib header.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is zlib / deflate compressed with a header\n     * stream, false otherwise\n     * \n     * @since 1.9\n     */\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.compressors.deflate;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.zip.Inflater;\nimport java.util.zip.InflaterInputStream;\n\nimport org.apache.commons.compress.compressors.CompressorInputStream;\n\n/**\n * Deflate decompressor.\n * @since 1.9\n */\npublic class DeflateCompressorInputStream extends CompressorInputStream {\n    private static final int MAGIC_1 = 0x78;\n    private static final int MAGIC_2a = 0x01;\n    private static final int MAGIC_2b = 0x5e;\n    private static final int MAGIC_2c = 0x9c;\n    private static final int MAGIC_2d = 0xda;\n    \n    private final InputStream in;\n\n    /**\n     * Creates a new input stream that decompresses Deflate-compressed data\n     * from the specified input stream.\n     *\n     * @param       inputStream where to read the compressed data\n     *\n     */\n    public DeflateCompressorInputStream(InputStream inputStream) {\n        this(inputStream, new DeflateParameters());\n    }\n\n    /**\n     * Creates a new input stream that decompresses Deflate-compressed data\n     * from the specified input stream.\n     *\n     * @param       inputStream where to read the compressed data\n     * @param       parameters parameters\n     */\n    public DeflateCompressorInputStream(InputStream inputStream,\n                                        DeflateParameters parameters) {\n        in = new InflaterInputStream(inputStream, new Inflater(!parameters.withZlibHeader()));\n    }\n    \n    /** {@inheritDoc} */\n    @Override\n    public int read() throws IOException {\n        int ret = in.read();\n        count(ret == -1 ? 0 : 1);\n        return ret;\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        int ret = in.read(buf, off, len);\n        count(ret);\n        return ret;\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public long skip(long n) throws IOException {\n        return in.skip(n);\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public int available() throws IOException {\n        return in.available();\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n    \n    /**\n     * Checks if the signature matches what is expected for a zlib / deflated file\n     *  with the zlib header.\n     * \n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is zlib / deflate compressed with a header\n     * stream, false otherwise\n     * \n     * @since 1.9\n     */\n    public static boolean matches(byte[] signature, int length) {\n        return length > 3 && signature[0] == MAGIC_1 && (\n                signature[1] == (byte) MAGIC_2a ||\n                signature[1] == (byte) MAGIC_2b ||\n                signature[1] == (byte) MAGIC_2c ||\n                signature[1] == (byte) MAGIC_2d);\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 34, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.X7875_NewUnix", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.Serializable;\nimport java.math.BigInteger;\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.reverse;\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.signedByteToUnsignedInt;\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.unsignedIntToSignedByte;\n\n/**\n * An extra field that stores UNIX UID/GID data (owner &amp; group ownership) for a given\n * zip entry.  We're using the field definition given in Info-Zip's source archive:\n * zip-3.0.tar.gz/proginfo/extrafld.txt\n *\n * <pre>\n * Local-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x7875        Short       tag for this extra block type (\"ux\")\n * TSize         Short       total data size for this block\n * Version       1 byte      version of this extra field, currently 1\n * UIDSize       1 byte      Size of UID field\n * UID           Variable    UID for this entry (little endian)\n * GIDSize       1 byte      Size of GID field\n * GID           Variable    GID for this entry (little endian)\n *\n * Central-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x7855        Short       tag for this extra block type (\"Ux\")\n * TSize         Short       total data size for this block (0)\n * </pre>\n * @since 1.5\n */\npublic class X7875_NewUnix implements ZipExtraField, Cloneable, Serializable {\n    private static final ZipShort HEADER_ID = new ZipShort(0x7875);\n    private static final BigInteger ONE_THOUSAND = BigInteger.valueOf(1000);\n    private static final long serialVersionUID = 1L;\n\n    private int version = 1; // always '1' according to current info-zip spec.\n\n    // BigInteger helps us with little-endian / big-endian conversions.\n    // (thanks to BigInteger.toByteArray() and a reverse() method we created).\n    // Also, the spec theoretically allows UID/GID up to 255 bytes long!\n    //\n    // NOTE:  equals() and hashCode() currently assume these can never be null.\n    private BigInteger uid;\n    private BigInteger gid;\n\n    /**\n     * Constructor for X7875_NewUnix.\n     */\n    public X7875_NewUnix() {\n        reset();\n    }\n\n    /**\n     * The Header-ID.\n     *\n     * @return the value for the header id for this extrafield\n     */\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /**\n     * Gets the UID as a long.  UID is typically a 32 bit unsigned\n     * value on most UNIX systems, so we return a long to avoid\n     * integer overflow into the negatives in case values above\n     * and including 2^31 are being used.\n     *\n     * @return the UID value.\n     */\n    public long getUID() { return ZipUtil.bigToLong(uid); }\n\n    /**\n     * Gets the GID as a long.  GID is typically a 32 bit unsigned\n     * value on most UNIX systems, so we return a long to avoid\n     * integer overflow into the negatives in case values above\n     * and including 2^31 are being used.\n     *\n     * @return the GID value.\n     */\n    public long getGID() { return ZipUtil.bigToLong(gid); }\n\n    /**\n     * Sets the UID.\n     *\n     * @param l UID value to set on this extra field.\n     */\n    public void setUID(long l) {\n        this.uid = ZipUtil.longToBig(l);\n    }\n\n    /**\n     * Sets the GID.\n     *\n     * @param l GID value to set on this extra field.\n     */\n    public void setGID(long l) {\n        this.gid = ZipUtil.longToBig(l);\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    public ZipShort getLocalFileDataLength() {\n        int uidSize = trimLeadingZeroesForceMinLength(uid.toByteArray()).length;\n        int gidSize = trimLeadingZeroesForceMinLength(gid.toByteArray()).length;\n\n        // The 3 comes from:  version=1 + uidsize=1 + gidsize=1\n        return new ZipShort(3 + uidSize + gidSize);\n    }\n\n    /**\n     * Length of the extra field in the central directory data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    public ZipShort getCentralDirectoryLength() {\n        return getLocalFileDataLength();\n    }\n\n    /**\n     * The actual data to put into local file data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    public byte[] getLocalFileDataData() {\n        byte[] uidBytes = uid.toByteArray();\n        byte[] gidBytes = gid.toByteArray();\n\n        // BigInteger might prepend a leading-zero to force a positive representation\n        // (e.g., so that the sign-bit is set to zero).  We need to remove that\n        // before sending the number over the wire.\n        uidBytes = trimLeadingZeroesForceMinLength(uidBytes);\n        gidBytes = trimLeadingZeroesForceMinLength(gidBytes);\n\n        // Couldn't bring myself to just call getLocalFileDataLength() when we've\n        // already got the arrays right here.  Yeah, yeah, I know, premature\n        // optimization is the root of all...\n        //\n        // The 3 comes from:  version=1 + uidsize=1 + gidsize=1\n        byte[] data = new byte[3 + uidBytes.length + gidBytes.length];\n\n        // reverse() switches byte array from big-endian to little-endian.\n        reverse(uidBytes);\n        reverse(gidBytes);\n\n        int pos = 0;\n        data[pos++] = unsignedIntToSignedByte(version);\n        data[pos++] = unsignedIntToSignedByte(uidBytes.length);\n        System.arraycopy(uidBytes, 0, data, pos, uidBytes.length);\n        pos += uidBytes.length;\n        data[pos++] = unsignedIntToSignedByte(gidBytes.length);\n        System.arraycopy(gidBytes, 0, data, pos, gidBytes.length);\n        return data;\n    }\n\n    /**\n     * The actual data to put into central directory data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    public byte[] getCentralDirectoryData() {\n        return new byte[0];\n    }\n\n    /**\n     * Populate data from this array as if it was in local file data.\n     *\n     * @param data   an array of bytes\n     * @param offset the start offset\n     * @param length the number of bytes in the array from offset\n     * @throws java.util.zip.ZipException on error\n     */\n    public void parseFromLocalFileData(\n            byte[] data, int offset, int length\n    ) throws ZipException {\n        reset();\n        this.version = signedByteToUnsignedInt(data[offset++]);\n        int uidSize = signedByteToUnsignedInt(data[offset++]);\n        byte[] uidBytes = new byte[uidSize];\n        System.arraycopy(data, offset, uidBytes, 0, uidSize);\n        offset += uidSize;\n        this.uid = new BigInteger(1, reverse(uidBytes)); // sign-bit forced positive\n\n        int gidSize = signedByteToUnsignedInt(data[offset++]);\n        byte[] gidBytes = new byte[gidSize];\n        System.arraycopy(data, offset, gidBytes, 0, gidSize);\n        this.gid = new BigInteger(1, reverse(gidBytes)); // sign-bit forced positive\n    }\n\n    /**\n     * Doesn't do anything since this class doesn't store anything\n     * inside the central directory.\n     */\n    public void parseFromCentralDirectoryData(\n            byte[] buffer, int offset, int length\n    ) throws ZipException {\n    }\n\n    /**\n     * Reset state back to newly constructed state.  Helps us make sure\n     * parse() calls always generate clean results.\n     */\n    private void reset() {\n        // Typical UID/GID of the first non-root user created on a unix system.\n        uid = ONE_THOUSAND;\n        gid = ONE_THOUSAND;\n    }\n\n    /**\n     * Returns a String representation of this class useful for\n     * debugging purposes.\n     *\n     * @return A String representation of this class useful for\n     *         debugging purposes.\n     */\n    @Override\n    public String toString() {\n        return \"0x7875 Zip Extra Field: UID=\" + uid + \" GID=\" + gid;\n    }\n\n    @Override\n    public Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (o instanceof X7875_NewUnix) {\n            X7875_NewUnix xf = (X7875_NewUnix) o;\n            // We assume uid and gid can never be null.\n            return version == xf.version && uid.equals(xf.uid) && gid.equals(xf.gid);\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode() {\n        int hc = -1234567 * version;\n        // Since most UID's and GID's are below 65,536, this is (hopefully!)\n        // a nice way to make sure typical UID and GID values impact the hash\n        // as much as possible.\n        hc ^= Integer.rotateLeft(uid.hashCode(), 16);\n        hc ^= gid.hashCode();\n        return hc;\n    }\n\n    /**\n     * Not really for external usage, but marked \"package\" visibility\n     * to help us JUnit it.   Trims a byte array of leading zeroes while\n     * also enforcing a minimum length, and thus it really trims AND pads\n     * at the same time.\n     *\n     * @param array byte[] array to trim & pad.\n     * @return trimmed & padded byte[] array.\n     */\n    static byte[] trimLeadingZeroesForceMinLength(byte[] array) {\n        if (array == null) {\n            return array;\n        }\n\n        int pos = 0;\n        for (byte b : array) {\n            if (b == 0) {\n                pos++;\n            } else {\n                break;\n            }\n        }\n\n        /*\n\n        I agonized over my choice of MIN_LENGTH=1.  Here's the situation:\n        InfoZip (the tool I am using to test interop) always sets these\n        to length=4.  And so a UID of 0 (typically root) for example is\n        encoded as {4,0,0,0,0} (len=4, 32 bits of zero), when it could just\n        as easily be encoded as {1,0} (len=1, 8 bits of zero) according to\n        the spec.\n\n        In the end I decided on MIN_LENGTH=1 for four reasons:\n\n        1.)  We are adhering to the spec as far as I can tell, and so\n             a consumer that cannot parse this is broken.\n\n        2.)  Fundamentally, zip files are about shrinking things, so\n             let's save a few bytes per entry while we can.\n\n        3.)  Of all the people creating zip files using commons-\n             compress, how many care about UNIX UID/GID attributes\n             of the files they store?   (e.g., I am probably thinking\n             way too hard about this and no one cares!)\n\n        4.)  InfoZip's tool, even though it carefully stores every UID/GID\n             for every file zipped on a unix machine (by default) currently\n             appears unable to ever restore UID/GID.\n             unzip -X has no effect on my machine, even when run as root!!!!\n\n        And thus it is decided:  MIN_LENGTH=1.\n\n        If anyone runs into interop problems from this, feel free to set\n        it to MIN_LENGTH=4 at some future time, and then we will behave\n        exactly like InfoZip (requires changes to unit tests, though).\n\n        And I am sorry that the time you spent reading this comment is now\n        gone and you can never have it back.\n\n        */\n        final int MIN_LENGTH = 1;\n\n        byte[] trimmedArray = new byte[Math.max(MIN_LENGTH, array.length - pos)];\n        int startPos = trimmedArray.length - (array.length - pos);\n        System.arraycopy(array, pos, trimmedArray, startPos, trimmedArray.length - startPos);\n        return trimmedArray;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.Serializable;\nimport java.math.BigInteger;\nimport java.util.zip.ZipException;\n\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.reverse;\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.signedByteToUnsignedInt;\nimport static org.apache.commons.compress.archivers.zip.ZipUtil.unsignedIntToSignedByte;\n\n/**\n * An extra field that stores UNIX UID/GID data (owner &amp; group ownership) for a given\n * zip entry.  We're using the field definition given in Info-Zip's source archive:\n * zip-3.0.tar.gz/proginfo/extrafld.txt\n *\n * <pre>\n * Local-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x7875        Short       tag for this extra block type (\"ux\")\n * TSize         Short       total data size for this block\n * Version       1 byte      version of this extra field, currently 1\n * UIDSize       1 byte      Size of UID field\n * UID           Variable    UID for this entry (little endian)\n * GIDSize       1 byte      Size of GID field\n * GID           Variable    GID for this entry (little endian)\n *\n * Central-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x7855        Short       tag for this extra block type (\"Ux\")\n * TSize         Short       total data size for this block (0)\n * </pre>\n * @since 1.5\n */\npublic class X7875_NewUnix implements ZipExtraField, Cloneable, Serializable {\n    private static final ZipShort HEADER_ID = new ZipShort(0x7875);\n    private static final ZipShort ZERO = new ZipShort(0);\n    private static final BigInteger ONE_THOUSAND = BigInteger.valueOf(1000);\n    private static final long serialVersionUID = 1L;\n\n    private int version = 1; // always '1' according to current info-zip spec.\n\n    // BigInteger helps us with little-endian / big-endian conversions.\n    // (thanks to BigInteger.toByteArray() and a reverse() method we created).\n    // Also, the spec theoretically allows UID/GID up to 255 bytes long!\n    //\n    // NOTE:  equals() and hashCode() currently assume these can never be null.\n    private BigInteger uid;\n    private BigInteger gid;\n\n    /**\n     * Constructor for X7875_NewUnix.\n     */\n    public X7875_NewUnix() {\n        reset();\n    }\n\n    /**\n     * The Header-ID.\n     *\n     * @return the value for the header id for this extrafield\n     */\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /**\n     * Gets the UID as a long.  UID is typically a 32 bit unsigned\n     * value on most UNIX systems, so we return a long to avoid\n     * integer overflow into the negatives in case values above\n     * and including 2^31 are being used.\n     *\n     * @return the UID value.\n     */\n    public long getUID() { return ZipUtil.bigToLong(uid); }\n\n    /**\n     * Gets the GID as a long.  GID is typically a 32 bit unsigned\n     * value on most UNIX systems, so we return a long to avoid\n     * integer overflow into the negatives in case values above\n     * and including 2^31 are being used.\n     *\n     * @return the GID value.\n     */\n    public long getGID() { return ZipUtil.bigToLong(gid); }\n\n    /**\n     * Sets the UID.\n     *\n     * @param l UID value to set on this extra field.\n     */\n    public void setUID(long l) {\n        this.uid = ZipUtil.longToBig(l);\n    }\n\n    /**\n     * Sets the GID.\n     *\n     * @param l GID value to set on this extra field.\n     */\n    public void setGID(long l) {\n        this.gid = ZipUtil.longToBig(l);\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    public ZipShort getLocalFileDataLength() {\n        int uidSize = trimLeadingZeroesForceMinLength(uid.toByteArray()).length;\n        int gidSize = trimLeadingZeroesForceMinLength(gid.toByteArray()).length;\n\n        // The 3 comes from:  version=1 + uidsize=1 + gidsize=1\n        return new ZipShort(3 + uidSize + gidSize);\n    }\n\n    /**\n     * Length of the extra field in the central directory data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    public ZipShort getCentralDirectoryLength() {\n        return ZERO;\n    }\n\n    /**\n     * The actual data to put into local file data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    public byte[] getLocalFileDataData() {\n        byte[] uidBytes = uid.toByteArray();\n        byte[] gidBytes = gid.toByteArray();\n\n        // BigInteger might prepend a leading-zero to force a positive representation\n        // (e.g., so that the sign-bit is set to zero).  We need to remove that\n        // before sending the number over the wire.\n        uidBytes = trimLeadingZeroesForceMinLength(uidBytes);\n        gidBytes = trimLeadingZeroesForceMinLength(gidBytes);\n\n        // Couldn't bring myself to just call getLocalFileDataLength() when we've\n        // already got the arrays right here.  Yeah, yeah, I know, premature\n        // optimization is the root of all...\n        //\n        // The 3 comes from:  version=1 + uidsize=1 + gidsize=1\n        byte[] data = new byte[3 + uidBytes.length + gidBytes.length];\n\n        // reverse() switches byte array from big-endian to little-endian.\n        reverse(uidBytes);\n        reverse(gidBytes);\n\n        int pos = 0;\n        data[pos++] = unsignedIntToSignedByte(version);\n        data[pos++] = unsignedIntToSignedByte(uidBytes.length);\n        System.arraycopy(uidBytes, 0, data, pos, uidBytes.length);\n        pos += uidBytes.length;\n        data[pos++] = unsignedIntToSignedByte(gidBytes.length);\n        System.arraycopy(gidBytes, 0, data, pos, gidBytes.length);\n        return data;\n    }\n\n    /**\n     * The actual data to put into central directory data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    public byte[] getCentralDirectoryData() {\n        return new byte[0];\n    }\n\n    /**\n     * Populate data from this array as if it was in local file data.\n     *\n     * @param data   an array of bytes\n     * @param offset the start offset\n     * @param length the number of bytes in the array from offset\n     * @throws java.util.zip.ZipException on error\n     */\n    public void parseFromLocalFileData(\n            byte[] data, int offset, int length\n    ) throws ZipException {\n        reset();\n        this.version = signedByteToUnsignedInt(data[offset++]);\n        int uidSize = signedByteToUnsignedInt(data[offset++]);\n        byte[] uidBytes = new byte[uidSize];\n        System.arraycopy(data, offset, uidBytes, 0, uidSize);\n        offset += uidSize;\n        this.uid = new BigInteger(1, reverse(uidBytes)); // sign-bit forced positive\n\n        int gidSize = signedByteToUnsignedInt(data[offset++]);\n        byte[] gidBytes = new byte[gidSize];\n        System.arraycopy(data, offset, gidBytes, 0, gidSize);\n        this.gid = new BigInteger(1, reverse(gidBytes)); // sign-bit forced positive\n    }\n\n    /**\n     * Doesn't do anything since this class doesn't store anything\n     * inside the central directory.\n     */\n    public void parseFromCentralDirectoryData(\n            byte[] buffer, int offset, int length\n    ) throws ZipException {\n    }\n\n    /**\n     * Reset state back to newly constructed state.  Helps us make sure\n     * parse() calls always generate clean results.\n     */\n    private void reset() {\n        // Typical UID/GID of the first non-root user created on a unix system.\n        uid = ONE_THOUSAND;\n        gid = ONE_THOUSAND;\n    }\n\n    /**\n     * Returns a String representation of this class useful for\n     * debugging purposes.\n     *\n     * @return A String representation of this class useful for\n     *         debugging purposes.\n     */\n    @Override\n    public String toString() {\n        return \"0x7875 Zip Extra Field: UID=\" + uid + \" GID=\" + gid;\n    }\n\n    @Override\n    public Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (o instanceof X7875_NewUnix) {\n            X7875_NewUnix xf = (X7875_NewUnix) o;\n            // We assume uid and gid can never be null.\n            return version == xf.version && uid.equals(xf.uid) && gid.equals(xf.gid);\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode() {\n        int hc = -1234567 * version;\n        // Since most UID's and GID's are below 65,536, this is (hopefully!)\n        // a nice way to make sure typical UID and GID values impact the hash\n        // as much as possible.\n        hc ^= Integer.rotateLeft(uid.hashCode(), 16);\n        hc ^= gid.hashCode();\n        return hc;\n    }\n\n    /**\n     * Not really for external usage, but marked \"package\" visibility\n     * to help us JUnit it.   Trims a byte array of leading zeroes while\n     * also enforcing a minimum length, and thus it really trims AND pads\n     * at the same time.\n     *\n     * @param array byte[] array to trim & pad.\n     * @return trimmed & padded byte[] array.\n     */\n    static byte[] trimLeadingZeroesForceMinLength(byte[] array) {\n        if (array == null) {\n            return array;\n        }\n\n        int pos = 0;\n        for (byte b : array) {\n            if (b == 0) {\n                pos++;\n            } else {\n                break;\n            }\n        }\n\n        /*\n\n        I agonized over my choice of MIN_LENGTH=1.  Here's the situation:\n        InfoZip (the tool I am using to test interop) always sets these\n        to length=4.  And so a UID of 0 (typically root) for example is\n        encoded as {4,0,0,0,0} (len=4, 32 bits of zero), when it could just\n        as easily be encoded as {1,0} (len=1, 8 bits of zero) according to\n        the spec.\n\n        In the end I decided on MIN_LENGTH=1 for four reasons:\n\n        1.)  We are adhering to the spec as far as I can tell, and so\n             a consumer that cannot parse this is broken.\n\n        2.)  Fundamentally, zip files are about shrinking things, so\n             let's save a few bytes per entry while we can.\n\n        3.)  Of all the people creating zip files using commons-\n             compress, how many care about UNIX UID/GID attributes\n             of the files they store?   (e.g., I am probably thinking\n             way too hard about this and no one cares!)\n\n        4.)  InfoZip's tool, even though it carefully stores every UID/GID\n             for every file zipped on a unix machine (by default) currently\n             appears unable to ever restore UID/GID.\n             unzip -X has no effect on my machine, even when run as root!!!!\n\n        And thus it is decided:  MIN_LENGTH=1.\n\n        If anyone runs into interop problems from this, feel free to set\n        it to MIN_LENGTH=4 at some future time, and then we will behave\n        exactly like InfoZip (requires changes to unit tests, though).\n\n        And I am sorry that the time you spent reading this comment is now\n        gone and you can never have it back.\n\n        */\n        final int MIN_LENGTH = 1;\n\n        byte[] trimmedArray = new byte[Math.max(MIN_LENGTH, array.length - pos)];\n        int startPos = trimmedArray.length - (array.length - pos);\n        System.arraycopy(array, pos, trimmedArray, startPos, trimmedArray.length - startPos);\n        return trimmedArray;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 35, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     * @throws IOException on error\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     * @throws IOException on error\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = 0;\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                if ('0' <= b && b <= '7' && digits++ < 6) {\n                    storedSum = storedSum * 8 + b - '0';\n                } else if (digits > 0) {\n                    digits = 6;\n                }\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n        return storedSum == unsignedSum || storedSum == signedSum;\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            public boolean canEncode(String name) { return true; }\n\n            public ByteBuffer encode(String name) {\n                final int length = name.length();\n                byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            public String decode(byte[] buffer) {\n                final int length = buffer.length;\n                StringBuilder result = new StringBuilder(length);\n\n                for (byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2, (length - 1) * 8) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(byte[] buffer, final int offset,\n            final int length, int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     * @throws IOException on error\n     */\n    public static String parseName(byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     * @throws IOException on error\n     */\n    public static int formatNameBytes(String name, byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value);\n        if (val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val |= 0xff << bits;\n            val++;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(byte[] header) {\n        long storedSum = parseOctal(header, CHKSUM_OFFSET, CHKSUMLEN);\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        int digits = 0;\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n        return storedSum == unsignedSum || storedSum == signedSum;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 36, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.sevenz.SevenZFile", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.BufferedInputStream;\nimport java.io.ByteArrayInputStream;\nimport java.io.Closeable;\nimport java.io.DataInput;\nimport java.io.DataInputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.RandomAccessFile;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.BitSet;\nimport java.util.LinkedList;\nimport java.util.zip.CRC32;\n\nimport org.apache.commons.compress.utils.BoundedInputStream;\nimport org.apache.commons.compress.utils.CRC32VerifyingInputStream;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Reads a 7z file, using RandomAccessFile under\n * the covers.\n * <p>\n * The 7z file format is a flexible container\n * that can contain many compression and\n * encryption types, but at the moment only\n * only Copy, LZMA, LZMA2, BZIP2, Deflate and AES-256 + SHA-256\n * are supported.\n * <p>\n * The format is very Windows/Intel specific,\n * so it uses little-endian byte order,\n * doesn't store user/group or permission bits,\n * and represents times using NTFS timestamps\n * (100 nanosecond units since 1 January 1601).\n * Hence the official tools recommend against\n * using it for backup purposes on *nix, and\n * recommend .tar.7z or .tar.lzma or .tar.xz\n * instead.  \n * <p>\n * Both the header and file contents may be\n * compressed and/or encrypted. With both\n * encrypted, neither file names nor file\n * contents can be read, but the use of\n * encryption isn't plausibly deniable.\n * \n * @NotThreadSafe\n * @since 1.6\n */\npublic class SevenZFile implements Closeable {\n    static final int SIGNATURE_HEADER_SIZE = 32;\n\n    private final String fileName;\n    private RandomAccessFile file;\n    private final Archive archive;\n    private int currentEntryIndex = -1;\n    private int currentFolderIndex = -1;\n    private InputStream currentFolderInputStream = null;\n    private byte[] password;\n\n    private final ArrayList<InputStream> deferredBlockStreams = new ArrayList<InputStream>();\n\n    static final byte[] sevenZSignature = {\n        (byte)'7', (byte)'z', (byte)0xBC, (byte)0xAF, (byte)0x27, (byte)0x1C\n    };\n    \n    /**\n     * Reads a file as 7z archive\n     *\n     * @param filename the file to read\n     * @param password optional password if the archive is encrypted -\n     * the byte array is supposed to be the UTF16-LE encoded\n     * representation of the password.\n     * @throws IOException if reading the archive fails\n     */\n    public SevenZFile(final File filename, final byte[] password) throws IOException {\n        boolean succeeded = false;\n        this.file = new RandomAccessFile(filename, \"r\");\n        this.fileName = filename.getAbsolutePath();\n        try {\n            archive = readHeaders(password);\n            if (password != null) {\n                this.password = new byte[password.length];\n                System.arraycopy(password, 0, this.password, 0, password.length);\n            } else {\n                this.password = null;\n            }\n            succeeded = true;\n        } finally {\n            if (!succeeded) {\n                this.file.close();\n            }\n        }\n    }\n    \n    /**\n     * Reads a file as unencrypted 7z archive\n     *\n     * @param filename the file to read\n     * @throws IOException if reading the archive fails\n     */\n    public SevenZFile(final File filename) throws IOException {\n        this(filename, null);\n    }\n\n    /**\n     * Closes the archive.\n     * @throws IOException if closing the file fails\n     */\n    @Override\n    public void close() throws IOException {\n        if (file != null) {\n            try {\n                file.close();\n            } finally {\n                file = null;\n                if (password != null) {\n                    Arrays.fill(password, (byte) 0);\n                }\n                password = null;\n            }\n        }\n    }\n    \n    /**\n     * Returns the next Archive Entry in this archive.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    public SevenZArchiveEntry getNextEntry() throws IOException {\n        if (currentEntryIndex >= archive.files.length - 1) {\n            return null;\n        }\n        ++currentEntryIndex;\n        final SevenZArchiveEntry entry = archive.files[currentEntryIndex];\n        buildDecodingStream();\n        return entry;\n    }\n    \n    /**\n     * Returns meta-data of all archive entries.\n     *\n     * <p>This method only provides meta-data, the entries can not be\n     * used to read the contents, you still need to process all\n     * entries in order using {@link #getNextEntry} for that.</p>\n     *\n     * <p>The content methods are only available for entries that have\n     * already been reached via {@link #getNextEntry}.</p>\n     *\n     * @return meta-data of all archive entries.\n     * @since 1.11\n     */\n    public Iterable<SevenZArchiveEntry> getEntries() {\n        return Arrays.asList(archive.files);\n    }\n    \n    private Archive readHeaders(final byte[] password) throws IOException {\n        final byte[] signature = new byte[6];\n        file.readFully(signature);\n        if (!Arrays.equals(signature, sevenZSignature)) {\n            throw new IOException(\"Bad 7z signature\");\n        }\n        // 7zFormat.txt has it wrong - it's first major then minor\n        final byte archiveVersionMajor = file.readByte();\n        final byte archiveVersionMinor = file.readByte();\n        if (archiveVersionMajor != 0) {\n            throw new IOException(String.format(\"Unsupported 7z version (%d,%d)\",\n                    archiveVersionMajor, archiveVersionMinor));\n        }\n\n        final long startHeaderCrc = 0xffffFFFFL & Integer.reverseBytes(file.readInt());\n        final StartHeader startHeader = readStartHeader(startHeaderCrc);\n        \n        final int nextHeaderSizeInt = (int) startHeader.nextHeaderSize;\n        if (nextHeaderSizeInt != startHeader.nextHeaderSize) {\n            throw new IOException(\"cannot handle nextHeaderSize \" + startHeader.nextHeaderSize);\n        }\n        file.seek(SIGNATURE_HEADER_SIZE + startHeader.nextHeaderOffset);\n        final byte[] nextHeader = new byte[nextHeaderSizeInt];\n        file.readFully(nextHeader);\n        final CRC32 crc = new CRC32();\n        crc.update(nextHeader);\n        if (startHeader.nextHeaderCrc != crc.getValue()) {\n            throw new IOException(\"NextHeader CRC mismatch\");\n        }\n        \n        final ByteArrayInputStream byteStream = new ByteArrayInputStream(nextHeader);\n        DataInputStream nextHeaderInputStream = new DataInputStream(\n                byteStream);\n        Archive archive = new Archive();\n        int nid = nextHeaderInputStream.readUnsignedByte();\n        if (nid == NID.kEncodedHeader) {\n            nextHeaderInputStream =\n                readEncodedHeader(nextHeaderInputStream, archive, password);\n            // Archive gets rebuilt with the new header\n            archive = new Archive();\n            nid = nextHeaderInputStream.readUnsignedByte();\n        }\n        if (nid == NID.kHeader) {\n            readHeader(nextHeaderInputStream, archive);\n            nextHeaderInputStream.close();\n        } else {\n            throw new IOException(\"Broken or unsupported archive: no Header\");\n        }\n        return archive;\n    }\n    \n    private StartHeader readStartHeader(final long startHeaderCrc) throws IOException {\n        final StartHeader startHeader = new StartHeader();\n        DataInputStream dataInputStream = null;\n        try {\n             dataInputStream = new DataInputStream(new CRC32VerifyingInputStream(\n                    new BoundedRandomAccessFileInputStream(file, 20), 20, startHeaderCrc));\n             startHeader.nextHeaderOffset = Long.reverseBytes(dataInputStream.readLong());\n             startHeader.nextHeaderSize = Long.reverseBytes(dataInputStream.readLong());\n             startHeader.nextHeaderCrc = 0xffffFFFFL & Integer.reverseBytes(dataInputStream.readInt());\n             return startHeader;\n        } finally {\n            if (dataInputStream != null) {\n                dataInputStream.close();\n            }\n        }\n    }\n    \n    private void readHeader(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        \n        if (nid == NID.kArchiveProperties) {\n            readArchiveProperties(header);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kAdditionalStreamsInfo) {\n            throw new IOException(\"Additional streams unsupported\");\n            //nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kMainStreamsInfo) {\n            readStreamsInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kFilesInfo) {\n            readFilesInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated header, found \" + nid);\n        }\n    }\n    \n    private void readArchiveProperties(final DataInput input) throws IOException {\n        // FIXME: the reference implementation just throws them away?\n        int nid =  input.readUnsignedByte();\n        while (nid != NID.kEnd) {\n            final long propertySize = readUint64(input);\n            final byte[] property = new byte[(int)propertySize];\n            input.readFully(property);\n            nid = input.readUnsignedByte();\n        }\n    }\n    \n    private DataInputStream readEncodedHeader(final DataInputStream header, final Archive archive,\n                                              final byte[] password) throws IOException {\n        readStreamsInfo(header, archive);\n        \n        // FIXME: merge with buildDecodingStream()/buildDecoderStack() at some stage?\n        final Folder folder = archive.folders[0];\n        final int firstPackStreamIndex = 0;\n        final long folderOffset = SIGNATURE_HEADER_SIZE + archive.packPos +\n                0;\n        \n        file.seek(folderOffset);\n        InputStream inputStreamStack = new BoundedRandomAccessFileInputStream(file,\n                archive.packSizes[firstPackStreamIndex]);\n        for (final Coder coder : folder.getOrderedCoders()) {\n            if (coder.numInStreams != 1 || coder.numOutStreams != 1) {\n                throw new IOException(\"Multi input/output stream coders are not yet supported\");\n            }\n            inputStreamStack = Coders.addDecoder(fileName, inputStreamStack,\n                    folder.getUnpackSizeForCoder(coder), coder, password);\n        }\n        if (folder.hasCrc) {\n            inputStreamStack = new CRC32VerifyingInputStream(inputStreamStack,\n                    folder.getUnpackSize(), folder.crc);\n        }\n        final byte[] nextHeader = new byte[(int)folder.getUnpackSize()];\n        final DataInputStream nextHeaderInputStream = new DataInputStream(inputStreamStack);\n        try {\n            nextHeaderInputStream.readFully(nextHeader);\n        } finally {\n            nextHeaderInputStream.close();\n        }\n        return new DataInputStream(new ByteArrayInputStream(nextHeader));\n    }\n    \n    private void readStreamsInfo(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        \n        if (nid == NID.kPackInfo) {\n            readPackInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kUnpackInfo) {\n            readUnpackInfo(header, archive);\n            nid = header.readUnsignedByte();\n        } else {\n            // archive without unpack/coders info\n            archive.folders = new Folder[0];\n        }\n        \n        if (nid == NID.kSubStreamsInfo) {\n            readSubStreamsInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated StreamsInfo\");\n        }\n    }\n    \n    private void readPackInfo(final DataInput header, final Archive archive) throws IOException {\n        archive.packPos = readUint64(header);\n        final long numPackStreams = readUint64(header);\n        int nid = header.readUnsignedByte();\n        if (nid == NID.kSize) {\n            archive.packSizes = new long[(int)numPackStreams];\n            for (int i = 0; i < archive.packSizes.length; i++) {\n                archive.packSizes[i] = readUint64(header);\n            }\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kCRC) {\n            archive.packCrcsDefined = readAllOrBits(header, (int)numPackStreams);\n            archive.packCrcs = new long[(int)numPackStreams];\n            for (int i = 0; i < (int)numPackStreams; i++) {\n                if (archive.packCrcsDefined.get(i)) {\n                    archive.packCrcs[i] = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated PackInfo (\" + nid + \")\");\n        }\n    }\n    \n    private void readUnpackInfo(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        if (nid != NID.kFolder) {\n            throw new IOException(\"Expected kFolder, got \" + nid);\n        }\n        final long numFolders = readUint64(header);\n        final Folder[] folders = new Folder[(int)numFolders];\n        archive.folders = folders;\n        final int external = header.readUnsignedByte();\n        if (external != 0) {\n            throw new IOException(\"External unsupported\");\n        }\n        for (int i = 0; i < (int)numFolders; i++) {\n            folders[i] = readFolder(header);\n        }\n        \n        nid = header.readUnsignedByte();\n        if (nid != NID.kCodersUnpackSize) {\n            throw new IOException(\"Expected kCodersUnpackSize, got \" + nid);\n        }\n        for (final Folder folder : folders) {\n            folder.unpackSizes = new long[(int)folder.totalOutputStreams];\n            for (int i = 0; i < folder.totalOutputStreams; i++) {\n                folder.unpackSizes[i] = readUint64(header);\n            }\n        }\n        \n        nid = header.readUnsignedByte();\n        if (nid == NID.kCRC) {\n            final BitSet crcsDefined = readAllOrBits(header, (int)numFolders);\n            for (int i = 0; i < (int)numFolders; i++) {\n                if (crcsDefined.get(i)) {\n                    folders[i].hasCrc = true;\n                    folders[i].crc = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                } else {\n                    folders[i].hasCrc = false;\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated UnpackInfo\");\n        }\n    }\n    \n    private void readSubStreamsInfo(final DataInput header, final Archive archive) throws IOException {\n        for (final Folder folder : archive.folders) {\n            folder.numUnpackSubStreams = 1;\n        }\n        int totalUnpackStreams = archive.folders.length;\n        \n        int nid = header.readUnsignedByte();\n        if (nid == NID.kNumUnpackStream) {\n            totalUnpackStreams = 0;\n            for (final Folder folder : archive.folders) {\n                final long numStreams = readUint64(header);\n                folder.numUnpackSubStreams = (int)numStreams;\n                totalUnpackStreams += numStreams;\n            }\n            nid = header.readUnsignedByte();\n        }\n        \n        final SubStreamsInfo subStreamsInfo = new SubStreamsInfo();\n        subStreamsInfo.unpackSizes = new long[totalUnpackStreams];\n        subStreamsInfo.hasCrc = new BitSet(totalUnpackStreams);\n        subStreamsInfo.crcs = new long[totalUnpackStreams];\n        \n        int nextUnpackStream = 0;\n        for (final Folder folder : archive.folders) {\n            if (folder.numUnpackSubStreams == 0) {\n                continue;\n            }\n            long sum = 0;\n            if (nid == NID.kSize) {\n                for (int i = 0; i < folder.numUnpackSubStreams - 1; i++) {\n                    final long size = readUint64(header);\n                    subStreamsInfo.unpackSizes[nextUnpackStream++] = size;\n                    sum += size;\n                }\n            }\n            subStreamsInfo.unpackSizes[nextUnpackStream++] = folder.getUnpackSize() - sum;\n        }\n        if (nid == NID.kSize) {\n            nid = header.readUnsignedByte();\n        }\n        \n        int numDigests = 0;\n        for (final Folder folder : archive.folders) {\n            if (folder.numUnpackSubStreams != 1 || !folder.hasCrc) {\n                numDigests += folder.numUnpackSubStreams;\n            }\n        }\n        \n        if (nid == NID.kCRC) {\n            final BitSet hasMissingCrc = readAllOrBits(header, numDigests);\n            final long[] missingCrcs = new long[numDigests];\n            for (int i = 0; i < numDigests; i++) {\n                if (hasMissingCrc.get(i)) {\n                    missingCrcs[i] = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                }\n            }\n            int nextCrc = 0;\n            int nextMissingCrc = 0;\n            for (final Folder folder: archive.folders) {\n                if (folder.numUnpackSubStreams == 1 && folder.hasCrc) {\n                    subStreamsInfo.hasCrc.set(nextCrc, true);\n                    subStreamsInfo.crcs[nextCrc] = folder.crc;\n                    ++nextCrc;\n                } else {\n                    for (int i = 0; i < folder.numUnpackSubStreams; i++) {\n                        subStreamsInfo.hasCrc.set(nextCrc, hasMissingCrc.get(nextMissingCrc));\n                        subStreamsInfo.crcs[nextCrc] = missingCrcs[nextMissingCrc];\n                        ++nextCrc;\n                        ++nextMissingCrc;\n                    }\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated SubStreamsInfo\");\n        }\n        \n        archive.subStreamsInfo = subStreamsInfo;\n    }\n    \n    private Folder readFolder(final DataInput header) throws IOException {\n        final Folder folder = new Folder();\n        \n        final long numCoders = readUint64(header);\n        final Coder[] coders = new Coder[(int)numCoders];\n        long totalInStreams = 0;\n        long totalOutStreams = 0;\n        for (int i = 0; i < coders.length; i++) {\n            coders[i] = new Coder();\n            final int bits = header.readUnsignedByte();\n            final int idSize = bits & 0xf;\n            final boolean isSimple = (bits & 0x10) == 0;\n            final boolean hasAttributes = (bits & 0x20) != 0;\n            final boolean moreAlternativeMethods = (bits & 0x80) != 0;\n            \n            coders[i].decompressionMethodId = new byte[idSize];\n            header.readFully(coders[i].decompressionMethodId);\n            if (isSimple) {\n                coders[i].numInStreams = 1;\n                coders[i].numOutStreams = 1;\n            } else {\n                coders[i].numInStreams = readUint64(header);\n                coders[i].numOutStreams = readUint64(header);\n            }\n            totalInStreams += coders[i].numInStreams;\n            totalOutStreams += coders[i].numOutStreams;\n            if (hasAttributes) {\n                final long propertiesSize = readUint64(header);\n                coders[i].properties = new byte[(int)propertiesSize];\n                header.readFully(coders[i].properties);\n            }\n            // would need to keep looping as above:\n            while (moreAlternativeMethods) {\n                throw new IOException(\"Alternative methods are unsupported, please report. \" +\n                        \"The reference implementation doesn't support them either.\");\n            }\n        }\n        folder.coders = coders;\n        folder.totalInputStreams = totalInStreams;\n        folder.totalOutputStreams = totalOutStreams;\n        \n        if (totalOutStreams == 0) {\n            throw new IOException(\"Total output streams can't be 0\");\n        }\n        final long numBindPairs = totalOutStreams - 1;\n        final BindPair[] bindPairs = new BindPair[(int)numBindPairs];\n        for (int i = 0; i < bindPairs.length; i++) {\n            bindPairs[i] = new BindPair();\n            bindPairs[i].inIndex = readUint64(header);\n            bindPairs[i].outIndex = readUint64(header);\n        }\n        folder.bindPairs = bindPairs;\n        \n        if (totalInStreams < numBindPairs) {\n            throw new IOException(\"Total input streams can't be less than the number of bind pairs\");\n        }\n        final long numPackedStreams = totalInStreams - numBindPairs;\n        final long packedStreams[] = new long[(int)numPackedStreams];\n        if (numPackedStreams == 1) {\n            int i;\n            for (i = 0; i < (int)totalInStreams; i++) {\n                if (folder.findBindPairForInStream(i) < 0) {\n                    break;\n                }\n            }\n            if (i == (int)totalInStreams) {\n                throw new IOException(\"Couldn't find stream's bind pair index\");\n            }\n            packedStreams[0] = i;\n        } else {\n            for (int i = 0; i < (int)numPackedStreams; i++) {\n                packedStreams[i] = readUint64(header);\n            }\n        }\n        folder.packedStreams = packedStreams;\n        \n        return folder;\n    }\n    \n    private BitSet readAllOrBits(final DataInput header, final int size) throws IOException {\n        final int areAllDefined = header.readUnsignedByte();\n        final BitSet bits;\n        if (areAllDefined != 0) {\n            bits = new BitSet(size);\n            for (int i = 0; i < size; i++) {\n                bits.set(i, true);\n            }\n        } else {\n            bits = readBits(header, size);\n        }\n        return bits;\n    }\n    \n    private BitSet readBits(final DataInput header, final int size) throws IOException {\n        final BitSet bits = new BitSet(size);\n        int mask = 0;\n        int cache = 0;\n        for (int i = 0; i < size; i++) {\n            if (mask == 0) {\n                mask = 0x80;\n                cache = header.readUnsignedByte();\n            }\n            bits.set(i, (cache & mask) != 0);\n            mask >>>= 1;\n        }\n        return bits;\n    }\n    \n    private void readFilesInfo(final DataInput header, final Archive archive) throws IOException {\n        final long numFiles = readUint64(header);\n        final SevenZArchiveEntry[] files = new SevenZArchiveEntry[(int)numFiles];\n        for (int i = 0; i < files.length; i++) {\n            files[i] = new SevenZArchiveEntry();\n        }\n        BitSet isEmptyStream = null;\n        BitSet isEmptyFile = null; \n        BitSet isAnti = null;\n        while (true) {\n            final int propertyType = header.readUnsignedByte();\n            if (propertyType == 0) {\n                break;\n            }\n            final long size = readUint64(header);\n            switch (propertyType) {\n                case NID.kEmptyStream: {\n                    isEmptyStream = readBits(header, files.length);\n                    break;\n                }\n                case NID.kEmptyFile: {\n                    if (isEmptyStream == null) { // protect against NPE\n                        throw new IOException(\"Header format error: kEmptyStream must appear before kEmptyFile\");\n                    }\n                    isEmptyFile = readBits(header, isEmptyStream.cardinality());\n                    break;\n                }\n                case NID.kAnti: {\n                    if (isEmptyStream == null) { // protect against NPE\n                        throw new IOException(\"Header format error: kEmptyStream must appear before kAnti\");\n                    }\n                    isAnti = readBits(header, isEmptyStream.cardinality());\n                    break;\n                }\n                case NID.kName: {\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Not implemented\");\n                    }\n                    if (((size - 1) & 1) != 0) {\n                        throw new IOException(\"File names length invalid\");\n                    }\n                    final byte[] names = new byte[(int)(size - 1)];\n                    header.readFully(names);\n                    int nextFile = 0;\n                    int nextName = 0;\n                    for (int i = 0; i < names.length; i += 2) {\n                        if (names[i] == 0 && names[i+1] == 0) {\n                            files[nextFile++].setName(new String(names, nextName, i-nextName, CharsetNames.UTF_16LE));\n                            nextName = i + 2;\n                        }\n                    }\n                    if (nextName != names.length || nextFile != files.length) {\n                        throw new IOException(\"Error parsing file names\");\n                    }\n                    break;\n                }\n                case NID.kCTime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasCreationDate(timesDefined.get(i));\n                        if (files[i].getHasCreationDate()) {\n                            files[i].setCreationDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kATime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasAccessDate(timesDefined.get(i));\n                        if (files[i].getHasAccessDate()) {\n                            files[i].setAccessDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kMTime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasLastModifiedDate(timesDefined.get(i));\n                        if (files[i].getHasLastModifiedDate()) {\n                            files[i].setLastModifiedDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kWinAttributes: {\n                    final BitSet attributesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasWindowsAttributes(attributesDefined.get(i));\n                        if (files[i].getHasWindowsAttributes()) {\n                            files[i].setWindowsAttributes(Integer.reverseBytes(header.readInt()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kStartPos: {\n                    throw new IOException(\"kStartPos is unsupported, please report\");\n                }\n                case NID.kDummy: {\n                    // 7z 9.20 asserts the content is all zeros and ignores the property\n                    // Compress up to 1.8.1 would throw an exception, now we ignore it (see COMPRESS-287\n                    \n                    if (skipBytesFully(header, size) < size) {\n                        throw new IOException(\"Incomplete kDummy property\");\n                    }\n                    break;\n                }\n\n                default: {\n                    // Compress up to 1.8.1 would throw an exception, now we ignore it (see COMPRESS-287\n                    if (skipBytesFully(header, size) < size) {\n                        throw new IOException(\"Incomplete property of type \" + propertyType);\n                    }\n                    break;\n                }\n            }\n        }\n        int nonEmptyFileCounter = 0;\n        int emptyFileCounter = 0;\n        for (int i = 0; i < files.length; i++) {\n            files[i].setHasStream(isEmptyStream == null ? true : !isEmptyStream.get(i));\n            if (files[i].hasStream()) {\n                files[i].setDirectory(false);\n                files[i].setAntiItem(false);\n                files[i].setHasCrc(archive.subStreamsInfo.hasCrc.get(nonEmptyFileCounter));\n                files[i].setCrcValue(archive.subStreamsInfo.crcs[nonEmptyFileCounter]);\n                files[i].setSize(archive.subStreamsInfo.unpackSizes[nonEmptyFileCounter]);\n                ++nonEmptyFileCounter;\n            } else {\n                files[i].setDirectory(isEmptyFile == null ? true : !isEmptyFile.get(emptyFileCounter));\n                files[i].setAntiItem(isAnti == null ? false : isAnti.get(emptyFileCounter));\n                files[i].setHasCrc(false);\n                files[i].setSize(0);\n                ++emptyFileCounter;\n            }\n        }\n        archive.files = files;\n        calculateStreamMap(archive);\n    }\n    \n    private void calculateStreamMap(final Archive archive) throws IOException {\n        final StreamMap streamMap = new StreamMap();\n        \n        int nextFolderPackStreamIndex = 0;\n        final int numFolders = archive.folders != null ? archive.folders.length : 0;\n        streamMap.folderFirstPackStreamIndex = new int[numFolders];\n        for (int i = 0; i < numFolders; i++) {\n            streamMap.folderFirstPackStreamIndex[i] = nextFolderPackStreamIndex;\n            nextFolderPackStreamIndex += archive.folders[i].packedStreams.length;\n        }\n        \n        long nextPackStreamOffset = 0;\n        final int numPackSizes = archive.packSizes != null ? archive.packSizes.length : 0;\n        streamMap.packStreamOffsets = new long[numPackSizes];\n        for (int i = 0; i < numPackSizes; i++) {\n            streamMap.packStreamOffsets[i] = nextPackStreamOffset;\n            nextPackStreamOffset += archive.packSizes[i]; \n        }\n        \n        streamMap.folderFirstFileIndex = new int[numFolders];\n        streamMap.fileFolderIndex = new int[archive.files.length];\n        int nextFolderIndex = 0;\n        int nextFolderUnpackStreamIndex = 0;\n        for (int i = 0; i < archive.files.length; i++) {\n            if (!archive.files[i].hasStream() && nextFolderUnpackStreamIndex == 0) {\n                streamMap.fileFolderIndex[i] = -1;\n                continue;\n            }\n            if (nextFolderUnpackStreamIndex == 0) {\n                for (; nextFolderIndex < archive.folders.length; ++nextFolderIndex) {\n                    streamMap.folderFirstFileIndex[nextFolderIndex] = i;\n                    if (archive.folders[nextFolderIndex].numUnpackSubStreams > 0) {\n                        break;\n                    }\n                }\n                if (nextFolderIndex >= archive.folders.length) {\n                    throw new IOException(\"Too few folders in archive\");\n                }\n            }\n            streamMap.fileFolderIndex[i] = nextFolderIndex;\n            if (!archive.files[i].hasStream()) {\n                continue;\n            }\n            ++nextFolderUnpackStreamIndex;\n            if (nextFolderUnpackStreamIndex >= archive.folders[nextFolderIndex].numUnpackSubStreams) {\n                ++nextFolderIndex;\n                nextFolderUnpackStreamIndex = 0;\n            }\n        }\n        \n        archive.streamMap = streamMap;\n    }\n    \n    private void buildDecodingStream() throws IOException {\n        final int folderIndex = archive.streamMap.fileFolderIndex[currentEntryIndex];\n        if (folderIndex < 0) {\n            deferredBlockStreams.clear();\n            // TODO: previously it'd return an empty stream?\n            // new BoundedInputStream(new ByteArrayInputStream(new byte[0]), 0);\n            return;\n        }\n        final SevenZArchiveEntry file = archive.files[currentEntryIndex];\n        if (currentFolderIndex == folderIndex) {\n            // (COMPRESS-320).\n            // The current entry is within the same (potentially opened) folder. The\n            // previous stream has to be fully decoded before we can start reading\n            // but don't do it eagerly -- if the user skips over the entire folder nothing\n            // is effectively decompressed.\n\n            file.setContentMethods(archive.files[currentEntryIndex - 1].getContentMethods());\n        } else {\n            // We're opening a new folder. Discard any queued streams/ folder stream.\n            currentFolderIndex = folderIndex;\n            deferredBlockStreams.clear();\n            if (currentFolderInputStream != null) {\n                currentFolderInputStream.close();\n                currentFolderInputStream = null;\n            }\n            \n            final Folder folder = archive.folders[folderIndex];\n            final int firstPackStreamIndex = archive.streamMap.folderFirstPackStreamIndex[folderIndex];\n            final long folderOffset = SIGNATURE_HEADER_SIZE + archive.packPos +\n                    archive.streamMap.packStreamOffsets[firstPackStreamIndex];\n            currentFolderInputStream = buildDecoderStack(folder, folderOffset, firstPackStreamIndex, file);\n        }\n\n        InputStream fileStream = new BoundedInputStream(currentFolderInputStream, file.getSize());\n        if (file.getHasCrc()) {\n            fileStream = new CRC32VerifyingInputStream(fileStream, file.getSize(), file.getCrcValue());\n        }\n        \n        deferredBlockStreams.add(fileStream);\n    }\n\n    private InputStream buildDecoderStack(final Folder folder, final long folderOffset,\n                final int firstPackStreamIndex, final SevenZArchiveEntry entry) throws IOException {\n        file.seek(folderOffset);\n        InputStream inputStreamStack =\n            new BufferedInputStream(\n              new BoundedRandomAccessFileInputStream(file,\n                  archive.packSizes[firstPackStreamIndex]));\n        final LinkedList<SevenZMethodConfiguration> methods = new LinkedList<SevenZMethodConfiguration>();\n        for (final Coder coder : folder.getOrderedCoders()) {\n            if (coder.numInStreams != 1 || coder.numOutStreams != 1) {\n                throw new IOException(\"Multi input/output stream coders are not yet supported\");\n            }\n            final SevenZMethod method = SevenZMethod.byId(coder.decompressionMethodId);\n            inputStreamStack = Coders.addDecoder(fileName, inputStreamStack,\n                    folder.getUnpackSizeForCoder(coder), coder, password);\n            methods.addFirst(new SevenZMethodConfiguration(method,\n                     Coders.findByMethod(method).getOptionsFromCoder(coder, inputStreamStack)));\n        }\n        entry.setContentMethods(methods);\n        if (folder.hasCrc) {\n            return new CRC32VerifyingInputStream(inputStreamStack,\n                    folder.getUnpackSize(), folder.crc);\n        }\n        return inputStreamStack;\n    }\n    \n    /**\n     * Reads a byte of data.\n     * \n     * @return the byte read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read() throws IOException {\n        return getCurrentStream().read();\n    }\n    \n    private InputStream getCurrentStream() throws IOException {\n        if (deferredBlockStreams.isEmpty()) {\n            throw new IllegalStateException(\"No current 7z entry (call getNextEntry() first).\");\n        }\n        \n        while (deferredBlockStreams.size() > 1) {\n            // In solid compression mode we need to decompress all leading folder'\n            // streams to get access to an entry. We defer this until really needed\n            // so that entire blocks can be skipped without wasting time for decompression.\n            final InputStream stream = deferredBlockStreams.remove(0);\n            IOUtils.skip(stream, Long.MAX_VALUE);\n            stream.close();\n        }\n\n        return deferredBlockStreams.get(0);\n    }\n\n    /**\n     * Reads data into an array of bytes.\n     * \n     * @param b the array to write data to\n     * @return the number of bytes read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read(final byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n    \n    /**\n     * Reads data into an array of bytes.\n     * \n     * @param b the array to write data to\n     * @param off offset into the buffer to start filling at\n     * @param len of bytes to read\n     * @return the number of bytes read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read(final byte[] b, final int off, final int len) throws IOException {\n        return getCurrentStream().read(b, off, len);\n    }\n    \n    private static long readUint64(final DataInput in) throws IOException {\n        // long rather than int as it might get shifted beyond the range of an int\n        final long firstByte = in.readUnsignedByte();\n        int mask = 0x80;\n        long value = 0;\n        for (int i = 0; i < 8; i++) {\n            if ((firstByte & mask) == 0) {\n                return value | ((firstByte & (mask - 1)) << (8 * i));\n            }\n            final long nextByte = in.readUnsignedByte();\n            value |= nextByte << (8 * i);\n            mask >>>= 1;\n        }\n        return value;\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a 7z file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this is the signature of a 7z archive.\n     * @since 1.8\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < sevenZSignature.length) {\n            return false;\n        }\n\n        for (int i = 0; i < sevenZSignature.length; i++) {\n            if (signature[i] != sevenZSignature[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    private static long skipBytesFully(final DataInput input, long bytesToSkip) throws IOException {\n        if (bytesToSkip < 1) {\n            return 0;\n        }\n        long skipped = 0;\n        while (bytesToSkip > Integer.MAX_VALUE) {\n            final long skippedNow = skipBytesFully(input, Integer.MAX_VALUE);\n            if (skippedNow == 0) {\n                return skipped;\n            }\n            skipped += skippedNow;\n            bytesToSkip -= skippedNow;\n        }\n        while (bytesToSkip > 0) {\n            final int skippedNow = input.skipBytes((int) bytesToSkip);\n            if (skippedNow == 0) {\n                return skipped;\n            }\n            skipped += skippedNow;\n            bytesToSkip -= skippedNow;\n        }\n        return skipped;\n    }\n    \n    @Override\n    public String toString() {\n      return archive.toString();\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.sevenz;\n\nimport java.io.BufferedInputStream;\nimport java.io.ByteArrayInputStream;\nimport java.io.Closeable;\nimport java.io.DataInput;\nimport java.io.DataInputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.RandomAccessFile;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.BitSet;\nimport java.util.LinkedList;\nimport java.util.zip.CRC32;\n\nimport org.apache.commons.compress.utils.BoundedInputStream;\nimport org.apache.commons.compress.utils.CRC32VerifyingInputStream;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * Reads a 7z file, using RandomAccessFile under\n * the covers.\n * <p>\n * The 7z file format is a flexible container\n * that can contain many compression and\n * encryption types, but at the moment only\n * only Copy, LZMA, LZMA2, BZIP2, Deflate and AES-256 + SHA-256\n * are supported.\n * <p>\n * The format is very Windows/Intel specific,\n * so it uses little-endian byte order,\n * doesn't store user/group or permission bits,\n * and represents times using NTFS timestamps\n * (100 nanosecond units since 1 January 1601).\n * Hence the official tools recommend against\n * using it for backup purposes on *nix, and\n * recommend .tar.7z or .tar.lzma or .tar.xz\n * instead.  \n * <p>\n * Both the header and file contents may be\n * compressed and/or encrypted. With both\n * encrypted, neither file names nor file\n * contents can be read, but the use of\n * encryption isn't plausibly deniable.\n * \n * @NotThreadSafe\n * @since 1.6\n */\npublic class SevenZFile implements Closeable {\n    static final int SIGNATURE_HEADER_SIZE = 32;\n\n    private final String fileName;\n    private RandomAccessFile file;\n    private final Archive archive;\n    private int currentEntryIndex = -1;\n    private int currentFolderIndex = -1;\n    private InputStream currentFolderInputStream = null;\n    private byte[] password;\n\n    private final ArrayList<InputStream> deferredBlockStreams = new ArrayList<InputStream>();\n\n    static final byte[] sevenZSignature = {\n        (byte)'7', (byte)'z', (byte)0xBC, (byte)0xAF, (byte)0x27, (byte)0x1C\n    };\n    \n    /**\n     * Reads a file as 7z archive\n     *\n     * @param filename the file to read\n     * @param password optional password if the archive is encrypted -\n     * the byte array is supposed to be the UTF16-LE encoded\n     * representation of the password.\n     * @throws IOException if reading the archive fails\n     */\n    public SevenZFile(final File filename, final byte[] password) throws IOException {\n        boolean succeeded = false;\n        this.file = new RandomAccessFile(filename, \"r\");\n        this.fileName = filename.getAbsolutePath();\n        try {\n            archive = readHeaders(password);\n            if (password != null) {\n                this.password = new byte[password.length];\n                System.arraycopy(password, 0, this.password, 0, password.length);\n            } else {\n                this.password = null;\n            }\n            succeeded = true;\n        } finally {\n            if (!succeeded) {\n                this.file.close();\n            }\n        }\n    }\n    \n    /**\n     * Reads a file as unencrypted 7z archive\n     *\n     * @param filename the file to read\n     * @throws IOException if reading the archive fails\n     */\n    public SevenZFile(final File filename) throws IOException {\n        this(filename, null);\n    }\n\n    /**\n     * Closes the archive.\n     * @throws IOException if closing the file fails\n     */\n    @Override\n    public void close() throws IOException {\n        if (file != null) {\n            try {\n                file.close();\n            } finally {\n                file = null;\n                if (password != null) {\n                    Arrays.fill(password, (byte) 0);\n                }\n                password = null;\n            }\n        }\n    }\n    \n    /**\n     * Returns the next Archive Entry in this archive.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    public SevenZArchiveEntry getNextEntry() throws IOException {\n        if (currentEntryIndex >= archive.files.length - 1) {\n            return null;\n        }\n        ++currentEntryIndex;\n        final SevenZArchiveEntry entry = archive.files[currentEntryIndex];\n        buildDecodingStream();\n        return entry;\n    }\n    \n    /**\n     * Returns meta-data of all archive entries.\n     *\n     * <p>This method only provides meta-data, the entries can not be\n     * used to read the contents, you still need to process all\n     * entries in order using {@link #getNextEntry} for that.</p>\n     *\n     * <p>The content methods are only available for entries that have\n     * already been reached via {@link #getNextEntry}.</p>\n     *\n     * @return meta-data of all archive entries.\n     * @since 1.11\n     */\n    public Iterable<SevenZArchiveEntry> getEntries() {\n        return Arrays.asList(archive.files);\n    }\n    \n    private Archive readHeaders(final byte[] password) throws IOException {\n        final byte[] signature = new byte[6];\n        file.readFully(signature);\n        if (!Arrays.equals(signature, sevenZSignature)) {\n            throw new IOException(\"Bad 7z signature\");\n        }\n        // 7zFormat.txt has it wrong - it's first major then minor\n        final byte archiveVersionMajor = file.readByte();\n        final byte archiveVersionMinor = file.readByte();\n        if (archiveVersionMajor != 0) {\n            throw new IOException(String.format(\"Unsupported 7z version (%d,%d)\",\n                    archiveVersionMajor, archiveVersionMinor));\n        }\n\n        final long startHeaderCrc = 0xffffFFFFL & Integer.reverseBytes(file.readInt());\n        final StartHeader startHeader = readStartHeader(startHeaderCrc);\n        \n        final int nextHeaderSizeInt = (int) startHeader.nextHeaderSize;\n        if (nextHeaderSizeInt != startHeader.nextHeaderSize) {\n            throw new IOException(\"cannot handle nextHeaderSize \" + startHeader.nextHeaderSize);\n        }\n        file.seek(SIGNATURE_HEADER_SIZE + startHeader.nextHeaderOffset);\n        final byte[] nextHeader = new byte[nextHeaderSizeInt];\n        file.readFully(nextHeader);\n        final CRC32 crc = new CRC32();\n        crc.update(nextHeader);\n        if (startHeader.nextHeaderCrc != crc.getValue()) {\n            throw new IOException(\"NextHeader CRC mismatch\");\n        }\n        \n        final ByteArrayInputStream byteStream = new ByteArrayInputStream(nextHeader);\n        DataInputStream nextHeaderInputStream = new DataInputStream(\n                byteStream);\n        Archive archive = new Archive();\n        int nid = nextHeaderInputStream.readUnsignedByte();\n        if (nid == NID.kEncodedHeader) {\n            nextHeaderInputStream =\n                readEncodedHeader(nextHeaderInputStream, archive, password);\n            // Archive gets rebuilt with the new header\n            archive = new Archive();\n            nid = nextHeaderInputStream.readUnsignedByte();\n        }\n        if (nid == NID.kHeader) {\n            readHeader(nextHeaderInputStream, archive);\n            nextHeaderInputStream.close();\n        } else {\n            throw new IOException(\"Broken or unsupported archive: no Header\");\n        }\n        return archive;\n    }\n    \n    private StartHeader readStartHeader(final long startHeaderCrc) throws IOException {\n        final StartHeader startHeader = new StartHeader();\n        DataInputStream dataInputStream = null;\n        try {\n             dataInputStream = new DataInputStream(new CRC32VerifyingInputStream(\n                    new BoundedRandomAccessFileInputStream(file, 20), 20, startHeaderCrc));\n             startHeader.nextHeaderOffset = Long.reverseBytes(dataInputStream.readLong());\n             startHeader.nextHeaderSize = Long.reverseBytes(dataInputStream.readLong());\n             startHeader.nextHeaderCrc = 0xffffFFFFL & Integer.reverseBytes(dataInputStream.readInt());\n             return startHeader;\n        } finally {\n            if (dataInputStream != null) {\n                dataInputStream.close();\n            }\n        }\n    }\n    \n    private void readHeader(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        \n        if (nid == NID.kArchiveProperties) {\n            readArchiveProperties(header);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kAdditionalStreamsInfo) {\n            throw new IOException(\"Additional streams unsupported\");\n            //nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kMainStreamsInfo) {\n            readStreamsInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kFilesInfo) {\n            readFilesInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated header, found \" + nid);\n        }\n    }\n    \n    private void readArchiveProperties(final DataInput input) throws IOException {\n        // FIXME: the reference implementation just throws them away?\n        int nid =  input.readUnsignedByte();\n        while (nid != NID.kEnd) {\n            final long propertySize = readUint64(input);\n            final byte[] property = new byte[(int)propertySize];\n            input.readFully(property);\n            nid = input.readUnsignedByte();\n        }\n    }\n    \n    private DataInputStream readEncodedHeader(final DataInputStream header, final Archive archive,\n                                              final byte[] password) throws IOException {\n        readStreamsInfo(header, archive);\n        \n        // FIXME: merge with buildDecodingStream()/buildDecoderStack() at some stage?\n        final Folder folder = archive.folders[0];\n        final int firstPackStreamIndex = 0;\n        final long folderOffset = SIGNATURE_HEADER_SIZE + archive.packPos +\n                0;\n        \n        file.seek(folderOffset);\n        InputStream inputStreamStack = new BoundedRandomAccessFileInputStream(file,\n                archive.packSizes[firstPackStreamIndex]);\n        for (final Coder coder : folder.getOrderedCoders()) {\n            if (coder.numInStreams != 1 || coder.numOutStreams != 1) {\n                throw new IOException(\"Multi input/output stream coders are not yet supported\");\n            }\n            inputStreamStack = Coders.addDecoder(fileName, inputStreamStack,\n                    folder.getUnpackSizeForCoder(coder), coder, password);\n        }\n        if (folder.hasCrc) {\n            inputStreamStack = new CRC32VerifyingInputStream(inputStreamStack,\n                    folder.getUnpackSize(), folder.crc);\n        }\n        final byte[] nextHeader = new byte[(int)folder.getUnpackSize()];\n        final DataInputStream nextHeaderInputStream = new DataInputStream(inputStreamStack);\n        try {\n            nextHeaderInputStream.readFully(nextHeader);\n        } finally {\n            nextHeaderInputStream.close();\n        }\n        return new DataInputStream(new ByteArrayInputStream(nextHeader));\n    }\n    \n    private void readStreamsInfo(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        \n        if (nid == NID.kPackInfo) {\n            readPackInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kUnpackInfo) {\n            readUnpackInfo(header, archive);\n            nid = header.readUnsignedByte();\n        } else {\n            // archive without unpack/coders info\n            archive.folders = new Folder[0];\n        }\n        \n        if (nid == NID.kSubStreamsInfo) {\n            readSubStreamsInfo(header, archive);\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated StreamsInfo\");\n        }\n    }\n    \n    private void readPackInfo(final DataInput header, final Archive archive) throws IOException {\n        archive.packPos = readUint64(header);\n        final long numPackStreams = readUint64(header);\n        int nid = header.readUnsignedByte();\n        if (nid == NID.kSize) {\n            archive.packSizes = new long[(int)numPackStreams];\n            for (int i = 0; i < archive.packSizes.length; i++) {\n                archive.packSizes[i] = readUint64(header);\n            }\n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid == NID.kCRC) {\n            archive.packCrcsDefined = readAllOrBits(header, (int)numPackStreams);\n            archive.packCrcs = new long[(int)numPackStreams];\n            for (int i = 0; i < (int)numPackStreams; i++) {\n                if (archive.packCrcsDefined.get(i)) {\n                    archive.packCrcs[i] = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated PackInfo (\" + nid + \")\");\n        }\n    }\n    \n    private void readUnpackInfo(final DataInput header, final Archive archive) throws IOException {\n        int nid = header.readUnsignedByte();\n        if (nid != NID.kFolder) {\n            throw new IOException(\"Expected kFolder, got \" + nid);\n        }\n        final long numFolders = readUint64(header);\n        final Folder[] folders = new Folder[(int)numFolders];\n        archive.folders = folders;\n        final int external = header.readUnsignedByte();\n        if (external != 0) {\n            throw new IOException(\"External unsupported\");\n        }\n        for (int i = 0; i < (int)numFolders; i++) {\n            folders[i] = readFolder(header);\n        }\n        \n        nid = header.readUnsignedByte();\n        if (nid != NID.kCodersUnpackSize) {\n            throw new IOException(\"Expected kCodersUnpackSize, got \" + nid);\n        }\n        for (final Folder folder : folders) {\n            folder.unpackSizes = new long[(int)folder.totalOutputStreams];\n            for (int i = 0; i < folder.totalOutputStreams; i++) {\n                folder.unpackSizes[i] = readUint64(header);\n            }\n        }\n        \n        nid = header.readUnsignedByte();\n        if (nid == NID.kCRC) {\n            final BitSet crcsDefined = readAllOrBits(header, (int)numFolders);\n            for (int i = 0; i < (int)numFolders; i++) {\n                if (crcsDefined.get(i)) {\n                    folders[i].hasCrc = true;\n                    folders[i].crc = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                } else {\n                    folders[i].hasCrc = false;\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated UnpackInfo\");\n        }\n    }\n    \n    private void readSubStreamsInfo(final DataInput header, final Archive archive) throws IOException {\n        for (final Folder folder : archive.folders) {\n            folder.numUnpackSubStreams = 1;\n        }\n        int totalUnpackStreams = archive.folders.length;\n        \n        int nid = header.readUnsignedByte();\n        if (nid == NID.kNumUnpackStream) {\n            totalUnpackStreams = 0;\n            for (final Folder folder : archive.folders) {\n                final long numStreams = readUint64(header);\n                folder.numUnpackSubStreams = (int)numStreams;\n                totalUnpackStreams += numStreams;\n            }\n            nid = header.readUnsignedByte();\n        }\n        \n        final SubStreamsInfo subStreamsInfo = new SubStreamsInfo();\n        subStreamsInfo.unpackSizes = new long[totalUnpackStreams];\n        subStreamsInfo.hasCrc = new BitSet(totalUnpackStreams);\n        subStreamsInfo.crcs = new long[totalUnpackStreams];\n        \n        int nextUnpackStream = 0;\n        for (final Folder folder : archive.folders) {\n            if (folder.numUnpackSubStreams == 0) {\n                continue;\n            }\n            long sum = 0;\n            if (nid == NID.kSize) {\n                for (int i = 0; i < folder.numUnpackSubStreams - 1; i++) {\n                    final long size = readUint64(header);\n                    subStreamsInfo.unpackSizes[nextUnpackStream++] = size;\n                    sum += size;\n                }\n            }\n            subStreamsInfo.unpackSizes[nextUnpackStream++] = folder.getUnpackSize() - sum;\n        }\n        if (nid == NID.kSize) {\n            nid = header.readUnsignedByte();\n        }\n        \n        int numDigests = 0;\n        for (final Folder folder : archive.folders) {\n            if (folder.numUnpackSubStreams != 1 || !folder.hasCrc) {\n                numDigests += folder.numUnpackSubStreams;\n            }\n        }\n        \n        if (nid == NID.kCRC) {\n            final BitSet hasMissingCrc = readAllOrBits(header, numDigests);\n            final long[] missingCrcs = new long[numDigests];\n            for (int i = 0; i < numDigests; i++) {\n                if (hasMissingCrc.get(i)) {\n                    missingCrcs[i] = 0xffffFFFFL & Integer.reverseBytes(header.readInt());\n                }\n            }\n            int nextCrc = 0;\n            int nextMissingCrc = 0;\n            for (final Folder folder: archive.folders) {\n                if (folder.numUnpackSubStreams == 1 && folder.hasCrc) {\n                    subStreamsInfo.hasCrc.set(nextCrc, true);\n                    subStreamsInfo.crcs[nextCrc] = folder.crc;\n                    ++nextCrc;\n                } else {\n                    for (int i = 0; i < folder.numUnpackSubStreams; i++) {\n                        subStreamsInfo.hasCrc.set(nextCrc, hasMissingCrc.get(nextMissingCrc));\n                        subStreamsInfo.crcs[nextCrc] = missingCrcs[nextMissingCrc];\n                        ++nextCrc;\n                        ++nextMissingCrc;\n                    }\n                }\n            }\n            \n            nid = header.readUnsignedByte();\n        }\n        \n        if (nid != NID.kEnd) {\n            throw new IOException(\"Badly terminated SubStreamsInfo\");\n        }\n        \n        archive.subStreamsInfo = subStreamsInfo;\n    }\n    \n    private Folder readFolder(final DataInput header) throws IOException {\n        final Folder folder = new Folder();\n        \n        final long numCoders = readUint64(header);\n        final Coder[] coders = new Coder[(int)numCoders];\n        long totalInStreams = 0;\n        long totalOutStreams = 0;\n        for (int i = 0; i < coders.length; i++) {\n            coders[i] = new Coder();\n            final int bits = header.readUnsignedByte();\n            final int idSize = bits & 0xf;\n            final boolean isSimple = (bits & 0x10) == 0;\n            final boolean hasAttributes = (bits & 0x20) != 0;\n            final boolean moreAlternativeMethods = (bits & 0x80) != 0;\n            \n            coders[i].decompressionMethodId = new byte[idSize];\n            header.readFully(coders[i].decompressionMethodId);\n            if (isSimple) {\n                coders[i].numInStreams = 1;\n                coders[i].numOutStreams = 1;\n            } else {\n                coders[i].numInStreams = readUint64(header);\n                coders[i].numOutStreams = readUint64(header);\n            }\n            totalInStreams += coders[i].numInStreams;\n            totalOutStreams += coders[i].numOutStreams;\n            if (hasAttributes) {\n                final long propertiesSize = readUint64(header);\n                coders[i].properties = new byte[(int)propertiesSize];\n                header.readFully(coders[i].properties);\n            }\n            // would need to keep looping as above:\n            while (moreAlternativeMethods) {\n                throw new IOException(\"Alternative methods are unsupported, please report. \" +\n                        \"The reference implementation doesn't support them either.\");\n            }\n        }\n        folder.coders = coders;\n        folder.totalInputStreams = totalInStreams;\n        folder.totalOutputStreams = totalOutStreams;\n        \n        if (totalOutStreams == 0) {\n            throw new IOException(\"Total output streams can't be 0\");\n        }\n        final long numBindPairs = totalOutStreams - 1;\n        final BindPair[] bindPairs = new BindPair[(int)numBindPairs];\n        for (int i = 0; i < bindPairs.length; i++) {\n            bindPairs[i] = new BindPair();\n            bindPairs[i].inIndex = readUint64(header);\n            bindPairs[i].outIndex = readUint64(header);\n        }\n        folder.bindPairs = bindPairs;\n        \n        if (totalInStreams < numBindPairs) {\n            throw new IOException(\"Total input streams can't be less than the number of bind pairs\");\n        }\n        final long numPackedStreams = totalInStreams - numBindPairs;\n        final long packedStreams[] = new long[(int)numPackedStreams];\n        if (numPackedStreams == 1) {\n            int i;\n            for (i = 0; i < (int)totalInStreams; i++) {\n                if (folder.findBindPairForInStream(i) < 0) {\n                    break;\n                }\n            }\n            if (i == (int)totalInStreams) {\n                throw new IOException(\"Couldn't find stream's bind pair index\");\n            }\n            packedStreams[0] = i;\n        } else {\n            for (int i = 0; i < (int)numPackedStreams; i++) {\n                packedStreams[i] = readUint64(header);\n            }\n        }\n        folder.packedStreams = packedStreams;\n        \n        return folder;\n    }\n    \n    private BitSet readAllOrBits(final DataInput header, final int size) throws IOException {\n        final int areAllDefined = header.readUnsignedByte();\n        final BitSet bits;\n        if (areAllDefined != 0) {\n            bits = new BitSet(size);\n            for (int i = 0; i < size; i++) {\n                bits.set(i, true);\n            }\n        } else {\n            bits = readBits(header, size);\n        }\n        return bits;\n    }\n    \n    private BitSet readBits(final DataInput header, final int size) throws IOException {\n        final BitSet bits = new BitSet(size);\n        int mask = 0;\n        int cache = 0;\n        for (int i = 0; i < size; i++) {\n            if (mask == 0) {\n                mask = 0x80;\n                cache = header.readUnsignedByte();\n            }\n            bits.set(i, (cache & mask) != 0);\n            mask >>>= 1;\n        }\n        return bits;\n    }\n    \n    private void readFilesInfo(final DataInput header, final Archive archive) throws IOException {\n        final long numFiles = readUint64(header);\n        final SevenZArchiveEntry[] files = new SevenZArchiveEntry[(int)numFiles];\n        for (int i = 0; i < files.length; i++) {\n            files[i] = new SevenZArchiveEntry();\n        }\n        BitSet isEmptyStream = null;\n        BitSet isEmptyFile = null; \n        BitSet isAnti = null;\n        while (true) {\n            final int propertyType = header.readUnsignedByte();\n            if (propertyType == 0) {\n                break;\n            }\n            final long size = readUint64(header);\n            switch (propertyType) {\n                case NID.kEmptyStream: {\n                    isEmptyStream = readBits(header, files.length);\n                    break;\n                }\n                case NID.kEmptyFile: {\n                    if (isEmptyStream == null) { // protect against NPE\n                        throw new IOException(\"Header format error: kEmptyStream must appear before kEmptyFile\");\n                    }\n                    isEmptyFile = readBits(header, isEmptyStream.cardinality());\n                    break;\n                }\n                case NID.kAnti: {\n                    if (isEmptyStream == null) { // protect against NPE\n                        throw new IOException(\"Header format error: kEmptyStream must appear before kAnti\");\n                    }\n                    isAnti = readBits(header, isEmptyStream.cardinality());\n                    break;\n                }\n                case NID.kName: {\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Not implemented\");\n                    }\n                    if (((size - 1) & 1) != 0) {\n                        throw new IOException(\"File names length invalid\");\n                    }\n                    final byte[] names = new byte[(int)(size - 1)];\n                    header.readFully(names);\n                    int nextFile = 0;\n                    int nextName = 0;\n                    for (int i = 0; i < names.length; i += 2) {\n                        if (names[i] == 0 && names[i+1] == 0) {\n                            files[nextFile++].setName(new String(names, nextName, i-nextName, CharsetNames.UTF_16LE));\n                            nextName = i + 2;\n                        }\n                    }\n                    if (nextName != names.length || nextFile != files.length) {\n                        throw new IOException(\"Error parsing file names\");\n                    }\n                    break;\n                }\n                case NID.kCTime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasCreationDate(timesDefined.get(i));\n                        if (files[i].getHasCreationDate()) {\n                            files[i].setCreationDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kATime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasAccessDate(timesDefined.get(i));\n                        if (files[i].getHasAccessDate()) {\n                            files[i].setAccessDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kMTime: {\n                    final BitSet timesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasLastModifiedDate(timesDefined.get(i));\n                        if (files[i].getHasLastModifiedDate()) {\n                            files[i].setLastModifiedDate(Long.reverseBytes(header.readLong()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kWinAttributes: {\n                    final BitSet attributesDefined = readAllOrBits(header, files.length);\n                    final int external = header.readUnsignedByte();\n                    if (external != 0) {\n                        throw new IOException(\"Unimplemented\");\n                    }\n                    for (int i = 0; i < files.length; i++) {\n                        files[i].setHasWindowsAttributes(attributesDefined.get(i));\n                        if (files[i].getHasWindowsAttributes()) {\n                            files[i].setWindowsAttributes(Integer.reverseBytes(header.readInt()));\n                        }\n                    }\n                    break;\n                }\n                case NID.kStartPos: {\n                    throw new IOException(\"kStartPos is unsupported, please report\");\n                }\n                case NID.kDummy: {\n                    // 7z 9.20 asserts the content is all zeros and ignores the property\n                    // Compress up to 1.8.1 would throw an exception, now we ignore it (see COMPRESS-287\n                    \n                    if (skipBytesFully(header, size) < size) {\n                        throw new IOException(\"Incomplete kDummy property\");\n                    }\n                    break;\n                }\n\n                default: {\n                    // Compress up to 1.8.1 would throw an exception, now we ignore it (see COMPRESS-287\n                    if (skipBytesFully(header, size) < size) {\n                        throw new IOException(\"Incomplete property of type \" + propertyType);\n                    }\n                    break;\n                }\n            }\n        }\n        int nonEmptyFileCounter = 0;\n        int emptyFileCounter = 0;\n        for (int i = 0; i < files.length; i++) {\n            files[i].setHasStream(isEmptyStream == null ? true : !isEmptyStream.get(i));\n            if (files[i].hasStream()) {\n                files[i].setDirectory(false);\n                files[i].setAntiItem(false);\n                files[i].setHasCrc(archive.subStreamsInfo.hasCrc.get(nonEmptyFileCounter));\n                files[i].setCrcValue(archive.subStreamsInfo.crcs[nonEmptyFileCounter]);\n                files[i].setSize(archive.subStreamsInfo.unpackSizes[nonEmptyFileCounter]);\n                ++nonEmptyFileCounter;\n            } else {\n                files[i].setDirectory(isEmptyFile == null ? true : !isEmptyFile.get(emptyFileCounter));\n                files[i].setAntiItem(isAnti == null ? false : isAnti.get(emptyFileCounter));\n                files[i].setHasCrc(false);\n                files[i].setSize(0);\n                ++emptyFileCounter;\n            }\n        }\n        archive.files = files;\n        calculateStreamMap(archive);\n    }\n    \n    private void calculateStreamMap(final Archive archive) throws IOException {\n        final StreamMap streamMap = new StreamMap();\n        \n        int nextFolderPackStreamIndex = 0;\n        final int numFolders = archive.folders != null ? archive.folders.length : 0;\n        streamMap.folderFirstPackStreamIndex = new int[numFolders];\n        for (int i = 0; i < numFolders; i++) {\n            streamMap.folderFirstPackStreamIndex[i] = nextFolderPackStreamIndex;\n            nextFolderPackStreamIndex += archive.folders[i].packedStreams.length;\n        }\n        \n        long nextPackStreamOffset = 0;\n        final int numPackSizes = archive.packSizes != null ? archive.packSizes.length : 0;\n        streamMap.packStreamOffsets = new long[numPackSizes];\n        for (int i = 0; i < numPackSizes; i++) {\n            streamMap.packStreamOffsets[i] = nextPackStreamOffset;\n            nextPackStreamOffset += archive.packSizes[i]; \n        }\n        \n        streamMap.folderFirstFileIndex = new int[numFolders];\n        streamMap.fileFolderIndex = new int[archive.files.length];\n        int nextFolderIndex = 0;\n        int nextFolderUnpackStreamIndex = 0;\n        for (int i = 0; i < archive.files.length; i++) {\n            if (!archive.files[i].hasStream() && nextFolderUnpackStreamIndex == 0) {\n                streamMap.fileFolderIndex[i] = -1;\n                continue;\n            }\n            if (nextFolderUnpackStreamIndex == 0) {\n                for (; nextFolderIndex < archive.folders.length; ++nextFolderIndex) {\n                    streamMap.folderFirstFileIndex[nextFolderIndex] = i;\n                    if (archive.folders[nextFolderIndex].numUnpackSubStreams > 0) {\n                        break;\n                    }\n                }\n                if (nextFolderIndex >= archive.folders.length) {\n                    throw new IOException(\"Too few folders in archive\");\n                }\n            }\n            streamMap.fileFolderIndex[i] = nextFolderIndex;\n            if (!archive.files[i].hasStream()) {\n                continue;\n            }\n            ++nextFolderUnpackStreamIndex;\n            if (nextFolderUnpackStreamIndex >= archive.folders[nextFolderIndex].numUnpackSubStreams) {\n                ++nextFolderIndex;\n                nextFolderUnpackStreamIndex = 0;\n            }\n        }\n        \n        archive.streamMap = streamMap;\n    }\n    \n    private void buildDecodingStream() throws IOException {\n        final int folderIndex = archive.streamMap.fileFolderIndex[currentEntryIndex];\n        if (folderIndex < 0) {\n            deferredBlockStreams.clear();\n            // TODO: previously it'd return an empty stream?\n            // new BoundedInputStream(new ByteArrayInputStream(new byte[0]), 0);\n            return;\n        }\n        final SevenZArchiveEntry file = archive.files[currentEntryIndex];\n        if (currentFolderIndex == folderIndex) {\n            // (COMPRESS-320).\n            // The current entry is within the same (potentially opened) folder. The\n            // previous stream has to be fully decoded before we can start reading\n            // but don't do it eagerly -- if the user skips over the entire folder nothing\n            // is effectively decompressed.\n\n            file.setContentMethods(archive.files[currentEntryIndex - 1].getContentMethods());\n        } else {\n            // We're opening a new folder. Discard any queued streams/ folder stream.\n            currentFolderIndex = folderIndex;\n            deferredBlockStreams.clear();\n            if (currentFolderInputStream != null) {\n                currentFolderInputStream.close();\n                currentFolderInputStream = null;\n            }\n            \n            final Folder folder = archive.folders[folderIndex];\n            final int firstPackStreamIndex = archive.streamMap.folderFirstPackStreamIndex[folderIndex];\n            final long folderOffset = SIGNATURE_HEADER_SIZE + archive.packPos +\n                    archive.streamMap.packStreamOffsets[firstPackStreamIndex];\n            currentFolderInputStream = buildDecoderStack(folder, folderOffset, firstPackStreamIndex, file);\n        }\n\n        InputStream fileStream = new BoundedInputStream(currentFolderInputStream, file.getSize());\n        if (file.getHasCrc()) {\n            fileStream = new CRC32VerifyingInputStream(fileStream, file.getSize(), file.getCrcValue());\n        }\n        \n        deferredBlockStreams.add(fileStream);\n    }\n\n    private InputStream buildDecoderStack(final Folder folder, final long folderOffset,\n                final int firstPackStreamIndex, final SevenZArchiveEntry entry) throws IOException {\n        file.seek(folderOffset);\n        InputStream inputStreamStack =\n            new BufferedInputStream(\n              new BoundedRandomAccessFileInputStream(file,\n                  archive.packSizes[firstPackStreamIndex]));\n        final LinkedList<SevenZMethodConfiguration> methods = new LinkedList<SevenZMethodConfiguration>();\n        for (final Coder coder : folder.getOrderedCoders()) {\n            if (coder.numInStreams != 1 || coder.numOutStreams != 1) {\n                throw new IOException(\"Multi input/output stream coders are not yet supported\");\n            }\n            final SevenZMethod method = SevenZMethod.byId(coder.decompressionMethodId);\n            inputStreamStack = Coders.addDecoder(fileName, inputStreamStack,\n                    folder.getUnpackSizeForCoder(coder), coder, password);\n            methods.addFirst(new SevenZMethodConfiguration(method,\n                     Coders.findByMethod(method).getOptionsFromCoder(coder, inputStreamStack)));\n        }\n        entry.setContentMethods(methods);\n        if (folder.hasCrc) {\n            return new CRC32VerifyingInputStream(inputStreamStack,\n                    folder.getUnpackSize(), folder.crc);\n        }\n        return inputStreamStack;\n    }\n    \n    /**\n     * Reads a byte of data.\n     * \n     * @return the byte read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read() throws IOException {\n        return getCurrentStream().read();\n    }\n    \n    private InputStream getCurrentStream() throws IOException {\n        if (archive.files[currentEntryIndex].getSize() == 0) {\n            return new ByteArrayInputStream(new byte[0]);\n        }\n        if (deferredBlockStreams.isEmpty()) {\n            throw new IllegalStateException(\"No current 7z entry (call getNextEntry() first).\");\n        }\n        \n        while (deferredBlockStreams.size() > 1) {\n            // In solid compression mode we need to decompress all leading folder'\n            // streams to get access to an entry. We defer this until really needed\n            // so that entire blocks can be skipped without wasting time for decompression.\n            final InputStream stream = deferredBlockStreams.remove(0);\n            IOUtils.skip(stream, Long.MAX_VALUE);\n            stream.close();\n        }\n\n        return deferredBlockStreams.get(0);\n    }\n\n    /**\n     * Reads data into an array of bytes.\n     * \n     * @param b the array to write data to\n     * @return the number of bytes read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read(final byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n    \n    /**\n     * Reads data into an array of bytes.\n     * \n     * @param b the array to write data to\n     * @param off offset into the buffer to start filling at\n     * @param len of bytes to read\n     * @return the number of bytes read, or -1 if end of input is reached\n     * @throws IOException\n     *             if an I/O error has occurred\n     */\n    public int read(final byte[] b, final int off, final int len) throws IOException {\n        return getCurrentStream().read(b, off, len);\n    }\n    \n    private static long readUint64(final DataInput in) throws IOException {\n        // long rather than int as it might get shifted beyond the range of an int\n        final long firstByte = in.readUnsignedByte();\n        int mask = 0x80;\n        long value = 0;\n        for (int i = 0; i < 8; i++) {\n            if ((firstByte & mask) == 0) {\n                return value | ((firstByte & (mask - 1)) << (8 * i));\n            }\n            final long nextByte = in.readUnsignedByte();\n            value |= nextByte << (8 * i);\n            mask >>>= 1;\n        }\n        return value;\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a 7z file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this is the signature of a 7z archive.\n     * @since 1.8\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < sevenZSignature.length) {\n            return false;\n        }\n\n        for (int i = 0; i < sevenZSignature.length; i++) {\n            if (signature[i] != sevenZSignature[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    private static long skipBytesFully(final DataInput input, long bytesToSkip) throws IOException {\n        if (bytesToSkip < 1) {\n            return 0;\n        }\n        long skipped = 0;\n        while (bytesToSkip > Integer.MAX_VALUE) {\n            final long skippedNow = skipBytesFully(input, Integer.MAX_VALUE);\n            if (skippedNow == 0) {\n                return skipped;\n            }\n            skipped += skippedNow;\n            bytesToSkip -= skippedNow;\n        }\n        while (bytesToSkip > 0) {\n            final int skippedNow = input.skipBytes((int) bytesToSkip);\n            if (skippedNow == 0) {\n                return skipped;\n            }\n            skipped += skippedNow;\n            bytesToSkip -= skippedNow;\n        }\n        return skipped;\n    }\n    \n    @Override\n    public String toString() {\n      return archive.toString();\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 37, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    // the global PAX header\n    private Map<String, String> globalPaxHeaders = new HashMap<String, String>();\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(final InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize,\n                                 final String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize,\n                                 final String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (isDirectory()) {\n            return 0;\n        }\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0 || isDirectory()) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(final int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        final byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (final IllegalArgumentException e) {\n            throw new IOException(\"Error detected parsing the header\", e);\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            final byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            final byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isGlobalPaxHeader()){ // Process Global Pax headers\n            readGlobalPaxHeaders();\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        } else if (!globalPaxHeaders.isEmpty()) {\n            applyPaxHeadersToCurrentEntry(globalPaxHeaders);\n        }\n\n        if (currEntry.isOldGNUSparse()){ // Process sparse files\n            readOldGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (!isDirectory() && this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            final long numRecords = (this.entrySize / this.recordSize) + 1;\n            final long padding = (numRecords * this.recordSize) - this.entrySize;\n            final long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        final ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            final byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(final byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        final byte[] record = new byte[recordSize];\n\n        final int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void readGlobalPaxHeaders() throws IOException {\n        globalPaxHeaders = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n    }\n\n    private void paxHeaders() throws IOException{\n        final Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    // NOTE, using a Map here makes it impossible to ever support GNU\n    // sparse files using the PAX Format 0.0, see\n    // https://www.gnu.org/software/tar/manual/html_section/tar_92.html#SEC188\n    Map<String, String> parsePaxHeaders(final InputStream i)\n        throws IOException {\n        final Map<String, String> headers = new HashMap<String, String>(globalPaxHeaders);\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == ' '){\n                    // Get keyword\n                    final ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            final String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            if (restLen == 1) { // only NL\n                                headers.remove(keyword);\n                            } else {\n                                final byte[] rest = new byte[restLen];\n                                final int got = IOUtils.readFully(i, rest);\n                                if (got != restLen) {\n                                    throw new IOException(\"Failed to read \"\n                                                          + \"Paxheader. Expected \"\n                                                          + restLen\n                                                          + \" bytes, read \"\n                                                          + got);\n                                }\n                                // Drop trailing NL\n                                final String value = new String(rest, 0,\n                                                          restLen - 1, CharsetNames.UTF_8);\n                                headers.put(keyword, value);\n                            }\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(final Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         *\n         * GNU sparse files use additional members, we use\n         * GNU.sparse.size to detect the 0.0 and 0.1 versions and\n         * GNU.sparse.realsize for 1.0.\n         *\n         * star files use additional members of which we use\n         * SCHILY.filetype in order to detect star sparse files.\n         */\n        for (final Entry<String, String> ent : headers.entrySet()){\n            final String key = ent.getKey();\n            final String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Long.parseLong(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Long.parseLong(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            } else if (\"GNU.sparse.size\".equals(key)) {\n                currEntry.fillGNUSparse0xData(headers);\n            } else if (\"GNU.sparse.realsize\".equals(key)) {\n                currEntry.fillGNUSparse1xData(headers);\n            } else if (\"SCHILY.filetype\".equals(key) && \"sparse\".equals(val)) {\n                currEntry.fillStarSparseData(headers);\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readOldGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                final byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    private boolean isDirectory() {\n        return currEntry != null && currEntry.isDirectory();\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        final boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(final byte[] buf, final int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || isDirectory() || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            final TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(final TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(final boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        final long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            final long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\n\n/*\n * This package is based on the work done by Timothy Gerard Endres\n * (time@ice.com) to whom the Ant project is very grateful for his great code.\n */\n\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.CharsetNames;\nimport org.apache.commons.compress.utils.IOUtils;\n\n/**\n * The TarInputStream reads a UNIX tar archive as an InputStream.\n * methods are provided to position at each successive entry in\n * the archive, and the read each entry as a normal input stream\n * using read().\n * @NotThreadSafe\n */\npublic class TarArchiveInputStream extends ArchiveInputStream {\n\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[SMALL_BUFFER_SIZE];\n\n    /** The size the TAR header */\n    private final int recordSize;\n\n    /** The size of a block */\n    private final int blockSize;\n\n    /** True if file has hit EOF */\n    private boolean hasHitEOF;\n\n    /** Size of the current entry */\n    private long entrySize;\n\n    /** How far into the entry the stream is at */\n    private long entryOffset;\n\n    /** An input stream to read from */\n    private final InputStream is;\n\n    /** The meta-data about the current entry */\n    private TarArchiveEntry currEntry;\n\n    /** The encoding of the file */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    // the global PAX header\n    private Map<String, String> globalPaxHeaders = new HashMap<String, String>();\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     */\n    public TarArchiveInputStream(final InputStream is) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final String encoding) {\n        this(is, TarConstants.DEFAULT_BLKSIZE, TarConstants.DEFAULT_RCDSIZE,\n             encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize,\n                                 final String encoding) {\n        this(is, blockSize, TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize) {\n        this(is, blockSize, recordSize, null);      \n    }\n\n    /**\n     * Constructor for TarInputStream.\n     * @param is the input stream to use\n     * @param blockSize the block size to use\n     * @param recordSize the record size to use\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     */\n    public TarArchiveInputStream(final InputStream is, final int blockSize, final int recordSize,\n                                 final String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    /**\n     * Closes this stream. Calls the TarBuffer's close() method.\n     * @throws IOException on error\n     */\n    @Override\n    public void close() throws IOException {\n        is.close();\n    }\n\n    /**\n     * Get the record size being used by this stream's buffer.\n     *\n     * @return The TarBuffer record size.\n     */\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    /**\n     * Get the available data that can be read from the current\n     * entry in the archive. This does not indicate how much data\n     * is left in the entire archive, only in the current entry.\n     * This value is determined from the entry's size header field\n     * and the amount of data already read from the current entry.\n     * Integer.MAX_VALUE is returned in case more than Integer.MAX_VALUE\n     * bytes are left in the current entry in the archive.\n     *\n     * @return The number of available bytes for the current entry.\n     * @throws IOException for signature\n     */\n    @Override\n    public int available() throws IOException {\n        if (isDirectory()) {\n            return 0;\n        }\n        if (entrySize - entryOffset > Integer.MAX_VALUE) {\n            return Integer.MAX_VALUE;\n        }\n        return (int) (entrySize - entryOffset);\n    }\n\n    \n    /**\n     * Skips over and discards <code>n</code> bytes of data from this input\n     * stream. The <code>skip</code> method may, for a variety of reasons, end\n     * up skipping over some smaller number of bytes, possibly <code>0</code>.\n     * This may result from any of a number of conditions; reaching end of file\n     * or end of entry before <code>n</code> bytes have been skipped; are only\n     * two possibilities. The actual number of bytes skipped is returned. If\n     * <code>n</code> is negative, no bytes are skipped.\n     * \n     * \n     * @param n\n     *            the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @exception IOException\n     *                if some other I/O error occurs.\n     */\n    @Override\n    public long skip(final long n) throws IOException {\n        if (n <= 0 || isDirectory()) {\n            return 0;\n        }\n\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(Math.min(n, available)); \n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    /**\n     * Since we do not support marking just yet, we return false.\n     *\n     * @return False.\n     */\n    @Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     *\n     * @param markLimit The limit to mark.\n     */\n    @Override\n    public void mark(final int markLimit) {\n    }\n\n    /**\n     * Since we do not support marking just yet, we do nothing.\n     */\n    @Override\n    public synchronized void reset() {\n    }\n\n    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            /* Skip will only go to the end of the current entry */\n            IOUtils.skip(this, Long.MAX_VALUE);\n\n            /* skip to the end of the last record */\n            skipRecordPadding();\n        }\n\n        final byte[] headerBuf = getRecord();\n\n        if (headerBuf == null) {\n            /* hit EOF */\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            currEntry = new TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (final IllegalArgumentException e) {\n            throw new IOException(\"Error detected parsing the header\", e);\n        }\n\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n\n        if (currEntry.isGNULongLinkEntry()) {\n            final byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long link entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n\n        if (currEntry.isGNULongNameEntry()) {\n            final byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                // Bugzilla: 40334\n                // Malformed tar file - long entry name not followed by\n                // entry\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n\n        if (currEntry.isGlobalPaxHeader()){ // Process Global Pax headers\n            readGlobalPaxHeaders();\n        }\n\n        if (currEntry.isPaxHeader()){ // Process Pax headers\n            paxHeaders();\n        } else if (!globalPaxHeaders.isEmpty()) {\n            applyPaxHeadersToCurrentEntry(globalPaxHeaders);\n        }\n\n        if (currEntry.isOldGNUSparse()){ // Process sparse files\n            readOldGNUSparse();\n        }\n\n        // If the size of the next element in the archive has changed\n        // due to a new size being reported in the posix header\n        // information, we update entrySize here so that it contains\n        // the correct value.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }\n    \n    /**\n     * The last record block should be written at the full size, so skip any\n     * additional space used to fill a record after an entry\n     */\n    private void skipRecordPadding() throws IOException {\n        if (!isDirectory() && this.entrySize > 0 && this.entrySize % this.recordSize != 0) {\n            final long numRecords = (this.entrySize / this.recordSize) + 1;\n            final long padding = (numRecords * this.recordSize) - this.entrySize;\n            final long skipped = IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Get the next entry in this tar archive as longname data.\n     *\n     * @return The next entry in the archive as longname data, or null.\n     * @throws IOException on error\n     */\n    protected byte[] getLongNameData() throws IOException {\n        // read in the name\n        final ByteArrayOutputStream longName = new ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        }\n        getNextEntry();\n        if (currEntry == null) {\n            // Bugzilla: 40334\n            // Malformed tar file - long entry name not followed by entry\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        // remove trailing null terminator(s)\n        length = longNameData.length;\n        while (length > 0 && longNameData[length - 1] == 0) {\n            --length;\n        }\n        if (length != longNameData.length) {\n            final byte[] l = new byte[length];\n            System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    /**\n     * Get the next record in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry.\n     *\n     * <p>If there are no more entries in the archive, null will be\n     * returned to indicate that the end of the archive has been\n     * reached.  At the same time the {@code hasHitEOF} marker will be\n     * set to true.</p>\n     *\n     * @return The next header in the archive, or null.\n     * @throws IOException on error\n     */\n    private byte[] getRecord() throws IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && headerBuf != null) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    /**\n     * Determine if an archive record indicate End of Archive. End of\n     * archive is indicated by a record that consists entirely of null bytes.\n     *\n     * @param record The record data to check.\n     * @return true if the record data is an End of Archive\n     */\n    protected boolean isEOFRecord(final byte[] record) {\n        return record == null || ArchiveUtils.isArrayZero(record, recordSize);\n    }\n    \n    /**\n     * Read a record from the input stream and return the data.\n     *\n     * @return The record data or null if EOF has been hit.\n     * @throws IOException on error\n     */\n    protected byte[] readRecord() throws IOException {\n\n        final byte[] record = new byte[recordSize];\n\n        final int readNow = IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n\n        return record;\n    }\n\n    private void readGlobalPaxHeaders() throws IOException {\n        globalPaxHeaders = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n    }\n\n    private void paxHeaders() throws IOException{\n        final Map<String, String> headers = parsePaxHeaders(this);\n        getNextEntry(); // Get the actual file entry\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    // NOTE, using a Map here makes it impossible to ever support GNU\n    // sparse files using the PAX Format 0.0, see\n    // https://www.gnu.org/software/tar/manual/html_section/tar_92.html#SEC188\n    Map<String, String> parsePaxHeaders(final InputStream i)\n        throws IOException {\n        final Map<String, String> headers = new HashMap<String, String>(globalPaxHeaders);\n        // Format is \"length keyword=value\\n\";\n        while(true){ // get length\n            int ch;\n            int len = 0;\n            int read = 0;\n            while((ch = i.read()) != -1) {\n                read++;\n                if (ch == '\\n') { // blank line in header\n                    break;\n                } else if (ch == ' '){ // End of length string\n                    // Get keyword\n                    final ByteArrayOutputStream coll = new ByteArrayOutputStream();\n                    while((ch = i.read()) != -1) {\n                        read++;\n                        if (ch == '='){ // end of keyword\n                            final String keyword = coll.toString(CharsetNames.UTF_8);\n                            // Get rest of entry\n                            final int restLen = len - read;\n                            if (restLen == 1) { // only NL\n                                headers.remove(keyword);\n                            } else {\n                                final byte[] rest = new byte[restLen];\n                                final int got = IOUtils.readFully(i, rest);\n                                if (got != restLen) {\n                                    throw new IOException(\"Failed to read \"\n                                                          + \"Paxheader. Expected \"\n                                                          + restLen\n                                                          + \" bytes, read \"\n                                                          + got);\n                                }\n                                // Drop trailing NL\n                                final String value = new String(rest, 0,\n                                                          restLen - 1, CharsetNames.UTF_8);\n                                headers.put(keyword, value);\n                            }\n                            break;\n                        }\n                        coll.write((byte) ch);\n                    }\n                    break; // Processed single header\n                }\n                len *= 10;\n                len += ch - '0';\n            }\n            if (ch == -1){ // EOF\n                break;\n            }\n        }\n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(final Map<String, String> headers) {\n        /*\n         * The following headers are defined for Pax.\n         * atime, ctime, charset: cannot use these without changing TarArchiveEntry fields\n         * mtime\n         * comment\n         * gid, gname\n         * linkpath\n         * size\n         * uid,uname\n         * SCHILY.devminor, SCHILY.devmajor: don't have setters/getters for those\n         *\n         * GNU sparse files use additional members, we use\n         * GNU.sparse.size to detect the 0.0 and 0.1 versions and\n         * GNU.sparse.realsize for 1.0.\n         *\n         * star files use additional members of which we use\n         * SCHILY.filetype in order to detect star sparse files.\n         */\n        for (final Entry<String, String> ent : headers.entrySet()){\n            final String key = ent.getKey();\n            final String val = ent.getValue();\n            if (\"path\".equals(key)){\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)){\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Long.parseLong(val));\n            } else if (\"gname\".equals(key)){\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Long.parseLong(val));\n            } else if (\"uname\".equals(key)){\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)){\n                currEntry.setSize(Long.parseLong(val));\n            } else if (\"mtime\".equals(key)){\n                currEntry.setModTime((long) (Double.parseDouble(val) * 1000));\n            } else if (\"SCHILY.devminor\".equals(key)){\n                currEntry.setDevMinor(Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)){\n                currEntry.setDevMajor(Integer.parseInt(val));\n            } else if (\"GNU.sparse.size\".equals(key)) {\n                currEntry.fillGNUSparse0xData(headers);\n            } else if (\"GNU.sparse.realsize\".equals(key)) {\n                currEntry.fillGNUSparse1xData(headers);\n            } else if (\"SCHILY.filetype\".equals(key) && \"sparse\".equals(val)) {\n                currEntry.fillStarSparseData(headers);\n            }\n        }\n    }\n\n    /**\n     * Adds the sparse chunks from the current entry to the sparse chunks,\n     * including any additional sparse entries following the current entry.\n     *\n     * @throws IOException on error\n     *\n     * @todo Sparse files get not yet really processed.\n     */\n    private void readOldGNUSparse() throws IOException {\n        /* we do not really process sparse files yet\n        sparses = new ArrayList();\n        sparses.addAll(currEntry.getSparses());\n        */\n        if (currEntry.isExtended()) {\n            TarArchiveSparseEntry entry;\n            do {\n                final byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new TarArchiveSparseEntry(headerBuf);\n                /* we do not really process sparse files yet\n                sparses.addAll(entry.getSparses());\n                */\n            } while (entry.isExtended());\n        }\n    }\n\n    private boolean isDirectory() {\n        return currEntry != null && currEntry.isDirectory();\n    }\n\n    /**\n     * Returns the next Archive Entry in this Stream.\n     *\n     * @return the next entry,\n     *         or {@code null} if there are no more entries\n     * @throws IOException if the next entry could not be read\n     */\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextTarEntry();\n    }\n    \n    /**\n     * Tries to read the next record rewinding the stream if it is not a EOF record.\n     *\n     * <p>This is meant to protect against cases where a tar\n     * implementation has written only one EOF record when two are\n     * expected.  Actually this won't help since a non-conforming\n     * implementation likely won't fill full blocks consisting of - by\n     * default - ten records either so we probably have already read\n     * beyond the archive anyway.</p>\n     */\n    private void tryToConsumeSecondEOFRecord() throws IOException {\n        boolean shouldReset = true;\n        final boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n            \tis.reset();\n            }\n        }\n    }\n\n    /**\n     * Reads bytes from the current tar archive entry.\n     *\n     * This method is aware of the boundaries of the current\n     * entry in the archive and will deal with them as if they\n     * were this stream's start and EOF.\n     *\n     * @param buf The buffer into which to place bytes read.\n     * @param offset The offset at which to place bytes read.\n     * @param numToRead The number of bytes to read.\n     * @return The number of bytes read, or -1 at EOF.\n     * @throws IOException on error\n     */\n    @Override\n    public int read(final byte[] buf, final int offset, int numToRead) throws IOException {\n    \tint totalRead = 0;\n\n        if (hasHitEOF || isDirectory() || entryOffset >= entrySize) {\n            return -1;\n        }\n\n        if (currEntry == null) {\n            throw new IllegalStateException(\"No current tar entry\");\n        }\n\n        numToRead = Math.min(numToRead, available());\n        \n        totalRead = is.read(buf, offset, numToRead);\n        \n        if (totalRead == -1) {\n            if (numToRead > 0) {\n                throw new IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n\n        return totalRead;\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if the current entry is a sparse file.</p>\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof TarArchiveEntry) {\n            final TarArchiveEntry te = (TarArchiveEntry) ae;\n            return !te.isSparse();\n        }\n        return false;\n    }\n\n    /**\n     * Get the current TAR Archive Entry that this input stream is processing\n     * \n     * @return The current Archive Entry\n     */\n    public TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(final TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(final boolean b) {\n        hasHitEOF = b;\n    }\n\n    /**\n     * This method is invoked once the end of the archive is hit, it\n     * tries to consume the remaining bytes under the assumption that\n     * the tool creating this archive has padded the last block.\n     */\n    private void consumeRemainderOfLastBlock() throws IOException {\n        final long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            final long skipped = IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a tar file.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a tar archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < TarConstants.VERSION_OFFSET+TarConstants.VERSIONLEN) {\n            return false;\n        }\n\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_POSIX,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_POSIX,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_GNU,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            (\n             ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_SPACE,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            ||\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_GNU_ZERO,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n            )\n                ){\n            return true;\n        }\n        // COMPRESS-107 - recognise Ant tar files\n        if (ArchiveUtils.matchAsciiBuffer(TarConstants.MAGIC_ANT,\n                signature, TarConstants.MAGIC_OFFSET, TarConstants.MAGICLEN)\n            &&\n            ArchiveUtils.matchAsciiBuffer(TarConstants.VERSION_ANT,\n                signature, TarConstants.VERSION_OFFSET, TarConstants.VERSIONLEN)\n                ){\n            return true;\n        }\n        return false;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 38, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarArchiveEntry", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.util.Map;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * This class represents an entry in a Tar archive. It consists\n * of the entry's header, as well as the entry's File. Entries\n * can be instantiated in one of three ways, depending on how\n * they are to be used.\n * <p>\n * TarEntries that are created from the header bytes read from\n * an archive are instantiated with the TarEntry( byte[] )\n * constructor. These entries will be used when extracting from\n * or listing the contents of an archive. These entries have their\n * header filled in using the header bytes. They also set the File\n * to null, since they reference an archive entry not a file.\n * <p>\n * TarEntries that are created from Files that are to be written\n * into an archive are instantiated with the TarEntry( File )\n * constructor. These entries have their header filled in using\n * the File's information. They also keep a reference to the File\n * for convenience when writing entries.\n * <p>\n * Finally, TarEntries can be constructed from nothing but a name.\n * This allows the programmer to construct the entry by hand, for\n * instance when only an InputStream is available for writing to\n * the archive, and the header information is constructed from\n * other information. In this case the header fields are set to\n * defaults and the File is set to null.\n *\n * <p>\n * The C structure for a Tar Entry's header is:\n * <pre>\n * struct header {\n * char name[100];     // TarConstants.NAMELEN    - offset   0\n * char mode[8];       // TarConstants.MODELEN    - offset 100\n * char uid[8];        // TarConstants.UIDLEN     - offset 108\n * char gid[8];        // TarConstants.GIDLEN     - offset 116\n * char size[12];      // TarConstants.SIZELEN    - offset 124\n * char mtime[12];     // TarConstants.MODTIMELEN - offset 136\n * char chksum[8];     // TarConstants.CHKSUMLEN  - offset 148\n * char linkflag[1];   //                         - offset 156\n * char linkname[100]; // TarConstants.NAMELEN    - offset 157\n * The following fields are only present in new-style POSIX tar archives:\n * char magic[6];      // TarConstants.MAGICLEN   - offset 257\n * char version[2];    // TarConstants.VERSIONLEN - offset 263\n * char uname[32];     // TarConstants.UNAMELEN   - offset 265\n * char gname[32];     // TarConstants.GNAMELEN   - offset 297\n * char devmajor[8];   // TarConstants.DEVLEN     - offset 329\n * char devminor[8];   // TarConstants.DEVLEN     - offset 337\n * char prefix[155];   // TarConstants.PREFIXLEN  - offset 345\n * // Used if \"name\" field is not long enough to hold the path\n * char pad[12];       // NULs                    - offset 500\n * } header;\n * All unused bytes are set to null.\n * New-style GNU tar files are slightly different from the above.\n * For values of size larger than 077777777777L (11 7s)\n * or uid and gid larger than 07777777L (7 7s)\n * the sign bit of the first byte is set, and the rest of the\n * field is the binary representation of the number.\n * See TarUtils.parseOctalOrBinary.\n * </pre>\n *\n * <p>\n * The C structure for a old GNU Tar Entry's header is:\n * <pre>\n * struct oldgnu_header {\n * char unused_pad1[345]; // TarConstants.PAD1LEN_GNU       - offset 0\n * char atime[12];        // TarConstants.ATIMELEN_GNU      - offset 345\n * char ctime[12];        // TarConstants.CTIMELEN_GNU      - offset 357\n * char offset[12];       // TarConstants.OFFSETLEN_GNU     - offset 369\n * char longnames[4];     // TarConstants.LONGNAMESLEN_GNU  - offset 381\n * char unused_pad2;      // TarConstants.PAD2LEN_GNU       - offset 385\n * struct sparse sp[4];   // TarConstants.SPARSELEN_GNU     - offset 386\n * char isextended;       // TarConstants.ISEXTENDEDLEN_GNU - offset 482\n * char realsize[12];     // TarConstants.REALSIZELEN_GNU   - offset 483\n * char unused_pad[17];   // TarConstants.PAD3LEN_GNU       - offset 495\n * };\n * </pre>\n * Whereas, \"struct sparse\" is:\n * <pre>\n * struct sparse {\n * char offset[12];   // offset 0\n * char numbytes[12]; // offset 12\n * };\n * </pre>\n *\n * <p>\n * The C structure for a xstar (J\u00f6rg Schilling star) Tar Entry's header is:\n * <pre>\n * struct star_header {\n *  char name[100];\t\t// offset   0\n *  char mode[8];\t\t// offset 100\n *  char uid[8];\t\t// offset 108\n *  char gid[8];\t\t// offset 116\n *  char size[12];\t\t// offset 124\n *  char mtime[12];\t\t// offset 136\n *  char chksum[8];\t\t// offset 148\n *  char typeflag;\t\t// offset 156\n *  char linkname[100];\t\t// offset 157\n *  char magic[6];\t\t// offset 257\n *  char version[2];\t\t// offset 263\n *  char uname[32];\t\t// offset 265\n *  char gname[32];\t\t// offset 297\n *  char devmajor[8];\t\t// offset 329\n *  char devminor[8];\t\t// offset 337\n *  char prefix[131];\t\t// offset 345\n *  char atime[12];             // offset 476\n *  char ctime[12];             // offset 488\n *  char mfill[8];              // offset 500 \n *  char xmagic[4];             // offset 508  \"tar\"\n * };\n * </pre>\n * <p>which is identical to new-style POSIX up to the first 130 bytes of the prefix.</p>\n *\n * @NotThreadSafe\n */\n\npublic class TarArchiveEntry implements TarConstants, ArchiveEntry {\n    private static final TarArchiveEntry[] EMPTY_TAR_ARCHIVE_ENTRIES = new TarArchiveEntry[0];\n\n    /** The entry's name. */\n    private String name = \"\";\n\n    /** Whether to enforce leading slashes on the name */\n    private boolean preserveLeadingSlashes;\n\n    /** The entry's permission mode. */\n    private int mode;\n\n    /** The entry's user id. */\n    private long userId = 0;\n\n    /** The entry's group id. */\n    private long groupId = 0;\n\n    /** The entry's size. */\n    private long size = 0;\n\n    /** The entry's modification time. */\n    private long modTime;\n\n    /** If the header checksum is reasonably correct. */\n    private boolean checkSumOK;\n\n    /** The entry's link flag. */\n    private byte linkFlag;\n\n    /** The entry's link name. */\n    private String linkName = \"\";\n\n    /** The entry's magic tag. */\n    private String magic = MAGIC_POSIX;\n    /** The version of the format */\n    private String version = VERSION_POSIX;\n\n    /** The entry's user name. */\n    private String userName;\n\n    /** The entry's group name. */\n    private String groupName = \"\";\n\n    /** The entry's major device number. */\n    private int devMajor = 0;\n\n    /** The entry's minor device number. */\n    private int devMinor = 0;\n\n    /** If an extension sparse header follows. */\n    private boolean isExtended;\n\n    /** The entry's real size in case of a sparse file. */\n    private long realSize;\n\n    /** is this entry a GNU sparse entry using one of the PAX formats? */\n    private boolean paxGNUSparse;\n\n    /** is this entry a star sparse entry using the PAX header? */\n    private boolean starSparse;\n\n    /** The entry's file reference */\n    private final File file;\n\n    /** Maximum length of a user's name in the tar file */\n    public static final int MAX_NAMELEN = 31;\n\n    /** Default permissions bits for directories */\n    public static final int DEFAULT_DIR_MODE = 040755;\n\n    /** Default permissions bits for files */\n    public static final int DEFAULT_FILE_MODE = 0100644;\n\n    /** Convert millis to seconds */\n    public static final int MILLIS_PER_SECOND = 1000;\n\n    /**\n     * Construct an empty entry and prepares the header values.\n     */\n    private TarArchiveEntry() {\n        String user = System.getProperty(\"user.name\", \"\");\n\n        if (user.length() > MAX_NAMELEN) {\n            user = user.substring(0, MAX_NAMELEN);\n        }\n\n        this.userName = user;\n        this.file = null;\n    }\n\n    /**\n     * Construct an entry with only a name. This allows the programmer\n     * to construct the entry's header \"by hand\". File is set to null.\n     *\n     * @param name the entry name\n     */\n    public TarArchiveEntry(final String name) {\n        this(name, false);\n    }\n\n    /**\n     * Construct an entry with only a name. This allows the programmer\n     * to construct the entry's header \"by hand\". File is set to null.\n     *\n     * @param name the entry name\n     * @param preserveLeadingSlashes whether to allow leading slashes\n     * in the name.\n     *\n     * @since 1.1\n     */\n    public TarArchiveEntry(String name, final boolean preserveLeadingSlashes) {\n        this();\n\n        this.preserveLeadingSlashes = preserveLeadingSlashes;\n\n        name = normalizeFileName(name, preserveLeadingSlashes);\n        final boolean isDir = name.endsWith(\"/\");\n\n        this.name = name;\n        this.mode = isDir ? DEFAULT_DIR_MODE : DEFAULT_FILE_MODE;\n        this.linkFlag = isDir ? LF_DIR : LF_NORMAL;\n        this.modTime = new Date().getTime() / MILLIS_PER_SECOND;\n        this.userName = \"\";\n    }\n\n    /**\n     * Construct an entry with a name and a link flag.\n     *\n     * @param name the entry name\n     * @param linkFlag the entry link flag.\n     */\n    public TarArchiveEntry(final String name, final byte linkFlag) {\n        this(name, linkFlag, false);\n    }\n\n    /**\n     * Construct an entry with a name and a link flag.\n     *\n     * @param name the entry name\n     * @param linkFlag the entry link flag.\n     * @param preserveLeadingSlashes whether to allow leading slashes\n     * in the name.\n     *\n     * @since 1.5\n     */\n    public TarArchiveEntry(final String name, final byte linkFlag, final boolean preserveLeadingSlashes) {\n        this(name, preserveLeadingSlashes);\n        this.linkFlag = linkFlag;\n        if (linkFlag == LF_GNUTYPE_LONGNAME) {\n            magic = MAGIC_GNU;\n            version = VERSION_GNU_SPACE;\n        }\n    }\n\n    /**\n     * Construct an entry for a file. File is set to file, and the\n     * header is constructed from information from the file.\n     * The name is set from the normalized file path.\n     *\n     * @param file The file that the entry represents.\n     */\n    public TarArchiveEntry(final File file) {\n        this(file, file.getPath());\n    }\n\n    /**\n     * Construct an entry for a file. File is set to file, and the\n     * header is constructed from information from the file.\n     *\n     * @param file The file that the entry represents.\n     * @param fileName the name to be used for the entry.\n     */\n    public TarArchiveEntry(final File file, final String fileName) {\n        final String normalizedName = normalizeFileName(fileName, false);\n        this.file = file;\n\n        if (file.isDirectory()) {\n            this.mode = DEFAULT_DIR_MODE;\n            this.linkFlag = LF_DIR;\n\n            final int nameLength = normalizedName.length();\n            if (nameLength == 0 || normalizedName.charAt(nameLength - 1) != '/') {\n                this.name = normalizedName + \"/\";\n            } else {\n                this.name = normalizedName;\n            }\n        } else {\n            this.mode = DEFAULT_FILE_MODE;\n            this.linkFlag = LF_NORMAL;\n            this.size = file.length();\n            this.name = normalizedName;\n        }\n\n        this.modTime = file.lastModified() / MILLIS_PER_SECOND;\n        this.userName = \"\";\n    }\n\n    /**\n     * Construct an entry from an archive's header bytes. File is set\n     * to null.\n     *\n     * @param headerBuf The header bytes from a tar archive entry.\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     */\n    public TarArchiveEntry(final byte[] headerBuf) {\n        this();\n        parseTarHeader(headerBuf);\n    }\n\n    /**\n     * Construct an entry from an archive's header bytes. File is set\n     * to null.\n     *\n     * @param headerBuf The header bytes from a tar archive entry.\n     * @param encoding encoding to use for file names\n     * @since 1.4\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     * @throws IOException on error\n     */\n    public TarArchiveEntry(final byte[] headerBuf, final ZipEncoding encoding)\n        throws IOException {\n        this();\n        parseTarHeader(headerBuf, encoding);\n    }\n\n    /**\n     * Determine if the two entries are equal. Equality is determined\n     * by the header names being equal.\n     *\n     * @param it Entry to be checked for equality.\n     * @return True if the entries are equal.\n     */\n    public boolean equals(final TarArchiveEntry it) {\n        return getName().equals(it.getName());\n    }\n\n    /**\n     * Determine if the two entries are equal. Equality is determined\n     * by the header names being equal.\n     *\n     * @param it Entry to be checked for equality.\n     * @return True if the entries are equal.\n     */\n    @Override\n    public boolean equals(final Object it) {\n        if (it == null || getClass() != it.getClass()) {\n            return false;\n        }\n        return equals((TarArchiveEntry) it);\n    }\n\n    /**\n     * Hashcodes are based on entry names.\n     *\n     * @return the entry hashcode\n     */\n    @Override\n    public int hashCode() {\n        return getName().hashCode();\n    }\n\n    /**\n     * Determine if the given entry is a descendant of this entry.\n     * Descendancy is determined by the name of the descendant\n     * starting with this entry's name.\n     *\n     * @param desc Entry to be checked as a descendent of this.\n     * @return True if entry is a descendant of this.\n     */\n    public boolean isDescendent(final TarArchiveEntry desc) {\n        return desc.getName().startsWith(getName());\n    }\n\n    /**\n     * Get this entry's name.\n     *\n     * @return This entry's name.\n     */\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    /**\n     * Set this entry's name.\n     *\n     * @param name This entry's new name.\n     */\n    public void setName(final String name) {\n        this.name = normalizeFileName(name, this.preserveLeadingSlashes);\n    }\n\n    /**\n     * Set the mode for this entry\n     *\n     * @param mode the mode for this entry\n     */\n    public void setMode(final int mode) {\n        this.mode = mode;\n    }\n\n    /**\n     * Get this entry's link name.\n     *\n     * @return This entry's link name.\n     */\n    public String getLinkName() {\n        return linkName;\n    }\n\n    /**\n     * Set this entry's link name.\n     *\n     * @param link the link name to use.\n     *\n     * @since 1.1\n     */\n    public void setLinkName(final String link) {\n        this.linkName = link;\n    }\n\n    /**\n     * Get this entry's user id.\n     *\n     * @return This entry's user id.\n     * @deprecated use #getLongUserId instead as user ids can be\n     * bigger than {@link Integer#MAX_VALUE}\n     */\n    @Deprecated\n    public int getUserId() {\n        return (int) (userId & 0xffffffff);\n    }\n\n    /**\n     * Set this entry's user id.\n     *\n     * @param userId This entry's new user id.\n     */\n    public void setUserId(final int userId) {\n        setUserId((long) userId);\n    }\n\n    /**\n     * Get this entry's user id.\n     *\n     * @return This entry's user id.\n     * @since 1.10\n     */\n    public long getLongUserId() {\n        return userId;\n    }\n\n    /**\n     * Set this entry's user id.\n     *\n     * @param userId This entry's new user id.\n     * @since 1.10\n     */\n    public void setUserId(final long userId) {\n        this.userId = userId;\n    }\n\n    /**\n     * Get this entry's group id.\n     *\n     * @return This entry's group id.\n     * @deprecated use #getLongGroupId instead as group ids can be\n     * bigger than {@link Integer#MAX_VALUE}\n     */\n    @Deprecated\n    public int getGroupId() {\n        return (int) (groupId & 0xffffffff);\n    }\n\n    /**\n     * Set this entry's group id.\n     *\n     * @param groupId This entry's new group id.\n     */\n    public void setGroupId(final int groupId) {\n        setGroupId((long) groupId);\n    }\n\n    /**\n     * Get this entry's group id.\n     *\n     * @since 1.10\n     * @return This entry's group id.\n     */\n    public long getLongGroupId() {\n        return groupId;\n    }\n\n    /**\n     * Set this entry's group id.\n     *\n     * @since 1.10\n     * @param groupId This entry's new group id.\n     */\n    public void setGroupId(final long groupId) {\n        this.groupId = groupId;\n    }\n\n    /**\n     * Get this entry's user name.\n     *\n     * @return This entry's user name.\n     */\n    public String getUserName() {\n        return userName;\n    }\n\n    /**\n     * Set this entry's user name.\n     *\n     * @param userName This entry's new user name.\n     */\n    public void setUserName(final String userName) {\n        this.userName = userName;\n    }\n\n    /**\n     * Get this entry's group name.\n     *\n     * @return This entry's group name.\n     */\n    public String getGroupName() {\n        return groupName;\n    }\n\n    /**\n     * Set this entry's group name.\n     *\n     * @param groupName This entry's new group name.\n     */\n    public void setGroupName(final String groupName) {\n        this.groupName = groupName;\n    }\n\n    /**\n     * Convenience method to set this entry's group and user ids.\n     *\n     * @param userId This entry's new user id.\n     * @param groupId This entry's new group id.\n     */\n    public void setIds(final int userId, final int groupId) {\n        setUserId(userId);\n        setGroupId(groupId);\n    }\n\n    /**\n     * Convenience method to set this entry's group and user names.\n     *\n     * @param userName This entry's new user name.\n     * @param groupName This entry's new group name.\n     */\n    public void setNames(final String userName, final String groupName) {\n        setUserName(userName);\n        setGroupName(groupName);\n    }\n\n    /**\n     * Set this entry's modification time. The parameter passed\n     * to this method is in \"Java time\".\n     *\n     * @param time This entry's new modification time.\n     */\n    public void setModTime(final long time) {\n        modTime = time / MILLIS_PER_SECOND;\n    }\n\n    /**\n     * Set this entry's modification time.\n     *\n     * @param time This entry's new modification time.\n     */\n    public void setModTime(final Date time) {\n        modTime = time.getTime() / MILLIS_PER_SECOND;\n    }\n\n    /**\n     * Set this entry's modification time.\n     *\n     * @return time This entry's new modification time.\n     */\n    public Date getModTime() {\n        return new Date(modTime * MILLIS_PER_SECOND);\n    }\n\n    @Override\n    public Date getLastModifiedDate() {\n        return getModTime();\n    }\n\n    /**\n     * Get this entry's checksum status.\n     *\n     * @return if the header checksum is reasonably correct\n     * @see TarUtils#verifyCheckSum(byte[])\n     * @since 1.5\n     */\n    public boolean isCheckSumOK() {\n        return checkSumOK;\n    }\n\n    /**\n     * Get this entry's file.\n     *\n     * @return This entry's file.\n     */\n    public File getFile() {\n        return file;\n    }\n\n    /**\n     * Get this entry's mode.\n     *\n     * @return This entry's mode.\n     */\n    public int getMode() {\n        return mode;\n    }\n\n    /**\n     * Get this entry's file size.\n     *\n     * @return This entry's file size.\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Set this entry's file size.\n     *\n     * @param size This entry's new file size.\n     * @throws IllegalArgumentException if the size is &lt; 0.\n     */\n    public void setSize(final long size) {\n        if (size < 0){\n            throw new IllegalArgumentException(\"Size is out of range: \"+size);\n        }\n        this.size = size;\n    }\n\n    /**\n     * Get this entry's major device number.\n     *\n     * @return This entry's major device number.\n     * @since 1.4\n     */\n    public int getDevMajor() {\n        return devMajor;\n    }\n\n    /**\n     * Set this entry's major device number.\n     *\n     * @param devNo This entry's major device number.\n     * @throws IllegalArgumentException if the devNo is &lt; 0.\n     * @since 1.4\n     */\n    public void setDevMajor(final int devNo) {\n        if (devNo < 0){\n            throw new IllegalArgumentException(\"Major device number is out of \"\n                                               + \"range: \" + devNo);\n        }\n        this.devMajor = devNo;\n    }\n\n    /**\n     * Get this entry's minor device number.\n     *\n     * @return This entry's minor device number.\n     * @since 1.4\n     */\n    public int getDevMinor() {\n        return devMinor;\n    }\n\n    /**\n     * Set this entry's minor device number.\n     *\n     * @param devNo This entry's minor device number.\n     * @throws IllegalArgumentException if the devNo is &lt; 0.\n     * @since 1.4\n     */\n    public void setDevMinor(final int devNo) {\n        if (devNo < 0){\n            throw new IllegalArgumentException(\"Minor device number is out of \"\n                                               + \"range: \" + devNo);\n        }\n        this.devMinor = devNo;\n    }\n\n    /**\n     * Indicates in case of an oldgnu sparse file if an extension\n     * sparse header follows.\n     *\n     * @return true if an extension oldgnu sparse header follows.\n     */\n    public boolean isExtended() {\n        return isExtended;\n    }\n\n    /**\n     * Get this entry's real file size in case of a sparse file.\n     *\n     * @return This entry's real file size.\n     */\n    public long getRealSize() {\n        return realSize;\n    }\n\n    /**\n     * Indicate if this entry is a GNU sparse block.\n     *\n     * @return true if this is a sparse extension provided by GNU tar\n     */\n    public boolean isGNUSparse() {\n        return isOldGNUSparse() || isPaxGNUSparse();\n    }\n\n    /**\n     * Indicate if this entry is a GNU or star sparse block using the\n     * oldgnu format.\n     *\n     * @return true if this is a sparse extension provided by GNU tar or star\n     * @since 1.11\n     */\n    public boolean isOldGNUSparse() {\n        return linkFlag == LF_GNUTYPE_SPARSE;\n    }\n\n    /**\n     * Indicate if this entry is a GNU sparse block using one of the\n     * PAX formats.\n     *\n     * @return true if this is a sparse extension provided by GNU tar\n     * @since 1.11\n     */\n    public boolean isPaxGNUSparse() {\n        return paxGNUSparse;\n    }\n\n    /**\n     * Indicate if this entry is a star sparse block using PAX headers.\n     *\n     * @return true if this is a sparse extension provided by star\n     * @since 1.11\n     */\n    public boolean isStarSparse() {\n        return starSparse;\n    }\n\n    /**\n     * Indicate if this entry is a GNU long linkname block\n     *\n     * @return true if this is a long name extension provided by GNU tar\n     */\n    public boolean isGNULongLinkEntry() {\n        return linkFlag == LF_GNUTYPE_LONGLINK;\n    }\n\n    /**\n     * Indicate if this entry is a GNU long name block\n     *\n     * @return true if this is a long name extension provided by GNU tar\n     */\n    public boolean isGNULongNameEntry() {\n        return linkFlag == LF_GNUTYPE_LONGNAME;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     *\n     */\n    public boolean isPaxHeader(){\n        return linkFlag == LF_PAX_EXTENDED_HEADER_LC\n            || linkFlag == LF_PAX_EXTENDED_HEADER_UC;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     */\n    public boolean isGlobalPaxHeader(){\n        return linkFlag == LF_PAX_GLOBAL_EXTENDED_HEADER;\n    }\n\n    /**\n     * Return whether or not this entry represents a directory.\n     *\n     * @return True if this entry is a directory.\n     */\n    @Override\n    public boolean isDirectory() {\n        if (file != null) {\n            return file.isDirectory();\n        }\n\n        if (linkFlag == LF_DIR) {\n            return true;\n        }\n\n        if (getName().endsWith(\"/\")) {\n            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Check if this is a \"normal file\"\n     *\n     * @since 1.2\n     * @return whether this is a \"normal file\"\n     */\n    public boolean isFile() {\n        if (file != null) {\n            return file.isFile();\n        }\n        if (linkFlag == LF_OLDNORM || linkFlag == LF_NORMAL) {\n            return true;\n        }\n        return !getName().endsWith(\"/\");\n    }\n\n    /**\n     * Check if this is a symbolic link entry.\n     *\n     * @since 1.2\n     * @return whether this is a symbolic link\n     */\n    public boolean isSymbolicLink() {\n        return linkFlag == LF_SYMLINK;\n    }\n\n    /**\n     * Check if this is a link entry.\n     *\n     * @since 1.2\n     * @return whether this is a link entry\n     */\n    public boolean isLink() {\n        return linkFlag == LF_LINK;\n    }\n\n    /**\n     * Check if this is a character device entry.\n     *\n     * @since 1.2\n     * @return whether this is a character device\n     */\n    public boolean isCharacterDevice() {\n        return linkFlag == LF_CHR;\n    }\n\n    /**\n     * Check if this is a block device entry.\n     *\n     * @since 1.2\n     * @return whether this is a block device\n     */\n    public boolean isBlockDevice() {\n        return linkFlag == LF_BLK;\n    }\n\n    /**\n     * Check if this is a FIFO (pipe) entry.\n     *\n     * @since 1.2\n     * @return whether this is a FIFO entry\n     */\n    public boolean isFIFO() {\n        return linkFlag == LF_FIFO;\n    }\n\n    /**\n     * Check whether this is a sparse entry.\n     *\n     * @return whether this is a sparse entry\n     * @since 1.11\n     */\n    public boolean isSparse() {\n        return isGNUSparse() || isStarSparse();\n    }\n\n    /**\n     * If this entry represents a file, and the file is a directory, return\n     * an array of TarEntries for this entry's children.\n     *\n     * @return An array of TarEntry's for this entry's children.\n     */\n    public TarArchiveEntry[] getDirectoryEntries() {\n        if (file == null || !file.isDirectory()) {\n            return EMPTY_TAR_ARCHIVE_ENTRIES;\n        }\n\n        final String[] list = file.list();\n        if (list == null) {\n            return EMPTY_TAR_ARCHIVE_ENTRIES;\n        }\n        final TarArchiveEntry[] result = new TarArchiveEntry[list.length];\n\n        for (int i = 0; i < result.length; ++i) {\n            result[i] = new TarArchiveEntry(new File(file, list[i]));\n        }\n\n        return result;\n    }\n\n    /**\n     * Write an entry's header information to a header buffer.\n     *\n     * <p>This method does not use the star/GNU tar/BSD tar extensions.</p>\n     *\n     * @param outbuf The tar entry header buffer to fill in.\n     */\n    public void writeEntryHeader(final byte[] outbuf) {\n        try {\n            writeEntryHeader(outbuf, TarUtils.DEFAULT_ENCODING, false);\n        } catch (final IOException ex) {\n            try {\n                writeEntryHeader(outbuf, TarUtils.FALLBACK_ENCODING, false);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Write an entry's header information to a header buffer.\n     *\n     * @param outbuf The tar entry header buffer to fill in.\n     * @param encoding encoding to use when writing the file name.\n     * @param starMode whether to use the star/GNU tar/BSD tar\n     * extension for numeric fields if their value doesn't fit in the\n     * maximum size of standard tar archives\n     * @since 1.4\n     * @throws IOException on error\n     */\n    public void writeEntryHeader(final byte[] outbuf, final ZipEncoding encoding,\n                                 final boolean starMode) throws IOException {\n        int offset = 0;\n\n        offset = TarUtils.formatNameBytes(name, outbuf, offset, NAMELEN,\n                                          encoding);\n        offset = writeEntryHeaderField(mode, outbuf, offset, MODELEN, starMode);\n        offset = writeEntryHeaderField(userId, outbuf, offset, UIDLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(groupId, outbuf, offset, GIDLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(size, outbuf, offset, SIZELEN, starMode);\n        offset = writeEntryHeaderField(modTime, outbuf, offset, MODTIMELEN,\n                                       starMode);\n\n        final int csOffset = offset;\n\n        for (int c = 0; c < CHKSUMLEN; ++c) {\n            outbuf[offset++] = (byte) ' ';\n        }\n\n        outbuf[offset++] = linkFlag;\n        offset = TarUtils.formatNameBytes(linkName, outbuf, offset, NAMELEN,\n                                          encoding);\n        offset = TarUtils.formatNameBytes(magic, outbuf, offset, MAGICLEN);\n        offset = TarUtils.formatNameBytes(version, outbuf, offset, VERSIONLEN);\n        offset = TarUtils.formatNameBytes(userName, outbuf, offset, UNAMELEN,\n                                          encoding);\n        offset = TarUtils.formatNameBytes(groupName, outbuf, offset, GNAMELEN,\n                                          encoding);\n        offset = writeEntryHeaderField(devMajor, outbuf, offset, DEVLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(devMinor, outbuf, offset, DEVLEN,\n                                       starMode);\n\n        while (offset < outbuf.length) {\n            outbuf[offset++] = 0;\n        }\n\n        final long chk = TarUtils.computeCheckSum(outbuf);\n\n        TarUtils.formatCheckSumOctalBytes(chk, outbuf, csOffset, CHKSUMLEN);\n    }\n\n    private int writeEntryHeaderField(final long value, final byte[] outbuf, final int offset,\n                                      final int length, final boolean starMode) {\n        if (!starMode && (value < 0\n                          || value >= 1l << 3 * (length - 1))) {\n            // value doesn't fit into field when written as octal\n            // number, will be written to PAX header or causes an\n            // error\n            return TarUtils.formatLongOctalBytes(0, outbuf, offset, length);\n        }\n        return TarUtils.formatLongOctalOrBinaryBytes(value, outbuf, offset,\n                                                     length);\n    }\n\n    /**\n     * Parse an entry's header information from a header buffer.\n     *\n     * @param header The tar entry header buffer to get information from.\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     */\n    public void parseTarHeader(final byte[] header) {\n        try {\n            parseTarHeader(header, TarUtils.DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                parseTarHeader(header, TarUtils.DEFAULT_ENCODING, true);\n            } catch (final IOException ex2) {\n                // not really possible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry's header information from a header buffer.\n     *\n     * @param header The tar entry header buffer to get information from.\n     * @param encoding encoding to use for file names\n     * @since 1.4\n     * @throws IllegalArgumentException if any of the numeric fields\n     * have an invalid format\n     * @throws IOException on error\n     */\n    public void parseTarHeader(final byte[] header, final ZipEncoding encoding)\n        throws IOException {\n        parseTarHeader(header, encoding, false);\n    }\n\n    private void parseTarHeader(final byte[] header, final ZipEncoding encoding,\n                                final boolean oldStyle)\n        throws IOException {\n        int offset = 0;\n\n        name = oldStyle ? TarUtils.parseName(header, offset, NAMELEN)\n            : TarUtils.parseName(header, offset, NAMELEN, encoding);\n        offset += NAMELEN;\n        mode = (int) TarUtils.parseOctalOrBinary(header, offset, MODELEN);\n        offset += MODELEN;\n        userId = (int) TarUtils.parseOctalOrBinary(header, offset, UIDLEN);\n        offset += UIDLEN;\n        groupId = (int) TarUtils.parseOctalOrBinary(header, offset, GIDLEN);\n        offset += GIDLEN;\n        size = TarUtils.parseOctalOrBinary(header, offset, SIZELEN);\n        offset += SIZELEN;\n        modTime = TarUtils.parseOctalOrBinary(header, offset, MODTIMELEN);\n        offset += MODTIMELEN;\n        checkSumOK = TarUtils.verifyCheckSum(header);\n        offset += CHKSUMLEN;\n        linkFlag = header[offset++];\n        linkName = oldStyle ? TarUtils.parseName(header, offset, NAMELEN)\n            : TarUtils.parseName(header, offset, NAMELEN, encoding);\n        offset += NAMELEN;\n        magic = TarUtils.parseName(header, offset, MAGICLEN);\n        offset += MAGICLEN;\n        version = TarUtils.parseName(header, offset, VERSIONLEN);\n        offset += VERSIONLEN;\n        userName = oldStyle ? TarUtils.parseName(header, offset, UNAMELEN)\n            : TarUtils.parseName(header, offset, UNAMELEN, encoding);\n        offset += UNAMELEN;\n        groupName = oldStyle ? TarUtils.parseName(header, offset, GNAMELEN)\n            : TarUtils.parseName(header, offset, GNAMELEN, encoding);\n        offset += GNAMELEN;\n        devMajor = (int) TarUtils.parseOctalOrBinary(header, offset, DEVLEN);\n        offset += DEVLEN;\n        devMinor = (int) TarUtils.parseOctalOrBinary(header, offset, DEVLEN);\n        offset += DEVLEN;\n\n        final int type = evaluateType(header);\n        switch (type) {\n        case FORMAT_OLDGNU: {\n            offset += ATIMELEN_GNU;\n            offset += CTIMELEN_GNU;\n            offset += OFFSETLEN_GNU;\n            offset += LONGNAMESLEN_GNU;\n            offset += PAD2LEN_GNU;\n            offset += SPARSELEN_GNU;\n            isExtended = TarUtils.parseBoolean(header, offset);\n            offset += ISEXTENDEDLEN_GNU;\n            realSize = TarUtils.parseOctal(header, offset, REALSIZELEN_GNU);\n            offset += REALSIZELEN_GNU;\n            break;\n        }\n        case FORMAT_XSTAR: {\n            final String xstarPrefix = oldStyle\n                ? TarUtils.parseName(header, offset, PREFIXLEN_XSTAR)\n                : TarUtils.parseName(header, offset, PREFIXLEN_XSTAR, encoding);\n            if (xstarPrefix.length() > 0) {\n                name = xstarPrefix + \"/\" + name;\n            }\n            break;\n        }\n        case FORMAT_POSIX:\n        default: {\n            final String prefix = oldStyle\n                ? TarUtils.parseName(header, offset, PREFIXLEN)\n                : TarUtils.parseName(header, offset, PREFIXLEN, encoding);\n            // SunOS tar -E does not add / to directory names, so fix\n            // up to be consistent\n            if (isDirectory() && !name.endsWith(\"/\")){\n                name = name + \"/\";\n            }\n            if (prefix.length() > 0){\n                name = prefix + \"/\" + name;\n            }\n        }\n        }\n    }\n\n    /**\n     * Strips Windows' drive letter as well as any leading slashes,\n     * turns path separators into forward slahes.\n     */\n    private static String normalizeFileName(String fileName,\n                                            final boolean preserveLeadingSlashes) {\n        final String osname = System.getProperty(\"os.name\").toLowerCase(Locale.ENGLISH);\n\n        if (osname != null) {\n\n            // Strip off drive letters!\n            // REVIEW Would a better check be \"(File.separator == '\\')\"?\n\n            if (osname.startsWith(\"windows\")) {\n                if (fileName.length() > 2) {\n                    final char ch1 = fileName.charAt(0);\n                    final char ch2 = fileName.charAt(1);\n\n                    if (ch2 == ':'\n                        && (ch1 >= 'a' && ch1 <= 'z'\n                            || ch1 >= 'A' && ch1 <= 'Z')) {\n                        fileName = fileName.substring(2);\n                    }\n                }\n            } else if (osname.contains(\"netware\")) {\n                final int colon = fileName.indexOf(':');\n                if (colon != -1) {\n                    fileName = fileName.substring(colon + 1);\n                }\n            }\n        }\n\n        fileName = fileName.replace(File.separatorChar, '/');\n\n        // No absolute pathnames\n        // Windows (and Posix?) paths can start with \"\\\\NetworkDrive\\\",\n        // so we loop on starting /'s.\n        while (!preserveLeadingSlashes && fileName.startsWith(\"/\")) {\n            fileName = fileName.substring(1);\n        }\n        return fileName;\n    }\n\n    /**\n     * Evaluate an entry's header format from a header buffer.\n     *\n     * @param header The tar entry header buffer to evaluate the format for.\n     * @return format type\n     */\n    private int evaluateType(final byte[] header) {\n        if (ArchiveUtils.matchAsciiBuffer(MAGIC_GNU, header, MAGIC_OFFSET, MAGICLEN)) {\n            return FORMAT_OLDGNU;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(MAGIC_POSIX, header, MAGIC_OFFSET, MAGICLEN)) {\n            if (ArchiveUtils.matchAsciiBuffer(MAGIC_XSTAR, header, XSTAR_MAGIC_OFFSET,\n                                              XSTAR_MAGIC_LEN)) {\n                return FORMAT_XSTAR;\n            }\n            return FORMAT_POSIX;\n        }\n        return 0;\n    }\n\n    void fillGNUSparse0xData(final Map<String, String> headers) {\n        paxGNUSparse = true;\n        realSize = Integer.parseInt(headers.get(\"GNU.sparse.size\"));\n        if (headers.containsKey(\"GNU.sparse.name\")) {\n            // version 0.1\n            name = headers.get(\"GNU.sparse.name\");\n        }\n    }\n\n    void fillGNUSparse1xData(final Map<String, String> headers) {\n        paxGNUSparse = true;\n        realSize = Integer.parseInt(headers.get(\"GNU.sparse.realsize\"));\n        name = headers.get(\"GNU.sparse.name\");\n    }\n\n    void fillStarSparseData(final Map<String, String> headers) {\n        starSparse = true;\n        if (headers.containsKey(\"SCHILY.realsize\")) {\n            realSize = Long.parseLong(headers.get(\"SCHILY.realsize\"));\n        }\n    }\n}\n\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.util.Map;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.utils.ArchiveUtils;\n\n/**\n * This class represents an entry in a Tar archive. It consists\n * of the entry's header, as well as the entry's File. Entries\n * can be instantiated in one of three ways, depending on how\n * they are to be used.\n * <p>\n * TarEntries that are created from the header bytes read from\n * an archive are instantiated with the TarEntry( byte[] )\n * constructor. These entries will be used when extracting from\n * or listing the contents of an archive. These entries have their\n * header filled in using the header bytes. They also set the File\n * to null, since they reference an archive entry not a file.\n * <p>\n * TarEntries that are created from Files that are to be written\n * into an archive are instantiated with the TarEntry( File )\n * constructor. These entries have their header filled in using\n * the File's information. They also keep a reference to the File\n * for convenience when writing entries.\n * <p>\n * Finally, TarEntries can be constructed from nothing but a name.\n * This allows the programmer to construct the entry by hand, for\n * instance when only an InputStream is available for writing to\n * the archive, and the header information is constructed from\n * other information. In this case the header fields are set to\n * defaults and the File is set to null.\n *\n * <p>\n * The C structure for a Tar Entry's header is:\n * <pre>\n * struct header {\n * char name[100];     // TarConstants.NAMELEN    - offset   0\n * char mode[8];       // TarConstants.MODELEN    - offset 100\n * char uid[8];        // TarConstants.UIDLEN     - offset 108\n * char gid[8];        // TarConstants.GIDLEN     - offset 116\n * char size[12];      // TarConstants.SIZELEN    - offset 124\n * char mtime[12];     // TarConstants.MODTIMELEN - offset 136\n * char chksum[8];     // TarConstants.CHKSUMLEN  - offset 148\n * char linkflag[1];   //                         - offset 156\n * char linkname[100]; // TarConstants.NAMELEN    - offset 157\n * The following fields are only present in new-style POSIX tar archives:\n * char magic[6];      // TarConstants.MAGICLEN   - offset 257\n * char version[2];    // TarConstants.VERSIONLEN - offset 263\n * char uname[32];     // TarConstants.UNAMELEN   - offset 265\n * char gname[32];     // TarConstants.GNAMELEN   - offset 297\n * char devmajor[8];   // TarConstants.DEVLEN     - offset 329\n * char devminor[8];   // TarConstants.DEVLEN     - offset 337\n * char prefix[155];   // TarConstants.PREFIXLEN  - offset 345\n * // Used if \"name\" field is not long enough to hold the path\n * char pad[12];       // NULs                    - offset 500\n * } header;\n * All unused bytes are set to null.\n * New-style GNU tar files are slightly different from the above.\n * For values of size larger than 077777777777L (11 7s)\n * or uid and gid larger than 07777777L (7 7s)\n * the sign bit of the first byte is set, and the rest of the\n * field is the binary representation of the number.\n * See TarUtils.parseOctalOrBinary.\n * </pre>\n *\n * <p>\n * The C structure for a old GNU Tar Entry's header is:\n * <pre>\n * struct oldgnu_header {\n * char unused_pad1[345]; // TarConstants.PAD1LEN_GNU       - offset 0\n * char atime[12];        // TarConstants.ATIMELEN_GNU      - offset 345\n * char ctime[12];        // TarConstants.CTIMELEN_GNU      - offset 357\n * char offset[12];       // TarConstants.OFFSETLEN_GNU     - offset 369\n * char longnames[4];     // TarConstants.LONGNAMESLEN_GNU  - offset 381\n * char unused_pad2;      // TarConstants.PAD2LEN_GNU       - offset 385\n * struct sparse sp[4];   // TarConstants.SPARSELEN_GNU     - offset 386\n * char isextended;       // TarConstants.ISEXTENDEDLEN_GNU - offset 482\n * char realsize[12];     // TarConstants.REALSIZELEN_GNU   - offset 483\n * char unused_pad[17];   // TarConstants.PAD3LEN_GNU       - offset 495\n * };\n * </pre>\n * Whereas, \"struct sparse\" is:\n * <pre>\n * struct sparse {\n * char offset[12];   // offset 0\n * char numbytes[12]; // offset 12\n * };\n * </pre>\n *\n * <p>\n * The C structure for a xstar (J\u00f6rg Schilling star) Tar Entry's header is:\n * <pre>\n * struct star_header {\n *  char name[100];\t\t// offset   0\n *  char mode[8];\t\t// offset 100\n *  char uid[8];\t\t// offset 108\n *  char gid[8];\t\t// offset 116\n *  char size[12];\t\t// offset 124\n *  char mtime[12];\t\t// offset 136\n *  char chksum[8];\t\t// offset 148\n *  char typeflag;\t\t// offset 156\n *  char linkname[100];\t\t// offset 157\n *  char magic[6];\t\t// offset 257\n *  char version[2];\t\t// offset 263\n *  char uname[32];\t\t// offset 265\n *  char gname[32];\t\t// offset 297\n *  char devmajor[8];\t\t// offset 329\n *  char devminor[8];\t\t// offset 337\n *  char prefix[131];\t\t// offset 345\n *  char atime[12];             // offset 476\n *  char ctime[12];             // offset 488\n *  char mfill[8];              // offset 500 \n *  char xmagic[4];             // offset 508  \"tar\"\n * };\n * </pre>\n * <p>which is identical to new-style POSIX up to the first 130 bytes of the prefix.</p>\n *\n * @NotThreadSafe\n */\n\npublic class TarArchiveEntry implements TarConstants, ArchiveEntry {\n    private static final TarArchiveEntry[] EMPTY_TAR_ARCHIVE_ENTRIES = new TarArchiveEntry[0];\n\n    /** The entry's name. */\n    private String name = \"\";\n\n    /** Whether to enforce leading slashes on the name */\n    private boolean preserveLeadingSlashes;\n\n    /** The entry's permission mode. */\n    private int mode;\n\n    /** The entry's user id. */\n    private long userId = 0;\n\n    /** The entry's group id. */\n    private long groupId = 0;\n\n    /** The entry's size. */\n    private long size = 0;\n\n    /** The entry's modification time. */\n    private long modTime;\n\n    /** If the header checksum is reasonably correct. */\n    private boolean checkSumOK;\n\n    /** The entry's link flag. */\n    private byte linkFlag;\n\n    /** The entry's link name. */\n    private String linkName = \"\";\n\n    /** The entry's magic tag. */\n    private String magic = MAGIC_POSIX;\n    /** The version of the format */\n    private String version = VERSION_POSIX;\n\n    /** The entry's user name. */\n    private String userName;\n\n    /** The entry's group name. */\n    private String groupName = \"\";\n\n    /** The entry's major device number. */\n    private int devMajor = 0;\n\n    /** The entry's minor device number. */\n    private int devMinor = 0;\n\n    /** If an extension sparse header follows. */\n    private boolean isExtended;\n\n    /** The entry's real size in case of a sparse file. */\n    private long realSize;\n\n    /** is this entry a GNU sparse entry using one of the PAX formats? */\n    private boolean paxGNUSparse;\n\n    /** is this entry a star sparse entry using the PAX header? */\n    private boolean starSparse;\n\n    /** The entry's file reference */\n    private final File file;\n\n    /** Maximum length of a user's name in the tar file */\n    public static final int MAX_NAMELEN = 31;\n\n    /** Default permissions bits for directories */\n    public static final int DEFAULT_DIR_MODE = 040755;\n\n    /** Default permissions bits for files */\n    public static final int DEFAULT_FILE_MODE = 0100644;\n\n    /** Convert millis to seconds */\n    public static final int MILLIS_PER_SECOND = 1000;\n\n    /**\n     * Construct an empty entry and prepares the header values.\n     */\n    private TarArchiveEntry() {\n        String user = System.getProperty(\"user.name\", \"\");\n\n        if (user.length() > MAX_NAMELEN) {\n            user = user.substring(0, MAX_NAMELEN);\n        }\n\n        this.userName = user;\n        this.file = null;\n    }\n\n    /**\n     * Construct an entry with only a name. This allows the programmer\n     * to construct the entry's header \"by hand\". File is set to null.\n     *\n     * @param name the entry name\n     */\n    public TarArchiveEntry(final String name) {\n        this(name, false);\n    }\n\n    /**\n     * Construct an entry with only a name. This allows the programmer\n     * to construct the entry's header \"by hand\". File is set to null.\n     *\n     * @param name the entry name\n     * @param preserveLeadingSlashes whether to allow leading slashes\n     * in the name.\n     *\n     * @since 1.1\n     */\n    public TarArchiveEntry(String name, final boolean preserveLeadingSlashes) {\n        this();\n\n        this.preserveLeadingSlashes = preserveLeadingSlashes;\n\n        name = normalizeFileName(name, preserveLeadingSlashes);\n        final boolean isDir = name.endsWith(\"/\");\n\n        this.name = name;\n        this.mode = isDir ? DEFAULT_DIR_MODE : DEFAULT_FILE_MODE;\n        this.linkFlag = isDir ? LF_DIR : LF_NORMAL;\n        this.modTime = new Date().getTime() / MILLIS_PER_SECOND;\n        this.userName = \"\";\n    }\n\n    /**\n     * Construct an entry with a name and a link flag.\n     *\n     * @param name the entry name\n     * @param linkFlag the entry link flag.\n     */\n    public TarArchiveEntry(final String name, final byte linkFlag) {\n        this(name, linkFlag, false);\n    }\n\n    /**\n     * Construct an entry with a name and a link flag.\n     *\n     * @param name the entry name\n     * @param linkFlag the entry link flag.\n     * @param preserveLeadingSlashes whether to allow leading slashes\n     * in the name.\n     *\n     * @since 1.5\n     */\n    public TarArchiveEntry(final String name, final byte linkFlag, final boolean preserveLeadingSlashes) {\n        this(name, preserveLeadingSlashes);\n        this.linkFlag = linkFlag;\n        if (linkFlag == LF_GNUTYPE_LONGNAME) {\n            magic = MAGIC_GNU;\n            version = VERSION_GNU_SPACE;\n        }\n    }\n\n    /**\n     * Construct an entry for a file. File is set to file, and the\n     * header is constructed from information from the file.\n     * The name is set from the normalized file path.\n     *\n     * @param file The file that the entry represents.\n     */\n    public TarArchiveEntry(final File file) {\n        this(file, file.getPath());\n    }\n\n    /**\n     * Construct an entry for a file. File is set to file, and the\n     * header is constructed from information from the file.\n     *\n     * @param file The file that the entry represents.\n     * @param fileName the name to be used for the entry.\n     */\n    public TarArchiveEntry(final File file, final String fileName) {\n        final String normalizedName = normalizeFileName(fileName, false);\n        this.file = file;\n\n        if (file.isDirectory()) {\n            this.mode = DEFAULT_DIR_MODE;\n            this.linkFlag = LF_DIR;\n\n            final int nameLength = normalizedName.length();\n            if (nameLength == 0 || normalizedName.charAt(nameLength - 1) != '/') {\n                this.name = normalizedName + \"/\";\n            } else {\n                this.name = normalizedName;\n            }\n        } else {\n            this.mode = DEFAULT_FILE_MODE;\n            this.linkFlag = LF_NORMAL;\n            this.size = file.length();\n            this.name = normalizedName;\n        }\n\n        this.modTime = file.lastModified() / MILLIS_PER_SECOND;\n        this.userName = \"\";\n    }\n\n    /**\n     * Construct an entry from an archive's header bytes. File is set\n     * to null.\n     *\n     * @param headerBuf The header bytes from a tar archive entry.\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     */\n    public TarArchiveEntry(final byte[] headerBuf) {\n        this();\n        parseTarHeader(headerBuf);\n    }\n\n    /**\n     * Construct an entry from an archive's header bytes. File is set\n     * to null.\n     *\n     * @param headerBuf The header bytes from a tar archive entry.\n     * @param encoding encoding to use for file names\n     * @since 1.4\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     * @throws IOException on error\n     */\n    public TarArchiveEntry(final byte[] headerBuf, final ZipEncoding encoding)\n        throws IOException {\n        this();\n        parseTarHeader(headerBuf, encoding);\n    }\n\n    /**\n     * Determine if the two entries are equal. Equality is determined\n     * by the header names being equal.\n     *\n     * @param it Entry to be checked for equality.\n     * @return True if the entries are equal.\n     */\n    public boolean equals(final TarArchiveEntry it) {\n        return getName().equals(it.getName());\n    }\n\n    /**\n     * Determine if the two entries are equal. Equality is determined\n     * by the header names being equal.\n     *\n     * @param it Entry to be checked for equality.\n     * @return True if the entries are equal.\n     */\n    @Override\n    public boolean equals(final Object it) {\n        if (it == null || getClass() != it.getClass()) {\n            return false;\n        }\n        return equals((TarArchiveEntry) it);\n    }\n\n    /**\n     * Hashcodes are based on entry names.\n     *\n     * @return the entry hashcode\n     */\n    @Override\n    public int hashCode() {\n        return getName().hashCode();\n    }\n\n    /**\n     * Determine if the given entry is a descendant of this entry.\n     * Descendancy is determined by the name of the descendant\n     * starting with this entry's name.\n     *\n     * @param desc Entry to be checked as a descendent of this.\n     * @return True if entry is a descendant of this.\n     */\n    public boolean isDescendent(final TarArchiveEntry desc) {\n        return desc.getName().startsWith(getName());\n    }\n\n    /**\n     * Get this entry's name.\n     *\n     * @return This entry's name.\n     */\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    /**\n     * Set this entry's name.\n     *\n     * @param name This entry's new name.\n     */\n    public void setName(final String name) {\n        this.name = normalizeFileName(name, this.preserveLeadingSlashes);\n    }\n\n    /**\n     * Set the mode for this entry\n     *\n     * @param mode the mode for this entry\n     */\n    public void setMode(final int mode) {\n        this.mode = mode;\n    }\n\n    /**\n     * Get this entry's link name.\n     *\n     * @return This entry's link name.\n     */\n    public String getLinkName() {\n        return linkName;\n    }\n\n    /**\n     * Set this entry's link name.\n     *\n     * @param link the link name to use.\n     *\n     * @since 1.1\n     */\n    public void setLinkName(final String link) {\n        this.linkName = link;\n    }\n\n    /**\n     * Get this entry's user id.\n     *\n     * @return This entry's user id.\n     * @deprecated use #getLongUserId instead as user ids can be\n     * bigger than {@link Integer#MAX_VALUE}\n     */\n    @Deprecated\n    public int getUserId() {\n        return (int) (userId & 0xffffffff);\n    }\n\n    /**\n     * Set this entry's user id.\n     *\n     * @param userId This entry's new user id.\n     */\n    public void setUserId(final int userId) {\n        setUserId((long) userId);\n    }\n\n    /**\n     * Get this entry's user id.\n     *\n     * @return This entry's user id.\n     * @since 1.10\n     */\n    public long getLongUserId() {\n        return userId;\n    }\n\n    /**\n     * Set this entry's user id.\n     *\n     * @param userId This entry's new user id.\n     * @since 1.10\n     */\n    public void setUserId(final long userId) {\n        this.userId = userId;\n    }\n\n    /**\n     * Get this entry's group id.\n     *\n     * @return This entry's group id.\n     * @deprecated use #getLongGroupId instead as group ids can be\n     * bigger than {@link Integer#MAX_VALUE}\n     */\n    @Deprecated\n    public int getGroupId() {\n        return (int) (groupId & 0xffffffff);\n    }\n\n    /**\n     * Set this entry's group id.\n     *\n     * @param groupId This entry's new group id.\n     */\n    public void setGroupId(final int groupId) {\n        setGroupId((long) groupId);\n    }\n\n    /**\n     * Get this entry's group id.\n     *\n     * @since 1.10\n     * @return This entry's group id.\n     */\n    public long getLongGroupId() {\n        return groupId;\n    }\n\n    /**\n     * Set this entry's group id.\n     *\n     * @since 1.10\n     * @param groupId This entry's new group id.\n     */\n    public void setGroupId(final long groupId) {\n        this.groupId = groupId;\n    }\n\n    /**\n     * Get this entry's user name.\n     *\n     * @return This entry's user name.\n     */\n    public String getUserName() {\n        return userName;\n    }\n\n    /**\n     * Set this entry's user name.\n     *\n     * @param userName This entry's new user name.\n     */\n    public void setUserName(final String userName) {\n        this.userName = userName;\n    }\n\n    /**\n     * Get this entry's group name.\n     *\n     * @return This entry's group name.\n     */\n    public String getGroupName() {\n        return groupName;\n    }\n\n    /**\n     * Set this entry's group name.\n     *\n     * @param groupName This entry's new group name.\n     */\n    public void setGroupName(final String groupName) {\n        this.groupName = groupName;\n    }\n\n    /**\n     * Convenience method to set this entry's group and user ids.\n     *\n     * @param userId This entry's new user id.\n     * @param groupId This entry's new group id.\n     */\n    public void setIds(final int userId, final int groupId) {\n        setUserId(userId);\n        setGroupId(groupId);\n    }\n\n    /**\n     * Convenience method to set this entry's group and user names.\n     *\n     * @param userName This entry's new user name.\n     * @param groupName This entry's new group name.\n     */\n    public void setNames(final String userName, final String groupName) {\n        setUserName(userName);\n        setGroupName(groupName);\n    }\n\n    /**\n     * Set this entry's modification time. The parameter passed\n     * to this method is in \"Java time\".\n     *\n     * @param time This entry's new modification time.\n     */\n    public void setModTime(final long time) {\n        modTime = time / MILLIS_PER_SECOND;\n    }\n\n    /**\n     * Set this entry's modification time.\n     *\n     * @param time This entry's new modification time.\n     */\n    public void setModTime(final Date time) {\n        modTime = time.getTime() / MILLIS_PER_SECOND;\n    }\n\n    /**\n     * Set this entry's modification time.\n     *\n     * @return time This entry's new modification time.\n     */\n    public Date getModTime() {\n        return new Date(modTime * MILLIS_PER_SECOND);\n    }\n\n    @Override\n    public Date getLastModifiedDate() {\n        return getModTime();\n    }\n\n    /**\n     * Get this entry's checksum status.\n     *\n     * @return if the header checksum is reasonably correct\n     * @see TarUtils#verifyCheckSum(byte[])\n     * @since 1.5\n     */\n    public boolean isCheckSumOK() {\n        return checkSumOK;\n    }\n\n    /**\n     * Get this entry's file.\n     *\n     * @return This entry's file.\n     */\n    public File getFile() {\n        return file;\n    }\n\n    /**\n     * Get this entry's mode.\n     *\n     * @return This entry's mode.\n     */\n    public int getMode() {\n        return mode;\n    }\n\n    /**\n     * Get this entry's file size.\n     *\n     * @return This entry's file size.\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Set this entry's file size.\n     *\n     * @param size This entry's new file size.\n     * @throws IllegalArgumentException if the size is &lt; 0.\n     */\n    public void setSize(final long size) {\n        if (size < 0){\n            throw new IllegalArgumentException(\"Size is out of range: \"+size);\n        }\n        this.size = size;\n    }\n\n    /**\n     * Get this entry's major device number.\n     *\n     * @return This entry's major device number.\n     * @since 1.4\n     */\n    public int getDevMajor() {\n        return devMajor;\n    }\n\n    /**\n     * Set this entry's major device number.\n     *\n     * @param devNo This entry's major device number.\n     * @throws IllegalArgumentException if the devNo is &lt; 0.\n     * @since 1.4\n     */\n    public void setDevMajor(final int devNo) {\n        if (devNo < 0){\n            throw new IllegalArgumentException(\"Major device number is out of \"\n                                               + \"range: \" + devNo);\n        }\n        this.devMajor = devNo;\n    }\n\n    /**\n     * Get this entry's minor device number.\n     *\n     * @return This entry's minor device number.\n     * @since 1.4\n     */\n    public int getDevMinor() {\n        return devMinor;\n    }\n\n    /**\n     * Set this entry's minor device number.\n     *\n     * @param devNo This entry's minor device number.\n     * @throws IllegalArgumentException if the devNo is &lt; 0.\n     * @since 1.4\n     */\n    public void setDevMinor(final int devNo) {\n        if (devNo < 0){\n            throw new IllegalArgumentException(\"Minor device number is out of \"\n                                               + \"range: \" + devNo);\n        }\n        this.devMinor = devNo;\n    }\n\n    /**\n     * Indicates in case of an oldgnu sparse file if an extension\n     * sparse header follows.\n     *\n     * @return true if an extension oldgnu sparse header follows.\n     */\n    public boolean isExtended() {\n        return isExtended;\n    }\n\n    /**\n     * Get this entry's real file size in case of a sparse file.\n     *\n     * @return This entry's real file size.\n     */\n    public long getRealSize() {\n        return realSize;\n    }\n\n    /**\n     * Indicate if this entry is a GNU sparse block.\n     *\n     * @return true if this is a sparse extension provided by GNU tar\n     */\n    public boolean isGNUSparse() {\n        return isOldGNUSparse() || isPaxGNUSparse();\n    }\n\n    /**\n     * Indicate if this entry is a GNU or star sparse block using the\n     * oldgnu format.\n     *\n     * @return true if this is a sparse extension provided by GNU tar or star\n     * @since 1.11\n     */\n    public boolean isOldGNUSparse() {\n        return linkFlag == LF_GNUTYPE_SPARSE;\n    }\n\n    /**\n     * Indicate if this entry is a GNU sparse block using one of the\n     * PAX formats.\n     *\n     * @return true if this is a sparse extension provided by GNU tar\n     * @since 1.11\n     */\n    public boolean isPaxGNUSparse() {\n        return paxGNUSparse;\n    }\n\n    /**\n     * Indicate if this entry is a star sparse block using PAX headers.\n     *\n     * @return true if this is a sparse extension provided by star\n     * @since 1.11\n     */\n    public boolean isStarSparse() {\n        return starSparse;\n    }\n\n    /**\n     * Indicate if this entry is a GNU long linkname block\n     *\n     * @return true if this is a long name extension provided by GNU tar\n     */\n    public boolean isGNULongLinkEntry() {\n        return linkFlag == LF_GNUTYPE_LONGLINK;\n    }\n\n    /**\n     * Indicate if this entry is a GNU long name block\n     *\n     * @return true if this is a long name extension provided by GNU tar\n     */\n    public boolean isGNULongNameEntry() {\n        return linkFlag == LF_GNUTYPE_LONGNAME;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     *\n     */\n    public boolean isPaxHeader(){\n        return linkFlag == LF_PAX_EXTENDED_HEADER_LC\n            || linkFlag == LF_PAX_EXTENDED_HEADER_UC;\n    }\n\n    /**\n     * Check if this is a Pax header.\n     *\n     * @return {@code true} if this is a Pax header.\n     *\n     * @since 1.1\n     */\n    public boolean isGlobalPaxHeader(){\n        return linkFlag == LF_PAX_GLOBAL_EXTENDED_HEADER;\n    }\n\n    /**\n     * Return whether or not this entry represents a directory.\n     *\n     * @return True if this entry is a directory.\n     */\n    @Override\n    public boolean isDirectory() {\n        if (file != null) {\n            return file.isDirectory();\n        }\n\n        if (linkFlag == LF_DIR) {\n            return true;\n        }\n\n        if (!isPaxHeader() && !isGlobalPaxHeader() && getName().endsWith(\"/\")) {\n            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Check if this is a \"normal file\"\n     *\n     * @since 1.2\n     * @return whether this is a \"normal file\"\n     */\n    public boolean isFile() {\n        if (file != null) {\n            return file.isFile();\n        }\n        if (linkFlag == LF_OLDNORM || linkFlag == LF_NORMAL) {\n            return true;\n        }\n        return !getName().endsWith(\"/\");\n    }\n\n    /**\n     * Check if this is a symbolic link entry.\n     *\n     * @since 1.2\n     * @return whether this is a symbolic link\n     */\n    public boolean isSymbolicLink() {\n        return linkFlag == LF_SYMLINK;\n    }\n\n    /**\n     * Check if this is a link entry.\n     *\n     * @since 1.2\n     * @return whether this is a link entry\n     */\n    public boolean isLink() {\n        return linkFlag == LF_LINK;\n    }\n\n    /**\n     * Check if this is a character device entry.\n     *\n     * @since 1.2\n     * @return whether this is a character device\n     */\n    public boolean isCharacterDevice() {\n        return linkFlag == LF_CHR;\n    }\n\n    /**\n     * Check if this is a block device entry.\n     *\n     * @since 1.2\n     * @return whether this is a block device\n     */\n    public boolean isBlockDevice() {\n        return linkFlag == LF_BLK;\n    }\n\n    /**\n     * Check if this is a FIFO (pipe) entry.\n     *\n     * @since 1.2\n     * @return whether this is a FIFO entry\n     */\n    public boolean isFIFO() {\n        return linkFlag == LF_FIFO;\n    }\n\n    /**\n     * Check whether this is a sparse entry.\n     *\n     * @return whether this is a sparse entry\n     * @since 1.11\n     */\n    public boolean isSparse() {\n        return isGNUSparse() || isStarSparse();\n    }\n\n    /**\n     * If this entry represents a file, and the file is a directory, return\n     * an array of TarEntries for this entry's children.\n     *\n     * @return An array of TarEntry's for this entry's children.\n     */\n    public TarArchiveEntry[] getDirectoryEntries() {\n        if (file == null || !file.isDirectory()) {\n            return EMPTY_TAR_ARCHIVE_ENTRIES;\n        }\n\n        final String[] list = file.list();\n        if (list == null) {\n            return EMPTY_TAR_ARCHIVE_ENTRIES;\n        }\n        final TarArchiveEntry[] result = new TarArchiveEntry[list.length];\n\n        for (int i = 0; i < result.length; ++i) {\n            result[i] = new TarArchiveEntry(new File(file, list[i]));\n        }\n\n        return result;\n    }\n\n    /**\n     * Write an entry's header information to a header buffer.\n     *\n     * <p>This method does not use the star/GNU tar/BSD tar extensions.</p>\n     *\n     * @param outbuf The tar entry header buffer to fill in.\n     */\n    public void writeEntryHeader(final byte[] outbuf) {\n        try {\n            writeEntryHeader(outbuf, TarUtils.DEFAULT_ENCODING, false);\n        } catch (final IOException ex) {\n            try {\n                writeEntryHeader(outbuf, TarUtils.FALLBACK_ENCODING, false);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Write an entry's header information to a header buffer.\n     *\n     * @param outbuf The tar entry header buffer to fill in.\n     * @param encoding encoding to use when writing the file name.\n     * @param starMode whether to use the star/GNU tar/BSD tar\n     * extension for numeric fields if their value doesn't fit in the\n     * maximum size of standard tar archives\n     * @since 1.4\n     * @throws IOException on error\n     */\n    public void writeEntryHeader(final byte[] outbuf, final ZipEncoding encoding,\n                                 final boolean starMode) throws IOException {\n        int offset = 0;\n\n        offset = TarUtils.formatNameBytes(name, outbuf, offset, NAMELEN,\n                                          encoding);\n        offset = writeEntryHeaderField(mode, outbuf, offset, MODELEN, starMode);\n        offset = writeEntryHeaderField(userId, outbuf, offset, UIDLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(groupId, outbuf, offset, GIDLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(size, outbuf, offset, SIZELEN, starMode);\n        offset = writeEntryHeaderField(modTime, outbuf, offset, MODTIMELEN,\n                                       starMode);\n\n        final int csOffset = offset;\n\n        for (int c = 0; c < CHKSUMLEN; ++c) {\n            outbuf[offset++] = (byte) ' ';\n        }\n\n        outbuf[offset++] = linkFlag;\n        offset = TarUtils.formatNameBytes(linkName, outbuf, offset, NAMELEN,\n                                          encoding);\n        offset = TarUtils.formatNameBytes(magic, outbuf, offset, MAGICLEN);\n        offset = TarUtils.formatNameBytes(version, outbuf, offset, VERSIONLEN);\n        offset = TarUtils.formatNameBytes(userName, outbuf, offset, UNAMELEN,\n                                          encoding);\n        offset = TarUtils.formatNameBytes(groupName, outbuf, offset, GNAMELEN,\n                                          encoding);\n        offset = writeEntryHeaderField(devMajor, outbuf, offset, DEVLEN,\n                                       starMode);\n        offset = writeEntryHeaderField(devMinor, outbuf, offset, DEVLEN,\n                                       starMode);\n\n        while (offset < outbuf.length) {\n            outbuf[offset++] = 0;\n        }\n\n        final long chk = TarUtils.computeCheckSum(outbuf);\n\n        TarUtils.formatCheckSumOctalBytes(chk, outbuf, csOffset, CHKSUMLEN);\n    }\n\n    private int writeEntryHeaderField(final long value, final byte[] outbuf, final int offset,\n                                      final int length, final boolean starMode) {\n        if (!starMode && (value < 0\n                          || value >= 1l << 3 * (length - 1))) {\n            // value doesn't fit into field when written as octal\n            // number, will be written to PAX header or causes an\n            // error\n            return TarUtils.formatLongOctalBytes(0, outbuf, offset, length);\n        }\n        return TarUtils.formatLongOctalOrBinaryBytes(value, outbuf, offset,\n                                                     length);\n    }\n\n    /**\n     * Parse an entry's header information from a header buffer.\n     *\n     * @param header The tar entry header buffer to get information from.\n     * @throws IllegalArgumentException if any of the numeric fields have an invalid format\n     */\n    public void parseTarHeader(final byte[] header) {\n        try {\n            parseTarHeader(header, TarUtils.DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                parseTarHeader(header, TarUtils.DEFAULT_ENCODING, true);\n            } catch (final IOException ex2) {\n                // not really possible\n                throw new RuntimeException(ex2);\n            }\n        }\n    }\n\n    /**\n     * Parse an entry's header information from a header buffer.\n     *\n     * @param header The tar entry header buffer to get information from.\n     * @param encoding encoding to use for file names\n     * @since 1.4\n     * @throws IllegalArgumentException if any of the numeric fields\n     * have an invalid format\n     * @throws IOException on error\n     */\n    public void parseTarHeader(final byte[] header, final ZipEncoding encoding)\n        throws IOException {\n        parseTarHeader(header, encoding, false);\n    }\n\n    private void parseTarHeader(final byte[] header, final ZipEncoding encoding,\n                                final boolean oldStyle)\n        throws IOException {\n        int offset = 0;\n\n        name = oldStyle ? TarUtils.parseName(header, offset, NAMELEN)\n            : TarUtils.parseName(header, offset, NAMELEN, encoding);\n        offset += NAMELEN;\n        mode = (int) TarUtils.parseOctalOrBinary(header, offset, MODELEN);\n        offset += MODELEN;\n        userId = (int) TarUtils.parseOctalOrBinary(header, offset, UIDLEN);\n        offset += UIDLEN;\n        groupId = (int) TarUtils.parseOctalOrBinary(header, offset, GIDLEN);\n        offset += GIDLEN;\n        size = TarUtils.parseOctalOrBinary(header, offset, SIZELEN);\n        offset += SIZELEN;\n        modTime = TarUtils.parseOctalOrBinary(header, offset, MODTIMELEN);\n        offset += MODTIMELEN;\n        checkSumOK = TarUtils.verifyCheckSum(header);\n        offset += CHKSUMLEN;\n        linkFlag = header[offset++];\n        linkName = oldStyle ? TarUtils.parseName(header, offset, NAMELEN)\n            : TarUtils.parseName(header, offset, NAMELEN, encoding);\n        offset += NAMELEN;\n        magic = TarUtils.parseName(header, offset, MAGICLEN);\n        offset += MAGICLEN;\n        version = TarUtils.parseName(header, offset, VERSIONLEN);\n        offset += VERSIONLEN;\n        userName = oldStyle ? TarUtils.parseName(header, offset, UNAMELEN)\n            : TarUtils.parseName(header, offset, UNAMELEN, encoding);\n        offset += UNAMELEN;\n        groupName = oldStyle ? TarUtils.parseName(header, offset, GNAMELEN)\n            : TarUtils.parseName(header, offset, GNAMELEN, encoding);\n        offset += GNAMELEN;\n        devMajor = (int) TarUtils.parseOctalOrBinary(header, offset, DEVLEN);\n        offset += DEVLEN;\n        devMinor = (int) TarUtils.parseOctalOrBinary(header, offset, DEVLEN);\n        offset += DEVLEN;\n\n        final int type = evaluateType(header);\n        switch (type) {\n        case FORMAT_OLDGNU: {\n            offset += ATIMELEN_GNU;\n            offset += CTIMELEN_GNU;\n            offset += OFFSETLEN_GNU;\n            offset += LONGNAMESLEN_GNU;\n            offset += PAD2LEN_GNU;\n            offset += SPARSELEN_GNU;\n            isExtended = TarUtils.parseBoolean(header, offset);\n            offset += ISEXTENDEDLEN_GNU;\n            realSize = TarUtils.parseOctal(header, offset, REALSIZELEN_GNU);\n            offset += REALSIZELEN_GNU;\n            break;\n        }\n        case FORMAT_XSTAR: {\n            final String xstarPrefix = oldStyle\n                ? TarUtils.parseName(header, offset, PREFIXLEN_XSTAR)\n                : TarUtils.parseName(header, offset, PREFIXLEN_XSTAR, encoding);\n            if (xstarPrefix.length() > 0) {\n                name = xstarPrefix + \"/\" + name;\n            }\n            break;\n        }\n        case FORMAT_POSIX:\n        default: {\n            final String prefix = oldStyle\n                ? TarUtils.parseName(header, offset, PREFIXLEN)\n                : TarUtils.parseName(header, offset, PREFIXLEN, encoding);\n            // SunOS tar -E does not add / to directory names, so fix\n            // up to be consistent\n            if (isDirectory() && !name.endsWith(\"/\")){\n                name = name + \"/\";\n            }\n            if (prefix.length() > 0){\n                name = prefix + \"/\" + name;\n            }\n        }\n        }\n    }\n\n    /**\n     * Strips Windows' drive letter as well as any leading slashes,\n     * turns path separators into forward slahes.\n     */\n    private static String normalizeFileName(String fileName,\n                                            final boolean preserveLeadingSlashes) {\n        final String osname = System.getProperty(\"os.name\").toLowerCase(Locale.ENGLISH);\n\n        if (osname != null) {\n\n            // Strip off drive letters!\n            // REVIEW Would a better check be \"(File.separator == '\\')\"?\n\n            if (osname.startsWith(\"windows\")) {\n                if (fileName.length() > 2) {\n                    final char ch1 = fileName.charAt(0);\n                    final char ch2 = fileName.charAt(1);\n\n                    if (ch2 == ':'\n                        && (ch1 >= 'a' && ch1 <= 'z'\n                            || ch1 >= 'A' && ch1 <= 'Z')) {\n                        fileName = fileName.substring(2);\n                    }\n                }\n            } else if (osname.contains(\"netware\")) {\n                final int colon = fileName.indexOf(':');\n                if (colon != -1) {\n                    fileName = fileName.substring(colon + 1);\n                }\n            }\n        }\n\n        fileName = fileName.replace(File.separatorChar, '/');\n\n        // No absolute pathnames\n        // Windows (and Posix?) paths can start with \"\\\\NetworkDrive\\\",\n        // so we loop on starting /'s.\n        while (!preserveLeadingSlashes && fileName.startsWith(\"/\")) {\n            fileName = fileName.substring(1);\n        }\n        return fileName;\n    }\n\n    /**\n     * Evaluate an entry's header format from a header buffer.\n     *\n     * @param header The tar entry header buffer to evaluate the format for.\n     * @return format type\n     */\n    private int evaluateType(final byte[] header) {\n        if (ArchiveUtils.matchAsciiBuffer(MAGIC_GNU, header, MAGIC_OFFSET, MAGICLEN)) {\n            return FORMAT_OLDGNU;\n        }\n        if (ArchiveUtils.matchAsciiBuffer(MAGIC_POSIX, header, MAGIC_OFFSET, MAGICLEN)) {\n            if (ArchiveUtils.matchAsciiBuffer(MAGIC_XSTAR, header, XSTAR_MAGIC_OFFSET,\n                                              XSTAR_MAGIC_LEN)) {\n                return FORMAT_XSTAR;\n            }\n            return FORMAT_POSIX;\n        }\n        return 0;\n    }\n\n    void fillGNUSparse0xData(final Map<String, String> headers) {\n        paxGNUSparse = true;\n        realSize = Integer.parseInt(headers.get(\"GNU.sparse.size\"));\n        if (headers.containsKey(\"GNU.sparse.name\")) {\n            // version 0.1\n            name = headers.get(\"GNU.sparse.name\");\n        }\n    }\n\n    void fillGNUSparse1xData(final Map<String, String> headers) {\n        paxGNUSparse = true;\n        realSize = Integer.parseInt(headers.get(\"GNU.sparse.realsize\"));\n        name = headers.get(\"GNU.sparse.name\");\n    }\n\n    void fillStarSparseData(final Map<String, String> headers) {\n        starSparse = true;\n        if (headers.containsKey(\"SCHILY.realsize\")) {\n            realSize = Long.parseLong(headers.get(\"SCHILY.realsize\"));\n        }\n    }\n}\n\n"}]}
{"project": "Compress", "bug_id": 39, "classes_modified": [{"class_name": "org.apache.commons.compress.utils.ArchiveUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * \n */\n\npackage org.apache.commons.compress.utils;\n\nimport java.io.UnsupportedEncodingException;\nimport java.util.Arrays;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Generic Archive utilities\n */\npublic class ArchiveUtils {\n\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private ArchiveUtils(){\n    }\n\n    /**\n     * Generates a string containing the name, isDirectory setting and size of an entry.\n     * <p>\n     * For example:\n     * <pre>\n     * -    2000 main.c\n     * d     100 testfiles\n     * </pre>\n     * \n     * @param entry the entry\n     * @return the representation of the entry\n     */\n    public static String toString(final ArchiveEntry entry){\n        final StringBuilder sb = new StringBuilder();\n        sb.append(entry.isDirectory()? 'd' : '-');// c.f. \"ls -l\" output\n        final String size = Long.toString(entry.getSize());\n        sb.append(' ');\n        // Pad output to 7 places, leading spaces\n        for(int i=7; i > size.length(); i--){\n            sb.append(' ');\n        }\n        sb.append(size);\n        sb.append(' ').append(entry.getName());\n        return sb.toString();\n    }\n\n    /**\n     * Check if buffer contents matches Ascii String.\n     * \n     * @param expected expected string\n     * @param buffer the buffer\n     * @param offset offset to read from\n     * @param length length of the buffer\n     * @return {@code true} if buffer is the same as the expected string\n     */\n    public static boolean matchAsciiBuffer(\n            final String expected, final byte[] buffer, final int offset, final int length){\n        byte[] buffer1;\n        try {\n            buffer1 = expected.getBytes(CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should not happen\n        }\n        return isEqual(buffer1, 0, buffer1.length, buffer, offset, length, false);\n    }\n\n    /**\n     * Check if buffer contents matches Ascii String.\n     * \n     * @param expected the expected strin\n     * @param buffer the buffer\n     * @return {@code true} if buffer is the same as the expected string\n     */\n    public static boolean matchAsciiBuffer(final String expected, final byte[] buffer){\n        return matchAsciiBuffer(expected, buffer, 0, buffer.length);\n    }\n\n    /**\n     * Convert a string to Ascii bytes.\n     * Used for comparing \"magic\" strings which need to be independent of the default Locale.\n     * \n     * @param inputString string to convert\n     * @return the bytes\n     */\n    public static byte[] toAsciiBytes(final String inputString){\n        try {\n            return inputString.getBytes(CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n           throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Convert an input byte array to a String using the ASCII character set.\n     * \n     * @param inputBytes bytes to convert\n     * @return the bytes, interpreted as an Ascii string\n     */\n    public static String toAsciiString(final byte[] inputBytes){\n        try {\n            return new String(inputBytes, CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Convert an input byte array to a String using the ASCII character set.\n     * \n     * @param inputBytes input byte array\n     * @param offset offset within array\n     * @param length length of array\n     * @return the bytes, interpreted as an Ascii string\n     */\n    public static String toAsciiString(final byte[] inputBytes, final int offset, final int length){\n        try {\n            return new String(inputBytes, offset, length, CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Compare byte buffers, optionally ignoring trailing nulls\n     * \n     * @param buffer1 first buffer\n     * @param offset1 first offset\n     * @param length1 first length\n     * @param buffer2 second buffer\n     * @param offset2 second offset\n     * @param length2 second length\n     * @param ignoreTrailingNulls whether to ignore trailing nulls\n     * @return {@code true} if buffer1 and buffer2 have same contents, having regard to trailing nulls\n     */\n    public static boolean isEqual(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2,\n            final boolean ignoreTrailingNulls){\n        final int minLen=length1 < length2 ? length1 : length2;\n        for (int i=0; i < minLen; i++){\n            if (buffer1[offset1+i] != buffer2[offset2+i]){\n                return false;\n            }\n        }\n        if (length1 == length2){\n            return true;\n        }\n        if (ignoreTrailingNulls){\n            if (length1 > length2){\n                for(int i = length2; i < length1; i++){\n                    if (buffer1[offset1+i] != 0){\n                        return false;\n                    }\n                }\n            } else {\n                for(int i = length1; i < length2; i++){\n                    if (buffer2[offset2+i] != 0){\n                        return false;\n                    }\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n\n    /**\n     * Compare byte buffers\n     * \n     * @param buffer1 the first buffer\n     * @param offset1 the first offset\n     * @param length1 the first length\n     * @param buffer2 the second buffer\n     * @param offset2 the second offset\n     * @param length2 the second length\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2){\n        return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, false);\n    }\n\n    /**\n     * Compare byte buffers\n     * \n     * @param buffer1 the first buffer\n     * @param buffer2 the second buffer\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(final byte[] buffer1, final byte[] buffer2 ){\n        return isEqual(buffer1, 0, buffer1.length, buffer2, 0, buffer2.length, false);\n    }\n\n    /**\n     * Compare byte buffers, optionally ignoring trailing nulls\n     * \n     * @param buffer1 the first buffer\n     * @param buffer2 the second buffer \n     * @param ignoreTrailingNulls whether to ignore tariling nulls\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(final byte[] buffer1, final byte[] buffer2, final boolean ignoreTrailingNulls){\n        return isEqual(buffer1, 0, buffer1.length, buffer2, 0, buffer2.length, ignoreTrailingNulls);\n    }\n\n    /**\n     * Compare byte buffers, ignoring trailing nulls\n     * \n     * @param buffer1 the first buffer\n     * @param offset1 the first offset\n     * @param length1 the first length\n     * @param buffer2 the second buffer\n     * @param offset2 the second offset\n     * @param length2 the second length\n     * @return {@code true} if buffer1 and buffer2 have same contents, having regard to trailing nulls\n     */\n    public static boolean isEqualWithNull(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2){\n        return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, true);\n    }\n    \n    /**\n     * Returns true if the first N bytes of an array are all zero\n     * \n     * @param a\n     *            The array to check\n     * @param size\n     *            The number of characters to check (not the size of the array)\n     * @return true if the first N bytes are zero\n     */\n    public static boolean isArrayZero(final byte[] a, final int size) {\n        for (int i = 0; i < size; i++) {\n            if (a[i] != 0) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Returns a \"sanitized\" version of the string given as arguments,\n     * where sanitized means non-printable characters have been\n     * replaced with a question mark and the outcome is not longer\n     * than 255 chars.\n     *\n     * <p>This method is used to clean up file names when they are\n     * used in exception messages as they may end up in log files or\n     * as console output and may have been read from a corrupted\n     * input.</p>\n     *\n     * @param s the string to sanitize\n     * @return a sanitized version of the argument\n     * @since Compress 1.12\n     */\n    public static String sanitize(String s) {\n        final char[] chars = s.toCharArray();\n        final int len = chars.length;\n        final StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < len; i++) {\n            final char c = chars[i];\n            if (!Character.isISOControl(c)) {\n                Character.UnicodeBlock block = Character.UnicodeBlock.of(c);\n                if (block != null && block != Character.UnicodeBlock.SPECIALS) {\n                    sb.append(c);\n                    continue;\n                }\n            }\n            sb.append('?');\n        }\n        return sb.toString();\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * \n */\n\npackage org.apache.commons.compress.utils;\n\nimport java.io.UnsupportedEncodingException;\nimport java.util.Arrays;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\n/**\n * Generic Archive utilities\n */\npublic class ArchiveUtils {\n\n    private static final int MAX_SANITIZED_NAME_LENGTH = 255;\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private ArchiveUtils(){\n    }\n\n    /**\n     * Generates a string containing the name, isDirectory setting and size of an entry.\n     * <p>\n     * For example:\n     * <pre>\n     * -    2000 main.c\n     * d     100 testfiles\n     * </pre>\n     * \n     * @param entry the entry\n     * @return the representation of the entry\n     */\n    public static String toString(final ArchiveEntry entry){\n        final StringBuilder sb = new StringBuilder();\n        sb.append(entry.isDirectory()? 'd' : '-');// c.f. \"ls -l\" output\n        final String size = Long.toString(entry.getSize());\n        sb.append(' ');\n        // Pad output to 7 places, leading spaces\n        for(int i=7; i > size.length(); i--){\n            sb.append(' ');\n        }\n        sb.append(size);\n        sb.append(' ').append(entry.getName());\n        return sb.toString();\n    }\n\n    /**\n     * Check if buffer contents matches Ascii String.\n     * \n     * @param expected expected string\n     * @param buffer the buffer\n     * @param offset offset to read from\n     * @param length length of the buffer\n     * @return {@code true} if buffer is the same as the expected string\n     */\n    public static boolean matchAsciiBuffer(\n            final String expected, final byte[] buffer, final int offset, final int length){\n        byte[] buffer1;\n        try {\n            buffer1 = expected.getBytes(CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should not happen\n        }\n        return isEqual(buffer1, 0, buffer1.length, buffer, offset, length, false);\n    }\n\n    /**\n     * Check if buffer contents matches Ascii String.\n     * \n     * @param expected the expected strin\n     * @param buffer the buffer\n     * @return {@code true} if buffer is the same as the expected string\n     */\n    public static boolean matchAsciiBuffer(final String expected, final byte[] buffer){\n        return matchAsciiBuffer(expected, buffer, 0, buffer.length);\n    }\n\n    /**\n     * Convert a string to Ascii bytes.\n     * Used for comparing \"magic\" strings which need to be independent of the default Locale.\n     * \n     * @param inputString string to convert\n     * @return the bytes\n     */\n    public static byte[] toAsciiBytes(final String inputString){\n        try {\n            return inputString.getBytes(CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n           throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Convert an input byte array to a String using the ASCII character set.\n     * \n     * @param inputBytes bytes to convert\n     * @return the bytes, interpreted as an Ascii string\n     */\n    public static String toAsciiString(final byte[] inputBytes){\n        try {\n            return new String(inputBytes, CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Convert an input byte array to a String using the ASCII character set.\n     * \n     * @param inputBytes input byte array\n     * @param offset offset within array\n     * @param length length of array\n     * @return the bytes, interpreted as an Ascii string\n     */\n    public static String toAsciiString(final byte[] inputBytes, final int offset, final int length){\n        try {\n            return new String(inputBytes, offset, length, CharsetNames.US_ASCII);\n        } catch (final UnsupportedEncodingException e) {\n            throw new RuntimeException(e); // Should never happen\n        }\n    }\n\n    /**\n     * Compare byte buffers, optionally ignoring trailing nulls\n     * \n     * @param buffer1 first buffer\n     * @param offset1 first offset\n     * @param length1 first length\n     * @param buffer2 second buffer\n     * @param offset2 second offset\n     * @param length2 second length\n     * @param ignoreTrailingNulls whether to ignore trailing nulls\n     * @return {@code true} if buffer1 and buffer2 have same contents, having regard to trailing nulls\n     */\n    public static boolean isEqual(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2,\n            final boolean ignoreTrailingNulls){\n        final int minLen=length1 < length2 ? length1 : length2;\n        for (int i=0; i < minLen; i++){\n            if (buffer1[offset1+i] != buffer2[offset2+i]){\n                return false;\n            }\n        }\n        if (length1 == length2){\n            return true;\n        }\n        if (ignoreTrailingNulls){\n            if (length1 > length2){\n                for(int i = length2; i < length1; i++){\n                    if (buffer1[offset1+i] != 0){\n                        return false;\n                    }\n                }\n            } else {\n                for(int i = length1; i < length2; i++){\n                    if (buffer2[offset2+i] != 0){\n                        return false;\n                    }\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n\n    /**\n     * Compare byte buffers\n     * \n     * @param buffer1 the first buffer\n     * @param offset1 the first offset\n     * @param length1 the first length\n     * @param buffer2 the second buffer\n     * @param offset2 the second offset\n     * @param length2 the second length\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2){\n        return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, false);\n    }\n\n    /**\n     * Compare byte buffers\n     * \n     * @param buffer1 the first buffer\n     * @param buffer2 the second buffer\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(final byte[] buffer1, final byte[] buffer2 ){\n        return isEqual(buffer1, 0, buffer1.length, buffer2, 0, buffer2.length, false);\n    }\n\n    /**\n     * Compare byte buffers, optionally ignoring trailing nulls\n     * \n     * @param buffer1 the first buffer\n     * @param buffer2 the second buffer \n     * @param ignoreTrailingNulls whether to ignore tariling nulls\n     * @return {@code true} if buffer1 and buffer2 have same contents\n     */\n    public static boolean isEqual(final byte[] buffer1, final byte[] buffer2, final boolean ignoreTrailingNulls){\n        return isEqual(buffer1, 0, buffer1.length, buffer2, 0, buffer2.length, ignoreTrailingNulls);\n    }\n\n    /**\n     * Compare byte buffers, ignoring trailing nulls\n     * \n     * @param buffer1 the first buffer\n     * @param offset1 the first offset\n     * @param length1 the first length\n     * @param buffer2 the second buffer\n     * @param offset2 the second offset\n     * @param length2 the second length\n     * @return {@code true} if buffer1 and buffer2 have same contents, having regard to trailing nulls\n     */\n    public static boolean isEqualWithNull(\n            final byte[] buffer1, final int offset1, final int length1,\n            final byte[] buffer2, final int offset2, final int length2){\n        return isEqual(buffer1, offset1, length1, buffer2, offset2, length2, true);\n    }\n    \n    /**\n     * Returns true if the first N bytes of an array are all zero\n     * \n     * @param a\n     *            The array to check\n     * @param size\n     *            The number of characters to check (not the size of the array)\n     * @return true if the first N bytes are zero\n     */\n    public static boolean isArrayZero(final byte[] a, final int size) {\n        for (int i = 0; i < size; i++) {\n            if (a[i] != 0) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Returns a \"sanitized\" version of the string given as arguments,\n     * where sanitized means non-printable characters have been\n     * replaced with a question mark and the outcome is not longer\n     * than 255 chars.\n     *\n     * <p>This method is used to clean up file names when they are\n     * used in exception messages as they may end up in log files or\n     * as console output and may have been read from a corrupted\n     * input.</p>\n     *\n     * @param s the string to sanitize\n     * @return a sanitized version of the argument\n     * @since Compress 1.12\n     */\n    public static String sanitize(String s) {\n        final char[] cs = s.toCharArray();\n        final char[] chars = cs.length <= MAX_SANITIZED_NAME_LENGTH ? cs : Arrays.copyOf(cs, MAX_SANITIZED_NAME_LENGTH);\n        if (cs.length > MAX_SANITIZED_NAME_LENGTH) {\n            for (int i = MAX_SANITIZED_NAME_LENGTH - 3; i < MAX_SANITIZED_NAME_LENGTH; i++) {\n                chars[i] = '.';\n            }\n        }\n        final int len = chars.length;\n        final StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < len; i++) {\n            final char c = chars[i];\n            if (!Character.isISOControl(c)) {\n                Character.UnicodeBlock block = Character.UnicodeBlock.of(c);\n                if (block != null && block != Character.UnicodeBlock.SPECIALS) {\n                    sb.append(c);\n                    continue;\n                }\n            }\n            sb.append('?');\n        }\n        return sb.toString();\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 40, "classes_modified": [{"class_name": "org.apache.commons.compress.utils.BitInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.ByteOrder;\n\n/**\n * Reads bits from an InputStream.\n * @since 1.10\n * @NotThreadSafe\n */\npublic class BitInputStream implements Closeable {\n    private static final int MAXIMUM_CACHE_SIZE = 63; // bits in long minus sign bit\n    private static final long[] MASKS = new long[MAXIMUM_CACHE_SIZE + 1];\n\n    static {\n        for (int i = 1; i <= MAXIMUM_CACHE_SIZE; i++) {\n            MASKS[i] = (MASKS[i - 1] << 1) + 1;\n        }\n    }\n\n    private final InputStream in;\n    private final ByteOrder byteOrder;\n    private long bitsCached = 0;\n    private int bitsCachedSize = 0;\n\n    /**\n     * Constructor taking an InputStream and its bit arrangement. \n     * @param in the InputStream\n     * @param byteOrder the bit arrangement across byte boundaries,\n     *      either BIG_ENDIAN (aaaaabbb bb000000) or LITTLE_ENDIAN (bbbaaaaa 000000bb)\n     */\n    public BitInputStream(final InputStream in, final ByteOrder byteOrder) {\n        this.in = in;\n        this.byteOrder = byteOrder;\n    }\n    \n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n    \n    /**\n     * Clears the cache of bits that have been read from the\n     * underlying stream but not yet provided via {@link #readBits}.\n     */\n    public void clearBitCache() {\n        bitsCached = 0;\n        bitsCachedSize = 0;\n    }\n    \n    /**\n     * Returns at most 63 bits read from the underlying stream.\n     *\n     * @param count the number of bits to read, must be a positive\n     * number not bigger than 63.\n     * @return the bits concatenated as a long using the stream's byte order.\n     *         -1 if the end of the underlying stream has been reached before reading\n     *         the requested number of bits\n     * @throws IOException on error\n     */\n    public long readBits(final int count) throws IOException {\n        if (count < 0 || count > MAXIMUM_CACHE_SIZE) {\n            throw new IllegalArgumentException(\"count must not be negative or greater than \" + MAXIMUM_CACHE_SIZE);\n        }\n        while (bitsCachedSize < count) {\n            final long nextByte = in.read();\n            if (nextByte < 0) {\n                return nextByte;\n            }\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                bitsCached |= (nextByte << bitsCachedSize);\n            } else {\n                bitsCached <<= 8;\n                bitsCached |= nextByte;\n            }\n            bitsCachedSize += 8;\n        }\n            // bitsCachedSize >= 57 and left-shifting it 8 bits would cause an overflow\n        \n        final long bitsOut;\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                bitsOut = (bitsCached & MASKS[count]);\n                bitsCached >>>= count;\n            } else {\n                bitsOut = (bitsCached >> (bitsCachedSize - count)) & MASKS[count];\n            }\n            bitsCachedSize -= count;\n        return bitsOut;\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.ByteOrder;\n\n/**\n * Reads bits from an InputStream.\n * @since 1.10\n * @NotThreadSafe\n */\npublic class BitInputStream implements Closeable {\n    private static final int MAXIMUM_CACHE_SIZE = 63; // bits in long minus sign bit\n    private static final long[] MASKS = new long[MAXIMUM_CACHE_SIZE + 1];\n\n    static {\n        for (int i = 1; i <= MAXIMUM_CACHE_SIZE; i++) {\n            MASKS[i] = (MASKS[i - 1] << 1) + 1;\n        }\n    }\n\n    private final InputStream in;\n    private final ByteOrder byteOrder;\n    private long bitsCached = 0;\n    private int bitsCachedSize = 0;\n\n    /**\n     * Constructor taking an InputStream and its bit arrangement. \n     * @param in the InputStream\n     * @param byteOrder the bit arrangement across byte boundaries,\n     *      either BIG_ENDIAN (aaaaabbb bb000000) or LITTLE_ENDIAN (bbbaaaaa 000000bb)\n     */\n    public BitInputStream(final InputStream in, final ByteOrder byteOrder) {\n        this.in = in;\n        this.byteOrder = byteOrder;\n    }\n    \n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n    \n    /**\n     * Clears the cache of bits that have been read from the\n     * underlying stream but not yet provided via {@link #readBits}.\n     */\n    public void clearBitCache() {\n        bitsCached = 0;\n        bitsCachedSize = 0;\n    }\n    \n    /**\n     * Returns at most 63 bits read from the underlying stream.\n     *\n     * @param count the number of bits to read, must be a positive\n     * number not bigger than 63.\n     * @return the bits concatenated as a long using the stream's byte order.\n     *         -1 if the end of the underlying stream has been reached before reading\n     *         the requested number of bits\n     * @throws IOException on error\n     */\n    public long readBits(final int count) throws IOException {\n        if (count < 0 || count > MAXIMUM_CACHE_SIZE) {\n            throw new IllegalArgumentException(\"count must not be negative or greater than \" + MAXIMUM_CACHE_SIZE);\n        }\n        while (bitsCachedSize < count && bitsCachedSize < 57) {\n            final long nextByte = in.read();\n            if (nextByte < 0) {\n                return nextByte;\n            }\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                bitsCached |= (nextByte << bitsCachedSize);\n            } else {\n                bitsCached <<= 8;\n                bitsCached |= nextByte;\n            }\n            bitsCachedSize += 8;\n        }\n        int overflowBits = 0;\n        long overflow = 0l;\n        if (bitsCachedSize < count) {\n            // bitsCachedSize >= 57 and left-shifting it 8 bits would cause an overflow\n            int bitsToAddCount = count - bitsCachedSize;\n            overflowBits = 8 - bitsToAddCount;\n            final long nextByte = in.read();\n            if (nextByte < 0) {\n                return nextByte;\n            }\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                long bitsToAdd = nextByte & MASKS[bitsToAddCount];\n                bitsCached |= (bitsToAdd << bitsCachedSize);\n                overflow = (nextByte >>> bitsToAddCount) & MASKS[overflowBits];\n            } else {\n                bitsCached <<= bitsToAddCount;\n                long bitsToAdd = (nextByte >>> (overflowBits)) & MASKS[bitsToAddCount];\n                bitsCached |= bitsToAdd;\n                overflow = nextByte & MASKS[overflowBits];\n            }\n            bitsCachedSize = count;\n        }\n        \n        final long bitsOut;\n        if (overflowBits == 0) {\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                bitsOut = (bitsCached & MASKS[count]);\n                bitsCached >>>= count;\n            } else {\n                bitsOut = (bitsCached >> (bitsCachedSize - count)) & MASKS[count];\n            }\n            bitsCachedSize -= count;\n        } else {\n            bitsOut = bitsCached & MASKS[count];\n            bitsCached = overflow;\n            bitsCachedSize = overflowBits;\n        }\n        return bitsOut;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 41, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n                current.in = new BZip2CompressorInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        final int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        final ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n            return null;\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n                current.in = new BZip2CompressorInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField) \n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        final int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        final ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(SKIP_BUF, 0, (int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n    \n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n    \n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 42, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.UnixStat", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Constants from stat.h on Unix systems.\n */\n// CheckStyle:InterfaceIsTypeCheck OFF - backward compatible\npublic interface UnixStat {\n\n    /**\n     * Bits used for permissions (and sticky bit)\n     */\n    int PERM_MASK = 07777;\n    /**\n     * Bits used to indicate the filesystem object type.\n     * @since 1.14\n     */\n    /**\n     * Indicates symbolic links.\n     */\n    int LINK_FLAG = 0120000;\n    /**\n     * Indicates plain files.\n     */\n    int FILE_FLAG = 0100000;\n    /**\n     * Indicates directories.\n     */\n    int DIR_FLAG = 040000;\n\n    // ----------------------------------------------------------\n    // somewhat arbitrary choices that are quite common for shared\n    // installations\n    // -----------------------------------------------------------\n\n    /**\n     * Default permissions for symbolic links.\n     */\n    int DEFAULT_LINK_PERM = 0777;\n\n    /**\n     * Default permissions for directories.\n     */\n    int DEFAULT_DIR_PERM = 0755;\n\n    /**\n     * Default permissions for plain files.\n     */\n    int DEFAULT_FILE_PERM = 0644;\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Constants from stat.h on Unix systems.\n */\n// CheckStyle:InterfaceIsTypeCheck OFF - backward compatible\npublic interface UnixStat {\n\n    /**\n     * Bits used for permissions (and sticky bit)\n     */\n    int PERM_MASK = 07777;\n    /**\n     * Bits used to indicate the filesystem object type.\n     * @since 1.14\n     */\n    int FILE_TYPE_FLAG = 0170000;\n    /**\n     * Indicates symbolic links.\n     */\n    int LINK_FLAG = 0120000;\n    /**\n     * Indicates plain files.\n     */\n    int FILE_FLAG = 0100000;\n    /**\n     * Indicates directories.\n     */\n    int DIR_FLAG = 040000;\n\n    // ----------------------------------------------------------\n    // somewhat arbitrary choices that are quite common for shared\n    // installations\n    // -----------------------------------------------------------\n\n    /**\n     * Default permissions for symbolic links.\n     */\n    int DEFAULT_LINK_PERM = 0777;\n\n    /**\n     * Default permissions for directories.\n     */\n    int DEFAULT_DIR_PERM = 0755;\n\n    /**\n     * Default permissions for plain files.\n     */\n    int DEFAULT_FILE_PERM = 0644;\n}\n"}, {"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveEntry", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.List;\nimport java.util.zip.ZipException;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">APPNOTE.TXT</a>:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    public static final int CRC_UNKNOWN = -1;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n    private static final byte[] EMPTY = new byte[0];\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = ZipMethod.UNKNOWN_CODE;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int versionRequired;\n    private int versionMadeBy;\n    private int platform = PLATFORM_FAT;\n    private int rawFlag;\n    private long externalAttributes = 0;\n    private ZipExtraField[] extraFields;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n    private static final ZipExtraField[] noExtraFields = new ZipExtraField[0];\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(final String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(final java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        final byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(final ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(getAllExtraFieldsNoCopy());\n        setPlatform(entry.getPlatform());\n        final GeneralPurposeBit other = entry.getGeneralPurposeBit();\n        setGeneralPurposeBit(other == null ? null :\n                             (GeneralPurposeBit) other.clone());\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     * @param inputFile file to create the entry from\n     * @param entryName name of the entry\n     */\n    public ZipArchiveEntry(final File inputFile, final String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        final ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getAllExtraFieldsNoCopy());\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public void setMethod(final int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} is unable to fill\n     * this field, you must use {@link ZipFile} if you want to read\n     * entries using this attribute.</p>\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(final int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} is unable to fill\n     * this field, you must use {@link ZipFile} if you want to read\n     * entries using this attribute.</p>\n     *\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(final long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(final int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Returns true if this entry represents a unix symlink,\n     * in which case the entry's content contains the target path\n     * for the symlink.\n     *\n     * @since 1.5\n     * @return true if the entry represents a unix symlink, false otherwise.\n     */\n    public boolean isUnixSymlink() {\n        return (getUnixMode() & UnixStat.LINK_FLAG) == UnixStat.LINK_FLAG;\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATFORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(final int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(final ZipExtraField[] fields) {\n        final List<ZipExtraField> newFields = new ArrayList<>();\n        for (final ZipExtraField field : fields) {\n            if (field instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) field;\n            } else {\n                newFields.add( field);\n            }\n        }\n        extraFields = newFields.toArray(new ZipExtraField[newFields.size()]);\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     *\n     * <p><b>Note</b>: The set of extra fields may be incomplete when\n     * {@link ZipArchiveInputStream} has been used as some extra\n     * fields use the central directory to store additional\n     * information.</p>\n     *\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getParseableExtraFields();\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since 1.1\n     */\n    public ZipExtraField[] getExtraFields(final boolean includeUnparseable) {\n        return includeUnparseable ?\n                getAllExtraFields() :\n                getParseableExtraFields();\n    }\n\n    private ZipExtraField[] getParseableExtraFieldsNoCopy() {\n        if (extraFields == null) {\n            return noExtraFields;\n        }\n        return extraFields;\n    }\n\n    private ZipExtraField[] getParseableExtraFields() {\n        final ZipExtraField[] parseableExtraFields = getParseableExtraFieldsNoCopy();\n        return (parseableExtraFields == extraFields) ? copyOf(parseableExtraFields) : parseableExtraFields;\n    }\n\n    /**\n     * Get all extra fields, including unparseable ones.\n     * @return An array of all extra fields. Not necessarily a copy of internal data structures, hence private method\n     */\n    private ZipExtraField[] getAllExtraFieldsNoCopy() {\n        if (extraFields == null) {\n            return getUnparseableOnly();\n        }\n        return unparseableExtra != null ? getMergedFields() : extraFields;\n    }\n\n    private ZipExtraField[] copyOf(final ZipExtraField[] src){\n        return copyOf(src, src.length);\n    }\n\n    private ZipExtraField[] copyOf(final ZipExtraField[] src, final int length) {\n        final ZipExtraField[] cpy = new ZipExtraField[length];\n        System.arraycopy(src, 0, cpy, 0, Math.min(src.length, length));\n        return cpy;\n    }\n\n    private ZipExtraField[] getMergedFields() {\n        final ZipExtraField[] zipExtraFields = copyOf(extraFields, extraFields.length + 1);\n        zipExtraFields[extraFields.length] = unparseableExtra;\n        return zipExtraFields;\n    }\n\n    private ZipExtraField[] getUnparseableOnly() {\n        return unparseableExtra == null ? noExtraFields : new ZipExtraField[] { unparseableExtra };\n    }\n\n    private ZipExtraField[] getAllExtraFields() {\n        final ZipExtraField[] allExtraFieldsNoCopy = getAllExtraFieldsNoCopy();\n        return (allExtraFieldsNoCopy == extraFields) ? copyOf( allExtraFieldsNoCopy) : allExtraFieldsNoCopy;\n    }\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(final ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new ZipExtraField[]{ ze};\n            } else {\n                if (getExtraField(ze.getHeaderId())!= null){\n                    removeExtraField(ze.getHeaderId());\n                }\n                final ZipExtraField[] zipExtraFields = copyOf(extraFields, extraFields.length + 1);\n                zipExtraFields[zipExtraFields.length -1] = ze;\n                extraFields = zipExtraFields;\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(final ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (getExtraField(ze.getHeaderId()) != null){\n                removeExtraField(ze.getHeaderId());\n            }\n            final ZipExtraField[] copy = extraFields;\n            final int newLen = extraFields != null ? extraFields.length + 1: 1;\n            extraFields = new ZipExtraField[newLen];\n            extraFields[0] = ze;\n            if (copy != null){\n                System.arraycopy(copy, 0, extraFields, 1, extraFields.length - 1);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(final ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n\n        final List<ZipExtraField> newResult = new ArrayList<>();\n        for (final ZipExtraField extraField : extraFields) {\n            if (!type.equals(extraField.getHeaderId())){\n                newResult.add( extraField);\n            }\n        }\n        if (extraFields.length == newResult.size()) {\n            throw new java.util.NoSuchElementException();\n        }\n        extraFields = newResult.toArray(new ZipExtraField[newResult.size()]);\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @param type the header id\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(final ZipShort type) {\n        if (extraFields != null) {\n            for (final ZipExtraField extraField : extraFields) {\n                if (type.equals(extraField.getHeaderId())) {\n                    return extraField;\n                }\n            }\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(final byte[] extra) throws RuntimeException {\n        try {\n            final ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (final ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \" //NOSONAR\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getAllExtraFieldsNoCopy()));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     * @param b an array of bytes to be parsed into extra fields\n     */\n    public void setCentralDirectoryExtra(final byte[] b) {\n        try {\n            final ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (final ZipException e) {\n            throw new RuntimeException(e.getMessage(), e); //NOSONAR\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        final byte[] extra = getExtra();\n        return extra != null ? extra : EMPTY;\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getAllExtraFieldsNoCopy());\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        if (name != null && getPlatform() == PLATFORM_FAT\n            && !name.contains(\"/\")) {\n            name = name.replace('\\\\', '/');\n        }\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} may create\n     * entries that return {@link #SIZE_UNKNOWN SIZE_UNKNOWN} as long\n     * as the entry hasn't been read completely.</p>\n     *\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @throws IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(final long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since 1.2\n     */\n    protected void setName(final String name, final byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @return the raw name bytes\n     * @since 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            final byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @return the general purpose bit\n     * @since 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @param b the general purpose bit\n     * @since 1.1\n     */\n    public void setGeneralPurposeBit(final GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(final ZipExtraField[] f, final boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (final ZipExtraField element : f) {\n                ZipExtraField existing;\n                if (element instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(element.getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(element);\n                } else {\n                    if (local) {\n                        final byte[] b = element.getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        final byte[] b = element.getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /**\n     * Wraps {@link java.util.zip.ZipEntry#getTime} with a {@link Date} as the\n     * entry's last modified date.\n     *\n     * <p>Changes to the implementation of {@link java.util.zip.ZipEntry#getTime}\n     * leak through and the returned value may depend on your local\n     * time zone as well as your version of Java.</p>\n     */\n    @Override\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(final Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        final ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        final String myName = getName();\n        final String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            myComment = \"\";\n        }\n        if (otherComment == null) {\n            otherComment = \"\";\n        }\n        return getTime() == other.getTime()\n            && myComment.equals(otherComment)\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n\n    /**\n     * Sets the \"version made by\" field.\n     * @param versionMadeBy \"version made by\" field\n     * @since 1.11\n     */\n    public void setVersionMadeBy(final int versionMadeBy) {\n        this.versionMadeBy = versionMadeBy;\n    }\n\n    /**\n     * Sets the \"version required to expand\" field.\n     * @param versionRequired \"version required to expand\" field\n     * @since 1.11\n     */\n    public void setVersionRequired(final int versionRequired) {\n        this.versionRequired = versionRequired;\n    }\n\n    /**\n     * The \"version required to expand\" field.\n     * @return \"version required to expand\" field\n     * @since 1.11\n     */\n    public int getVersionRequired() {\n        return versionRequired;\n    }\n\n    /**\n     * The \"version made by\" field.\n     * @return \"version made by\" field\n     * @since 1.11\n     */\n    public int getVersionMadeBy() {\n        return versionMadeBy;\n    }\n\n    /**\n     * The content of the flags field.\n     * @return content of the flags field\n     * @since 1.11\n     */\n    public int getRawFlag() {\n        return rawFlag;\n    }\n\n    /**\n     * Sets the content of the flags field.\n     * @param rawFlag content of the flags field\n     * @since 1.11\n     */\n    public void setRawFlag(final int rawFlag) {\n        this.rawFlag = rawFlag;\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.List;\nimport java.util.zip.ZipException;\n\n/**\n * Extension that adds better handling of extra fields and provides\n * access to the internal and external file attributes.\n *\n * <p>The extra data is expected to follow the recommendation of\n * <a href=\"http://www.pkware.com/documents/casestudies/APPNOTE.TXT\">APPNOTE.TXT</a>:</p>\n * <ul>\n *   <li>the extra byte array consists of a sequence of extra fields</li>\n *   <li>each extra fields starts by a two byte header id followed by\n *   a two byte sequence holding the length of the remainder of\n *   data.</li>\n * </ul>\n *\n * <p>Any extra data that cannot be parsed by the rules above will be\n * consumed as \"unparseable\" extra data and treated differently by the\n * methods of this class.  Versions prior to Apache Commons Compress\n * 1.1 would have thrown an exception if any attempt was made to read\n * or write extra data not conforming to the recommendation.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveEntry extends java.util.zip.ZipEntry\n    implements ArchiveEntry {\n\n    public static final int PLATFORM_UNIX = 3;\n    public static final int PLATFORM_FAT  = 0;\n    public static final int CRC_UNKNOWN = -1;\n    private static final int SHORT_MASK = 0xFFFF;\n    private static final int SHORT_SHIFT = 16;\n    private static final byte[] EMPTY = new byte[0];\n\n    /**\n     * The {@link java.util.zip.ZipEntry} base class only supports\n     * the compression methods STORED and DEFLATED. We override the\n     * field so that any compression methods can be used.\n     * <p>\n     * The default value -1 means that the method has not been specified.\n     *\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-93\"\n     *        >COMPRESS-93</a>\n     */\n    private int method = ZipMethod.UNKNOWN_CODE;\n\n    /**\n     * The {@link java.util.zip.ZipEntry#setSize} method in the base\n     * class throws an IllegalArgumentException if the size is bigger\n     * than 2GB for Java versions < 7.  Need to keep our own size\n     * information for Zip64 support.\n     */\n    private long size = SIZE_UNKNOWN;\n\n    private int internalAttributes = 0;\n    private int versionRequired;\n    private int versionMadeBy;\n    private int platform = PLATFORM_FAT;\n    private int rawFlag;\n    private long externalAttributes = 0;\n    private ZipExtraField[] extraFields;\n    private UnparseableExtraFieldData unparseableExtra = null;\n    private String name = null;\n    private byte[] rawName = null;\n    private GeneralPurposeBit gpb = new GeneralPurposeBit();\n    private static final ZipExtraField[] noExtraFields = new ZipExtraField[0];\n\n    /**\n     * Creates a new zip entry with the specified name.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param name the name of the entry\n     */\n    public ZipArchiveEntry(final String name) {\n        super(name);\n        setName(name);\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(final java.util.zip.ZipEntry entry) throws ZipException {\n        super(entry);\n        setName(entry.getName());\n        final byte[] extra = entry.getExtra();\n        if (extra != null) {\n            setExtraFields(ExtraFieldUtils.parse(extra, true,\n                                                 ExtraFieldUtils\n                                                 .UnparseableExtraField.READ));\n        } else {\n            // initializes extra data to an empty byte array\n            setExtra();\n        }\n        setMethod(entry.getMethod());\n        this.size = entry.getSize();\n    }\n\n    /**\n     * Creates a new zip entry with fields taken from the specified zip entry.\n     *\n     * <p>Assumes the entry represents a directory if and only if the\n     * name ends with a forward slash \"/\".</p>\n     *\n     * @param entry the entry to get fields from\n     * @throws ZipException on error\n     */\n    public ZipArchiveEntry(final ZipArchiveEntry entry) throws ZipException {\n        this((java.util.zip.ZipEntry) entry);\n        setInternalAttributes(entry.getInternalAttributes());\n        setExternalAttributes(entry.getExternalAttributes());\n        setExtraFields(getAllExtraFieldsNoCopy());\n        setPlatform(entry.getPlatform());\n        final GeneralPurposeBit other = entry.getGeneralPurposeBit();\n        setGeneralPurposeBit(other == null ? null :\n                             (GeneralPurposeBit) other.clone());\n    }\n\n    /**\n     */\n    protected ZipArchiveEntry() {\n        this(\"\");\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     * @param inputFile file to create the entry from\n     * @param entryName name of the entry\n     */\n    public ZipArchiveEntry(final File inputFile, final String entryName) {\n        this(inputFile.isDirectory() && !entryName.endsWith(\"/\") ? \n             entryName + \"/\" : entryName);\n        if (inputFile.isFile()){\n            setSize(inputFile.length());\n        }\n        setTime(inputFile.lastModified());\n        // TODO are there any other fields we can set here?\n    }\n\n    /**\n     * Overwrite clone.\n     * @return a cloned copy of this ZipArchiveEntry\n     */\n    @Override\n    public Object clone() {\n        final ZipArchiveEntry e = (ZipArchiveEntry) super.clone();\n\n        e.setInternalAttributes(getInternalAttributes());\n        e.setExternalAttributes(getExternalAttributes());\n        e.setExtraFields(getAllExtraFieldsNoCopy());\n        return e;\n    }\n\n    /**\n     * Returns the compression method of this entry, or -1 if the\n     * compression method has not been specified.\n     *\n     * @return compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public int getMethod() {\n        return method;\n    }\n\n    /**\n     * Sets the compression method of this entry.\n     *\n     * @param method compression method\n     *\n     * @since 1.1\n     */\n    @Override\n    public void setMethod(final int method) {\n        if (method < 0) {\n            throw new IllegalArgumentException(\n                    \"ZIP compression method can not be negative: \" + method);\n        }\n        this.method = method;\n    }\n\n    /**\n     * Retrieves the internal file attributes.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} is unable to fill\n     * this field, you must use {@link ZipFile} if you want to read\n     * entries using this attribute.</p>\n     *\n     * @return the internal file attributes\n     */\n    public int getInternalAttributes() {\n        return internalAttributes;\n    }\n\n    /**\n     * Sets the internal file attributes.\n     * @param value an <code>int</code> value\n     */\n    public void setInternalAttributes(final int value) {\n        internalAttributes = value;\n    }\n\n    /**\n     * Retrieves the external file attributes.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} is unable to fill\n     * this field, you must use {@link ZipFile} if you want to read\n     * entries using this attribute.</p>\n     *\n     * @return the external file attributes\n     */\n    public long getExternalAttributes() {\n        return externalAttributes;\n    }\n\n    /**\n     * Sets the external file attributes.\n     * @param value an <code>long</code> value\n     */\n    public void setExternalAttributes(final long value) {\n        externalAttributes = value;\n    }\n\n    /**\n     * Sets Unix permissions in a way that is understood by Info-Zip's\n     * unzip command.\n     * @param mode an <code>int</code> value\n     */\n    public void setUnixMode(final int mode) {\n        // CheckStyle:MagicNumberCheck OFF - no point\n        setExternalAttributes((mode << SHORT_SHIFT)\n                              // MS-DOS read-only attribute\n                              | ((mode & 0200) == 0 ? 1 : 0)\n                              // MS-DOS directory flag\n                              | (isDirectory() ? 0x10 : 0));\n        // CheckStyle:MagicNumberCheck ON\n        platform = PLATFORM_UNIX;\n    }\n\n    /**\n     * Unix permission.\n     * @return the unix permissions\n     */\n    public int getUnixMode() {\n        return platform != PLATFORM_UNIX ? 0 :\n            (int) ((getExternalAttributes() >> SHORT_SHIFT) & SHORT_MASK);\n    }\n\n    /**\n     * Returns true if this entry represents a unix symlink,\n     * in which case the entry's content contains the target path\n     * for the symlink.\n     *\n     * @since 1.5\n     * @return true if the entry represents a unix symlink, false otherwise.\n     */\n    public boolean isUnixSymlink() {\n        return (getUnixMode() & UnixStat.FILE_TYPE_FLAG) == UnixStat.LINK_FLAG;\n    }\n\n    /**\n     * Platform specification to put into the &quot;version made\n     * by&quot; part of the central file header.\n     *\n     * @return PLATFORM_FAT unless {@link #setUnixMode setUnixMode}\n     * has been called, in which case PLATFORM_UNIX will be returned.\n     */\n    public int getPlatform() {\n        return platform;\n    }\n\n    /**\n     * Set the platform (UNIX or FAT).\n     * @param platform an <code>int</code> value - 0 is FAT, 3 is UNIX\n     */\n    protected void setPlatform(final int platform) {\n        this.platform = platform;\n    }\n\n    /**\n     * Replaces all currently attached extra fields with the new array.\n     * @param fields an array of extra fields\n     */\n    public void setExtraFields(final ZipExtraField[] fields) {\n        final List<ZipExtraField> newFields = new ArrayList<>();\n        for (final ZipExtraField field : fields) {\n            if (field instanceof UnparseableExtraFieldData) {\n                unparseableExtra = (UnparseableExtraFieldData) field;\n            } else {\n                newFields.add( field);\n            }\n        }\n        extraFields = newFields.toArray(new ZipExtraField[newFields.size()]);\n        setExtra();\n    }\n\n    /**\n     * Retrieves all extra fields that have been parsed successfully.\n     *\n     * <p><b>Note</b>: The set of extra fields may be incomplete when\n     * {@link ZipArchiveInputStream} has been used as some extra\n     * fields use the central directory to store additional\n     * information.</p>\n     *\n     * @return an array of the extra fields\n     */\n    public ZipExtraField[] getExtraFields() {\n        return getParseableExtraFields();\n    }\n\n    /**\n     * Retrieves extra fields.\n     * @param includeUnparseable whether to also return unparseable\n     * extra fields as {@link UnparseableExtraFieldData} if such data\n     * exists.\n     * @return an array of the extra fields\n     *\n     * @since 1.1\n     */\n    public ZipExtraField[] getExtraFields(final boolean includeUnparseable) {\n        return includeUnparseable ?\n                getAllExtraFields() :\n                getParseableExtraFields();\n    }\n\n    private ZipExtraField[] getParseableExtraFieldsNoCopy() {\n        if (extraFields == null) {\n            return noExtraFields;\n        }\n        return extraFields;\n    }\n\n    private ZipExtraField[] getParseableExtraFields() {\n        final ZipExtraField[] parseableExtraFields = getParseableExtraFieldsNoCopy();\n        return (parseableExtraFields == extraFields) ? copyOf(parseableExtraFields) : parseableExtraFields;\n    }\n\n    /**\n     * Get all extra fields, including unparseable ones.\n     * @return An array of all extra fields. Not necessarily a copy of internal data structures, hence private method\n     */\n    private ZipExtraField[] getAllExtraFieldsNoCopy() {\n        if (extraFields == null) {\n            return getUnparseableOnly();\n        }\n        return unparseableExtra != null ? getMergedFields() : extraFields;\n    }\n\n    private ZipExtraField[] copyOf(final ZipExtraField[] src){\n        return copyOf(src, src.length);\n    }\n\n    private ZipExtraField[] copyOf(final ZipExtraField[] src, final int length) {\n        final ZipExtraField[] cpy = new ZipExtraField[length];\n        System.arraycopy(src, 0, cpy, 0, Math.min(src.length, length));\n        return cpy;\n    }\n\n    private ZipExtraField[] getMergedFields() {\n        final ZipExtraField[] zipExtraFields = copyOf(extraFields, extraFields.length + 1);\n        zipExtraFields[extraFields.length] = unparseableExtra;\n        return zipExtraFields;\n    }\n\n    private ZipExtraField[] getUnparseableOnly() {\n        return unparseableExtra == null ? noExtraFields : new ZipExtraField[] { unparseableExtra };\n    }\n\n    private ZipExtraField[] getAllExtraFields() {\n        final ZipExtraField[] allExtraFieldsNoCopy = getAllExtraFieldsNoCopy();\n        return (allExtraFieldsNoCopy == extraFields) ? copyOf( allExtraFieldsNoCopy) : allExtraFieldsNoCopy;\n    }\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>If no extra field of the same type exists, the field will be\n     * added as last field.</p>\n     * @param ze an extra field\n     */\n    public void addExtraField(final ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (extraFields == null) {\n                extraFields = new ZipExtraField[]{ ze};\n            } else {\n                if (getExtraField(ze.getHeaderId())!= null){\n                    removeExtraField(ze.getHeaderId());\n                }\n                final ZipExtraField[] zipExtraFields = copyOf(extraFields, extraFields.length + 1);\n                zipExtraFields[zipExtraFields.length -1] = ze;\n                extraFields = zipExtraFields;\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Adds an extra field - replacing an already present extra field\n     * of the same type.\n     *\n     * <p>The new extra field will be the first one.</p>\n     * @param ze an extra field\n     */\n    public void addAsFirstExtraField(final ZipExtraField ze) {\n        if (ze instanceof UnparseableExtraFieldData) {\n            unparseableExtra = (UnparseableExtraFieldData) ze;\n        } else {\n            if (getExtraField(ze.getHeaderId()) != null){\n                removeExtraField(ze.getHeaderId());\n            }\n            final ZipExtraField[] copy = extraFields;\n            final int newLen = extraFields != null ? extraFields.length + 1: 1;\n            extraFields = new ZipExtraField[newLen];\n            extraFields[0] = ze;\n            if (copy != null){\n                System.arraycopy(copy, 0, extraFields, 1, extraFields.length - 1);\n            }\n        }\n        setExtra();\n    }\n\n    /**\n     * Remove an extra field.\n     * @param type the type of extra field to remove\n     */\n    public void removeExtraField(final ZipShort type) {\n        if (extraFields == null) {\n            throw new java.util.NoSuchElementException();\n        }\n\n        final List<ZipExtraField> newResult = new ArrayList<>();\n        for (final ZipExtraField extraField : extraFields) {\n            if (!type.equals(extraField.getHeaderId())){\n                newResult.add( extraField);\n            }\n        }\n        if (extraFields.length == newResult.size()) {\n            throw new java.util.NoSuchElementException();\n        }\n        extraFields = newResult.toArray(new ZipExtraField[newResult.size()]);\n        setExtra();\n    }\n\n    /**\n     * Removes unparseable extra field data.\n     *\n     * @since 1.1\n     */\n    public void removeUnparseableExtraFieldData() {\n        if (unparseableExtra == null) {\n            throw new java.util.NoSuchElementException();\n        }\n        unparseableExtra = null;\n        setExtra();\n    }\n\n    /**\n     * Looks up an extra field by its header id.\n     *\n     * @param type the header id\n     * @return null if no such field exists.\n     */\n    public ZipExtraField getExtraField(final ZipShort type) {\n        if (extraFields != null) {\n            for (final ZipExtraField extraField : extraFields) {\n                if (type.equals(extraField.getHeaderId())) {\n                    return extraField;\n                }\n            }\n        }\n        return null;\n    }\n\n    /**\n     * Looks up extra field data that couldn't be parsed correctly.\n     *\n     * @return null if no such field exists.\n     *\n     * @since 1.1\n     */\n    public UnparseableExtraFieldData getUnparseableExtraFieldData() {\n        return unparseableExtra;\n    }\n\n    /**\n     * Parses the given bytes as extra field data and consumes any\n     * unparseable data as an {@link UnparseableExtraFieldData}\n     * instance.\n     * @param extra an array of bytes to be parsed into extra fields\n     * @throws RuntimeException if the bytes cannot be parsed\n     * @throws RuntimeException on error\n     */\n    @Override\n    public void setExtra(final byte[] extra) throws RuntimeException {\n        try {\n            final ZipExtraField[] local =\n                ExtraFieldUtils.parse(extra, true,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(local, true);\n        } catch (final ZipException e) {\n            // actually this is not possible as of Commons Compress 1.1\n            throw new RuntimeException(\"Error parsing extra fields for entry: \" //NOSONAR\n                                       + getName() + \" - \" + e.getMessage(), e);\n        }\n    }\n\n    /**\n     * Unfortunately {@link java.util.zip.ZipOutputStream\n     * java.util.zip.ZipOutputStream} seems to access the extra data\n     * directly, so overriding getExtra doesn't help - we need to\n     * modify super's data directly.\n     */\n    protected void setExtra() {\n        super.setExtra(ExtraFieldUtils.mergeLocalFileDataData(getAllExtraFieldsNoCopy()));\n    }\n\n    /**\n     * Sets the central directory part of extra fields.\n     * @param b an array of bytes to be parsed into extra fields\n     */\n    public void setCentralDirectoryExtra(final byte[] b) {\n        try {\n            final ZipExtraField[] central =\n                ExtraFieldUtils.parse(b, false,\n                                      ExtraFieldUtils.UnparseableExtraField.READ);\n            mergeExtraFields(central, false);\n        } catch (final ZipException e) {\n            throw new RuntimeException(e.getMessage(), e); //NOSONAR\n        }\n    }\n\n    /**\n     * Retrieves the extra data for the local file data.\n     * @return the extra data for local file\n     */\n    public byte[] getLocalFileDataExtra() {\n        final byte[] extra = getExtra();\n        return extra != null ? extra : EMPTY;\n    }\n\n    /**\n     * Retrieves the extra data for the central directory.\n     * @return the central directory extra data\n     */\n    public byte[] getCentralDirectoryExtra() {\n        return ExtraFieldUtils.mergeCentralDirectoryData(getAllExtraFieldsNoCopy());\n    }\n\n    /**\n     * Get the name of the entry.\n     * @return the entry name\n     */\n    @Override\n    public String getName() {\n        return name == null ? super.getName() : name;\n    }\n\n    /**\n     * Is this entry a directory?\n     * @return true if the entry is a directory\n     */\n    @Override\n    public boolean isDirectory() {\n        return getName().endsWith(\"/\");\n    }\n\n    /**\n     * Set the name of the entry.\n     * @param name the name to use\n     */\n    protected void setName(String name) {\n        if (name != null && getPlatform() == PLATFORM_FAT\n            && !name.contains(\"/\")) {\n            name = name.replace('\\\\', '/');\n        }\n        this.name = name;\n    }\n\n    /**\n     * Gets the uncompressed size of the entry data.\n     *\n     * <p><b>Note</b>: {@link ZipArchiveInputStream} may create\n     * entries that return {@link #SIZE_UNKNOWN SIZE_UNKNOWN} as long\n     * as the entry hasn't been read completely.</p>\n     *\n     * @return the entry size\n     */\n    @Override\n    public long getSize() {\n        return size;\n    }\n\n    /**\n     * Sets the uncompressed size of the entry data.\n     * @param size the uncompressed size in bytes\n     * @throws IllegalArgumentException if the specified size is less\n     *            than 0\n     */\n    @Override\n    public void setSize(final long size) {\n        if (size < 0) {\n            throw new IllegalArgumentException(\"invalid entry size\");\n        }\n        this.size = size;\n    }\n\n    /**\n     * Sets the name using the raw bytes and the string created from\n     * it by guessing or using the configured encoding.\n     * @param name the name to use created from the raw bytes using\n     * the guessed or configured encoding\n     * @param rawName the bytes originally read as name from the\n     * archive\n     * @since 1.2\n     */\n    protected void setName(final String name, final byte[] rawName) {\n        setName(name);\n        this.rawName = rawName;\n    }\n\n    /**\n     * Returns the raw bytes that made up the name before it has been\n     * converted using the configured or guessed encoding.\n     *\n     * <p>This method will return null if this instance has not been\n     * read from an archive.</p>\n     *\n     * @return the raw name bytes\n     * @since 1.2\n     */\n    public byte[] getRawName() {\n        if (rawName != null) {\n            final byte[] b = new byte[rawName.length];\n            System.arraycopy(rawName, 0, b, 0, rawName.length);\n            return b;\n        }\n        return null;\n    }\n\n    /**\n     * Get the hashCode of the entry.\n     * This uses the name as the hashcode.\n     * @return a hashcode.\n     */\n    @Override\n    public int hashCode() {\n        // this method has severe consequences on performance. We cannot rely\n        // on the super.hashCode() method since super.getName() always return\n        // the empty string in the current implemention (there's no setter)\n        // so it is basically draining the performance of a hashmap lookup\n        return getName().hashCode();\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @return the general purpose bit\n     * @since 1.1\n     */\n    public GeneralPurposeBit getGeneralPurposeBit() {\n        return gpb;\n    }\n\n    /**\n     * The \"general purpose bit\" field.\n     * @param b the general purpose bit\n     * @since 1.1\n     */\n    public void setGeneralPurposeBit(final GeneralPurposeBit b) {\n        gpb = b;\n    }\n\n    /**\n     * If there are no extra fields, use the given fields as new extra\n     * data - otherwise merge the fields assuming the existing fields\n     * and the new fields stem from different locations inside the\n     * archive.\n     * @param f the extra fields to merge\n     * @param local whether the new fields originate from local data\n     */\n    private void mergeExtraFields(final ZipExtraField[] f, final boolean local)\n        throws ZipException {\n        if (extraFields == null) {\n            setExtraFields(f);\n        } else {\n            for (final ZipExtraField element : f) {\n                ZipExtraField existing;\n                if (element instanceof UnparseableExtraFieldData) {\n                    existing = unparseableExtra;\n                } else {\n                    existing = getExtraField(element.getHeaderId());\n                }\n                if (existing == null) {\n                    addExtraField(element);\n                } else {\n                    if (local) {\n                        final byte[] b = element.getLocalFileDataData();\n                        existing.parseFromLocalFileData(b, 0, b.length);\n                    } else {\n                        final byte[] b = element.getCentralDirectoryData();\n                        existing.parseFromCentralDirectoryData(b, 0, b.length);\n                    }\n                }\n            }\n            setExtra();\n        }\n    }\n\n    /**\n     * Wraps {@link java.util.zip.ZipEntry#getTime} with a {@link Date} as the\n     * entry's last modified date.\n     *\n     * <p>Changes to the implementation of {@link java.util.zip.ZipEntry#getTime}\n     * leak through and the returned value may depend on your local\n     * time zone as well as your version of Java.</p>\n     */\n    @Override\n    public Date getLastModifiedDate() {\n        return new Date(getTime());\n    }\n\n    /* (non-Javadoc)\n     * @see java.lang.Object#equals(java.lang.Object)\n     */\n    @Override\n    public boolean equals(final Object obj) {\n        if (this == obj) {\n            return true;\n        }\n        if (obj == null || getClass() != obj.getClass()) {\n            return false;\n        }\n        final ZipArchiveEntry other = (ZipArchiveEntry) obj;\n        final String myName = getName();\n        final String otherName = other.getName();\n        if (myName == null) {\n            if (otherName != null) {\n                return false;\n            }\n        } else if (!myName.equals(otherName)) {\n            return false;\n        }\n        String myComment = getComment();\n        String otherComment = other.getComment();\n        if (myComment == null) {\n            myComment = \"\";\n        }\n        if (otherComment == null) {\n            otherComment = \"\";\n        }\n        return getTime() == other.getTime()\n            && myComment.equals(otherComment)\n            && getInternalAttributes() == other.getInternalAttributes()\n            && getPlatform() == other.getPlatform()\n            && getExternalAttributes() == other.getExternalAttributes()\n            && getMethod() == other.getMethod()\n            && getSize() == other.getSize()\n            && getCrc() == other.getCrc()\n            && getCompressedSize() == other.getCompressedSize()\n            && Arrays.equals(getCentralDirectoryExtra(),\n                             other.getCentralDirectoryExtra())\n            && Arrays.equals(getLocalFileDataExtra(),\n                             other.getLocalFileDataExtra())\n            && gpb.equals(other.gpb);\n    }\n\n    /**\n     * Sets the \"version made by\" field.\n     * @param versionMadeBy \"version made by\" field\n     * @since 1.11\n     */\n    public void setVersionMadeBy(final int versionMadeBy) {\n        this.versionMadeBy = versionMadeBy;\n    }\n\n    /**\n     * Sets the \"version required to expand\" field.\n     * @param versionRequired \"version required to expand\" field\n     * @since 1.11\n     */\n    public void setVersionRequired(final int versionRequired) {\n        this.versionRequired = versionRequired;\n    }\n\n    /**\n     * The \"version required to expand\" field.\n     * @return \"version required to expand\" field\n     * @since 1.11\n     */\n    public int getVersionRequired() {\n        return versionRequired;\n    }\n\n    /**\n     * The \"version made by\" field.\n     * @return \"version made by\" field\n     * @since 1.11\n     */\n    public int getVersionMadeBy() {\n        return versionMadeBy;\n    }\n\n    /**\n     * The content of the flags field.\n     * @return content of the flags field\n     * @since 1.11\n     */\n    public int getRawFlag() {\n        return rawFlag;\n    }\n\n    /**\n     * Sets the content of the flags field.\n     * @param rawFlag content of the flags field\n     * @since 1.11\n     */\n    public void setRawFlag(final int rawFlag) {\n        this.rawFlag = rawFlag;\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 43, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.File;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SeekableByteChannel;\nimport java.nio.file.Files;\nimport java.nio.file.StandardOpenOption;\nimport java.util.Calendar;\nimport java.util.EnumSet;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.zip.Deflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DATA_DESCRIPTOR_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DEFLATE_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.INITIAL_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC_SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipLong.putLong;\nimport static org.apache.commons.compress.archivers.zip.ZipShort.putShort;\n\n/**\n * Reimplementation of {@link java.util.zip.ZipOutputStream\n * java.util.zip.ZipOutputStream} that does handle the extended\n * functionality of this package, especially internal/external file\n * attributes and extra fields with different layouts for local file\n * data and central directory entries.\n *\n * <p>This class will try to use {@link\n * java.nio.channels.SeekableByteChannel} when it knows that the\n * output is going to go to a file.</p>\n *\n * <p>If SeekableByteChannel cannot be used, this implementation will use\n * a Data Descriptor to store size and CRC information for {@link\n * #DEFLATED DEFLATED} entries, this means, you don't need to\n * calculate them yourself.  Unfortunately this is not possible for\n * the {@link #STORED STORED} method, here setting the CRC and\n * uncompressed size information is required before {@link\n * #putArchiveEntry(ArchiveEntry)} can be called.</p>\n *\n * <p>As of Apache Commons Compress 1.3 it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries in most cases but explicit\n * control is provided via {@link #setUseZip64}.  If the stream can not\n * use SeekableByteChannel and you try to write a ZipArchiveEntry of\n * unknown size then Zip64 extensions will be disabled by default.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveOutputStream extends ArchiveOutputStream {\n\n    static final int BUFFER_SIZE = 512;\n    private static final int LFH_SIG_OFFSET = 0;\n    private static final int LFH_VERSION_NEEDED_OFFSET = 4;\n    private static final int LFH_GPB_OFFSET = 6;\n    private static final int LFH_METHOD_OFFSET = 8;\n    private static final int LFH_TIME_OFFSET = 10;\n    private static final int LFH_CRC_OFFSET = 14;\n    private static final int LFH_COMPRESSED_SIZE_OFFSET = 18;\n    private static final int LFH_ORIGINAL_SIZE_OFFSET = 22;\n    private static final int LFH_FILENAME_LENGTH_OFFSET = 26;\n    private static final int LFH_EXTRA_LENGTH_OFFSET = 28;\n    private static final int LFH_FILENAME_OFFSET = 30;\n    private static final int CFH_SIG_OFFSET = 0;\n    private static final int CFH_VERSION_MADE_BY_OFFSET = 4;\n    private static final int CFH_VERSION_NEEDED_OFFSET = 6;\n    private static final int CFH_GPB_OFFSET = 8;\n    private static final int CFH_METHOD_OFFSET = 10;\n    private static final int CFH_TIME_OFFSET = 12;\n    private static final int CFH_CRC_OFFSET = 16;\n    private static final int CFH_COMPRESSED_SIZE_OFFSET = 20;\n    private static final int CFH_ORIGINAL_SIZE_OFFSET = 24;\n    private static final int CFH_FILENAME_LENGTH_OFFSET = 28;\n    private static final int CFH_EXTRA_LENGTH_OFFSET = 30;\n    private static final int CFH_COMMENT_LENGTH_OFFSET = 32;\n    private static final int CFH_DISK_NUMBER_OFFSET = 34;\n    private static final int CFH_INTERNAL_ATTRIBUTES_OFFSET = 36;\n    private static final int CFH_EXTERNAL_ATTRIBUTES_OFFSET = 38;\n    private static final int CFH_LFH_OFFSET = 42;\n    private static final int CFH_FILENAME_OFFSET = 46;\n\n    /** indicates if this archive is finished. protected for use in Jar implementation */\n    protected boolean finished = false;\n\n    /**\n     * Compression method for deflated entries.\n     */\n    public static final int DEFLATED = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * Default compression level for deflated entries.\n     */\n    public static final int DEFAULT_COMPRESSION = Deflater.DEFAULT_COMPRESSION;\n\n    /**\n     * Compression method for stored entries.\n     */\n    public static final int STORED = java.util.zip.ZipEntry.STORED;\n\n    /**\n     * default encoding for file names and comment.\n     */\n    static final String DEFAULT_ENCODING = ZipEncodingHelper.UTF8;\n\n    /**\n     * General purpose flag, which indicates that filenames are\n     * written in UTF-8.\n     * @deprecated use {@link GeneralPurposeBit#UFT8_NAMES_FLAG} instead\n     */\n    @Deprecated\n    public static final int EFS_FLAG = GeneralPurposeBit.UFT8_NAMES_FLAG;\n\n    private static final byte[] EMPTY = new byte[0];\n\n    /**\n     * Current entry.\n     */\n    private CurrentEntry entry;\n\n    /**\n     * The file comment.\n     */\n    private String comment = \"\";\n\n    /**\n     * Compression level for next entry.\n     */\n    private int level = DEFAULT_COMPRESSION;\n\n    /**\n     * Has the compression level changed when compared to the last\n     * entry?\n     */\n    private boolean hasCompressionLevelChanged = false;\n\n    /**\n     * Default compression method for next entry.\n     */\n    private int method = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * List of ZipArchiveEntries written so far.\n     */\n    private final List<ZipArchiveEntry> entries =\n        new LinkedList<>();\n\n    private final StreamCompressor streamCompressor;\n\n    /**\n     * Start of central directory.\n     */\n    private long cdOffset = 0;\n\n    /**\n     * Length of central directory.\n     */\n    private long cdLength = 0;\n\n    /**\n     * Helper, a 0 as ZipShort.\n     */\n    private static final byte[] ZERO = {0, 0};\n\n    /**\n     * Helper, a 0 as ZipLong.\n     */\n    private static final byte[] LZERO = {0, 0, 0, 0};\n\n    private static final byte[] ONE = ZipLong.getBytes(1L);\n\n    /**\n     * Holds some book-keeping data for each entry.\n     */\n    private final Map<ZipArchiveEntry, EntryMetaData> metaData =\n        new HashMap<>();\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private String encoding = DEFAULT_ENCODING;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     *\n     * This field is of internal use and will be set in {@link\n     * #setEncoding(String)}.\n     */\n    private ZipEncoding zipEncoding =\n        ZipEncodingHelper.getZipEncoding(DEFAULT_ENCODING);\n\n\n    /**\n     * This Deflater object is used for output.\n     *\n     */\n    protected final Deflater def;\n    /**\n     * Optional random access output.\n     */\n    private final SeekableByteChannel channel;\n\n    private final OutputStream out;\n\n    /**\n     * whether to use the general purpose bit flag when writing UTF-8\n     * filenames or not.\n     */\n    private boolean useUTF8Flag = true; \n\n    /**\n     * Whether to encode non-encodable file names as UTF-8.\n     */\n    private boolean fallbackToUTF8 = false;\n\n    /**\n     * whether to create UnicodePathExtraField-s for each entry.\n     */\n    private UnicodeExtraFieldPolicy createUnicodeExtraFields = UnicodeExtraFieldPolicy.NEVER;\n\n    /**\n     * Whether anything inside this archive has used a ZIP64 feature.\n     *\n     * @since 1.3\n     */\n    private boolean hasUsedZip64 = false;\n\n    private Zip64Mode zip64Mode = Zip64Mode.AsNeeded;\n\n    private final byte[] copyBuffer = new byte[32768];\n    private final Calendar calendarInstance = Calendar.getInstance();\n\n    /**\n     * Creates a new ZIP OutputStream filtering the underlying stream.\n     * @param out the outputstream to zip\n     */\n    public ZipArchiveOutputStream(final OutputStream out) {\n        this.out = out;\n        this.channel = null;\n        def = new Deflater(level, true);\n        streamCompressor = StreamCompressor.create(out, def);\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a File.  Will use\n     * random access if possible.\n     * @param file the file to zip to\n     * @throws IOException on error\n     */\n    public ZipArchiveOutputStream(final File file) throws IOException {\n        def = new Deflater(level, true);\n        OutputStream o = null;\n        SeekableByteChannel _channel = null;\n        StreamCompressor _streamCompressor = null;\n        try {\n            _channel = Files.newByteChannel(file.toPath(),\n                EnumSet.of(StandardOpenOption.CREATE, StandardOpenOption.WRITE,\n                           StandardOpenOption.READ,\n                           StandardOpenOption.TRUNCATE_EXISTING));\n            // will never get opened properly when an exception is thrown so doesn't need to get closed\n            _streamCompressor = StreamCompressor.create(_channel, def); //NOSONAR\n        } catch (final IOException e) {\n            IOUtils.closeQuietly(_channel);\n            _channel = null;\n            o = new FileOutputStream(file);\n            _streamCompressor = StreamCompressor.create(o, def);\n        }\n        out = o;\n        channel = _channel;\n        streamCompressor = _streamCompressor;\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a SeekableByteChannel.\n     *\n     * <p>{@link\n     * org.apache.commons.compress.utils.SeekableInMemoryByteChannel}\n     * allows you to write to an in-memory archive using random\n     * access.</p>\n     *\n     * @param channel the channel to zip to\n     * @throws IOException on error\n     * @since 1.13\n     */\n    public ZipArchiveOutputStream(SeekableByteChannel channel) throws IOException {\n        this.channel = channel;\n        def = new Deflater(level, true);\n        streamCompressor = StreamCompressor.create(channel, def);\n        out = null;\n    }\n\n    /**\n     * This method indicates whether this archive is writing to a\n     * seekable stream (i.e., to a random access file).\n     *\n     * <p>For seekable streams, you don't need to calculate the CRC or\n     * uncompressed size for {@link #STORED} entries before\n     * invoking {@link #putArchiveEntry(ArchiveEntry)}.\n     * @return true if seekable\n     */\n    public boolean isSeekable() {\n        return channel != null;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     */\n    public void setEncoding(final String encoding) {\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        if (useUTF8Flag && !ZipEncodingHelper.isUTF8(encoding)) {\n            useUTF8Flag = false;\n        }\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Whether to set the language encoding flag if the file name\n     * encoding is UTF-8.\n     *\n     * <p>Defaults to true.</p>\n     *\n     * @param b whether to set the language encoding flag if the file\n     * name encoding is UTF-8\n     */\n    public void setUseLanguageEncodingFlag(final boolean b) {\n        useUTF8Flag = b && ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * Whether to create Unicode Extra Fields.\n     *\n     * <p>Defaults to NEVER.</p>\n     *\n     * @param b whether to create Unicode Extra Fields.\n     */\n    public void setCreateUnicodeExtraFields(final UnicodeExtraFieldPolicy b) {\n        createUnicodeExtraFields = b;\n    }\n\n    /**\n     * Whether to fall back to UTF and the language encoding flag if\n     * the file name cannot be encoded using the specified encoding.\n     *\n     * <p>Defaults to false.</p>\n     *\n     * @param b whether to fall back to UTF and the language encoding\n     * flag if the file name cannot be encoded using the specified\n     * encoding.\n     */\n    public void setFallbackToUTF8(final boolean b) {\n        fallbackToUTF8 = b;\n    }\n\n    /**\n     * Whether Zip64 extensions will be used.\n     *\n     * <p>When setting the mode to {@link Zip64Mode#Never Never},\n     * {@link #putArchiveEntry}, {@link #closeArchiveEntry}, {@link\n     * #finish} or {@link #close} may throw a {@link\n     * Zip64RequiredException} if the entry's size or the total size\n     * of the archive exceeds 4GB or there are more than 65536 entries\n     * inside the archive.  Any archive created in this mode will be\n     * readable by implementations that don't support Zip64.</p>\n     *\n     * <p>When setting the mode to {@link Zip64Mode#Always Always},\n     * Zip64 extensions will be used for all entries.  Any archive\n     * created in this mode may be unreadable by implementations that\n     * don't support Zip64 even if all its contents would be.</p>\n     *\n     * <p>When setting the mode to {@link Zip64Mode#AsNeeded\n     * AsNeeded}, Zip64 extensions will transparently be used for\n     * those entries that require them.  This mode can only be used if\n     * the uncompressed size of the {@link ZipArchiveEntry} is known\n     * when calling {@link #putArchiveEntry} or the archive is written\n     * to a seekable output (i.e. you have used the {@link\n     * #ZipArchiveOutputStream(java.io.File) File-arg constructor}) -\n     * this mode is not valid when the output stream is not seekable\n     * and the uncompressed size is unknown when {@link\n     * #putArchiveEntry} is called.</p>\n     * \n     * <p>If no entry inside the resulting archive requires Zip64\n     * extensions then {@link Zip64Mode#Never Never} will create the\n     * smallest archive.  {@link Zip64Mode#AsNeeded AsNeeded} will\n     * create a slightly bigger archive if the uncompressed size of\n     * any entry has initially been unknown and create an archive\n     * identical to {@link Zip64Mode#Never Never} otherwise.  {@link\n     * Zip64Mode#Always Always} will create an archive that is at\n     * least 24 bytes per entry bigger than the one {@link\n     * Zip64Mode#Never Never} would create.</p>\n     *\n     * <p>Defaults to {@link Zip64Mode#AsNeeded AsNeeded} unless\n     * {@link #putArchiveEntry} is called with an entry of unknown\n     * size and data is written to a non-seekable stream - in this\n     * case the default is {@link Zip64Mode#Never Never}.</p>\n     *\n     * @since 1.3\n     * @param mode Whether Zip64 extensions will be used.\n     */\n    public void setUseZip64(final Zip64Mode mode) {\n        zip64Mode = mode;\n    }\n\n    /**\n     * {@inheritDoc}\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (entry != null) {\n            throw new IOException(\"This archive contains unclosed entries.\");\n        }\n\n        cdOffset = streamCompressor.getTotalBytesWritten();\n        writeCentralDirectoryInChunks();\n\n        cdLength = streamCompressor.getTotalBytesWritten() - cdOffset;\n        writeZip64CentralDirectory();\n        writeCentralDirectoryEnd();\n        metaData.clear();\n        entries.clear();\n        streamCompressor.close();\n        finished = true;\n    }\n\n    private void writeCentralDirectoryInChunks() throws IOException {\n        final int NUM_PER_WRITE = 1000;\n        final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(70 * NUM_PER_WRITE);\n        int count = 0;\n        for (final ZipArchiveEntry ze : entries) {\n            byteArrayOutputStream.write(createCentralFileHeader(ze));\n            if (++count > NUM_PER_WRITE){\n                writeCounted(byteArrayOutputStream.toByteArray());\n                byteArrayOutputStream.reset();\n                count = 0;\n            }\n        }\n        writeCounted(byteArrayOutputStream.toByteArray());\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size exceeds 4 GByte and {@link #setUseZip64} \n     * is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        preClose();\n\n        flushDeflater();\n\n        final long bytesWritten = streamCompressor.getTotalBytesWritten() - entry.dataStart;\n        final long realCrc = streamCompressor.getCrc32();\n        entry.bytesRead = streamCompressor.getBytesRead();\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        final boolean actuallyNeedsZip64 = handleSizesAndCrc(bytesWritten, realCrc, effectiveMode);\n        closeEntry(actuallyNeedsZip64, false);\n        streamCompressor.reset();\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     *\n     * @param phased              This entry is second phase of a 2-phase zip creation, size, compressed size and crc\n     *                            are known in ZipArchiveEntry\n     * @throws IOException            on error\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     *                                compressed size exceeds 4 GByte and {@link #setUseZip64}\n     *                                is {@link Zip64Mode#Never}.\n     */\n    private void closeCopiedEntry(final boolean phased) throws IOException {\n        preClose();\n        entry.bytesRead = entry.entry.getSize();\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        final boolean actuallyNeedsZip64 = checkIfNeedsZip64(effectiveMode);\n        closeEntry(actuallyNeedsZip64, phased);\n    }\n\n    private void closeEntry(final boolean actuallyNeedsZip64, final boolean phased) throws IOException {\n        if (!phased && channel != null) {\n            rewriteSizesAndCrc(actuallyNeedsZip64);\n        }\n\n        if (!phased) {\n            writeDataDescriptor(entry.entry);\n        }\n        entry = null;\n    }\n\n    private void preClose() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        if (entry == null) {\n            throw new IOException(\"No current entry to close\");\n        }\n\n        if (!entry.hasWritten) {\n            write(EMPTY, 0, 0);\n        }\n    }\n\n    /**\n     * Adds an archive entry with a raw input stream.\n     *\n     * If crc, size and compressed size are supplied on the entry, these values will be used as-is.\n     * Zip64 status is re-established based on the settings in this stream, and the supplied value\n     * is ignored.\n     *\n     * The entry is put and closed immediately.\n     *\n     * @param entry The archive entry to add\n     * @param rawStream The raw input stream of a different entry. May be compressed/encrypted.\n     * @throws IOException If copying fails\n     */\n    public void addRawArchiveEntry(final ZipArchiveEntry entry, final InputStream rawStream)\n            throws IOException {\n        final ZipArchiveEntry ae = new ZipArchiveEntry(entry);\n        if (hasZip64Extra(ae)) {\n            // Will be re-added as required. this may make the file generated with this method\n            // somewhat smaller than standard mode,\n            // since standard mode is unable to remove the zip 64 header.\n            ae.removeExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        }\n        final boolean is2PhaseSource = ae.getCrc() != ZipArchiveEntry.CRC_UNKNOWN\n                && ae.getSize() != ArchiveEntry.SIZE_UNKNOWN\n                && ae.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN;\n        putArchiveEntry(ae, is2PhaseSource);\n        copyFromZipInputStream(rawStream);\n        closeCopiedEntry(is2PhaseSource);\n    }\n\n    /**\n     * Ensures all bytes sent to the deflater are written to the stream.\n     */\n    private void flushDeflater() throws IOException {\n        if (entry.entry.getMethod() == DEFLATED) {\n            streamCompressor.flushDeflater();\n        }\n    }\n\n    /**\n     * Ensures the current entry's size and CRC information is set to\n     * the values just written, verifies it isn't too big in the\n     * Zip64Mode.Never case and returns whether the entry would\n     * require a Zip64 extra field.\n     */\n    private boolean handleSizesAndCrc(final long bytesWritten, final long crc,\n                                      final Zip64Mode effectiveMode)\n        throws ZipException {\n        if (entry.entry.getMethod() == DEFLATED) {\n            /* It turns out def.getBytesRead() returns wrong values if\n             * the size exceeds 4 GB on Java < Java7\n            entry.entry.setSize(def.getBytesRead());\n            */\n            entry.entry.setSize(entry.bytesRead);\n            entry.entry.setCompressedSize(bytesWritten);\n            entry.entry.setCrc(crc);\n\n        } else if (channel == null) {\n            if (entry.entry.getCrc() != crc) {\n                throw new ZipException(\"bad CRC checksum for entry \"\n                                       + entry.entry.getName() + \": \"\n                                       + Long.toHexString(entry.entry.getCrc())\n                                       + \" instead of \"\n                                       + Long.toHexString(crc));\n            }\n\n            if (entry.entry.getSize() != bytesWritten) {\n                throw new ZipException(\"bad size for entry \"\n                                       + entry.entry.getName() + \": \"\n                                       + entry.entry.getSize()\n                                       + \" instead of \"\n                                       + bytesWritten);\n            }\n        } else { /* method is STORED and we used SeekableByteChannel */\n            entry.entry.setSize(bytesWritten);\n            entry.entry.setCompressedSize(bytesWritten);\n            entry.entry.setCrc(crc);\n        }\n\n        return checkIfNeedsZip64(effectiveMode);\n    }\n\n    /**\n     * Verifies the sizes aren't too big in the Zip64Mode.Never case\n     * and returns whether the entry would require a Zip64 extra\n     * field.\n     */\n    private boolean checkIfNeedsZip64(final Zip64Mode effectiveMode)\n            throws ZipException {\n        final boolean actuallyNeedsZip64 = isZip64Required(entry.entry, effectiveMode);\n        if (actuallyNeedsZip64 && effectiveMode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException.getEntryTooBigMessage(entry.entry));\n        }\n        return actuallyNeedsZip64;\n    }\n\n    private boolean isZip64Required(final ZipArchiveEntry entry1, final Zip64Mode requestedMode) {\n        return requestedMode == Zip64Mode.Always || isTooLageForZip32(entry1);\n    }\n\n    private boolean isTooLageForZip32(final ZipArchiveEntry zipArchiveEntry){\n        return zipArchiveEntry.getSize() >= ZIP64_MAGIC || zipArchiveEntry.getCompressedSize() >= ZIP64_MAGIC;\n    }\n\n    /**\n     * When using random access output, write the local file header\n     * and potentiall the ZIP64 extra containing the correct CRC and\n     * compressed/uncompressed sizes.\n     */\n    private void rewriteSizesAndCrc(final boolean actuallyNeedsZip64)\n        throws IOException {\n        final long save = channel.position();\n\n        channel.position(entry.localDataStart);\n        writeOut(ZipLong.getBytes(entry.entry.getCrc()));\n        if (!hasZip64Extra(entry.entry) || !actuallyNeedsZip64) {\n            writeOut(ZipLong.getBytes(entry.entry.getCompressedSize()));\n            writeOut(ZipLong.getBytes(entry.entry.getSize()));\n        } else {\n            writeOut(ZipLong.ZIP64_MAGIC.getBytes());\n            writeOut(ZipLong.ZIP64_MAGIC.getBytes());\n        }\n\n        if (hasZip64Extra(entry.entry)) {\n            final ByteBuffer name = getName(entry.entry);\n            final int nameLen = name.limit() - name.position();\n            // seek to ZIP64 extra, skip header and size information\n            channel.position(entry.localDataStart + 3 * WORD + 2 * SHORT\n                             + nameLen + 2 * SHORT);\n            // inside the ZIP64 extra uncompressed size comes\n            // first, unlike the LFH, CD or data descriptor\n            writeOut(ZipEightByteInteger.getBytes(entry.entry.getSize()));\n            writeOut(ZipEightByteInteger.getBytes(entry.entry.getCompressedSize()));\n\n            if (!actuallyNeedsZip64) {\n                // do some cleanup:\n                // * rewrite version needed to extract\n                channel.position(entry.localDataStart  - 5 * SHORT);\n                writeOut(ZipShort.getBytes(versionNeededToExtract(entry.entry.getMethod(), false, false)));\n\n                // * remove ZIP64 extra so it doesn't get written\n                //   to the central directory\n                entry.entry.removeExtraField(Zip64ExtendedInformationExtraField\n                                             .HEADER_ID);\n                entry.entry.setExtra();\n\n                // * reset hasUsedZip64 if it has been set because\n                //   of this entry\n                if (entry.causedUseOfZip64) {\n                    hasUsedZip64 = false;\n                }\n            }\n        }\n        channel.position(save);\n    }\n\n    /**\n     * {@inheritDoc} \n     * @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size is known to exceed 4 GByte and {@link #setUseZip64} \n     * is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void putArchiveEntry(final ArchiveEntry archiveEntry) throws IOException {\n        putArchiveEntry(archiveEntry, false);\n    }\n\n    /**\n     * Writes the headers for an archive entry to the output stream.\n     * The caller must then write the content to the stream and call\n     * {@link #closeArchiveEntry()} to complete the process.\n\n     * @param archiveEntry The archiveEntry\n     * @param phased If true size, compressedSize and crc required to be known up-front in the archiveEntry\n     * @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size is known to exceed 4 GByte and {@link #setUseZip64}\n     * is {@link Zip64Mode#Never}.\n     */\n    private void putArchiveEntry(final ArchiveEntry archiveEntry, final boolean phased) throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        if (entry != null) {\n            closeArchiveEntry();\n        }\n\n        entry = new CurrentEntry((ZipArchiveEntry) archiveEntry);\n        entries.add(entry.entry);\n\n        setDefaults(entry.entry);\n\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        validateSizeInformation(effectiveMode);\n\n        if (shouldAddZip64Extra(entry.entry, effectiveMode)) {\n\n            final Zip64ExtendedInformationExtraField z64 = getZip64Extra(entry.entry);\n\n            ZipEightByteInteger size, compressedSize;\n            if (phased) {\n                // sizes are already known\n                size = new ZipEightByteInteger(entry.entry.getSize());\n                compressedSize = new ZipEightByteInteger(entry.entry.getCompressedSize());\n            } else if (entry.entry.getMethod() == STORED\n                    && entry.entry.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n                // actually, we already know the sizes\n                compressedSize = size = new ZipEightByteInteger(entry.entry.getSize());\n            } else {\n                // just a placeholder, real data will be in data\n                // descriptor or inserted later via SeekableByteChannel\n                compressedSize = size = ZipEightByteInteger.ZERO;\n            }\n            z64.setSize(size);\n            z64.setCompressedSize(compressedSize);\n            entry.entry.setExtra();\n        }\n\n        if (entry.entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n            def.setLevel(level);\n            hasCompressionLevelChanged = false;\n        }\n        writeLocalFileHeader((ZipArchiveEntry) archiveEntry, phased);\n    }\n\n    /**\n     * Provides default values for compression method and last\n     * modification time.\n     */\n    private void setDefaults(final ZipArchiveEntry entry) {\n        if (entry.getMethod() == -1) { // not specified\n            entry.setMethod(method);\n        }\n\n        if (entry.getTime() == -1) { // not specified\n            entry.setTime(System.currentTimeMillis());\n        }\n    }\n\n    /**\n     * Throws an exception if the size is unknown for a stored entry\n     * that is written to a non-seekable output or the entry is too\n     * big to be written without Zip64 extra but the mode has been set\n     * to Never.\n     */\n    private void validateSizeInformation(final Zip64Mode effectiveMode)\n        throws ZipException {\n        // Size/CRC not required if SeekableByteChannel is used\n        if (entry.entry.getMethod() == STORED && channel == null) {\n            if (entry.entry.getSize() == ArchiveEntry.SIZE_UNKNOWN) {\n                throw new ZipException(\"uncompressed size is required for\"\n                                       + \" STORED method when not writing to a\"\n                                       + \" file\");\n            }\n            if (entry.entry.getCrc() == ZipArchiveEntry.CRC_UNKNOWN) {\n                throw new ZipException(\"crc checksum is required for STORED\"\n                                       + \" method when not writing to a file\");\n            }\n            entry.entry.setCompressedSize(entry.entry.getSize());\n        }\n\n        if ((entry.entry.getSize() >= ZIP64_MAGIC\n             || entry.entry.getCompressedSize() >= ZIP64_MAGIC)\n            && effectiveMode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .getEntryTooBigMessage(entry.entry));\n        }\n    }\n\n    /**\n     * Whether to addd a Zip64 extended information extra field to the\n     * local file header.\n     *\n     * <p>Returns true if</p>\n     *\n     * <ul>\n     * <li>mode is Always</li>\n     * <li>or we already know it is going to be needed</li>\n     * <li>or the size is unknown and we can ensure it won't hurt\n     * other implementations if we add it (i.e. we can erase its\n     * usage</li>\n     * </ul>\n     */\n    private boolean shouldAddZip64Extra(final ZipArchiveEntry entry, final Zip64Mode mode) {\n        return mode == Zip64Mode.Always\n            || entry.getSize() >= ZIP64_MAGIC\n            || entry.getCompressedSize() >= ZIP64_MAGIC\n            || (entry.getSize() == ArchiveEntry.SIZE_UNKNOWN\n                && channel != null && mode != Zip64Mode.Never);\n    }\n\n    /**\n     * Set the file comment.\n     * @param comment the comment\n     */\n    public void setComment(final String comment) {\n        this.comment = comment;\n    }\n\n    /**\n     * Sets the compression level for subsequent entries.\n     *\n     * <p>Default is Deflater.DEFAULT_COMPRESSION.</p>\n     * @param level the compression level.\n     * @throws IllegalArgumentException if an invalid compression\n     * level is specified.\n     */\n    public void setLevel(final int level) {\n        if (level < Deflater.DEFAULT_COMPRESSION\n            || level > Deflater.BEST_COMPRESSION) {\n            throw new IllegalArgumentException(\"Invalid compression level: \"\n                                               + level);\n        }\n        hasCompressionLevelChanged = (this.level != level);\n        this.level = level;\n    }\n\n    /**\n     * Sets the default compression method for subsequent entries.\n     *\n     * <p>Default is DEFLATED.</p>\n     * @param method an <code>int</code> from java.util.zip.ZipEntry\n     */\n    public void setMethod(final int method) {\n        this.method = method;\n    }\n\n    /**\n     * Whether this stream is able to write the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canWriteEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry zae = (ZipArchiveEntry) ae;\n            return zae.getMethod() != ZipMethod.IMPLODING.getCode()\n                && zae.getMethod() != ZipMethod.UNSHRINKING.getCode()\n                && ZipUtil.canHandleEntryData(zae);\n        }\n        return false;\n    }\n\n    /**\n     * Writes bytes to ZIP entry.\n     * @param b the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    @Override\n    public void write(final byte[] b, final int offset, final int length) throws IOException {\n        if (entry == null) {\n            throw new IllegalStateException(\"No current entry\");\n        }\n        ZipUtil.checkRequestedFeatures(entry.entry);\n        final long writtenThisTime = streamCompressor.write(b, offset, length, entry.entry.getMethod());\n        count(writtenThisTime);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    private void writeCounted(final byte[] data) throws IOException {\n        streamCompressor.writeCounted(data);\n    }\n\n    private void copyFromZipInputStream(final InputStream src) throws IOException {\n        if (entry == null) {\n            throw new IllegalStateException(\"No current entry\");\n        }\n        ZipUtil.checkRequestedFeatures(entry.entry);\n        entry.hasWritten = true;\n        int length;\n        while ((length = src.read(copyBuffer)) >= 0 )\n        {\n            streamCompressor.writeCounted(copyBuffer, 0, length);\n            count( length );\n        }\n    }\n\n    /**\n     * Closes this output stream and releases any system resources\n     * associated with the stream.\n     *\n     * @throws  IOException  if an I/O error occurs.\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n        destroy();\n    }\n\n    /**\n     * Flushes this output stream and forces any buffered output bytes\n     * to be written out to the stream.\n     *\n     * @throws  IOException  if an I/O error occurs.\n     */\n    @Override\n    public void flush() throws IOException {\n        if (out != null) {\n            out.flush();\n        }\n    }\n\n    /*\n     * Various ZIP constants shared between this class, ZipArchiveInputStream and ZipFile\n     */\n    /**\n     * local file header signature\n     */\n    static final byte[] LFH_SIG = ZipLong.LFH_SIG.getBytes(); //NOSONAR\n    /**\n     * data descriptor signature\n     */\n    static final byte[] DD_SIG = ZipLong.DD_SIG.getBytes(); //NOSONAR\n    /**\n     * central file header signature\n     */\n    static final byte[] CFH_SIG = ZipLong.CFH_SIG.getBytes(); //NOSONAR\n    /**\n     * end of central dir signature\n     */\n    static final byte[] EOCD_SIG = ZipLong.getBytes(0X06054B50L); //NOSONAR\n    /**\n     * ZIP64 end of central dir signature\n     */\n    static final byte[] ZIP64_EOCD_SIG = ZipLong.getBytes(0X06064B50L); //NOSONAR\n    /**\n     * ZIP64 end of central dir locator signature\n     */\n    static final byte[] ZIP64_EOCD_LOC_SIG = ZipLong.getBytes(0X07064B50L); //NOSONAR\n\n    /**\n     * Writes next block of compressed data to the output stream.\n     * @throws IOException on error\n     */\n    protected final void deflate() throws IOException {\n        streamCompressor.deflate();\n    }\n\n    /**\n     * Writes the local file header entry\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeLocalFileHeader(final ZipArchiveEntry ze) throws IOException {\n        writeLocalFileHeader(ze, false);\n    }\n\n    private void writeLocalFileHeader(final ZipArchiveEntry ze, final boolean phased) throws IOException {\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        final ByteBuffer name = getName(ze);\n\n        if (createUnicodeExtraFields != UnicodeExtraFieldPolicy.NEVER) {\n            addUnicodeExtraFields(ze, encodable, name);\n        }\n\n        final long localHeaderStart = streamCompressor.getTotalBytesWritten();\n        final byte[] localHeader = createLocalFileHeader(ze, name, encodable, phased, localHeaderStart);\n        metaData.put(ze, new EntryMetaData(localHeaderStart, usesDataDescriptor(ze.getMethod())));\n        entry.localDataStart = localHeaderStart + LFH_CRC_OFFSET; // At crc offset\n        writeCounted(localHeader);\n        entry.dataStart = streamCompressor.getTotalBytesWritten();\n    }\n\n\n    private byte[] createLocalFileHeader(final ZipArchiveEntry ze, final ByteBuffer name, final boolean encodable,\n                                         final boolean phased, long archiveOffset) throws IOException {\n        ResourceAlignmentExtraField oldAlignmentEx =\n            (ResourceAlignmentExtraField) ze.getExtraField(ResourceAlignmentExtraField.ID);\n        if (oldAlignmentEx != null) {\n            ze.removeExtraField(ResourceAlignmentExtraField.ID);\n        }\n\n        int alignment = ze.getAlignment();\n        if (alignment <= 0 && oldAlignmentEx != null) {\n            alignment = oldAlignmentEx.getAlignment();\n        }\n\n        if (alignment > 1 || (oldAlignmentEx != null && !oldAlignmentEx.allowMethodChange())) {\n            int oldLength = LFH_FILENAME_OFFSET +\n                            name.limit() - name.position() +\n                            ze.getLocalFileDataExtra().length;\n\n            int padding = (int) ((-archiveOffset - oldLength - ZipExtraField.EXTRAFIELD_HEADER_SIZE\n                            - ResourceAlignmentExtraField.BASE_SIZE) &\n                            (alignment - 1));\n            ze.addExtraField(new ResourceAlignmentExtraField(alignment,\n                            oldAlignmentEx != null && oldAlignmentEx.allowMethodChange(), padding));\n        }\n\n        final byte[] extra = ze.getLocalFileDataExtra();\n        final int nameLen = name.limit() - name.position();\n        final int len = LFH_FILENAME_OFFSET + nameLen + extra.length;\n        final byte[] buf = new byte[len];\n\n        System.arraycopy(LFH_SIG,  0, buf, LFH_SIG_OFFSET, WORD);\n\n        //store method in local variable to prevent multiple method calls\n        final int zipMethod = ze.getMethod();\n        final boolean dataDescriptor = usesDataDescriptor(zipMethod);\n\n        putShort(versionNeededToExtract(zipMethod, hasZip64Extra(ze), dataDescriptor), buf, LFH_VERSION_NEEDED_OFFSET);\n\n        final GeneralPurposeBit generalPurposeBit = getGeneralPurposeBits(!encodable && fallbackToUTF8, dataDescriptor);\n        generalPurposeBit.encode(buf, LFH_GPB_OFFSET);\n\n        // compression method\n        putShort(zipMethod, buf, LFH_METHOD_OFFSET);\n\n        ZipUtil.toDosTime(calendarInstance, ze.getTime(), buf, LFH_TIME_OFFSET);\n\n        // CRC\n        if (phased){\n            putLong(ze.getCrc(), buf, LFH_CRC_OFFSET);\n        } else if (zipMethod == DEFLATED || channel != null) {\n            System.arraycopy(LZERO, 0, buf, LFH_CRC_OFFSET, WORD);\n        } else {\n            putLong(ze.getCrc(), buf, LFH_CRC_OFFSET);\n        }\n\n        // compressed length\n        // uncompressed length\n        if (hasZip64Extra(entry.entry)){\n            // point to ZIP64 extended information extra field for\n            // sizes, may get rewritten once sizes are known if\n            // stream is seekable\n            ZipLong.ZIP64_MAGIC.putLong(buf, LFH_COMPRESSED_SIZE_OFFSET);\n            ZipLong.ZIP64_MAGIC.putLong(buf, LFH_ORIGINAL_SIZE_OFFSET);\n        } else if (phased) {\n            putLong(ze.getCompressedSize(), buf, LFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, LFH_ORIGINAL_SIZE_OFFSET);\n        } else if (zipMethod == DEFLATED || channel != null) {\n            System.arraycopy(LZERO, 0, buf, LFH_COMPRESSED_SIZE_OFFSET, WORD);\n            System.arraycopy(LZERO, 0, buf, LFH_ORIGINAL_SIZE_OFFSET, WORD);\n        } else { // Stored\n            putLong(ze.getSize(), buf, LFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, LFH_ORIGINAL_SIZE_OFFSET);\n        }\n        // file name length\n        putShort(nameLen, buf, LFH_FILENAME_LENGTH_OFFSET);\n\n        // extra field length\n        putShort(extra.length, buf, LFH_EXTRA_LENGTH_OFFSET);\n\n        // file name\n        System.arraycopy( name.array(), name.arrayOffset(), buf, LFH_FILENAME_OFFSET, nameLen);\n\n        // extra fields\n        System.arraycopy(extra, 0, buf, LFH_FILENAME_OFFSET + nameLen, extra.length);\n\n        return buf;\n    }\n\n\n    /**\n     * Adds UnicodeExtra fields for name and file comment if mode is\n     * ALWAYS or the data cannot be encoded using the configured\n     * encoding.\n     */\n    private void addUnicodeExtraFields(final ZipArchiveEntry ze, final boolean encodable,\n                                       final ByteBuffer name)\n        throws IOException {\n        if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n            || !encodable) {\n            ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n                                                       name.array(),\n                                                       name.arrayOffset(),\n                                                       name.limit()\n                                                       - name.position()));\n        }\n\n        final String comm = ze.getComment();\n        if (comm != null && !\"\".equals(comm)) {\n\n            final boolean commentEncodable = zipEncoding.canEncode(comm);\n\n            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                || !commentEncodable) {\n                final ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n                ze.addExtraField(new UnicodeCommentExtraField(comm,\n                                                              commentB.array(),\n                                                              commentB.arrayOffset(),\n                                                              commentB.limit()\n                                                              - commentB.position())\n                                 );\n            }\n        }\n    }\n\n    /**\n     * Writes the data descriptor entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeDataDescriptor(final ZipArchiveEntry ze) throws IOException {\n        if (ze.getMethod() != DEFLATED || channel != null) {\n            return;\n        }\n        writeCounted(DD_SIG);\n        writeCounted(ZipLong.getBytes(ze.getCrc()));\n        if (!hasZip64Extra(ze)) {\n            writeCounted(ZipLong.getBytes(ze.getCompressedSize()));\n            writeCounted(ZipLong.getBytes(ze.getSize()));\n        } else {\n            writeCounted(ZipEightByteInteger.getBytes(ze.getCompressedSize()));\n            writeCounted(ZipEightByteInteger.getBytes(ze.getSize()));\n        }\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte and {@link Zip64Mode #setUseZip64} is {@link\n     * Zip64Mode#Never}.\n     */\n    protected void writeCentralFileHeader(final ZipArchiveEntry ze) throws IOException {\n        final byte[] centralFileHeader = createCentralFileHeader(ze);\n        writeCounted(centralFileHeader);\n    }\n\n    private byte[] createCentralFileHeader(final ZipArchiveEntry ze) throws IOException {\n\n        final EntryMetaData entryMetaData = metaData.get(ze);\n        final boolean needsZip64Extra = hasZip64Extra(ze)\n                || ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || entryMetaData.offset >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always;\n\n        if (needsZip64Extra && zip64Mode == Zip64Mode.Never) {\n            // must be the offset that is too big, otherwise an\n            // exception would have been throw in putArchiveEntry or\n            // closeArchiveEntry\n            throw new Zip64RequiredException(Zip64RequiredException\n                    .ARCHIVE_TOO_BIG_MESSAGE);\n        }\n\n\n        handleZip64Extra(ze, entryMetaData.offset, needsZip64Extra);\n\n        return createCentralFileHeader(ze, getName(ze), entryMetaData, needsZip64Extra);\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @param name The encoded name\n     * @param entryMetaData meta data for this file\n     * @throws IOException on error\n     */\n    private byte[] createCentralFileHeader(final ZipArchiveEntry ze, final ByteBuffer name,\n                                           final EntryMetaData entryMetaData,\n                                           final boolean needsZip64Extra) throws IOException {\n        final byte[] extra = ze.getCentralDirectoryExtra();\n\n        // file comment length\n        String comm = ze.getComment();\n        if (comm == null) {\n            comm = \"\";\n        }\n\n        final ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n        final int nameLen = name.limit() - name.position();\n        final int commentLen = commentB.limit() - commentB.position();\n        final int len= CFH_FILENAME_OFFSET + nameLen + extra.length + commentLen;\n        final byte[] buf = new byte[len];\n\n        System.arraycopy(CFH_SIG,  0, buf, CFH_SIG_OFFSET, WORD);\n\n        // version made by\n        // CheckStyle:MagicNumber OFF\n        putShort((ze.getPlatform() << 8) | (!hasUsedZip64 ? DATA_DESCRIPTOR_MIN_VERSION : ZIP64_MIN_VERSION),\n                buf, CFH_VERSION_MADE_BY_OFFSET);\n\n        final int zipMethod = ze.getMethod();\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        putShort(versionNeededToExtract(zipMethod, needsZip64Extra, entryMetaData.usesDataDescriptor),\n            buf, CFH_VERSION_NEEDED_OFFSET);\n        getGeneralPurposeBits(!encodable && fallbackToUTF8, entryMetaData.usesDataDescriptor).encode(buf, CFH_GPB_OFFSET);\n\n        // compression method\n        putShort(zipMethod, buf, CFH_METHOD_OFFSET);\n\n\n        // last mod. time and date\n        ZipUtil.toDosTime(calendarInstance, ze.getTime(), buf, CFH_TIME_OFFSET);\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        putLong(ze.getCrc(), buf, CFH_CRC_OFFSET);\n        if (ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always) {\n            ZipLong.ZIP64_MAGIC.putLong(buf, CFH_COMPRESSED_SIZE_OFFSET);\n            ZipLong.ZIP64_MAGIC.putLong(buf, CFH_ORIGINAL_SIZE_OFFSET);\n        } else {\n            putLong(ze.getCompressedSize(), buf, CFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, CFH_ORIGINAL_SIZE_OFFSET);\n        }\n\n        putShort(nameLen, buf, CFH_FILENAME_LENGTH_OFFSET);\n\n        // extra field length\n        putShort(extra.length, buf, CFH_EXTRA_LENGTH_OFFSET);\n\n        putShort(commentLen, buf, CFH_COMMENT_LENGTH_OFFSET);\n\n        // disk number start\n        System.arraycopy(ZERO, 0, buf, CFH_DISK_NUMBER_OFFSET, SHORT);\n\n        // internal file attributes\n        putShort(ze.getInternalAttributes(), buf, CFH_INTERNAL_ATTRIBUTES_OFFSET);\n\n        // external file attributes\n        putLong(ze.getExternalAttributes(), buf, CFH_EXTERNAL_ATTRIBUTES_OFFSET);\n\n        // relative offset of LFH\n        if (entryMetaData.offset >= ZIP64_MAGIC || zip64Mode == Zip64Mode.Always) {\n            putLong(ZIP64_MAGIC, buf, CFH_LFH_OFFSET);\n        } else {\n            putLong(Math.min(entryMetaData.offset, ZIP64_MAGIC), buf, CFH_LFH_OFFSET);\n        }\n\n        // file name\n        System.arraycopy(name.array(), name.arrayOffset(), buf, CFH_FILENAME_OFFSET, nameLen);\n\n        final int extraStart = CFH_FILENAME_OFFSET + nameLen;\n        System.arraycopy(extra, 0, buf, extraStart, extra.length);\n\n        final int commentStart = extraStart + extra.length;\n\n        // file comment\n        System.arraycopy(commentB.array(), commentB.arrayOffset(), buf, commentStart, commentLen);\n        return buf;\n    }\n\n    /**\n     * If the entry needs Zip64 extra information inside the central\n     * directory then configure its data.\n     */\n    private void handleZip64Extra(final ZipArchiveEntry ze, final long lfhOffset,\n                                  final boolean needsZip64Extra) {\n        if (needsZip64Extra) {\n            final Zip64ExtendedInformationExtraField z64 = getZip64Extra(ze);\n            if (ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always) {\n                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n            } else {\n                // reset value that may have been set for LFH\n                z64.setCompressedSize(null);\n                z64.setSize(null);\n            }\n            if (lfhOffset >= ZIP64_MAGIC || zip64Mode == Zip64Mode.Always) {\n                z64.setRelativeHeaderOffset(new ZipEightByteInteger(lfhOffset));\n            }\n            ze.setExtra();\n        }\n    }\n\n    /**\n     * Writes the &quot;End of central dir record&quot;.\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link Zip64Mode #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    protected void writeCentralDirectoryEnd() throws IOException {\n        writeCounted(EOCD_SIG);\n\n        // disk numbers\n        writeCounted(ZERO);\n        writeCounted(ZERO);\n\n        // number of entries\n        final int numberOfEntries = entries.size();\n        if (numberOfEntries > ZIP64_MAGIC_SHORT\n            && zip64Mode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .TOO_MANY_ENTRIES_MESSAGE);\n        }\n        if (cdOffset > ZIP64_MAGIC && zip64Mode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .ARCHIVE_TOO_BIG_MESSAGE);\n        }\n\n        final byte[] num = ZipShort.getBytes(Math.min(numberOfEntries,\n                                                ZIP64_MAGIC_SHORT));\n        writeCounted(num);\n        writeCounted(num);\n\n        // length and location of CD\n        writeCounted(ZipLong.getBytes(Math.min(cdLength, ZIP64_MAGIC)));\n        writeCounted(ZipLong.getBytes(Math.min(cdOffset, ZIP64_MAGIC)));\n\n        // ZIP file comment\n        final ByteBuffer data = this.zipEncoding.encode(comment);\n        final int dataLen = data.limit() - data.position();\n        writeCounted(ZipShort.getBytes(dataLen));\n        streamCompressor.writeCounted(data.array(), data.arrayOffset(), dataLen);\n    }\n\n    /**\n     * Writes the &quot;ZIP64 End of central dir record&quot; and\n     * &quot;ZIP64 End of central dir locator&quot;.\n     * @throws IOException on error\n     * @since 1.3\n     */\n    protected void writeZip64CentralDirectory() throws IOException {\n        if (zip64Mode == Zip64Mode.Never) {\n            return;\n        }\n\n        if (!hasUsedZip64\n            && (cdOffset >= ZIP64_MAGIC || cdLength >= ZIP64_MAGIC\n                || entries.size() >= ZIP64_MAGIC_SHORT)) {\n            // actually \"will use\"\n            hasUsedZip64 = true;\n        }\n\n        if (!hasUsedZip64) {\n            return;\n        }\n\n        final long offset = streamCompressor.getTotalBytesWritten();\n\n        writeOut(ZIP64_EOCD_SIG);\n        // size, we don't have any variable length as we don't support\n        // the extensible data sector, yet\n        writeOut(ZipEightByteInteger\n                 .getBytes(SHORT   /* version made by */\n                           + SHORT /* version needed to extract */\n                           + WORD  /* disk number */\n                           + WORD  /* disk with central directory */\n                           + DWORD /* number of entries in CD on this disk */\n                           + DWORD /* total number of entries */\n                           + DWORD /* size of CD */\n                           + (long) DWORD /* offset of CD */\n                           ));\n\n        // version made by and version needed to extract\n        writeOut(ZipShort.getBytes(ZIP64_MIN_VERSION));\n        writeOut(ZipShort.getBytes(ZIP64_MIN_VERSION));\n\n        // disk numbers - four bytes this time\n        writeOut(LZERO);\n        writeOut(LZERO);\n\n        // number of entries\n        final byte[] num = ZipEightByteInteger.getBytes(entries.size());\n        writeOut(num);\n        writeOut(num);\n\n        // length and location of CD\n        writeOut(ZipEightByteInteger.getBytes(cdLength));\n        writeOut(ZipEightByteInteger.getBytes(cdOffset));\n\n        // no \"zip64 extensible data sector\" for now\n\n        // and now the \"ZIP64 end of central directory locator\"\n        writeOut(ZIP64_EOCD_LOC_SIG);\n\n        // disk number holding the ZIP64 EOCD record\n        writeOut(LZERO);\n        // relative offset of ZIP64 EOCD record\n        writeOut(ZipEightByteInteger.getBytes(offset));\n        // total number of disks\n        writeOut(ONE);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(final byte[] data) throws IOException {\n        streamCompressor.writeOut(data, 0, data.length);\n    }\n\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(final byte[] data, final int offset, final int length)\n            throws IOException {\n        streamCompressor.writeOut(data, offset, length);\n    }\n\n\n    private GeneralPurposeBit getGeneralPurposeBits(final boolean utfFallback, boolean usesDataDescriptor) {\n        final GeneralPurposeBit b = new GeneralPurposeBit();\n        b.useUTF8ForNames(useUTF8Flag || utfFallback);\n        if (usesDataDescriptor) {\n            b.useDataDescriptor(true);\n        }\n        return b;\n    }\n\n    private int versionNeededToExtract(final int zipMethod, final boolean zip64, final boolean usedDataDescriptor) {\n        if (zip64) {\n            return ZIP64_MIN_VERSION;\n        }\n        if (usedDataDescriptor) {\n            return DATA_DESCRIPTOR_MIN_VERSION;\n        }\n        return versionNeededToExtractMethod(zipMethod);\n    }\n\n    private boolean usesDataDescriptor(final int zipMethod) {\n        return zipMethod == DEFLATED && channel == null;\n    }\n\n    private int versionNeededToExtractMethod(int zipMethod) {\n        return zipMethod == DEFLATED ? DEFLATE_MIN_VERSION : INITIAL_VERSION;\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     *\n     * <p>Must not be used if the stream has already been closed.</p>\n     */\n    @Override\n    public ArchiveEntry createArchiveEntry(final File inputFile, final String entryName)\n        throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new ZipArchiveEntry(inputFile, entryName);\n    }\n\n    /**\n     * Get the existing ZIP64 extended information extra field or\n     * create a new one and add it to the entry.\n     *\n     * @since 1.3\n     */\n    private Zip64ExtendedInformationExtraField\n        getZip64Extra(final ZipArchiveEntry ze) {\n        if (entry != null) {\n            entry.causedUseOfZip64 = !hasUsedZip64;\n        }\n        hasUsedZip64 = true;\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            ze.getExtraField(Zip64ExtendedInformationExtraField\n                             .HEADER_ID);\n        if (z64 == null) {\n            /*\n              System.err.println(\"Adding z64 for \" + ze.getName()\n              + \", method: \" + ze.getMethod()\n              + \" (\" + (ze.getMethod() == STORED) + \")\"\n              + \", channel: \" + (channel != null));\n            */\n            z64 = new Zip64ExtendedInformationExtraField();\n        }\n\n        // even if the field is there already, make sure it is the first one\n        ze.addAsFirstExtraField(z64);\n\n        return z64;\n    }\n\n    /**\n     * Is there a ZIP64 extended information extra field for the\n     * entry?\n     *\n     * @since 1.3\n     */\n    private boolean hasZip64Extra(final ZipArchiveEntry ze) {\n        return ze.getExtraField(Zip64ExtendedInformationExtraField\n                                .HEADER_ID)\n            != null;\n    }\n\n    /**\n     * If the mode is AsNeeded and the entry is a compressed entry of\n     * unknown size that gets written to a non-seekable stream then\n     * change the default to Never.\n     *\n     * @since 1.3\n     */\n    private Zip64Mode getEffectiveZip64Mode(final ZipArchiveEntry ze) {\n        if (zip64Mode != Zip64Mode.AsNeeded\n            || channel != null\n            || ze.getMethod() != DEFLATED\n            || ze.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            return zip64Mode;\n        }\n        return Zip64Mode.Never;\n    }\n\n    private ZipEncoding getEntryEncoding(final ZipArchiveEntry ze) {\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        return !encodable && fallbackToUTF8\n            ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n    }\n\n    private ByteBuffer getName(final ZipArchiveEntry ze) throws IOException {\n        return getEntryEncoding(ze).encode(ze.getName());\n    }\n\n    /**\n     * Closes the underlying stream/file without finishing the\n     * archive, the result will likely be a corrupt archive.\n     *\n     * <p>This method only exists to support tests that generate\n     * corrupt archives so they can clean up any temporary files.</p>\n     */\n    void destroy() throws IOException {\n        if (channel != null) {\n            channel.close();\n        }\n        if (out != null) {\n            out.close();\n        }\n    }\n\n    /**\n     * enum that represents the possible policies for creating Unicode\n     * extra fields.\n     */\n    public static final class UnicodeExtraFieldPolicy {\n        /**\n         * Always create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy ALWAYS = new UnicodeExtraFieldPolicy(\"always\");\n        /**\n         * Never create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy NEVER = new UnicodeExtraFieldPolicy(\"never\");\n        /**\n         * Create Unicode extra fields for filenames that cannot be\n         * encoded using the specified encoding.\n         */\n        public static final UnicodeExtraFieldPolicy NOT_ENCODEABLE =\n            new UnicodeExtraFieldPolicy(\"not encodeable\");\n\n        private final String name;\n        private UnicodeExtraFieldPolicy(final String n) {\n            name = n;\n        }\n        @Override\n        public String toString() {\n            return name;\n        }\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being written.\n     */\n    private static final class CurrentEntry {\n        private CurrentEntry(final ZipArchiveEntry entry) {\n            this.entry = entry;\n        }\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry;\n        /**\n         * Offset for CRC entry in the local file header data for the\n         * current entry starts here.\n         */\n        private long localDataStart = 0;\n        /**\n         * Data for local header data\n         */\n        private long dataStart = 0;\n        /**\n         * Number of bytes read for the current entry (can't rely on\n         * Deflater#getBytesRead) when using DEFLATED.\n         */\n        private long bytesRead = 0;\n        /**\n         * Whether current entry was the first one using ZIP64 features.\n         */\n        private boolean causedUseOfZip64 = false;\n        /**\n         * Whether write() has been called at all.\n         *\n         * <p>In order to create a valid archive {@link\n         * #closeArchiveEntry closeArchiveEntry} will write an empty\n         * array to get the CRC right if nothing has been written to\n         * the stream at all.</p>\n         */\n        private boolean hasWritten;\n    }\n\n    private static final class EntryMetaData {\n        private final long offset;\n        private final boolean usesDataDescriptor;\n        private EntryMetaData(long offset, boolean usesDataDescriptor) {\n            this.offset = offset;\n            this.usesDataDescriptor = usesDataDescriptor;\n        }\n    }\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.File;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SeekableByteChannel;\nimport java.nio.file.Files;\nimport java.nio.file.StandardOpenOption;\nimport java.util.Calendar;\nimport java.util.EnumSet;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.zip.Deflater;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveOutputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DATA_DESCRIPTOR_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DEFLATE_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.INITIAL_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC_SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MIN_VERSION;\nimport static org.apache.commons.compress.archivers.zip.ZipLong.putLong;\nimport static org.apache.commons.compress.archivers.zip.ZipShort.putShort;\n\n/**\n * Reimplementation of {@link java.util.zip.ZipOutputStream\n * java.util.zip.ZipOutputStream} that does handle the extended\n * functionality of this package, especially internal/external file\n * attributes and extra fields with different layouts for local file\n * data and central directory entries.\n *\n * <p>This class will try to use {@link\n * java.nio.channels.SeekableByteChannel} when it knows that the\n * output is going to go to a file.</p>\n *\n * <p>If SeekableByteChannel cannot be used, this implementation will use\n * a Data Descriptor to store size and CRC information for {@link\n * #DEFLATED DEFLATED} entries, this means, you don't need to\n * calculate them yourself.  Unfortunately this is not possible for\n * the {@link #STORED STORED} method, here setting the CRC and\n * uncompressed size information is required before {@link\n * #putArchiveEntry(ArchiveEntry)} can be called.</p>\n *\n * <p>As of Apache Commons Compress 1.3 it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries in most cases but explicit\n * control is provided via {@link #setUseZip64}.  If the stream can not\n * use SeekableByteChannel and you try to write a ZipArchiveEntry of\n * unknown size then Zip64 extensions will be disabled by default.</p>\n *\n * @NotThreadSafe\n */\npublic class ZipArchiveOutputStream extends ArchiveOutputStream {\n\n    static final int BUFFER_SIZE = 512;\n    private static final int LFH_SIG_OFFSET = 0;\n    private static final int LFH_VERSION_NEEDED_OFFSET = 4;\n    private static final int LFH_GPB_OFFSET = 6;\n    private static final int LFH_METHOD_OFFSET = 8;\n    private static final int LFH_TIME_OFFSET = 10;\n    private static final int LFH_CRC_OFFSET = 14;\n    private static final int LFH_COMPRESSED_SIZE_OFFSET = 18;\n    private static final int LFH_ORIGINAL_SIZE_OFFSET = 22;\n    private static final int LFH_FILENAME_LENGTH_OFFSET = 26;\n    private static final int LFH_EXTRA_LENGTH_OFFSET = 28;\n    private static final int LFH_FILENAME_OFFSET = 30;\n    private static final int CFH_SIG_OFFSET = 0;\n    private static final int CFH_VERSION_MADE_BY_OFFSET = 4;\n    private static final int CFH_VERSION_NEEDED_OFFSET = 6;\n    private static final int CFH_GPB_OFFSET = 8;\n    private static final int CFH_METHOD_OFFSET = 10;\n    private static final int CFH_TIME_OFFSET = 12;\n    private static final int CFH_CRC_OFFSET = 16;\n    private static final int CFH_COMPRESSED_SIZE_OFFSET = 20;\n    private static final int CFH_ORIGINAL_SIZE_OFFSET = 24;\n    private static final int CFH_FILENAME_LENGTH_OFFSET = 28;\n    private static final int CFH_EXTRA_LENGTH_OFFSET = 30;\n    private static final int CFH_COMMENT_LENGTH_OFFSET = 32;\n    private static final int CFH_DISK_NUMBER_OFFSET = 34;\n    private static final int CFH_INTERNAL_ATTRIBUTES_OFFSET = 36;\n    private static final int CFH_EXTERNAL_ATTRIBUTES_OFFSET = 38;\n    private static final int CFH_LFH_OFFSET = 42;\n    private static final int CFH_FILENAME_OFFSET = 46;\n\n    /** indicates if this archive is finished. protected for use in Jar implementation */\n    protected boolean finished = false;\n\n    /**\n     * Compression method for deflated entries.\n     */\n    public static final int DEFLATED = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * Default compression level for deflated entries.\n     */\n    public static final int DEFAULT_COMPRESSION = Deflater.DEFAULT_COMPRESSION;\n\n    /**\n     * Compression method for stored entries.\n     */\n    public static final int STORED = java.util.zip.ZipEntry.STORED;\n\n    /**\n     * default encoding for file names and comment.\n     */\n    static final String DEFAULT_ENCODING = ZipEncodingHelper.UTF8;\n\n    /**\n     * General purpose flag, which indicates that filenames are\n     * written in UTF-8.\n     * @deprecated use {@link GeneralPurposeBit#UFT8_NAMES_FLAG} instead\n     */\n    @Deprecated\n    public static final int EFS_FLAG = GeneralPurposeBit.UFT8_NAMES_FLAG;\n\n    private static final byte[] EMPTY = new byte[0];\n\n    /**\n     * Current entry.\n     */\n    private CurrentEntry entry;\n\n    /**\n     * The file comment.\n     */\n    private String comment = \"\";\n\n    /**\n     * Compression level for next entry.\n     */\n    private int level = DEFAULT_COMPRESSION;\n\n    /**\n     * Has the compression level changed when compared to the last\n     * entry?\n     */\n    private boolean hasCompressionLevelChanged = false;\n\n    /**\n     * Default compression method for next entry.\n     */\n    private int method = java.util.zip.ZipEntry.DEFLATED;\n\n    /**\n     * List of ZipArchiveEntries written so far.\n     */\n    private final List<ZipArchiveEntry> entries =\n        new LinkedList<>();\n\n    private final StreamCompressor streamCompressor;\n\n    /**\n     * Start of central directory.\n     */\n    private long cdOffset = 0;\n\n    /**\n     * Length of central directory.\n     */\n    private long cdLength = 0;\n\n    /**\n     * Helper, a 0 as ZipShort.\n     */\n    private static final byte[] ZERO = {0, 0};\n\n    /**\n     * Helper, a 0 as ZipLong.\n     */\n    private static final byte[] LZERO = {0, 0, 0, 0};\n\n    private static final byte[] ONE = ZipLong.getBytes(1L);\n\n    /**\n     * Holds some book-keeping data for each entry.\n     */\n    private final Map<ZipArchiveEntry, EntryMetaData> metaData =\n        new HashMap<>();\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     */\n    private String encoding = DEFAULT_ENCODING;\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     *\n     * This field is of internal use and will be set in {@link\n     * #setEncoding(String)}.\n     */\n    private ZipEncoding zipEncoding =\n        ZipEncodingHelper.getZipEncoding(DEFAULT_ENCODING);\n\n\n    /**\n     * This Deflater object is used for output.\n     *\n     */\n    protected final Deflater def;\n    /**\n     * Optional random access output.\n     */\n    private final SeekableByteChannel channel;\n\n    private final OutputStream out;\n\n    /**\n     * whether to use the general purpose bit flag when writing UTF-8\n     * filenames or not.\n     */\n    private boolean useUTF8Flag = true; \n\n    /**\n     * Whether to encode non-encodable file names as UTF-8.\n     */\n    private boolean fallbackToUTF8 = false;\n\n    /**\n     * whether to create UnicodePathExtraField-s for each entry.\n     */\n    private UnicodeExtraFieldPolicy createUnicodeExtraFields = UnicodeExtraFieldPolicy.NEVER;\n\n    /**\n     * Whether anything inside this archive has used a ZIP64 feature.\n     *\n     * @since 1.3\n     */\n    private boolean hasUsedZip64 = false;\n\n    private Zip64Mode zip64Mode = Zip64Mode.AsNeeded;\n\n    private final byte[] copyBuffer = new byte[32768];\n    private final Calendar calendarInstance = Calendar.getInstance();\n\n    /**\n     * Creates a new ZIP OutputStream filtering the underlying stream.\n     * @param out the outputstream to zip\n     */\n    public ZipArchiveOutputStream(final OutputStream out) {\n        this.out = out;\n        this.channel = null;\n        def = new Deflater(level, true);\n        streamCompressor = StreamCompressor.create(out, def);\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a File.  Will use\n     * random access if possible.\n     * @param file the file to zip to\n     * @throws IOException on error\n     */\n    public ZipArchiveOutputStream(final File file) throws IOException {\n        def = new Deflater(level, true);\n        OutputStream o = null;\n        SeekableByteChannel _channel = null;\n        StreamCompressor _streamCompressor = null;\n        try {\n            _channel = Files.newByteChannel(file.toPath(),\n                EnumSet.of(StandardOpenOption.CREATE, StandardOpenOption.WRITE,\n                           StandardOpenOption.READ,\n                           StandardOpenOption.TRUNCATE_EXISTING));\n            // will never get opened properly when an exception is thrown so doesn't need to get closed\n            _streamCompressor = StreamCompressor.create(_channel, def); //NOSONAR\n        } catch (final IOException e) {\n            IOUtils.closeQuietly(_channel);\n            _channel = null;\n            o = new FileOutputStream(file);\n            _streamCompressor = StreamCompressor.create(o, def);\n        }\n        out = o;\n        channel = _channel;\n        streamCompressor = _streamCompressor;\n    }\n\n    /**\n     * Creates a new ZIP OutputStream writing to a SeekableByteChannel.\n     *\n     * <p>{@link\n     * org.apache.commons.compress.utils.SeekableInMemoryByteChannel}\n     * allows you to write to an in-memory archive using random\n     * access.</p>\n     *\n     * @param channel the channel to zip to\n     * @throws IOException on error\n     * @since 1.13\n     */\n    public ZipArchiveOutputStream(SeekableByteChannel channel) throws IOException {\n        this.channel = channel;\n        def = new Deflater(level, true);\n        streamCompressor = StreamCompressor.create(channel, def);\n        out = null;\n    }\n\n    /**\n     * This method indicates whether this archive is writing to a\n     * seekable stream (i.e., to a random access file).\n     *\n     * <p>For seekable streams, you don't need to calculate the CRC or\n     * uncompressed size for {@link #STORED} entries before\n     * invoking {@link #putArchiveEntry(ArchiveEntry)}.\n     * @return true if seekable\n     */\n    public boolean isSeekable() {\n        return channel != null;\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * <p>For a list of possible values see <a\n     * href=\"http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html\">http://java.sun.com/j2se/1.5.0/docs/guide/intl/encoding.doc.html</a>.\n     * Defaults to UTF-8.</p>\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     */\n    public void setEncoding(final String encoding) {\n        this.encoding = encoding;\n        this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        if (useUTF8Flag && !ZipEncodingHelper.isUTF8(encoding)) {\n            useUTF8Flag = false;\n        }\n    }\n\n    /**\n     * The encoding to use for filenames and the file comment.\n     *\n     * @return null if using the platform's default character encoding.\n     */\n    public String getEncoding() {\n        return encoding;\n    }\n\n    /**\n     * Whether to set the language encoding flag if the file name\n     * encoding is UTF-8.\n     *\n     * <p>Defaults to true.</p>\n     *\n     * @param b whether to set the language encoding flag if the file\n     * name encoding is UTF-8\n     */\n    public void setUseLanguageEncodingFlag(final boolean b) {\n        useUTF8Flag = b && ZipEncodingHelper.isUTF8(encoding);\n    }\n\n    /**\n     * Whether to create Unicode Extra Fields.\n     *\n     * <p>Defaults to NEVER.</p>\n     *\n     * @param b whether to create Unicode Extra Fields.\n     */\n    public void setCreateUnicodeExtraFields(final UnicodeExtraFieldPolicy b) {\n        createUnicodeExtraFields = b;\n    }\n\n    /**\n     * Whether to fall back to UTF and the language encoding flag if\n     * the file name cannot be encoded using the specified encoding.\n     *\n     * <p>Defaults to false.</p>\n     *\n     * @param b whether to fall back to UTF and the language encoding\n     * flag if the file name cannot be encoded using the specified\n     * encoding.\n     */\n    public void setFallbackToUTF8(final boolean b) {\n        fallbackToUTF8 = b;\n    }\n\n    /**\n     * Whether Zip64 extensions will be used.\n     *\n     * <p>When setting the mode to {@link Zip64Mode#Never Never},\n     * {@link #putArchiveEntry}, {@link #closeArchiveEntry}, {@link\n     * #finish} or {@link #close} may throw a {@link\n     * Zip64RequiredException} if the entry's size or the total size\n     * of the archive exceeds 4GB or there are more than 65536 entries\n     * inside the archive.  Any archive created in this mode will be\n     * readable by implementations that don't support Zip64.</p>\n     *\n     * <p>When setting the mode to {@link Zip64Mode#Always Always},\n     * Zip64 extensions will be used for all entries.  Any archive\n     * created in this mode may be unreadable by implementations that\n     * don't support Zip64 even if all its contents would be.</p>\n     *\n     * <p>When setting the mode to {@link Zip64Mode#AsNeeded\n     * AsNeeded}, Zip64 extensions will transparently be used for\n     * those entries that require them.  This mode can only be used if\n     * the uncompressed size of the {@link ZipArchiveEntry} is known\n     * when calling {@link #putArchiveEntry} or the archive is written\n     * to a seekable output (i.e. you have used the {@link\n     * #ZipArchiveOutputStream(java.io.File) File-arg constructor}) -\n     * this mode is not valid when the output stream is not seekable\n     * and the uncompressed size is unknown when {@link\n     * #putArchiveEntry} is called.</p>\n     * \n     * <p>If no entry inside the resulting archive requires Zip64\n     * extensions then {@link Zip64Mode#Never Never} will create the\n     * smallest archive.  {@link Zip64Mode#AsNeeded AsNeeded} will\n     * create a slightly bigger archive if the uncompressed size of\n     * any entry has initially been unknown and create an archive\n     * identical to {@link Zip64Mode#Never Never} otherwise.  {@link\n     * Zip64Mode#Always Always} will create an archive that is at\n     * least 24 bytes per entry bigger than the one {@link\n     * Zip64Mode#Never Never} would create.</p>\n     *\n     * <p>Defaults to {@link Zip64Mode#AsNeeded AsNeeded} unless\n     * {@link #putArchiveEntry} is called with an entry of unknown\n     * size and data is written to a non-seekable stream - in this\n     * case the default is {@link Zip64Mode#Never Never}.</p>\n     *\n     * @since 1.3\n     * @param mode Whether Zip64 extensions will be used.\n     */\n    public void setUseZip64(final Zip64Mode mode) {\n        zip64Mode = mode;\n    }\n\n    /**\n     * {@inheritDoc}\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void finish() throws IOException {\n        if (finished) {\n            throw new IOException(\"This archive has already been finished\");\n        }\n\n        if (entry != null) {\n            throw new IOException(\"This archive contains unclosed entries.\");\n        }\n\n        cdOffset = streamCompressor.getTotalBytesWritten();\n        writeCentralDirectoryInChunks();\n\n        cdLength = streamCompressor.getTotalBytesWritten() - cdOffset;\n        writeZip64CentralDirectory();\n        writeCentralDirectoryEnd();\n        metaData.clear();\n        entries.clear();\n        streamCompressor.close();\n        finished = true;\n    }\n\n    private void writeCentralDirectoryInChunks() throws IOException {\n        final int NUM_PER_WRITE = 1000;\n        final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(70 * NUM_PER_WRITE);\n        int count = 0;\n        for (final ZipArchiveEntry ze : entries) {\n            byteArrayOutputStream.write(createCentralFileHeader(ze));\n            if (++count > NUM_PER_WRITE){\n                writeCounted(byteArrayOutputStream.toByteArray());\n                byteArrayOutputStream.reset();\n                count = 0;\n            }\n        }\n        writeCounted(byteArrayOutputStream.toByteArray());\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size exceeds 4 GByte and {@link #setUseZip64} \n     * is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void closeArchiveEntry() throws IOException {\n        preClose();\n\n        flushDeflater();\n\n        final long bytesWritten = streamCompressor.getTotalBytesWritten() - entry.dataStart;\n        final long realCrc = streamCompressor.getCrc32();\n        entry.bytesRead = streamCompressor.getBytesRead();\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        final boolean actuallyNeedsZip64 = handleSizesAndCrc(bytesWritten, realCrc, effectiveMode);\n        closeEntry(actuallyNeedsZip64, false);\n        streamCompressor.reset();\n    }\n\n    /**\n     * Writes all necessary data for this entry.\n     *\n     * @param phased              This entry is second phase of a 2-phase zip creation, size, compressed size and crc\n     *                            are known in ZipArchiveEntry\n     * @throws IOException            on error\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     *                                compressed size exceeds 4 GByte and {@link #setUseZip64}\n     *                                is {@link Zip64Mode#Never}.\n     */\n    private void closeCopiedEntry(final boolean phased) throws IOException {\n        preClose();\n        entry.bytesRead = entry.entry.getSize();\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        final boolean actuallyNeedsZip64 = checkIfNeedsZip64(effectiveMode);\n        closeEntry(actuallyNeedsZip64, phased);\n    }\n\n    private void closeEntry(final boolean actuallyNeedsZip64, final boolean phased) throws IOException {\n        if (!phased && channel != null) {\n            rewriteSizesAndCrc(actuallyNeedsZip64);\n        }\n\n        if (!phased) {\n            writeDataDescriptor(entry.entry);\n        }\n        entry = null;\n    }\n\n    private void preClose() throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        if (entry == null) {\n            throw new IOException(\"No current entry to close\");\n        }\n\n        if (!entry.hasWritten) {\n            write(EMPTY, 0, 0);\n        }\n    }\n\n    /**\n     * Adds an archive entry with a raw input stream.\n     *\n     * If crc, size and compressed size are supplied on the entry, these values will be used as-is.\n     * Zip64 status is re-established based on the settings in this stream, and the supplied value\n     * is ignored.\n     *\n     * The entry is put and closed immediately.\n     *\n     * @param entry The archive entry to add\n     * @param rawStream The raw input stream of a different entry. May be compressed/encrypted.\n     * @throws IOException If copying fails\n     */\n    public void addRawArchiveEntry(final ZipArchiveEntry entry, final InputStream rawStream)\n            throws IOException {\n        final ZipArchiveEntry ae = new ZipArchiveEntry(entry);\n        if (hasZip64Extra(ae)) {\n            // Will be re-added as required. this may make the file generated with this method\n            // somewhat smaller than standard mode,\n            // since standard mode is unable to remove the zip 64 header.\n            ae.removeExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        }\n        final boolean is2PhaseSource = ae.getCrc() != ZipArchiveEntry.CRC_UNKNOWN\n                && ae.getSize() != ArchiveEntry.SIZE_UNKNOWN\n                && ae.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN;\n        putArchiveEntry(ae, is2PhaseSource);\n        copyFromZipInputStream(rawStream);\n        closeCopiedEntry(is2PhaseSource);\n    }\n\n    /**\n     * Ensures all bytes sent to the deflater are written to the stream.\n     */\n    private void flushDeflater() throws IOException {\n        if (entry.entry.getMethod() == DEFLATED) {\n            streamCompressor.flushDeflater();\n        }\n    }\n\n    /**\n     * Ensures the current entry's size and CRC information is set to\n     * the values just written, verifies it isn't too big in the\n     * Zip64Mode.Never case and returns whether the entry would\n     * require a Zip64 extra field.\n     */\n    private boolean handleSizesAndCrc(final long bytesWritten, final long crc,\n                                      final Zip64Mode effectiveMode)\n        throws ZipException {\n        if (entry.entry.getMethod() == DEFLATED) {\n            /* It turns out def.getBytesRead() returns wrong values if\n             * the size exceeds 4 GB on Java < Java7\n            entry.entry.setSize(def.getBytesRead());\n            */\n            entry.entry.setSize(entry.bytesRead);\n            entry.entry.setCompressedSize(bytesWritten);\n            entry.entry.setCrc(crc);\n\n        } else if (channel == null) {\n            if (entry.entry.getCrc() != crc) {\n                throw new ZipException(\"bad CRC checksum for entry \"\n                                       + entry.entry.getName() + \": \"\n                                       + Long.toHexString(entry.entry.getCrc())\n                                       + \" instead of \"\n                                       + Long.toHexString(crc));\n            }\n\n            if (entry.entry.getSize() != bytesWritten) {\n                throw new ZipException(\"bad size for entry \"\n                                       + entry.entry.getName() + \": \"\n                                       + entry.entry.getSize()\n                                       + \" instead of \"\n                                       + bytesWritten);\n            }\n        } else { /* method is STORED and we used SeekableByteChannel */\n            entry.entry.setSize(bytesWritten);\n            entry.entry.setCompressedSize(bytesWritten);\n            entry.entry.setCrc(crc);\n        }\n\n        return checkIfNeedsZip64(effectiveMode);\n    }\n\n    /**\n     * Verifies the sizes aren't too big in the Zip64Mode.Never case\n     * and returns whether the entry would require a Zip64 extra\n     * field.\n     */\n    private boolean checkIfNeedsZip64(final Zip64Mode effectiveMode)\n            throws ZipException {\n        final boolean actuallyNeedsZip64 = isZip64Required(entry.entry, effectiveMode);\n        if (actuallyNeedsZip64 && effectiveMode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException.getEntryTooBigMessage(entry.entry));\n        }\n        return actuallyNeedsZip64;\n    }\n\n    private boolean isZip64Required(final ZipArchiveEntry entry1, final Zip64Mode requestedMode) {\n        return requestedMode == Zip64Mode.Always || isTooLageForZip32(entry1);\n    }\n\n    private boolean isTooLageForZip32(final ZipArchiveEntry zipArchiveEntry){\n        return zipArchiveEntry.getSize() >= ZIP64_MAGIC || zipArchiveEntry.getCompressedSize() >= ZIP64_MAGIC;\n    }\n\n    /**\n     * When using random access output, write the local file header\n     * and potentiall the ZIP64 extra containing the correct CRC and\n     * compressed/uncompressed sizes.\n     */\n    private void rewriteSizesAndCrc(final boolean actuallyNeedsZip64)\n        throws IOException {\n        final long save = channel.position();\n\n        channel.position(entry.localDataStart);\n        writeOut(ZipLong.getBytes(entry.entry.getCrc()));\n        if (!hasZip64Extra(entry.entry) || !actuallyNeedsZip64) {\n            writeOut(ZipLong.getBytes(entry.entry.getCompressedSize()));\n            writeOut(ZipLong.getBytes(entry.entry.getSize()));\n        } else {\n            writeOut(ZipLong.ZIP64_MAGIC.getBytes());\n            writeOut(ZipLong.ZIP64_MAGIC.getBytes());\n        }\n\n        if (hasZip64Extra(entry.entry)) {\n            final ByteBuffer name = getName(entry.entry);\n            final int nameLen = name.limit() - name.position();\n            // seek to ZIP64 extra, skip header and size information\n            channel.position(entry.localDataStart + 3 * WORD + 2 * SHORT\n                             + nameLen + 2 * SHORT);\n            // inside the ZIP64 extra uncompressed size comes\n            // first, unlike the LFH, CD or data descriptor\n            writeOut(ZipEightByteInteger.getBytes(entry.entry.getSize()));\n            writeOut(ZipEightByteInteger.getBytes(entry.entry.getCompressedSize()));\n\n            if (!actuallyNeedsZip64) {\n                // do some cleanup:\n                // * rewrite version needed to extract\n                channel.position(entry.localDataStart  - 5 * SHORT);\n                writeOut(ZipShort.getBytes(versionNeededToExtract(entry.entry.getMethod(), false, false)));\n\n                // * remove ZIP64 extra so it doesn't get written\n                //   to the central directory\n                entry.entry.removeExtraField(Zip64ExtendedInformationExtraField\n                                             .HEADER_ID);\n                entry.entry.setExtra();\n\n                // * reset hasUsedZip64 if it has been set because\n                //   of this entry\n                if (entry.causedUseOfZip64) {\n                    hasUsedZip64 = false;\n                }\n            }\n        }\n        channel.position(save);\n    }\n\n    /**\n     * {@inheritDoc} \n     * @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size is known to exceed 4 GByte and {@link #setUseZip64} \n     * is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void putArchiveEntry(final ArchiveEntry archiveEntry) throws IOException {\n        putArchiveEntry(archiveEntry, false);\n    }\n\n    /**\n     * Writes the headers for an archive entry to the output stream.\n     * The caller must then write the content to the stream and call\n     * {@link #closeArchiveEntry()} to complete the process.\n\n     * @param archiveEntry The archiveEntry\n     * @param phased If true size, compressedSize and crc required to be known up-front in the archiveEntry\n     * @throws ClassCastException if entry is not an instance of ZipArchiveEntry\n     * @throws Zip64RequiredException if the entry's uncompressed or\n     * compressed size is known to exceed 4 GByte and {@link #setUseZip64}\n     * is {@link Zip64Mode#Never}.\n     */\n    private void putArchiveEntry(final ArchiveEntry archiveEntry, final boolean phased) throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n\n        if (entry != null) {\n            closeArchiveEntry();\n        }\n\n        entry = new CurrentEntry((ZipArchiveEntry) archiveEntry);\n        entries.add(entry.entry);\n\n        setDefaults(entry.entry);\n\n        final Zip64Mode effectiveMode = getEffectiveZip64Mode(entry.entry);\n        validateSizeInformation(effectiveMode);\n\n        if (shouldAddZip64Extra(entry.entry, effectiveMode)) {\n\n            final Zip64ExtendedInformationExtraField z64 = getZip64Extra(entry.entry);\n\n            ZipEightByteInteger size, compressedSize;\n            if (phased) {\n                // sizes are already known\n                size = new ZipEightByteInteger(entry.entry.getSize());\n                compressedSize = new ZipEightByteInteger(entry.entry.getCompressedSize());\n            } else if (entry.entry.getMethod() == STORED\n                    && entry.entry.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n                // actually, we already know the sizes\n                compressedSize = size = new ZipEightByteInteger(entry.entry.getSize());\n            } else {\n                // just a placeholder, real data will be in data\n                // descriptor or inserted later via SeekableByteChannel\n                compressedSize = size = ZipEightByteInteger.ZERO;\n            }\n            z64.setSize(size);\n            z64.setCompressedSize(compressedSize);\n            entry.entry.setExtra();\n        }\n\n        if (entry.entry.getMethod() == DEFLATED && hasCompressionLevelChanged) {\n            def.setLevel(level);\n            hasCompressionLevelChanged = false;\n        }\n        writeLocalFileHeader((ZipArchiveEntry) archiveEntry, phased);\n    }\n\n    /**\n     * Provides default values for compression method and last\n     * modification time.\n     */\n    private void setDefaults(final ZipArchiveEntry entry) {\n        if (entry.getMethod() == -1) { // not specified\n            entry.setMethod(method);\n        }\n\n        if (entry.getTime() == -1) { // not specified\n            entry.setTime(System.currentTimeMillis());\n        }\n    }\n\n    /**\n     * Throws an exception if the size is unknown for a stored entry\n     * that is written to a non-seekable output or the entry is too\n     * big to be written without Zip64 extra but the mode has been set\n     * to Never.\n     */\n    private void validateSizeInformation(final Zip64Mode effectiveMode)\n        throws ZipException {\n        // Size/CRC not required if SeekableByteChannel is used\n        if (entry.entry.getMethod() == STORED && channel == null) {\n            if (entry.entry.getSize() == ArchiveEntry.SIZE_UNKNOWN) {\n                throw new ZipException(\"uncompressed size is required for\"\n                                       + \" STORED method when not writing to a\"\n                                       + \" file\");\n            }\n            if (entry.entry.getCrc() == ZipArchiveEntry.CRC_UNKNOWN) {\n                throw new ZipException(\"crc checksum is required for STORED\"\n                                       + \" method when not writing to a file\");\n            }\n            entry.entry.setCompressedSize(entry.entry.getSize());\n        }\n\n        if ((entry.entry.getSize() >= ZIP64_MAGIC\n             || entry.entry.getCompressedSize() >= ZIP64_MAGIC)\n            && effectiveMode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .getEntryTooBigMessage(entry.entry));\n        }\n    }\n\n    /**\n     * Whether to addd a Zip64 extended information extra field to the\n     * local file header.\n     *\n     * <p>Returns true if</p>\n     *\n     * <ul>\n     * <li>mode is Always</li>\n     * <li>or we already know it is going to be needed</li>\n     * <li>or the size is unknown and we can ensure it won't hurt\n     * other implementations if we add it (i.e. we can erase its\n     * usage</li>\n     * </ul>\n     */\n    private boolean shouldAddZip64Extra(final ZipArchiveEntry entry, final Zip64Mode mode) {\n        return mode == Zip64Mode.Always\n            || entry.getSize() >= ZIP64_MAGIC\n            || entry.getCompressedSize() >= ZIP64_MAGIC\n            || (entry.getSize() == ArchiveEntry.SIZE_UNKNOWN\n                && channel != null && mode != Zip64Mode.Never);\n    }\n\n    /**\n     * Set the file comment.\n     * @param comment the comment\n     */\n    public void setComment(final String comment) {\n        this.comment = comment;\n    }\n\n    /**\n     * Sets the compression level for subsequent entries.\n     *\n     * <p>Default is Deflater.DEFAULT_COMPRESSION.</p>\n     * @param level the compression level.\n     * @throws IllegalArgumentException if an invalid compression\n     * level is specified.\n     */\n    public void setLevel(final int level) {\n        if (level < Deflater.DEFAULT_COMPRESSION\n            || level > Deflater.BEST_COMPRESSION) {\n            throw new IllegalArgumentException(\"Invalid compression level: \"\n                                               + level);\n        }\n        hasCompressionLevelChanged = (this.level != level);\n        this.level = level;\n    }\n\n    /**\n     * Sets the default compression method for subsequent entries.\n     *\n     * <p>Default is DEFLATED.</p>\n     * @param method an <code>int</code> from java.util.zip.ZipEntry\n     */\n    public void setMethod(final int method) {\n        this.method = method;\n    }\n\n    /**\n     * Whether this stream is able to write the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canWriteEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry zae = (ZipArchiveEntry) ae;\n            return zae.getMethod() != ZipMethod.IMPLODING.getCode()\n                && zae.getMethod() != ZipMethod.UNSHRINKING.getCode()\n                && ZipUtil.canHandleEntryData(zae);\n        }\n        return false;\n    }\n\n    /**\n     * Writes bytes to ZIP entry.\n     * @param b the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    @Override\n    public void write(final byte[] b, final int offset, final int length) throws IOException {\n        if (entry == null) {\n            throw new IllegalStateException(\"No current entry\");\n        }\n        ZipUtil.checkRequestedFeatures(entry.entry);\n        final long writtenThisTime = streamCompressor.write(b, offset, length, entry.entry.getMethod());\n        count(writtenThisTime);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    private void writeCounted(final byte[] data) throws IOException {\n        streamCompressor.writeCounted(data);\n    }\n\n    private void copyFromZipInputStream(final InputStream src) throws IOException {\n        if (entry == null) {\n            throw new IllegalStateException(\"No current entry\");\n        }\n        ZipUtil.checkRequestedFeatures(entry.entry);\n        entry.hasWritten = true;\n        int length;\n        while ((length = src.read(copyBuffer)) >= 0 )\n        {\n            streamCompressor.writeCounted(copyBuffer, 0, length);\n            count( length );\n        }\n    }\n\n    /**\n     * Closes this output stream and releases any system resources\n     * associated with the stream.\n     *\n     * @throws  IOException  if an I/O error occurs.\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    @Override\n    public void close() throws IOException {\n        if (!finished) {\n            finish();\n        }\n        destroy();\n    }\n\n    /**\n     * Flushes this output stream and forces any buffered output bytes\n     * to be written out to the stream.\n     *\n     * @throws  IOException  if an I/O error occurs.\n     */\n    @Override\n    public void flush() throws IOException {\n        if (out != null) {\n            out.flush();\n        }\n    }\n\n    /*\n     * Various ZIP constants shared between this class, ZipArchiveInputStream and ZipFile\n     */\n    /**\n     * local file header signature\n     */\n    static final byte[] LFH_SIG = ZipLong.LFH_SIG.getBytes(); //NOSONAR\n    /**\n     * data descriptor signature\n     */\n    static final byte[] DD_SIG = ZipLong.DD_SIG.getBytes(); //NOSONAR\n    /**\n     * central file header signature\n     */\n    static final byte[] CFH_SIG = ZipLong.CFH_SIG.getBytes(); //NOSONAR\n    /**\n     * end of central dir signature\n     */\n    static final byte[] EOCD_SIG = ZipLong.getBytes(0X06054B50L); //NOSONAR\n    /**\n     * ZIP64 end of central dir signature\n     */\n    static final byte[] ZIP64_EOCD_SIG = ZipLong.getBytes(0X06064B50L); //NOSONAR\n    /**\n     * ZIP64 end of central dir locator signature\n     */\n    static final byte[] ZIP64_EOCD_LOC_SIG = ZipLong.getBytes(0X07064B50L); //NOSONAR\n\n    /**\n     * Writes next block of compressed data to the output stream.\n     * @throws IOException on error\n     */\n    protected final void deflate() throws IOException {\n        streamCompressor.deflate();\n    }\n\n    /**\n     * Writes the local file header entry\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeLocalFileHeader(final ZipArchiveEntry ze) throws IOException {\n        writeLocalFileHeader(ze, false);\n    }\n\n    private void writeLocalFileHeader(final ZipArchiveEntry ze, final boolean phased) throws IOException {\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        final ByteBuffer name = getName(ze);\n\n        if (createUnicodeExtraFields != UnicodeExtraFieldPolicy.NEVER) {\n            addUnicodeExtraFields(ze, encodable, name);\n        }\n\n        final long localHeaderStart = streamCompressor.getTotalBytesWritten();\n        final byte[] localHeader = createLocalFileHeader(ze, name, encodable, phased, localHeaderStart);\n        metaData.put(ze, new EntryMetaData(localHeaderStart, usesDataDescriptor(ze.getMethod(), phased)));\n        entry.localDataStart = localHeaderStart + LFH_CRC_OFFSET; // At crc offset\n        writeCounted(localHeader);\n        entry.dataStart = streamCompressor.getTotalBytesWritten();\n    }\n\n\n    private byte[] createLocalFileHeader(final ZipArchiveEntry ze, final ByteBuffer name, final boolean encodable,\n                                         final boolean phased, long archiveOffset) throws IOException {\n        ResourceAlignmentExtraField oldAlignmentEx =\n            (ResourceAlignmentExtraField) ze.getExtraField(ResourceAlignmentExtraField.ID);\n        if (oldAlignmentEx != null) {\n            ze.removeExtraField(ResourceAlignmentExtraField.ID);\n        }\n\n        int alignment = ze.getAlignment();\n        if (alignment <= 0 && oldAlignmentEx != null) {\n            alignment = oldAlignmentEx.getAlignment();\n        }\n\n        if (alignment > 1 || (oldAlignmentEx != null && !oldAlignmentEx.allowMethodChange())) {\n            int oldLength = LFH_FILENAME_OFFSET +\n                            name.limit() - name.position() +\n                            ze.getLocalFileDataExtra().length;\n\n            int padding = (int) ((-archiveOffset - oldLength - ZipExtraField.EXTRAFIELD_HEADER_SIZE\n                            - ResourceAlignmentExtraField.BASE_SIZE) &\n                            (alignment - 1));\n            ze.addExtraField(new ResourceAlignmentExtraField(alignment,\n                            oldAlignmentEx != null && oldAlignmentEx.allowMethodChange(), padding));\n        }\n\n        final byte[] extra = ze.getLocalFileDataExtra();\n        final int nameLen = name.limit() - name.position();\n        final int len = LFH_FILENAME_OFFSET + nameLen + extra.length;\n        final byte[] buf = new byte[len];\n\n        System.arraycopy(LFH_SIG,  0, buf, LFH_SIG_OFFSET, WORD);\n\n        //store method in local variable to prevent multiple method calls\n        final int zipMethod = ze.getMethod();\n        final boolean dataDescriptor = usesDataDescriptor(zipMethod, phased);\n\n        putShort(versionNeededToExtract(zipMethod, hasZip64Extra(ze), dataDescriptor), buf, LFH_VERSION_NEEDED_OFFSET);\n\n        final GeneralPurposeBit generalPurposeBit = getGeneralPurposeBits(!encodable && fallbackToUTF8, dataDescriptor);\n        generalPurposeBit.encode(buf, LFH_GPB_OFFSET);\n\n        // compression method\n        putShort(zipMethod, buf, LFH_METHOD_OFFSET);\n\n        ZipUtil.toDosTime(calendarInstance, ze.getTime(), buf, LFH_TIME_OFFSET);\n\n        // CRC\n        if (phased){\n            putLong(ze.getCrc(), buf, LFH_CRC_OFFSET);\n        } else if (zipMethod == DEFLATED || channel != null) {\n            System.arraycopy(LZERO, 0, buf, LFH_CRC_OFFSET, WORD);\n        } else {\n            putLong(ze.getCrc(), buf, LFH_CRC_OFFSET);\n        }\n\n        // compressed length\n        // uncompressed length\n        if (hasZip64Extra(entry.entry)){\n            // point to ZIP64 extended information extra field for\n            // sizes, may get rewritten once sizes are known if\n            // stream is seekable\n            ZipLong.ZIP64_MAGIC.putLong(buf, LFH_COMPRESSED_SIZE_OFFSET);\n            ZipLong.ZIP64_MAGIC.putLong(buf, LFH_ORIGINAL_SIZE_OFFSET);\n        } else if (phased) {\n            putLong(ze.getCompressedSize(), buf, LFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, LFH_ORIGINAL_SIZE_OFFSET);\n        } else if (zipMethod == DEFLATED || channel != null) {\n            System.arraycopy(LZERO, 0, buf, LFH_COMPRESSED_SIZE_OFFSET, WORD);\n            System.arraycopy(LZERO, 0, buf, LFH_ORIGINAL_SIZE_OFFSET, WORD);\n        } else { // Stored\n            putLong(ze.getSize(), buf, LFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, LFH_ORIGINAL_SIZE_OFFSET);\n        }\n        // file name length\n        putShort(nameLen, buf, LFH_FILENAME_LENGTH_OFFSET);\n\n        // extra field length\n        putShort(extra.length, buf, LFH_EXTRA_LENGTH_OFFSET);\n\n        // file name\n        System.arraycopy( name.array(), name.arrayOffset(), buf, LFH_FILENAME_OFFSET, nameLen);\n\n        // extra fields\n        System.arraycopy(extra, 0, buf, LFH_FILENAME_OFFSET + nameLen, extra.length);\n\n        return buf;\n    }\n\n\n    /**\n     * Adds UnicodeExtra fields for name and file comment if mode is\n     * ALWAYS or the data cannot be encoded using the configured\n     * encoding.\n     */\n    private void addUnicodeExtraFields(final ZipArchiveEntry ze, final boolean encodable,\n                                       final ByteBuffer name)\n        throws IOException {\n        if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n            || !encodable) {\n            ze.addExtraField(new UnicodePathExtraField(ze.getName(),\n                                                       name.array(),\n                                                       name.arrayOffset(),\n                                                       name.limit()\n                                                       - name.position()));\n        }\n\n        final String comm = ze.getComment();\n        if (comm != null && !\"\".equals(comm)) {\n\n            final boolean commentEncodable = zipEncoding.canEncode(comm);\n\n            if (createUnicodeExtraFields == UnicodeExtraFieldPolicy.ALWAYS\n                || !commentEncodable) {\n                final ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n                ze.addExtraField(new UnicodeCommentExtraField(comm,\n                                                              commentB.array(),\n                                                              commentB.arrayOffset(),\n                                                              commentB.limit()\n                                                              - commentB.position())\n                                 );\n            }\n        }\n    }\n\n    /**\n     * Writes the data descriptor entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     */\n    protected void writeDataDescriptor(final ZipArchiveEntry ze) throws IOException {\n        if (!usesDataDescriptor(ze.getMethod(), false)) {\n            return;\n        }\n        writeCounted(DD_SIG);\n        writeCounted(ZipLong.getBytes(ze.getCrc()));\n        if (!hasZip64Extra(ze)) {\n            writeCounted(ZipLong.getBytes(ze.getCompressedSize()));\n            writeCounted(ZipLong.getBytes(ze.getSize()));\n        } else {\n            writeCounted(ZipEightByteInteger.getBytes(ze.getCompressedSize()));\n            writeCounted(ZipEightByteInteger.getBytes(ze.getSize()));\n        }\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte and {@link Zip64Mode #setUseZip64} is {@link\n     * Zip64Mode#Never}.\n     */\n    protected void writeCentralFileHeader(final ZipArchiveEntry ze) throws IOException {\n        final byte[] centralFileHeader = createCentralFileHeader(ze);\n        writeCounted(centralFileHeader);\n    }\n\n    private byte[] createCentralFileHeader(final ZipArchiveEntry ze) throws IOException {\n\n        final EntryMetaData entryMetaData = metaData.get(ze);\n        final boolean needsZip64Extra = hasZip64Extra(ze)\n                || ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || entryMetaData.offset >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always;\n\n        if (needsZip64Extra && zip64Mode == Zip64Mode.Never) {\n            // must be the offset that is too big, otherwise an\n            // exception would have been throw in putArchiveEntry or\n            // closeArchiveEntry\n            throw new Zip64RequiredException(Zip64RequiredException\n                    .ARCHIVE_TOO_BIG_MESSAGE);\n        }\n\n\n        handleZip64Extra(ze, entryMetaData.offset, needsZip64Extra);\n\n        return createCentralFileHeader(ze, getName(ze), entryMetaData, needsZip64Extra);\n    }\n\n    /**\n     * Writes the central file header entry.\n     * @param ze the entry to write\n     * @param name The encoded name\n     * @param entryMetaData meta data for this file\n     * @throws IOException on error\n     */\n    private byte[] createCentralFileHeader(final ZipArchiveEntry ze, final ByteBuffer name,\n                                           final EntryMetaData entryMetaData,\n                                           final boolean needsZip64Extra) throws IOException {\n        final byte[] extra = ze.getCentralDirectoryExtra();\n\n        // file comment length\n        String comm = ze.getComment();\n        if (comm == null) {\n            comm = \"\";\n        }\n\n        final ByteBuffer commentB = getEntryEncoding(ze).encode(comm);\n        final int nameLen = name.limit() - name.position();\n        final int commentLen = commentB.limit() - commentB.position();\n        final int len= CFH_FILENAME_OFFSET + nameLen + extra.length + commentLen;\n        final byte[] buf = new byte[len];\n\n        System.arraycopy(CFH_SIG,  0, buf, CFH_SIG_OFFSET, WORD);\n\n        // version made by\n        // CheckStyle:MagicNumber OFF\n        putShort((ze.getPlatform() << 8) | (!hasUsedZip64 ? DATA_DESCRIPTOR_MIN_VERSION : ZIP64_MIN_VERSION),\n                buf, CFH_VERSION_MADE_BY_OFFSET);\n\n        final int zipMethod = ze.getMethod();\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        putShort(versionNeededToExtract(zipMethod, needsZip64Extra, entryMetaData.usesDataDescriptor),\n            buf, CFH_VERSION_NEEDED_OFFSET);\n        getGeneralPurposeBits(!encodable && fallbackToUTF8, entryMetaData.usesDataDescriptor).encode(buf, CFH_GPB_OFFSET);\n\n        // compression method\n        putShort(zipMethod, buf, CFH_METHOD_OFFSET);\n\n\n        // last mod. time and date\n        ZipUtil.toDosTime(calendarInstance, ze.getTime(), buf, CFH_TIME_OFFSET);\n\n        // CRC\n        // compressed length\n        // uncompressed length\n        putLong(ze.getCrc(), buf, CFH_CRC_OFFSET);\n        if (ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always) {\n            ZipLong.ZIP64_MAGIC.putLong(buf, CFH_COMPRESSED_SIZE_OFFSET);\n            ZipLong.ZIP64_MAGIC.putLong(buf, CFH_ORIGINAL_SIZE_OFFSET);\n        } else {\n            putLong(ze.getCompressedSize(), buf, CFH_COMPRESSED_SIZE_OFFSET);\n            putLong(ze.getSize(), buf, CFH_ORIGINAL_SIZE_OFFSET);\n        }\n\n        putShort(nameLen, buf, CFH_FILENAME_LENGTH_OFFSET);\n\n        // extra field length\n        putShort(extra.length, buf, CFH_EXTRA_LENGTH_OFFSET);\n\n        putShort(commentLen, buf, CFH_COMMENT_LENGTH_OFFSET);\n\n        // disk number start\n        System.arraycopy(ZERO, 0, buf, CFH_DISK_NUMBER_OFFSET, SHORT);\n\n        // internal file attributes\n        putShort(ze.getInternalAttributes(), buf, CFH_INTERNAL_ATTRIBUTES_OFFSET);\n\n        // external file attributes\n        putLong(ze.getExternalAttributes(), buf, CFH_EXTERNAL_ATTRIBUTES_OFFSET);\n\n        // relative offset of LFH\n        if (entryMetaData.offset >= ZIP64_MAGIC || zip64Mode == Zip64Mode.Always) {\n            putLong(ZIP64_MAGIC, buf, CFH_LFH_OFFSET);\n        } else {\n            putLong(Math.min(entryMetaData.offset, ZIP64_MAGIC), buf, CFH_LFH_OFFSET);\n        }\n\n        // file name\n        System.arraycopy(name.array(), name.arrayOffset(), buf, CFH_FILENAME_OFFSET, nameLen);\n\n        final int extraStart = CFH_FILENAME_OFFSET + nameLen;\n        System.arraycopy(extra, 0, buf, extraStart, extra.length);\n\n        final int commentStart = extraStart + extra.length;\n\n        // file comment\n        System.arraycopy(commentB.array(), commentB.arrayOffset(), buf, commentStart, commentLen);\n        return buf;\n    }\n\n    /**\n     * If the entry needs Zip64 extra information inside the central\n     * directory then configure its data.\n     */\n    private void handleZip64Extra(final ZipArchiveEntry ze, final long lfhOffset,\n                                  final boolean needsZip64Extra) {\n        if (needsZip64Extra) {\n            final Zip64ExtendedInformationExtraField z64 = getZip64Extra(ze);\n            if (ze.getCompressedSize() >= ZIP64_MAGIC\n                || ze.getSize() >= ZIP64_MAGIC\n                || zip64Mode == Zip64Mode.Always) {\n                z64.setCompressedSize(new ZipEightByteInteger(ze.getCompressedSize()));\n                z64.setSize(new ZipEightByteInteger(ze.getSize()));\n            } else {\n                // reset value that may have been set for LFH\n                z64.setCompressedSize(null);\n                z64.setSize(null);\n            }\n            if (lfhOffset >= ZIP64_MAGIC || zip64Mode == Zip64Mode.Always) {\n                z64.setRelativeHeaderOffset(new ZipEightByteInteger(lfhOffset));\n            }\n            ze.setExtra();\n        }\n    }\n\n    /**\n     * Writes the &quot;End of central dir record&quot;.\n     * @throws IOException on error\n     * @throws Zip64RequiredException if the archive's size exceeds 4\n     * GByte or there are more than 65535 entries inside the archive\n     * and {@link Zip64Mode #setUseZip64} is {@link Zip64Mode#Never}.\n     */\n    protected void writeCentralDirectoryEnd() throws IOException {\n        writeCounted(EOCD_SIG);\n\n        // disk numbers\n        writeCounted(ZERO);\n        writeCounted(ZERO);\n\n        // number of entries\n        final int numberOfEntries = entries.size();\n        if (numberOfEntries > ZIP64_MAGIC_SHORT\n            && zip64Mode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .TOO_MANY_ENTRIES_MESSAGE);\n        }\n        if (cdOffset > ZIP64_MAGIC && zip64Mode == Zip64Mode.Never) {\n            throw new Zip64RequiredException(Zip64RequiredException\n                                             .ARCHIVE_TOO_BIG_MESSAGE);\n        }\n\n        final byte[] num = ZipShort.getBytes(Math.min(numberOfEntries,\n                                                ZIP64_MAGIC_SHORT));\n        writeCounted(num);\n        writeCounted(num);\n\n        // length and location of CD\n        writeCounted(ZipLong.getBytes(Math.min(cdLength, ZIP64_MAGIC)));\n        writeCounted(ZipLong.getBytes(Math.min(cdOffset, ZIP64_MAGIC)));\n\n        // ZIP file comment\n        final ByteBuffer data = this.zipEncoding.encode(comment);\n        final int dataLen = data.limit() - data.position();\n        writeCounted(ZipShort.getBytes(dataLen));\n        streamCompressor.writeCounted(data.array(), data.arrayOffset(), dataLen);\n    }\n\n    /**\n     * Writes the &quot;ZIP64 End of central dir record&quot; and\n     * &quot;ZIP64 End of central dir locator&quot;.\n     * @throws IOException on error\n     * @since 1.3\n     */\n    protected void writeZip64CentralDirectory() throws IOException {\n        if (zip64Mode == Zip64Mode.Never) {\n            return;\n        }\n\n        if (!hasUsedZip64\n            && (cdOffset >= ZIP64_MAGIC || cdLength >= ZIP64_MAGIC\n                || entries.size() >= ZIP64_MAGIC_SHORT)) {\n            // actually \"will use\"\n            hasUsedZip64 = true;\n        }\n\n        if (!hasUsedZip64) {\n            return;\n        }\n\n        final long offset = streamCompressor.getTotalBytesWritten();\n\n        writeOut(ZIP64_EOCD_SIG);\n        // size, we don't have any variable length as we don't support\n        // the extensible data sector, yet\n        writeOut(ZipEightByteInteger\n                 .getBytes(SHORT   /* version made by */\n                           + SHORT /* version needed to extract */\n                           + WORD  /* disk number */\n                           + WORD  /* disk with central directory */\n                           + DWORD /* number of entries in CD on this disk */\n                           + DWORD /* total number of entries */\n                           + DWORD /* size of CD */\n                           + (long) DWORD /* offset of CD */\n                           ));\n\n        // version made by and version needed to extract\n        writeOut(ZipShort.getBytes(ZIP64_MIN_VERSION));\n        writeOut(ZipShort.getBytes(ZIP64_MIN_VERSION));\n\n        // disk numbers - four bytes this time\n        writeOut(LZERO);\n        writeOut(LZERO);\n\n        // number of entries\n        final byte[] num = ZipEightByteInteger.getBytes(entries.size());\n        writeOut(num);\n        writeOut(num);\n\n        // length and location of CD\n        writeOut(ZipEightByteInteger.getBytes(cdLength));\n        writeOut(ZipEightByteInteger.getBytes(cdOffset));\n\n        // no \"zip64 extensible data sector\" for now\n\n        // and now the \"ZIP64 end of central directory locator\"\n        writeOut(ZIP64_EOCD_LOC_SIG);\n\n        // disk number holding the ZIP64 EOCD record\n        writeOut(LZERO);\n        // relative offset of ZIP64 EOCD record\n        writeOut(ZipEightByteInteger.getBytes(offset));\n        // total number of disks\n        writeOut(ONE);\n    }\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(final byte[] data) throws IOException {\n        streamCompressor.writeOut(data, 0, data.length);\n    }\n\n\n    /**\n     * Write bytes to output or random access file.\n     * @param data the byte array to write\n     * @param offset the start position to write from\n     * @param length the number of bytes to write\n     * @throws IOException on error\n     */\n    protected final void writeOut(final byte[] data, final int offset, final int length)\n            throws IOException {\n        streamCompressor.writeOut(data, offset, length);\n    }\n\n\n    private GeneralPurposeBit getGeneralPurposeBits(final boolean utfFallback, boolean usesDataDescriptor) {\n        final GeneralPurposeBit b = new GeneralPurposeBit();\n        b.useUTF8ForNames(useUTF8Flag || utfFallback);\n        if (usesDataDescriptor) {\n            b.useDataDescriptor(true);\n        }\n        return b;\n    }\n\n    private int versionNeededToExtract(final int zipMethod, final boolean zip64, final boolean usedDataDescriptor) {\n        if (zip64) {\n            return ZIP64_MIN_VERSION;\n        }\n        if (usedDataDescriptor) {\n            return DATA_DESCRIPTOR_MIN_VERSION;\n        }\n        return versionNeededToExtractMethod(zipMethod);\n    }\n\n    private boolean usesDataDescriptor(final int zipMethod, boolean phased) {\n        return !phased && zipMethod == DEFLATED && channel == null;\n    }\n\n    private int versionNeededToExtractMethod(int zipMethod) {\n        return zipMethod == DEFLATED ? DEFLATE_MIN_VERSION : INITIAL_VERSION;\n    }\n\n    /**\n     * Creates a new zip entry taking some information from the given\n     * file and using the provided name.\n     *\n     * <p>The name will be adjusted to end with a forward slash \"/\" if\n     * the file is a directory.  If the file is not a directory a\n     * potential trailing forward slash will be stripped from the\n     * entry name.</p>\n     *\n     * <p>Must not be used if the stream has already been closed.</p>\n     */\n    @Override\n    public ArchiveEntry createArchiveEntry(final File inputFile, final String entryName)\n        throws IOException {\n        if (finished) {\n            throw new IOException(\"Stream has already been finished\");\n        }\n        return new ZipArchiveEntry(inputFile, entryName);\n    }\n\n    /**\n     * Get the existing ZIP64 extended information extra field or\n     * create a new one and add it to the entry.\n     *\n     * @since 1.3\n     */\n    private Zip64ExtendedInformationExtraField\n        getZip64Extra(final ZipArchiveEntry ze) {\n        if (entry != null) {\n            entry.causedUseOfZip64 = !hasUsedZip64;\n        }\n        hasUsedZip64 = true;\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            ze.getExtraField(Zip64ExtendedInformationExtraField\n                             .HEADER_ID);\n        if (z64 == null) {\n            /*\n              System.err.println(\"Adding z64 for \" + ze.getName()\n              + \", method: \" + ze.getMethod()\n              + \" (\" + (ze.getMethod() == STORED) + \")\"\n              + \", channel: \" + (channel != null));\n            */\n            z64 = new Zip64ExtendedInformationExtraField();\n        }\n\n        // even if the field is there already, make sure it is the first one\n        ze.addAsFirstExtraField(z64);\n\n        return z64;\n    }\n\n    /**\n     * Is there a ZIP64 extended information extra field for the\n     * entry?\n     *\n     * @since 1.3\n     */\n    private boolean hasZip64Extra(final ZipArchiveEntry ze) {\n        return ze.getExtraField(Zip64ExtendedInformationExtraField\n                                .HEADER_ID)\n            != null;\n    }\n\n    /**\n     * If the mode is AsNeeded and the entry is a compressed entry of\n     * unknown size that gets written to a non-seekable stream then\n     * change the default to Never.\n     *\n     * @since 1.3\n     */\n    private Zip64Mode getEffectiveZip64Mode(final ZipArchiveEntry ze) {\n        if (zip64Mode != Zip64Mode.AsNeeded\n            || channel != null\n            || ze.getMethod() != DEFLATED\n            || ze.getSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            return zip64Mode;\n        }\n        return Zip64Mode.Never;\n    }\n\n    private ZipEncoding getEntryEncoding(final ZipArchiveEntry ze) {\n        final boolean encodable = zipEncoding.canEncode(ze.getName());\n        return !encodable && fallbackToUTF8\n            ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n    }\n\n    private ByteBuffer getName(final ZipArchiveEntry ze) throws IOException {\n        return getEntryEncoding(ze).encode(ze.getName());\n    }\n\n    /**\n     * Closes the underlying stream/file without finishing the\n     * archive, the result will likely be a corrupt archive.\n     *\n     * <p>This method only exists to support tests that generate\n     * corrupt archives so they can clean up any temporary files.</p>\n     */\n    void destroy() throws IOException {\n        if (channel != null) {\n            channel.close();\n        }\n        if (out != null) {\n            out.close();\n        }\n    }\n\n    /**\n     * enum that represents the possible policies for creating Unicode\n     * extra fields.\n     */\n    public static final class UnicodeExtraFieldPolicy {\n        /**\n         * Always create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy ALWAYS = new UnicodeExtraFieldPolicy(\"always\");\n        /**\n         * Never create Unicode extra fields.\n         */\n        public static final UnicodeExtraFieldPolicy NEVER = new UnicodeExtraFieldPolicy(\"never\");\n        /**\n         * Create Unicode extra fields for filenames that cannot be\n         * encoded using the specified encoding.\n         */\n        public static final UnicodeExtraFieldPolicy NOT_ENCODEABLE =\n            new UnicodeExtraFieldPolicy(\"not encodeable\");\n\n        private final String name;\n        private UnicodeExtraFieldPolicy(final String n) {\n            name = n;\n        }\n        @Override\n        public String toString() {\n            return name;\n        }\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being written.\n     */\n    private static final class CurrentEntry {\n        private CurrentEntry(final ZipArchiveEntry entry) {\n            this.entry = entry;\n        }\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry;\n        /**\n         * Offset for CRC entry in the local file header data for the\n         * current entry starts here.\n         */\n        private long localDataStart = 0;\n        /**\n         * Data for local header data\n         */\n        private long dataStart = 0;\n        /**\n         * Number of bytes read for the current entry (can't rely on\n         * Deflater#getBytesRead) when using DEFLATED.\n         */\n        private long bytesRead = 0;\n        /**\n         * Whether current entry was the first one using ZIP64 features.\n         */\n        private boolean causedUseOfZip64 = false;\n        /**\n         * Whether write() has been called at all.\n         *\n         * <p>In order to create a valid archive {@link\n         * #closeArchiveEntry closeArchiveEntry} will write an empty\n         * array to get the CRC right if nothing has been written to\n         * the stream at all.</p>\n         */\n        private boolean hasWritten;\n    }\n\n    private static final class EntryMetaData {\n        private final long offset;\n        private final boolean usesDataDescriptor;\n        private EntryMetaData(long offset, boolean usesDataDescriptor) {\n            this.offset = offset;\n            this.usesDataDescriptor = usesDataDescriptor;\n        }\n    }\n}\n"}]}
{"project": "Compress", "bug_id": 44, "classes_modified": [{"class_name": "org.apache.commons.compress.utils.ChecksumCalculatingInputStream", "buggy_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.zip.Checksum;\n\n/**\n * A stream that calculates the checksum of the data read.\n * @NotThreadSafe\n * @since 1.14\n */\npublic class ChecksumCalculatingInputStream extends InputStream {\n    private final InputStream in;\n    private final Checksum checksum;\n\n    public ChecksumCalculatingInputStream(final Checksum checksum, final InputStream in) {\n\n\n\n        this.checksum = checksum;\n        this.in = in;\n    }\n\n    /**\n     * Reads a single byte from the stream\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read() throws IOException {\n        final int ret = in.read();\n        if (ret >= 0) {\n            checksum.update(ret);\n        }\n        return ret;\n    }\n\n    /**\n     * Reads a byte array from the stream\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read(final byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n\n    /**\n     * Reads from the stream into a byte array.\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len) throws IOException {\n        final int ret = in.read(b, off, len);\n        if (ret >= 0) {\n            checksum.update(b, off, ret);\n        }\n        return ret;\n    }\n\n    @Override\n    public long skip(final long n) throws IOException {\n        // Can't really skip, we have to hash everything to verify the checksum\n        if (read() >= 0) {\n            return 1;\n        }\n        return 0;\n    }\n\n    /**\n     * Returns the calculated checksum.\n     * @return the calculated checksum.\n     */\n    public long getValue() {\n        return checksum.getValue();\n    }\n\n}\n", "fixed_version": "/*\n *  Licensed to the Apache Software Foundation (ASF) under one or more\n *  contributor license agreements.  See the NOTICE file distributed with\n *  this work for additional information regarding copyright ownership.\n *  The ASF licenses this file to You under the Apache License, Version 2.0\n *  (the \"License\"); you may not use this file except in compliance with\n *  the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *\n */\npackage org.apache.commons.compress.utils;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.zip.Checksum;\n\n/**\n * A stream that calculates the checksum of the data read.\n * @NotThreadSafe\n * @since 1.14\n */\npublic class ChecksumCalculatingInputStream extends InputStream {\n    private final InputStream in;\n    private final Checksum checksum;\n\n    public ChecksumCalculatingInputStream(final Checksum checksum, final InputStream in) {\n\n        if ( checksum == null ){\n            throw new NullPointerException(\"Parameter checksum must not be null\");\n        }\n\n        if ( in == null ){\n            throw new NullPointerException(\"Parameter in must not be null\");\n        }\n\n        this.checksum = checksum;\n        this.in = in;\n    }\n\n    /**\n     * Reads a single byte from the stream\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read() throws IOException {\n        final int ret = in.read();\n        if (ret >= 0) {\n            checksum.update(ret);\n        }\n        return ret;\n    }\n\n    /**\n     * Reads a byte array from the stream\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read(final byte[] b) throws IOException {\n        return read(b, 0, b.length);\n    }\n\n    /**\n     * Reads from the stream into a byte array.\n     * @throws IOException if the underlying stream throws or the\n     * stream is exhausted and the Checksum doesn't match the expected\n     * value\n     */\n    @Override\n    public int read(final byte[] b, final int off, final int len) throws IOException {\n        final int ret = in.read(b, off, len);\n        if (ret >= 0) {\n            checksum.update(b, off, ret);\n        }\n        return ret;\n    }\n\n    @Override\n    public long skip(final long n) throws IOException {\n        // Can't really skip, we have to hash everything to verify the checksum\n        if (read() >= 0) {\n            return 1;\n        }\n        return 0;\n    }\n\n    /**\n     * Returns the calculated checksum.\n     * @return the calculated checksum.\n     */\n    public long getValue() {\n        return checksum.getValue();\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 45, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.tar.TarUtils", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            @Override\n            public boolean canEncode(final String name) { return true; }\n\n            @Override\n            public ByteBuffer encode(final String name) {\n                final int length = name.length();\n                final byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            @Override\n            public String decode(final byte[] buffer) {\n                final int length = buffer.length;\n                final StringBuilder result = new StringBuilder(length);\n\n                for (final byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2.0, (length - 1) * 8.0) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        final byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(final byte[] buffer, final int offset,\n            final int length, final int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(final byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2); //NOSONAR\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     * @throws IOException on error\n     */\n    public static String parseName(final byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            final byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(final String name, final byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2); //NOSONAR\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     * @throws IOException on error\n     */\n    public static int formatNameBytes(final String name, final byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, final byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        final int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, final byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        }\n        formatBigIntegerBinary(value, buf, offset, length, negative);\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, final byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value); // Long.MIN_VALUE stays Long.MIN_VALUE\n        if (val < 0 || val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val++;\n            val |= 0xffl << bits;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, final byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        final BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        if (len > length - 1) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (final byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(final byte[] header) {\n        final long storedSum = parseOctal(header, CHKSUM_OFFSET, CHKSUMLEN);\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n        return storedSum == unsignedSum || storedSum == signedSum;\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.tar;\n\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUMLEN;\nimport static org.apache.commons.compress.archivers.tar.TarConstants.CHKSUM_OFFSET;\n\nimport java.io.IOException;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport org.apache.commons.compress.archivers.zip.ZipEncoding;\nimport org.apache.commons.compress.archivers.zip.ZipEncodingHelper;\n\n/**\n * This class provides static utility methods to work with byte streams.\n *\n * @Immutable\n */\n// CheckStyle:HideUtilityClassConstructorCheck OFF (bc)\npublic class TarUtils {\n\n    private static final int BYTE_MASK = 255;\n\n    static final ZipEncoding DEFAULT_ENCODING =\n        ZipEncodingHelper.getZipEncoding(null);\n\n    /**\n     * Encapsulates the algorithms used up to Commons Compress 1.3 as\n     * ZipEncoding.\n     */\n    static final ZipEncoding FALLBACK_ENCODING = new ZipEncoding() {\n            @Override\n            public boolean canEncode(final String name) { return true; }\n\n            @Override\n            public ByteBuffer encode(final String name) {\n                final int length = name.length();\n                final byte[] buf = new byte[length];\n\n                // copy until end of input or output is reached.\n                for (int i = 0; i < length; ++i) {\n                    buf[i] = (byte) name.charAt(i);\n                }\n                return ByteBuffer.wrap(buf);\n            }\n\n            @Override\n            public String decode(final byte[] buffer) {\n                final int length = buffer.length;\n                final StringBuilder result = new StringBuilder(length);\n\n                for (final byte b : buffer) {\n                    if (b == 0) { // Trailing null\n                        break;\n                    }\n                    result.append((char) (b & 0xFF)); // Allow for sign-extension\n                }\n\n                return result.toString();\n            }\n        };\n\n    /** Private constructor to prevent instantiation of this utility class. */\n    private TarUtils(){\n    }\n\n    /**\n     * Parse an octal string from a buffer.\n     *\n     * <p>Leading spaces are ignored.\n     * The buffer must contain a trailing space or NUL,\n     * and may contain an additional trailing space or NUL.</p>\n     *\n     * <p>The input buffer is allowed to contain all NULs,\n     * in which case the method returns 0L\n     * (this allows for missing fields).</p>\n     *\n     * <p>To work-around some tar implementations that insert a\n     * leading NUL this method returns 0 if it detects a leading NUL\n     * since Commons Compress 1.4.</p>\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse - must be at least 2 bytes.\n     * @return The long value of the octal string.\n     * @throws IllegalArgumentException if the trailing space/NUL is missing or if a invalid byte is detected.\n     */\n    public static long parseOctal(final byte[] buffer, final int offset, final int length) {\n        long    result = 0;\n        int     end = offset + length;\n        int     start = offset;\n\n        if (length < 2){\n            throw new IllegalArgumentException(\"Length \"+length+\" must be at least 2\");\n        }\n\n        if (buffer[start] == 0) {\n            return 0L;\n        }\n\n        // Skip leading spaces\n        while (start < end){\n            if (buffer[start] == ' '){\n                start++;\n            } else {\n                break;\n            }\n        }\n\n        // Trim all trailing NULs and spaces.\n        // The ustar and POSIX tar specs require a trailing NUL or\n        // space but some implementations use the extra digit for big\n        // sizes/uids/gids ...\n        byte trailer = buffer[end - 1];\n        while (start < end && (trailer == 0 || trailer == ' ')) {\n            end--;\n            trailer = buffer[end - 1];\n        }\n\n        for ( ;start < end; start++) {\n            final byte currentByte = buffer[start];\n            // CheckStyle:MagicNumber OFF\n            if (currentByte < '0' || currentByte > '7'){\n                throw new IllegalArgumentException(\n                        exceptionMessage(buffer, offset, length, start, currentByte));\n            }\n            result = (result << 3) + (currentByte - '0'); // convert from ASCII\n            // CheckStyle:MagicNumber ON\n        }\n\n        return result;\n    }\n\n    /** \n     * Compute the value contained in a byte buffer.  If the most\n     * significant bit of the first byte in the buffer is set, this\n     * bit is ignored and the rest of the buffer is interpreted as a\n     * binary number.  Otherwise, the buffer is interpreted as an\n     * octal number as per the parseOctal function above.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The long value of the octal or binary string.\n     * @throws IllegalArgumentException if the trailing space/NUL is\n     * missing or an invalid byte is detected in an octal number, or\n     * if a binary number would exceed the size of a signed long\n     * 64-bit integer.\n     * @since 1.4\n     */\n    public static long parseOctalOrBinary(final byte[] buffer, final int offset,\n                                          final int length) {\n\n        if ((buffer[offset] & 0x80) == 0) {\n            return parseOctal(buffer, offset, length);\n        }\n        final boolean negative = buffer[offset] == (byte) 0xff;\n        if (length < 9) {\n            return parseBinaryLong(buffer, offset, length, negative);\n        }\n        return parseBinaryBigInteger(buffer, offset, length, negative);\n    }\n\n    private static long parseBinaryLong(final byte[] buffer, final int offset,\n                                        final int length,\n                                        final boolean negative) {\n        if (length >= 9) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        long val = 0;\n        for (int i = 1; i < length; i++) {\n            val = (val << 8) + (buffer[offset + i] & 0xff);\n        }\n        if (negative) {\n            // 2's complement\n            val--;\n            val ^= (long) Math.pow(2.0, (length - 1) * 8.0) - 1;\n        }\n        return negative ? -val : val;\n    }\n\n    private static long parseBinaryBigInteger(final byte[] buffer,\n                                              final int offset,\n                                              final int length,\n                                              final boolean negative) {\n        final byte[] remainder = new byte[length - 1];\n        System.arraycopy(buffer, offset + 1, remainder, 0, length - 1);\n        BigInteger val = new BigInteger(remainder);\n        if (negative) {\n            // 2's complement\n            val = val.add(BigInteger.valueOf(-1)).not();\n        }\n        if (val.bitLength() > 63) {\n            throw new IllegalArgumentException(\"At offset \" + offset + \", \"\n                                               + length + \" byte binary number\"\n                                               + \" exceeds maximum signed long\"\n                                               + \" value\");\n        }\n        return negative ? -val.longValue() : val.longValue();\n    }\n\n    /**\n     * Parse a boolean byte from a buffer.\n     * Leading spaces and NUL are ignored.\n     * The buffer may contain trailing spaces or NULs.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @return The boolean value of the bytes.\n     * @throws IllegalArgumentException if an invalid byte is detected.\n     */\n    public static boolean parseBoolean(final byte[] buffer, final int offset) {\n        return buffer[offset] == 1;\n    }\n\n    // Helper method to generate the exception message\n    private static String exceptionMessage(final byte[] buffer, final int offset,\n            final int length, final int current, final byte currentByte) {\n        // default charset is good enough for an exception message,\n        //\n        // the alternative was to modify parseOctal and\n        // parseOctalOrBinary to receive the ZipEncoding of the\n        // archive (deprecating the existing public methods, of\n        // course) and dealing with the fact that ZipEncoding#decode\n        // can throw an IOException which parseOctal* doesn't declare\n        String string = new String(buffer, offset, length);\n\n        string=string.replaceAll(\"\\0\", \"{NUL}\"); // Replace NULs to allow string to be printed\n        final String s = \"Invalid byte \"+currentByte+\" at offset \"+(current-offset)+\" in '\"+string+\"' len=\"+length;\n        return s;\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @return The entry name.\n     */\n    public static String parseName(final byte[] buffer, final int offset, final int length) {\n        try {\n            return parseName(buffer, offset, length, DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                return parseName(buffer, offset, length, FALLBACK_ENCODING);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2); //NOSONAR\n            }\n        }\n    }\n\n    /**\n     * Parse an entry name from a buffer.\n     * Parsing stops when a NUL is found\n     * or the buffer length is reached.\n     *\n     * @param buffer The buffer from which to parse.\n     * @param offset The offset into the buffer from which to parse.\n     * @param length The maximum number of bytes to parse.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The entry name.\n     * @throws IOException on error\n     */\n    public static String parseName(final byte[] buffer, final int offset,\n                                   final int length,\n                                   final ZipEncoding encoding)\n        throws IOException {\n\n        int len = length;\n        for (; len > 0; len--) {\n            if (buffer[offset + len - 1] != 0) {\n                break;\n            }\n        }\n        if (len > 0) {\n            final byte[] b = new byte[len];\n            System.arraycopy(buffer, offset, b, 0, len);\n            return encoding.decode(b);\n        }\n        return \"\";\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @return The updated offset, i.e. offset + length\n     */\n    public static int formatNameBytes(final String name, final byte[] buf, final int offset, final int length) {\n        try {\n            return formatNameBytes(name, buf, offset, length, DEFAULT_ENCODING);\n        } catch (final IOException ex) {\n            try {\n                return formatNameBytes(name, buf, offset, length,\n                                       FALLBACK_ENCODING);\n            } catch (final IOException ex2) {\n                // impossible\n                throw new RuntimeException(ex2); //NOSONAR\n            }\n        }\n    }\n\n    /**\n     * Copy a name into a buffer.\n     * Copies characters from the name into the buffer\n     * starting at the specified offset. \n     * If the buffer is longer than the name, the buffer\n     * is filled with trailing NULs.\n     * If the name is longer than the buffer,\n     * the output is truncated.\n     *\n     * @param name The header name from which to copy the characters.\n     * @param buf The buffer where the name is to be stored.\n     * @param offset The starting offset into the buffer\n     * @param length The maximum number of header bytes to copy.\n     * @param encoding name of the encoding to use for file names\n     * @since 1.4\n     * @return The updated offset, i.e. offset + length\n     * @throws IOException on error\n     */\n    public static int formatNameBytes(final String name, final byte[] buf, final int offset,\n                                      final int length,\n                                      final ZipEncoding encoding)\n        throws IOException {\n        int len = name.length();\n        ByteBuffer b = encoding.encode(name);\n        while (b.limit() > length && len > 0) {\n            b = encoding.encode(name.substring(0, --len));\n        }\n        final int limit = b.limit() - b.position();\n        System.arraycopy(b.array(), b.arrayOffset(), buf, offset, limit);\n\n        // Pad any remaining output bytes with NUL\n        for (int i = limit; i < length; ++i) {\n            buf[offset + i] = 0;\n        }\n\n        return offset + length;\n    }\n\n    /**\n     * Fill buffer with unsigned octal number, padded with leading zeroes.\n     * \n     * @param value number to convert to octal - treated as unsigned\n     * @param buffer destination buffer\n     * @param offset starting offset in buffer\n     * @param length length of buffer to fill\n     * @throws IllegalArgumentException if the value will not fit in the buffer\n     */\n    public static void formatUnsignedOctalString(final long value, final byte[] buffer,\n            final int offset, final int length) {\n        int remaining = length;\n        remaining--;\n        if (value == 0) {\n            buffer[offset + remaining--] = (byte) '0';\n        } else {\n            long val = value;\n            for (; remaining >= 0 && val != 0; --remaining) {\n                // CheckStyle:MagicNumber OFF\n                buffer[offset + remaining] = (byte) ((byte) '0' + (byte) (val & 7));\n                val = val >>> 3;\n                // CheckStyle:MagicNumber ON\n            }\n            if (val != 0){\n                throw new IllegalArgumentException\n                (value+\"=\"+Long.toOctalString(value)+ \" will not fit in octal number buffer of length \"+length);\n            }\n        }\n\n        for (; remaining >= 0; --remaining) { // leading zeros\n            buffer[offset + remaining] = (byte) '0';\n        }\n    }\n\n    /**\n     * Write an octal integer into a buffer.\n     *\n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by space and NUL\n     * \n     * @param value The value to write\n     * @param buf The buffer to receive the output\n     * @param offset The starting offset into the buffer\n     * @param length The size of the output buffer\n     * @return The updated offset, i.e offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // For space and trailing null\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++] = (byte) ' '; // Trailing space\n        buf[offset + idx]   = 0; // Trailing null\n\n        return offset + length;\n    }\n\n    /**\n     * Write an octal long integer into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write as octal\n     * @param buf The destinationbuffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer\n     * @return The updated offset\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatLongOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        final int idx=length-1; // For space\n\n        formatUnsignedOctalString(value, buf, offset, idx);\n        buf[offset + idx] = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Write an long integer into a buffer as an octal string if this\n     * will fit, or as a binary number otherwise.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by a space.\n     * \n     * @param value The value to write into the buffer.\n     * @param buf The destination buffer.\n     * @param offset The starting offset into the buffer.\n     * @param length The length of the buffer.\n     * @return The updated offset.\n     * @throws IllegalArgumentException if the value (and trailer)\n     * will not fit in the buffer.\n     * @since 1.4\n     */\n    public static int formatLongOctalOrBinaryBytes(\n        final long value, final byte[] buf, final int offset, final int length) {\n\n        // Check whether we are dealing with UID/GID or SIZE field\n        final long maxAsOctalChar = length == TarConstants.UIDLEN ? TarConstants.MAXID : TarConstants.MAXSIZE;\n\n        final boolean negative = value < 0;\n        if (!negative && value <= maxAsOctalChar) { // OK to store as octal chars\n            return formatLongOctalBytes(value, buf, offset, length);\n        }\n\n        if (length < 9) {\n            formatLongBinary(value, buf, offset, length, negative);\n        } else {\n            formatBigIntegerBinary(value, buf, offset, length, negative);\n        }\n\n        buf[offset] = (byte) (negative ? 0xff : 0x80);\n        return offset + length;\n    }\n\n    private static void formatLongBinary(final long value, final byte[] buf,\n                                         final int offset, final int length,\n                                         final boolean negative) {\n        final int bits = (length - 1) * 8;\n        final long max = 1l << bits;\n        long val = Math.abs(value); // Long.MIN_VALUE stays Long.MIN_VALUE\n        if (val < 0 || val >= max) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        if (negative) {\n            val ^= max - 1;\n            val++;\n            val |= 0xffl << bits;\n        }\n        for (int i = offset + length - 1; i >= offset; i--) {\n            buf[i] = (byte) val;\n            val >>= 8;\n        }\n    }\n\n    private static void formatBigIntegerBinary(final long value, final byte[] buf,\n                                               final int offset,\n                                               final int length,\n                                               final boolean negative) {\n        final BigInteger val = BigInteger.valueOf(value);\n        final byte[] b = val.toByteArray();\n        final int len = b.length;\n        if (len > length - 1) {\n            throw new IllegalArgumentException(\"Value \" + value +\n                \" is too large for \" + length + \" byte field.\");\n        }\n        final int off = offset + length - len;\n        System.arraycopy(b, 0, buf, off, len);\n        final byte fill = (byte) (negative ? 0xff : 0);\n        for (int i = offset + 1; i < off; i++) {\n            buf[i] = fill;\n        }\n    }\n\n    /**\n     * Writes an octal value into a buffer.\n     * \n     * Uses {@link #formatUnsignedOctalString} to format\n     * the value as an octal string with leading zeros.\n     * The converted number is followed by NUL and then space.\n     *\n     * @param value The value to convert\n     * @param buf The destination buffer\n     * @param offset The starting offset into the buffer.\n     * @param length The size of the buffer.\n     * @return The updated value of offset, i.e. offset+length\n     * @throws IllegalArgumentException if the value (and trailer) will not fit in the buffer\n     */\n    public static int formatCheckSumOctalBytes(final long value, final byte[] buf, final int offset, final int length) {\n\n        int idx=length-2; // for NUL and space\n        formatUnsignedOctalString(value, buf, offset, idx);\n\n        buf[offset + idx++]   = 0; // Trailing null\n        buf[offset + idx]     = (byte) ' '; // Trailing space\n\n        return offset + length;\n    }\n\n    /**\n     * Compute the checksum of a tar entry header.\n     *\n     * @param buf The tar entry's header buffer.\n     * @return The computed checksum.\n     */\n    public static long computeCheckSum(final byte[] buf) {\n        long sum = 0;\n\n        for (final byte element : buf) {\n            sum += BYTE_MASK & element;\n        }\n\n        return sum;\n    }\n\n    /**\n     * Wikipedia <a href=\"http://en.wikipedia.org/wiki/Tar_(file_format)#File_header\">says</a>:\n     * <blockquote>\n     * The checksum is calculated by taking the sum of the unsigned byte values\n     * of the header block with the eight checksum bytes taken to be ascii\n     * spaces (decimal value 32). It is stored as a six digit octal number with\n     * leading zeroes followed by a NUL and then a space. Various\n     * implementations do not adhere to this format. For better compatibility,\n     * ignore leading and trailing whitespace, and get the first six digits. In\n     * addition, some historic tar implementations treated bytes as signed.\n     * Implementations typically calculate the checksum both ways, and treat it\n     * as good if either the signed or unsigned sum matches the included\n     * checksum.\n     * </blockquote>\n     * <p>\n     * The return value of this method should be treated as a best-effort\n     * heuristic rather than an absolute and final truth. The checksum\n     * verification logic may well evolve over time as more special cases\n     * are encountered.\n     *\n     * @param header tar header\n     * @return whether the checksum is reasonably good\n     * @see <a href=\"https://issues.apache.org/jira/browse/COMPRESS-191\">COMPRESS-191</a>\n     * @since 1.5\n     */\n    public static boolean verifyCheckSum(final byte[] header) {\n        final long storedSum = parseOctal(header, CHKSUM_OFFSET, CHKSUMLEN);\n        long unsignedSum = 0;\n        long signedSum = 0;\n\n        for (int i = 0; i < header.length; i++) {\n            byte b = header[i];\n            if (CHKSUM_OFFSET  <= i && i < CHKSUM_OFFSET + CHKSUMLEN) {\n                b = ' ';\n            }\n            unsignedSum += 0xff & b;\n            signedSum += b;\n        }\n        return storedSum == unsignedSum || storedSum == signedSum;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 46, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.X5455_ExtendedTimestamp", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.Serializable;\nimport java.util.Date;\nimport java.util.zip.ZipException;\n\n/**\n * <p>An extra field that stores additional file and directory timestamp data\n * for zip entries.   Each zip entry can include up to three timestamps\n * (modify, access, create*).  The timestamps are stored as 32 bit signed\n * integers representing seconds since UNIX epoch (Jan 1st, 1970, UTC).\n * This field improves on zip's default timestamp granularity, since it\n * allows one to store additional timestamps, and, in addition, the timestamps\n * are stored using per-second granularity (zip's default behaviour can only store\n * timestamps to the nearest <em>even</em> second).\n * </p><p>\n * Unfortunately, 32 (signed) bits can only store dates up to the year 2037,\n * and so this extra field will eventually be obsolete.  Enjoy it while it lasts!\n * </p>\n * <ul>\n * <li><b>modifyTime:</b>\n * most recent time of file/directory modification\n * (or file/dir creation if the entry has not been\n * modified since it was created).\n * </li>\n * <li><b>accessTime:</b>\n * most recent time file/directory was opened\n * (e.g., read from disk).  Many people disable\n * their operating systems from updating this value\n * using the NOATIME mount option to optimize disk behaviour,\n * and thus it's not always reliable.  In those cases\n * it's always equal to modifyTime.\n * </li>\n * <li><b>*createTime:</b>\n * modern linux file systems (e.g., ext2 and newer)\n * do not appear to store a value like this, and so\n * it's usually omitted altogether in the zip extra\n * field.  Perhaps other unix systems track this.\n * </li></ul>\n * <p>\n * We're using the field definition given in Info-Zip's source archive:\n * zip-3.0.tar.gz/proginfo/extrafld.txt\n * </p>\n * <pre>\n * Value         Size        Description\n * -----         ----        -----------\n * 0x5455        Short       tag for this extra block type (\"UT\")\n * TSize         Short       total data size for this block\n * Flags         Byte        info bits\n * (ModTime)     Long        time of last modification (UTC/GMT)\n * (AcTime)      Long        time of last access (UTC/GMT)\n * (CrTime)      Long        time of original creation (UTC/GMT)\n *\n * Central-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x5455        Short       tag for this extra block type (\"UT\")\n * TSize         Short       total data size for this block\n * Flags         Byte        info bits (refers to local header!)\n * (ModTime)     Long        time of last modification (UTC/GMT)\n * </pre>\n * @since 1.5\n */\npublic class X5455_ExtendedTimestamp implements ZipExtraField, Cloneable, Serializable {\n    private static final ZipShort HEADER_ID = new ZipShort(0x5455);\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * The bit set inside the flags by when the last modification time\n     * is present in this extra field.\n     */\n    public static final byte MODIFY_TIME_BIT = 1;\n    /**\n     * The bit set inside the flags by when the lasr access time is\n     * present in this extra field.\n     */\n    public static final byte ACCESS_TIME_BIT = 2;\n    /**\n     * The bit set inside the flags by when the original creation time\n     * is present in this extra field.\n     */\n    public static final byte CREATE_TIME_BIT = 4;\n\n    // The 3 boolean fields (below) come from this flags byte.  The remaining 5 bits\n    // are ignored according to the current version of the spec (December 2012).\n    private byte flags;\n\n    // Note: even if bit1 and bit2 are set, the Central data will still not contain\n    // access/create fields:  only local data ever holds those!  This causes\n    // some of our implementation to look a little odd, with seemingly spurious\n    // != null and length checks.\n    private boolean bit0_modifyTimePresent;\n    private boolean bit1_accessTimePresent;\n    private boolean bit2_createTimePresent;\n\n    private ZipLong modifyTime;\n    private ZipLong accessTime;\n    private ZipLong createTime;\n\n    /**\n     * Constructor for X5455_ExtendedTimestamp.\n     */\n    public X5455_ExtendedTimestamp() {}\n\n    /**\n     * The Header-ID.\n     *\n     * @return the value for the header id for this extrafield\n     */\n    @Override\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    @Override\n    public ZipShort getLocalFileDataLength() {\n        return new ZipShort(1 +\n                (bit0_modifyTimePresent ? 4 : 0) +\n                (bit1_accessTimePresent && accessTime != null ? 4 : 0) +\n                (bit2_createTimePresent && createTime != null ? 4 : 0)\n        );\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * <p>For X5455 the central length is often smaller than the\n     * local length, because central cannot contain access or create\n     * timestamps.</p>\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    @Override\n    public ZipShort getCentralDirectoryLength() {\n        return new ZipShort(1 +\n                (bit0_modifyTimePresent ? 4 : 0)\n        );\n    }\n\n    /**\n     * The actual data to put into local file data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    @Override\n    public byte[] getLocalFileDataData() {\n        final byte[] data = new byte[getLocalFileDataLength().getValue()];\n        int pos = 0;\n        data[pos++] = 0;\n        if (bit0_modifyTimePresent) {\n            data[0] |= MODIFY_TIME_BIT;\n            System.arraycopy(modifyTime.getBytes(), 0, data, pos, 4);\n            pos += 4;\n        }\n        if (bit1_accessTimePresent && accessTime != null) {\n            data[0] |= ACCESS_TIME_BIT;\n            System.arraycopy(accessTime.getBytes(), 0, data, pos, 4);\n            pos += 4;\n        }\n        if (bit2_createTimePresent && createTime != null) {\n            data[0] |= CREATE_TIME_BIT;\n            System.arraycopy(createTime.getBytes(), 0, data, pos, 4);\n            pos += 4; // NOSONAR - assignment as documentation\n        }\n        return data;\n    }\n\n    /**\n     * The actual data to put into central directory data - without Header-ID\n     * or length specifier.\n     *\n     * @return the central directory data\n     */\n    @Override\n    public byte[] getCentralDirectoryData() {\n        final byte[] centralData = new byte[getCentralDirectoryLength().getValue()];\n        final byte[] localData = getLocalFileDataData();\n\n        // Truncate out create & access time (last 8 bytes) from\n        // the copy of the local data we obtained:\n        System.arraycopy(localData, 0, centralData, 0, centralData.length);\n        return centralData;\n    }\n\n    /**\n     * Populate data from this array as if it was in local file data.\n     *\n     * @param data   an array of bytes\n     * @param offset the start offset\n     * @param length the number of bytes in the array from offset\n     * @throws java.util.zip.ZipException on error\n     */\n    @Override\n    public void parseFromLocalFileData(\n            final byte[] data, int offset, final int length\n    ) throws ZipException {\n        reset();\n        final int len = offset + length;\n        setFlags(data[offset++]);\n        if (bit0_modifyTimePresent) {\n            modifyTime = new ZipLong(data, offset);\n            offset += 4;\n        }\n\n        // Notice the extra length check in case we are parsing the shorter\n        // central data field (for both access and create timestamps).\n        if (bit1_accessTimePresent && offset + 4 <= len) {\n            accessTime = new ZipLong(data, offset);\n            offset += 4;\n        }\n        if (bit2_createTimePresent && offset + 4 <= len) {\n            createTime = new ZipLong(data, offset);\n            offset += 4; // NOSONAR - assignment as documentation\n        }\n    }\n\n    /**\n     * Doesn't do anything special since this class always uses the\n     * same parsing logic for both central directory and local file data.\n     */\n    @Override\n    public void parseFromCentralDirectoryData(\n            final byte[] buffer, final int offset, final int length\n    ) throws ZipException {\n        reset();\n        parseFromLocalFileData(buffer, offset, length);\n    }\n\n    /**\n     * Reset state back to newly constructed state.  Helps us make sure\n     * parse() calls always generate clean results.\n     */\n    private void reset() {\n        setFlags((byte) 0);\n        this.modifyTime = null;\n        this.accessTime = null;\n        this.createTime = null;\n    }\n\n    /**\n     * Sets flags byte.  The flags byte tells us which of the\n     * three datestamp fields are present in the data:\n     * <pre>\n     * bit0 - modify time\n     * bit1 - access time\n     * bit2 - create time\n     * </pre>\n     * Only first 3 bits of flags are used according to the\n     * latest version of the spec (December 2012).\n     *\n     * @param flags flags byte indicating which of the\n     *              three datestamp fields are present.\n     */\n    public void setFlags(final byte flags) {\n        this.flags = flags;\n        this.bit0_modifyTimePresent = (flags & MODIFY_TIME_BIT) == MODIFY_TIME_BIT;\n        this.bit1_accessTimePresent = (flags & ACCESS_TIME_BIT) == ACCESS_TIME_BIT;\n        this.bit2_createTimePresent = (flags & CREATE_TIME_BIT) == CREATE_TIME_BIT;\n    }\n\n    /**\n     * Gets flags byte.  The flags byte tells us which of the\n     * three datestamp fields are present in the data:\n     * <pre>\n     * bit0 - modify time\n     * bit1 - access time\n     * bit2 - create time\n     * </pre>\n     * Only first 3 bits of flags are used according to the\n     * latest version of the spec (December 2012).\n     *\n     * @return flags byte indicating which of the\n     *         three datestamp fields are present.\n     */\n    public byte getFlags() { return flags; }\n\n    /**\n     * Returns whether bit0 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a modify timestamp in this particular zip entry.\n     *\n     * @return true if bit0 of the flags byte is set.\n     */\n    public boolean isBit0_modifyTimePresent() { return bit0_modifyTimePresent; }\n\n    /**\n     * Returns whether bit1 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a \"last access\" timestamp in this particular zip entry.\n     *\n     * @return true if bit1 of the flags byte is set.\n     */\n    public boolean isBit1_accessTimePresent() { return bit1_accessTimePresent; }\n\n    /**\n     * Returns whether bit2 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a create timestamp in this particular zip entry.\n     *\n     * @return true if bit2 of the flags byte is set.\n     */\n    public boolean isBit2_createTimePresent() { return bit2_createTimePresent; }\n\n    /**\n     * Returns the modify time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     *\n     * @return modify time (seconds since epoch) or null.\n     */\n    public ZipLong getModifyTime() { return modifyTime; }\n\n    /**\n     * Returns the access time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     *\n     * @return access time (seconds since epoch) or null.\n     */\n    public ZipLong getAccessTime() { return accessTime; }\n\n    /**\n     * <p>\n     * Returns the create time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     * </p><p>\n     * Note: modern linux file systems (e.g., ext2)\n     * do not appear to store a \"create time\" value, and so\n     * it's usually omitted altogether in the zip extra\n     * field.  Perhaps other unix systems track this.\n     *\n     * @return create time (seconds since epoch) or null.\n     */\n    public ZipLong getCreateTime() { return createTime; }\n\n    /**\n     * Returns the modify time as a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     *\n     * @return modify time as java.util.Date or null.\n     */\n    public Date getModifyJavaTime() {\n        return zipLongToDate(modifyTime);\n    }\n\n    /**\n     * Returns the access time as a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     *\n     * @return access time as java.util.Date or null.\n     */\n    public Date getAccessJavaTime() {\n        return zipLongToDate(accessTime);\n    }\n\n    private static Date zipLongToDate(ZipLong unixTime) {\n        return unixTime != null ? new Date(unixTime.getIntValue() * 1000L) : null;\n    }\n\n    /**\n     * <p>\n     * Returns the create time as a a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     * </p><p>\n     * Note: modern linux file systems (e.g., ext2)\n     * do not appear to store a \"create time\" value, and so\n     * it's usually omitted altogether in the zip extra\n     * field.  Perhaps other unix systems track this.\n     *\n     * @return create time as java.util.Date or null.\n     */\n    public Date getCreateJavaTime() {\n        return zipLongToDate(createTime);\n    }\n\n    /**\n     * <p>\n     * Sets the modify time (seconds since epoch) of this zip entry\n     * using a ZipLong object.\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the modify time (seconds per epoch)\n     */\n    public void setModifyTime(final ZipLong l) {\n        bit0_modifyTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | MODIFY_TIME_BIT)\n                        : (flags & ~MODIFY_TIME_BIT));\n        this.modifyTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the access time (seconds since epoch) of this zip entry\n     * using a ZipLong object\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the access time (seconds per epoch)\n     */\n    public void setAccessTime(final ZipLong l) {\n        bit1_accessTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | ACCESS_TIME_BIT)\n                        : (flags & ~ACCESS_TIME_BIT));\n        this.accessTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the create time (seconds since epoch) of this zip entry\n     * using a ZipLong object\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the create time (seconds per epoch)\n     */\n    public void setCreateTime(final ZipLong l) {\n        bit2_createTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | CREATE_TIME_BIT)\n                        : (flags & ~CREATE_TIME_BIT));\n        this.createTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the modify time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d modify time as java.util.Date\n     */\n    public void setModifyJavaTime(final Date d) { setModifyTime(dateToZipLong(d)); }\n\n    /**\n     * <p>\n     * Sets the access time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d access time as java.util.Date\n     */\n    public void setAccessJavaTime(final Date d) { setAccessTime(dateToZipLong(d)); }\n\n    /**\n     * <p>\n     * Sets the create time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d create time as java.util.Date\n     */\n    public void setCreateJavaTime(final Date d) { setCreateTime(dateToZipLong(d)); }\n\n    /**\n     * Utility method converts java.util.Date (milliseconds since epoch)\n     * into a ZipLong (seconds since epoch).\n     * <p/>\n     * Also makes sure the converted ZipLong is not too big to fit\n     * in 32 unsigned bits.\n     *\n     * @param d java.util.Date to convert to ZipLong\n     * @return ZipLong\n     */\n    private static ZipLong dateToZipLong(final Date d) {\n        if (d == null) { return null; }\n\n        return unixTimeToZipLong(d.getTime() / 1000);\n    }\n\n    private static ZipLong unixTimeToZipLong(long l) {\n        final long TWO_TO_32 = 0x100000000L;\n        if (l >= TWO_TO_32) {\n            throw new IllegalArgumentException(\"X5455 timestamps must fit in a signed 32 bit integer: \" + l);\n        }\n        return new ZipLong(l);\n    }\n\n    /**\n     * Returns a String representation of this class useful for\n     * debugging purposes.\n     *\n     * @return A String representation of this class useful for\n     *         debugging purposes.\n     */\n    @Override\n    public String toString() {\n        final StringBuilder buf = new StringBuilder();\n        buf.append(\"0x5455 Zip Extra Field: Flags=\");\n        buf.append(Integer.toBinaryString(ZipUtil.unsignedIntToSignedByte(flags))).append(\" \");\n        if (bit0_modifyTimePresent && modifyTime != null) {\n            final Date m = getModifyJavaTime();\n            buf.append(\" Modify:[\").append(m).append(\"] \");\n        }\n        if (bit1_accessTimePresent && accessTime != null) {\n            final Date a = getAccessJavaTime();\n            buf.append(\" Access:[\").append(a).append(\"] \");\n        }\n        if (bit2_createTimePresent && createTime != null) {\n            final Date c = getCreateJavaTime();\n            buf.append(\" Create:[\").append(c).append(\"] \");\n        }\n        return buf.toString();\n    }\n\n    @Override\n    public Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n\n    @Override\n    public boolean equals(final Object o) {\n        if (o instanceof X5455_ExtendedTimestamp) {\n            final X5455_ExtendedTimestamp xf = (X5455_ExtendedTimestamp) o;\n\n            // The ZipLong==ZipLong clauses handle the cases where both are null.\n            // and only last 3 bits of flags matter.\n            return ((flags & 0x07) == (xf.flags & 0x07)) &&\n                    (modifyTime == xf.modifyTime || (modifyTime != null && modifyTime.equals(xf.modifyTime))) &&\n                    (accessTime == xf.accessTime || (accessTime != null && accessTime.equals(xf.accessTime))) &&\n                    (createTime == xf.createTime || (createTime != null && createTime.equals(xf.createTime)));\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode() {\n        int hc = (-123 * (flags & 0x07)); // only last 3 bits of flags matter\n        if (modifyTime != null) {\n            hc ^= modifyTime.hashCode();\n        }\n        if (accessTime != null) {\n            // Since accessTime is often same as modifyTime,\n            // this prevents them from XOR negating each other.\n            hc ^= Integer.rotateLeft(accessTime.hashCode(), 11);\n        }\n        if (createTime != null) {\n            hc ^= Integer.rotateLeft(createTime.hashCode(), 22);\n        }\n        return hc;\n    }\n\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.Serializable;\nimport java.util.Date;\nimport java.util.zip.ZipException;\n\n/**\n * <p>An extra field that stores additional file and directory timestamp data\n * for zip entries.   Each zip entry can include up to three timestamps\n * (modify, access, create*).  The timestamps are stored as 32 bit signed\n * integers representing seconds since UNIX epoch (Jan 1st, 1970, UTC).\n * This field improves on zip's default timestamp granularity, since it\n * allows one to store additional timestamps, and, in addition, the timestamps\n * are stored using per-second granularity (zip's default behaviour can only store\n * timestamps to the nearest <em>even</em> second).\n * </p><p>\n * Unfortunately, 32 (signed) bits can only store dates up to the year 2037,\n * and so this extra field will eventually be obsolete.  Enjoy it while it lasts!\n * </p>\n * <ul>\n * <li><b>modifyTime:</b>\n * most recent time of file/directory modification\n * (or file/dir creation if the entry has not been\n * modified since it was created).\n * </li>\n * <li><b>accessTime:</b>\n * most recent time file/directory was opened\n * (e.g., read from disk).  Many people disable\n * their operating systems from updating this value\n * using the NOATIME mount option to optimize disk behaviour,\n * and thus it's not always reliable.  In those cases\n * it's always equal to modifyTime.\n * </li>\n * <li><b>*createTime:</b>\n * modern linux file systems (e.g., ext2 and newer)\n * do not appear to store a value like this, and so\n * it's usually omitted altogether in the zip extra\n * field.  Perhaps other unix systems track this.\n * </li></ul>\n * <p>\n * We're using the field definition given in Info-Zip's source archive:\n * zip-3.0.tar.gz/proginfo/extrafld.txt\n * </p>\n * <pre>\n * Value         Size        Description\n * -----         ----        -----------\n * 0x5455        Short       tag for this extra block type (\"UT\")\n * TSize         Short       total data size for this block\n * Flags         Byte        info bits\n * (ModTime)     Long        time of last modification (UTC/GMT)\n * (AcTime)      Long        time of last access (UTC/GMT)\n * (CrTime)      Long        time of original creation (UTC/GMT)\n *\n * Central-header version:\n *\n * Value         Size        Description\n * -----         ----        -----------\n * 0x5455        Short       tag for this extra block type (\"UT\")\n * TSize         Short       total data size for this block\n * Flags         Byte        info bits (refers to local header!)\n * (ModTime)     Long        time of last modification (UTC/GMT)\n * </pre>\n * @since 1.5\n */\npublic class X5455_ExtendedTimestamp implements ZipExtraField, Cloneable, Serializable {\n    private static final ZipShort HEADER_ID = new ZipShort(0x5455);\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * The bit set inside the flags by when the last modification time\n     * is present in this extra field.\n     */\n    public static final byte MODIFY_TIME_BIT = 1;\n    /**\n     * The bit set inside the flags by when the lasr access time is\n     * present in this extra field.\n     */\n    public static final byte ACCESS_TIME_BIT = 2;\n    /**\n     * The bit set inside the flags by when the original creation time\n     * is present in this extra field.\n     */\n    public static final byte CREATE_TIME_BIT = 4;\n\n    // The 3 boolean fields (below) come from this flags byte.  The remaining 5 bits\n    // are ignored according to the current version of the spec (December 2012).\n    private byte flags;\n\n    // Note: even if bit1 and bit2 are set, the Central data will still not contain\n    // access/create fields:  only local data ever holds those!  This causes\n    // some of our implementation to look a little odd, with seemingly spurious\n    // != null and length checks.\n    private boolean bit0_modifyTimePresent;\n    private boolean bit1_accessTimePresent;\n    private boolean bit2_createTimePresent;\n\n    private ZipLong modifyTime;\n    private ZipLong accessTime;\n    private ZipLong createTime;\n\n    /**\n     * Constructor for X5455_ExtendedTimestamp.\n     */\n    public X5455_ExtendedTimestamp() {}\n\n    /**\n     * The Header-ID.\n     *\n     * @return the value for the header id for this extrafield\n     */\n    @Override\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    @Override\n    public ZipShort getLocalFileDataLength() {\n        return new ZipShort(1 +\n                (bit0_modifyTimePresent ? 4 : 0) +\n                (bit1_accessTimePresent && accessTime != null ? 4 : 0) +\n                (bit2_createTimePresent && createTime != null ? 4 : 0)\n        );\n    }\n\n    /**\n     * Length of the extra field in the local file data - without\n     * Header-ID or length specifier.\n     *\n     * <p>For X5455 the central length is often smaller than the\n     * local length, because central cannot contain access or create\n     * timestamps.</p>\n     *\n     * @return a <code>ZipShort</code> for the length of the data of this extra field\n     */\n    @Override\n    public ZipShort getCentralDirectoryLength() {\n        return new ZipShort(1 +\n                (bit0_modifyTimePresent ? 4 : 0)\n        );\n    }\n\n    /**\n     * The actual data to put into local file data - without Header-ID\n     * or length specifier.\n     *\n     * @return get the data\n     */\n    @Override\n    public byte[] getLocalFileDataData() {\n        final byte[] data = new byte[getLocalFileDataLength().getValue()];\n        int pos = 0;\n        data[pos++] = 0;\n        if (bit0_modifyTimePresent) {\n            data[0] |= MODIFY_TIME_BIT;\n            System.arraycopy(modifyTime.getBytes(), 0, data, pos, 4);\n            pos += 4;\n        }\n        if (bit1_accessTimePresent && accessTime != null) {\n            data[0] |= ACCESS_TIME_BIT;\n            System.arraycopy(accessTime.getBytes(), 0, data, pos, 4);\n            pos += 4;\n        }\n        if (bit2_createTimePresent && createTime != null) {\n            data[0] |= CREATE_TIME_BIT;\n            System.arraycopy(createTime.getBytes(), 0, data, pos, 4);\n            pos += 4; // NOSONAR - assignment as documentation\n        }\n        return data;\n    }\n\n    /**\n     * The actual data to put into central directory data - without Header-ID\n     * or length specifier.\n     *\n     * @return the central directory data\n     */\n    @Override\n    public byte[] getCentralDirectoryData() {\n        final byte[] centralData = new byte[getCentralDirectoryLength().getValue()];\n        final byte[] localData = getLocalFileDataData();\n\n        // Truncate out create & access time (last 8 bytes) from\n        // the copy of the local data we obtained:\n        System.arraycopy(localData, 0, centralData, 0, centralData.length);\n        return centralData;\n    }\n\n    /**\n     * Populate data from this array as if it was in local file data.\n     *\n     * @param data   an array of bytes\n     * @param offset the start offset\n     * @param length the number of bytes in the array from offset\n     * @throws java.util.zip.ZipException on error\n     */\n    @Override\n    public void parseFromLocalFileData(\n            final byte[] data, int offset, final int length\n    ) throws ZipException {\n        reset();\n        final int len = offset + length;\n        setFlags(data[offset++]);\n        if (bit0_modifyTimePresent) {\n            modifyTime = new ZipLong(data, offset);\n            offset += 4;\n        }\n\n        // Notice the extra length check in case we are parsing the shorter\n        // central data field (for both access and create timestamps).\n        if (bit1_accessTimePresent && offset + 4 <= len) {\n            accessTime = new ZipLong(data, offset);\n            offset += 4;\n        }\n        if (bit2_createTimePresent && offset + 4 <= len) {\n            createTime = new ZipLong(data, offset);\n            offset += 4; // NOSONAR - assignment as documentation\n        }\n    }\n\n    /**\n     * Doesn't do anything special since this class always uses the\n     * same parsing logic for both central directory and local file data.\n     */\n    @Override\n    public void parseFromCentralDirectoryData(\n            final byte[] buffer, final int offset, final int length\n    ) throws ZipException {\n        reset();\n        parseFromLocalFileData(buffer, offset, length);\n    }\n\n    /**\n     * Reset state back to newly constructed state.  Helps us make sure\n     * parse() calls always generate clean results.\n     */\n    private void reset() {\n        setFlags((byte) 0);\n        this.modifyTime = null;\n        this.accessTime = null;\n        this.createTime = null;\n    }\n\n    /**\n     * Sets flags byte.  The flags byte tells us which of the\n     * three datestamp fields are present in the data:\n     * <pre>\n     * bit0 - modify time\n     * bit1 - access time\n     * bit2 - create time\n     * </pre>\n     * Only first 3 bits of flags are used according to the\n     * latest version of the spec (December 2012).\n     *\n     * @param flags flags byte indicating which of the\n     *              three datestamp fields are present.\n     */\n    public void setFlags(final byte flags) {\n        this.flags = flags;\n        this.bit0_modifyTimePresent = (flags & MODIFY_TIME_BIT) == MODIFY_TIME_BIT;\n        this.bit1_accessTimePresent = (flags & ACCESS_TIME_BIT) == ACCESS_TIME_BIT;\n        this.bit2_createTimePresent = (flags & CREATE_TIME_BIT) == CREATE_TIME_BIT;\n    }\n\n    /**\n     * Gets flags byte.  The flags byte tells us which of the\n     * three datestamp fields are present in the data:\n     * <pre>\n     * bit0 - modify time\n     * bit1 - access time\n     * bit2 - create time\n     * </pre>\n     * Only first 3 bits of flags are used according to the\n     * latest version of the spec (December 2012).\n     *\n     * @return flags byte indicating which of the\n     *         three datestamp fields are present.\n     */\n    public byte getFlags() { return flags; }\n\n    /**\n     * Returns whether bit0 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a modify timestamp in this particular zip entry.\n     *\n     * @return true if bit0 of the flags byte is set.\n     */\n    public boolean isBit0_modifyTimePresent() { return bit0_modifyTimePresent; }\n\n    /**\n     * Returns whether bit1 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a \"last access\" timestamp in this particular zip entry.\n     *\n     * @return true if bit1 of the flags byte is set.\n     */\n    public boolean isBit1_accessTimePresent() { return bit1_accessTimePresent; }\n\n    /**\n     * Returns whether bit2 of the flags byte is set or not,\n     * which should correspond to the presence or absence of\n     * a create timestamp in this particular zip entry.\n     *\n     * @return true if bit2 of the flags byte is set.\n     */\n    public boolean isBit2_createTimePresent() { return bit2_createTimePresent; }\n\n    /**\n     * Returns the modify time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     *\n     * @return modify time (seconds since epoch) or null.\n     */\n    public ZipLong getModifyTime() { return modifyTime; }\n\n    /**\n     * Returns the access time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     *\n     * @return access time (seconds since epoch) or null.\n     */\n    public ZipLong getAccessTime() { return accessTime; }\n\n    /**\n     * <p>\n     * Returns the create time (seconds since epoch) of this zip entry\n     * as a ZipLong object, or null if no such timestamp exists in the\n     * zip entry.\n     * </p><p>\n     * Note: modern linux file systems (e.g., ext2)\n     * do not appear to store a \"create time\" value, and so\n     * it's usually omitted altogether in the zip extra\n     * field.  Perhaps other unix systems track this.\n     *\n     * @return create time (seconds since epoch) or null.\n     */\n    public ZipLong getCreateTime() { return createTime; }\n\n    /**\n     * Returns the modify time as a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     *\n     * @return modify time as java.util.Date or null.\n     */\n    public Date getModifyJavaTime() {\n        return zipLongToDate(modifyTime);\n    }\n\n    /**\n     * Returns the access time as a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     *\n     * @return access time as java.util.Date or null.\n     */\n    public Date getAccessJavaTime() {\n        return zipLongToDate(accessTime);\n    }\n\n    private static Date zipLongToDate(ZipLong unixTime) {\n        return unixTime != null ? new Date(unixTime.getIntValue() * 1000L) : null;\n    }\n\n    /**\n     * <p>\n     * Returns the create time as a a java.util.Date\n     * of this zip entry, or null if no such timestamp exists in the zip entry.\n     * The milliseconds are always zeroed out, since the underlying data\n     * offers only per-second precision.\n     * </p><p>\n     * Note: modern linux file systems (e.g., ext2)\n     * do not appear to store a \"create time\" value, and so\n     * it's usually omitted altogether in the zip extra\n     * field.  Perhaps other unix systems track this.\n     *\n     * @return create time as java.util.Date or null.\n     */\n    public Date getCreateJavaTime() {\n        return zipLongToDate(createTime);\n    }\n\n    /**\n     * <p>\n     * Sets the modify time (seconds since epoch) of this zip entry\n     * using a ZipLong object.\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the modify time (seconds per epoch)\n     */\n    public void setModifyTime(final ZipLong l) {\n        bit0_modifyTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | MODIFY_TIME_BIT)\n                        : (flags & ~MODIFY_TIME_BIT));\n        this.modifyTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the access time (seconds since epoch) of this zip entry\n     * using a ZipLong object\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the access time (seconds per epoch)\n     */\n    public void setAccessTime(final ZipLong l) {\n        bit1_accessTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | ACCESS_TIME_BIT)\n                        : (flags & ~ACCESS_TIME_BIT));\n        this.accessTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the create time (seconds since epoch) of this zip entry\n     * using a ZipLong object\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param l ZipLong of the create time (seconds per epoch)\n     */\n    public void setCreateTime(final ZipLong l) {\n        bit2_createTimePresent = l != null;\n        flags = (byte) (l != null ? (flags | CREATE_TIME_BIT)\n                        : (flags & ~CREATE_TIME_BIT));\n        this.createTime = l;\n    }\n\n    /**\n     * <p>\n     * Sets the modify time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d modify time as java.util.Date\n     */\n    public void setModifyJavaTime(final Date d) { setModifyTime(dateToZipLong(d)); }\n\n    /**\n     * <p>\n     * Sets the access time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d access time as java.util.Date\n     */\n    public void setAccessJavaTime(final Date d) { setAccessTime(dateToZipLong(d)); }\n\n    /**\n     * <p>\n     * Sets the create time as a java.util.Date\n     * of this zip entry.  Supplied value is truncated to per-second\n     * precision (milliseconds zeroed-out).\n     * </p><p>\n     * Note: the setters for flags and timestamps are decoupled.\n     * Even if the timestamp is not-null, it will only be written\n     * out if the corresponding bit in the flags is also set.\n     * </p>\n     *\n     * @param d create time as java.util.Date\n     */\n    public void setCreateJavaTime(final Date d) { setCreateTime(dateToZipLong(d)); }\n\n    /**\n     * Utility method converts java.util.Date (milliseconds since epoch)\n     * into a ZipLong (seconds since epoch).\n     * <p/>\n     * Also makes sure the converted ZipLong is not too big to fit\n     * in 32 unsigned bits.\n     *\n     * @param d java.util.Date to convert to ZipLong\n     * @return ZipLong\n     */\n    private static ZipLong dateToZipLong(final Date d) {\n        if (d == null) { return null; }\n\n        return unixTimeToZipLong(d.getTime() / 1000);\n    }\n\n    private static ZipLong unixTimeToZipLong(long l) {\n        if (l < Integer.MIN_VALUE || l > Integer.MAX_VALUE) {\n            throw new IllegalArgumentException(\"X5455 timestamps must fit in a signed 32 bit integer: \" + l);\n        }\n        return new ZipLong(l);\n    }\n\n    /**\n     * Returns a String representation of this class useful for\n     * debugging purposes.\n     *\n     * @return A String representation of this class useful for\n     *         debugging purposes.\n     */\n    @Override\n    public String toString() {\n        final StringBuilder buf = new StringBuilder();\n        buf.append(\"0x5455 Zip Extra Field: Flags=\");\n        buf.append(Integer.toBinaryString(ZipUtil.unsignedIntToSignedByte(flags))).append(\" \");\n        if (bit0_modifyTimePresent && modifyTime != null) {\n            final Date m = getModifyJavaTime();\n            buf.append(\" Modify:[\").append(m).append(\"] \");\n        }\n        if (bit1_accessTimePresent && accessTime != null) {\n            final Date a = getAccessJavaTime();\n            buf.append(\" Access:[\").append(a).append(\"] \");\n        }\n        if (bit2_createTimePresent && createTime != null) {\n            final Date c = getCreateJavaTime();\n            buf.append(\" Create:[\").append(c).append(\"] \");\n        }\n        return buf.toString();\n    }\n\n    @Override\n    public Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n\n    @Override\n    public boolean equals(final Object o) {\n        if (o instanceof X5455_ExtendedTimestamp) {\n            final X5455_ExtendedTimestamp xf = (X5455_ExtendedTimestamp) o;\n\n            // The ZipLong==ZipLong clauses handle the cases where both are null.\n            // and only last 3 bits of flags matter.\n            return ((flags & 0x07) == (xf.flags & 0x07)) &&\n                    (modifyTime == xf.modifyTime || (modifyTime != null && modifyTime.equals(xf.modifyTime))) &&\n                    (accessTime == xf.accessTime || (accessTime != null && accessTime.equals(xf.accessTime))) &&\n                    (createTime == xf.createTime || (createTime != null && createTime.equals(xf.createTime)));\n        }\n        return false;\n    }\n\n    @Override\n    public int hashCode() {\n        int hc = (-123 * (flags & 0x07)); // only last 3 bits of flags matter\n        if (modifyTime != null) {\n            hc ^= modifyTime.hashCode();\n        }\n        if (accessTime != null) {\n            // Since accessTime is often same as modifyTime,\n            // this prevents them from XOR negating each other.\n            hc ^= Integer.rotateLeft(accessTime.hashCode(), 11);\n        }\n        if (createTime != null) {\n            hc ^= Integer.rotateLeft(createTime.hashCode(), 22);\n        }\n        return hc;\n    }\n\n}\n"}]}
{"project": "Compress", "bug_id": 47, "classes_modified": [{"class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream", "buggy_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate64.Deflate64CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] lfhBuf = new byte[LFH_LEN];\n    private final byte[] skipBuf = new byte[1024];\n    private final byte[] shortBuf = new byte[SHORT];\n    private final byte[] wordBuf = new byte[WORD];\n    private final byte[] twoDwordBuf = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        long currentHeaderOffset = getBytesRead();\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(lfhBuf);\n            } else {\n                readFully(lfhBuf);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(lfhBuf);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n            return null;\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(lfhBuf, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(lfhBuf, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(lfhBuf, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfhBuf, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(lfhBuf, off));\n            off += WORD;\n\n            cSize = new ZipLong(lfhBuf, off);\n            off += WORD;\n\n            size = new ZipLong(lfhBuf, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(lfhBuf, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(lfhBuf, off);\n        off += SHORT; // NOSONAR - assignment as documentation\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        if (hasUTF8Flag) {\n            current.entry.setNameSource(ZipArchiveEntry.NameSource.NAME_WITH_EFS_FLAG);\n        }\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        current.entry.setLocalHeaderOffset(currentHeaderOffset);\n        current.entry.setDataOffset(getBytesRead());\n        current.entry.setStreamContiguous(true);\n\n        ZipMethod m = ZipMethod.getMethodByCode(current.entry.getMethod());\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (ZipUtil.canHandleEntryData(current.entry) && m != ZipMethod.STORED && m != ZipMethod.DEFLATED) {\n                InputStream bis = new BoundedInputStream(in, current.entry.getCompressedSize());\n                switch (m) {\n                case UNSHRINKING:\n                    current.in = new UnshrinkingInputStream(bis);\n                    break;\n                case IMPLODING:\n                    current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        bis);\n                    break;\n                case BZIP2:\n                    current.in = new BZip2CompressorInputStream(bis);\n                    break;\n                case ENHANCED_DEFLATED:\n                    current.in = new Deflate64CompressorInputStream(bis);\n                    break;\n                default:\n                    // we should never get here as all supported methods have been covered\n                    // will cause an error when read is invoked, don't throw an exception here so people can\n                    // skip unsupported entries\n                    break;\n                }\n            }\n        } else if (m == ZipMethod.ENHANCED_DEFLATED) {\n            current.in = new Deflate64CompressorInputStream(in);\n        }\n\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze);\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n\n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            // this is guaranteed to exhaust the stream\n            skip(Long.MAX_VALUE); //NOSONAR\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        final int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(wordBuf);\n        ZipLong val = new ZipLong(wordBuf);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(wordBuf);\n            val = new ZipLong(wordBuf);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(twoDwordBuf);\n        final ZipLong potentialSig = new ZipLong(twoDwordBuf, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(twoDwordBuf, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(twoDwordBuf));\n            current.entry.setSize(ZipLong.getValue(twoDwordBuf, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(twoDwordBuf));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(twoDwordBuf, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED or ENHANCED_DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED\n                || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode();\n    }\n\n    /**\n     * Whether the compressed size for the entry is either known or\n     * not required by the compression method being used.\n     */\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(shortBuf);\n        // file comment\n        realSkip(ZipShort.getValue(shortBuf));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n\n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n", "fixed_version": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate64.Deflate64CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] lfhBuf = new byte[LFH_LEN];\n    private final byte[] skipBuf = new byte[1024];\n    private final byte[] shortBuf = new byte[SHORT];\n    private final byte[] wordBuf = new byte[WORD];\n    private final byte[] twoDwordBuf = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        long currentHeaderOffset = getBytesRead();\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(lfhBuf);\n            } else {\n                readFully(lfhBuf);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(lfhBuf);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n            return null;\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(lfhBuf, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(lfhBuf, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(lfhBuf, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfhBuf, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(lfhBuf, off));\n            off += WORD;\n\n            cSize = new ZipLong(lfhBuf, off);\n            off += WORD;\n\n            size = new ZipLong(lfhBuf, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(lfhBuf, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(lfhBuf, off);\n        off += SHORT; // NOSONAR - assignment as documentation\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        if (hasUTF8Flag) {\n            current.entry.setNameSource(ZipArchiveEntry.NameSource.NAME_WITH_EFS_FLAG);\n        }\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        current.entry.setLocalHeaderOffset(currentHeaderOffset);\n        current.entry.setDataOffset(getBytesRead());\n        current.entry.setStreamContiguous(true);\n\n        ZipMethod m = ZipMethod.getMethodByCode(current.entry.getMethod());\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (ZipUtil.canHandleEntryData(current.entry) && m != ZipMethod.STORED && m != ZipMethod.DEFLATED) {\n                InputStream bis = new BoundedInputStream(in, current.entry.getCompressedSize());\n                switch (m) {\n                case UNSHRINKING:\n                    current.in = new UnshrinkingInputStream(bis);\n                    break;\n                case IMPLODING:\n                    current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        bis);\n                    break;\n                case BZIP2:\n                    current.in = new BZip2CompressorInputStream(bis);\n                    break;\n                case ENHANCED_DEFLATED:\n                    current.in = new Deflate64CompressorInputStream(bis);\n                    break;\n                default:\n                    // we should never get here as all supported methods have been covered\n                    // will cause an error when read is invoked, don't throw an exception here so people can\n                    // skip unsupported entries\n                    break;\n                }\n            }\n        } else if (m == ZipMethod.ENHANCED_DEFLATED) {\n            current.in = new Deflate64CompressorInputStream(in);\n        }\n\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze)\n                && supportsCompressedSizeFor(ze);\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n        if (!supportsCompressedSizeFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.UNKNOWN_COMPRESSED_SIZE,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n\n        return read;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            // this is guaranteed to exhaust the stream\n            skip(Long.MAX_VALUE); //NOSONAR\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        final int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(wordBuf);\n        ZipLong val = new ZipLong(wordBuf);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(wordBuf);\n            val = new ZipLong(wordBuf);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(twoDwordBuf);\n        final ZipLong potentialSig = new ZipLong(twoDwordBuf, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(twoDwordBuf, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(twoDwordBuf));\n            current.entry.setSize(ZipLong.getValue(twoDwordBuf, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(twoDwordBuf));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(twoDwordBuf, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED or ENHANCED_DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED\n                || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode();\n    }\n\n    /**\n     * Whether the compressed size for the entry is either known or\n     * not required by the compression method being used.\n     */\n    private boolean supportsCompressedSizeFor(final ZipArchiveEntry entry) {\n        return entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN\n            || entry.getMethod() == ZipEntry.DEFLATED\n            || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n            || (entry.getGeneralPurposeBit().usesDataDescriptor()\n                && allowStoredEntriesWithDataDescriptor\n                && entry.getMethod() == ZipEntry.STORED);\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(shortBuf);\n        // file comment\n        realSkip(ZipShort.getValue(shortBuf));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n\n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n"}]}
