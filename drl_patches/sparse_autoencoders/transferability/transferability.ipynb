{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4540a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from drl_patches.sparse_autoencoders.get_vectorizer import load_tfidf_vectorizer\n",
    "from drl_patches.sparse_autoencoders.getting_experiment_config import (\n",
    "    load_training_indexes,\n",
    ")\n",
    "import torch\n",
    "from drl_patches.logger import logger\n",
    "from drl_patches.sparse_autoencoders.classical_data_mining import get_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14c1c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    dataset_path: str\n",
    "    training_idx_path: str\n",
    "\n",
    "GBUG_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/gbug-java.csv\",\n",
    "    training_idx_path=\"../artifacts/gbug-java_train_indexes.json\",\n",
    ")\n",
    "\n",
    "DEFECT_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/defects4j.csv\",\n",
    "    training_idx_path=\"../artifacts/defects4j_train_indexes.json\",\n",
    ")\n",
    "\n",
    "HUMAN_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/humaneval.csv\",\n",
    "    training_idx_path=\"../artifacts/humaneval_train_indexes.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acf0c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_testing_dataset(dataset: Dataset):\n",
    "    \"\"\"\n",
    "    Get the testing dataset path and the training indexes path.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(dataset.dataset_path)\n",
    "    print(df.shape)\n",
    "    with open( dataset.training_idx_path, \"r\") as f:\n",
    "        training_indices = json.load(f)\n",
    "    train_df = df.iloc[training_indices]\n",
    "    test_df = df.drop(train_df.index)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d736d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SAE_ACTIVATIONS:\n",
    "    feature_diff_path: str\n",
    "    model_path: str\n",
    "    layer: int\n",
    "    top_k: int\n",
    "    dataset: Dataset\n",
    "    gbug_feature_safe_path: str\n",
    "    gbug_feature_vuln_path: str\n",
    "    defects_feature_safe_path: str\n",
    "    defects_feature_vuln_path: str\n",
    "    humaneval_feature_safe_path: str\n",
    "    humaneval_feature_vuln_path: str\n",
    "\n",
    "SAE_ACTIVATIONS_GBUG_LAYER_1 = SAE_ACTIVATIONS(\n",
    "    feature_diff_path=\"../gpt2_gbug-java/layer1/feature_importance_diff.jsonl\",\n",
    "    gbug_feature_safe_path=\"../gpt2_gbug-java/layer1/feature_importance_safe.jsonl\",\n",
    "    gbug_feature_vuln_path=\"../gpt2_gbug-java/layer1/feature_importance_vuln.jsonl\",\n",
    "    defects_feature_safe_path=\"../gpt2_defects4j/layer1/feature_importance_safe.jsonl\",\n",
    "    defects_feature_vuln_path=\"../gpt2_defects4j/layer1/feature_importance_vuln.jsonl\",\n",
    "    humaneval_feature_safe_path=\"../gpt2_humaneval/layer1/feature_importance_safe.jsonl\",\n",
    "    humaneval_feature_vuln_path=\"../gpt2_humaneval/layer1/feature_importance_vuln.jsonl\",\n",
    "    model_path = \"models/gbug_decision_tree_layer10_k_76.pt\",\n",
    "    layer = 10,\n",
    "    top_k = 76,\n",
    "    dataset = GBUG_DATASET,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_jsonl_file(jsonl_path):\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def get_feature_diff_path(dataset: Dataset, training_indexes):\n",
    "    \"\"\"\n",
    "    Get the feature diff path for the given dataset.\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    diff_data = list(read_jsonl_file(dataset.feature_diff_path))\n",
    "    diff_df = pd.DataFrame(diff_data)\n",
    "\n",
    "    columns = diff_df.columns.to_list()\n",
    "    columns.remove(\"values\")\n",
    "\n",
    "    diff_df.drop(columns=columns, inplace=True)\n",
    "\n",
    "    for i in trange(len(diff_df[\"values\"][0])):\n",
    "        diff_df[f\"feature_{i}\"] = diff_df[\"values\"].apply(lambda x: x[i])\n",
    "\n",
    "    diff_df.drop(columns=[\"values\"], inplace=True)\n",
    "\n",
    "    \n",
    "    return diff_df\n",
    "\n",
    "\n",
    "\n",
    "def get_most_important_features(train_df_diff, n=100):\n",
    "    features = train_df_diff.sum(axis=0).sort_values(ascending=False).index[1 : n + 1]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUR_CONFIG = SAE_ACTIVATIONS_GBUG_LAYER_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1fea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_df = get_testing_dataset(OUR_CONFIG.dataset)\n",
    "\n",
    "with open(OUR_CONFIG.dataset.training_idx_path, \"r\") as f:\n",
    "    training_indices = json.load(f)\n",
    "\n",
    "train_df_diff = get_feature_diff_path(\n",
    "    SAE_ACTIVATIONS_GBUG_LAYER_1, training_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = get_most_important_features(train_df_diff, n=OUR_CONFIG.top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vuln_safe_data(vuln_jsonl_path, safe_jsonl_path, train_indexes):\n",
    "    vuln_data = list(read_jsonl_file(vuln_jsonl_path))\n",
    "    safe_data = list(read_jsonl_file(safe_jsonl_path))\n",
    "    vuln_df = pd.DataFrame(vuln_data)\n",
    "    safe_df = pd.DataFrame(safe_data)\n",
    "    vuln_df.drop(columns=[\"labels\", \"model\", \"plot_type\"], inplace=True)\n",
    "    vuln_df[\"vuln\"] = 1\n",
    "\n",
    "    safe_df.drop(columns=[\"labels\", \"model\", \"plot_type\"], inplace=True)\n",
    "    safe_df[\"vuln\"] = 0\n",
    "\n",
    "    for i in trange(len(vuln_df[\"values\"][0])):\n",
    "        vuln_df[f\"feature_{i}\"] = vuln_df[\"values\"].apply(lambda x: x[i])\n",
    "        safe_df[f\"feature_{i}\"] = safe_df[\"values\"].apply(lambda x: x[i])\n",
    "\n",
    "    safe_df_train = safe_df.loc[train_indexes]\n",
    "    safe_df_test = safe_df.drop(train_indexes)\n",
    "\n",
    "    vuln_df_train = vuln_df.loc[train_indexes]\n",
    "    vuln_df_test = vuln_df.drop(train_indexes)\n",
    "\n",
    "    df_train = pd.concat([safe_df_train, vuln_df_train])\n",
    "    df_test = pd.concat([safe_df_test, vuln_df_test])\n",
    "\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "    df_train.drop(columns=[\"values\"], inplace=True)\n",
    "    df_test.drop(columns=[\"values\"], inplace=True)\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, test_df):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "    \"\"\"\n",
    "    #bug_id\tfunc_before\tfunc_after\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i, row in tqdm(test_df.iterrows()):\n",
    "        X = row[top_k.tolist()]\n",
    "        y = row[\"vuln\"]\n",
    "\n",
    "        # Get the prediction\n",
    "        pred = clf.predict([X])\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        if pred == 1 and y == 1:\n",
    "            tp += 1\n",
    "        elif pred == 1 and y == 0:\n",
    "            fp += 1\n",
    "        elif pred == 0 and y == 1:\n",
    "            fn += 1\n",
    "        elif pred == 0 and y == 0:\n",
    "            tn += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    # Calculate the precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    # Calculate the recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    # Calculate the F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tn\": tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAE_ACTIVATIONS_GBUG_LAYER_1.model_path, \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "# Original (GBUG)\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.gbug_feature_vuln_path,\n",
    "    OUR_CONFIG.gbug_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defects4J\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.defects_feature_vuln_path,\n",
    "    OUR_CONFIG.defects_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defects4J\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.humaneval_feature_vuln_path,\n",
    "    OUR_CONFIG.humaneval_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01281b",
   "metadata": {},
   "source": [
    "# Baselines Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ec6046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaselineClassifier:\n",
    "    path: str\n",
    "    tfidf_vectorizer_path: str\n",
    "    base_dataset: Dataset\n",
    "    input_size: int\n",
    "\n",
    "DEFECTS4J_KNN_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/defects4j_knn_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=DEFECT_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "GBUG_KNN_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/gbug_knn_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=GBUG_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "HUMANEVAL_KNN_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/human_knn_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=HUMAN_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "DEFECTS4J_RF_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/defects4j_random_forest_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=DEFECT_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "GBUG_RF_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/gbug_random_forest_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=GBUG_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "HUMANEVAL_RF_BASELINE = BaselineClassifier(\n",
    "    path=\"../ole/human_random_forest_k_5000.pt\",\n",
    "    tfidf_vectorizer_path = \"../artifacts/vectorizer.pkl\",\n",
    "    base_dataset=HUMAN_DATASET,\n",
    "    input_size=5000,\n",
    ")\n",
    "\n",
    "def load_baseline_classifier(classifier: BaselineClassifier):\n",
    "    with open(classifier.path, \"rb\") as f:\n",
    "        clf = pickle.load(f)\n",
    "    return clf\n",
    "@dataclass\n",
    "class Results:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    accuracy: float\n",
    "    f1: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TransferabilityPerformance:\n",
    "    on_defects: Optional[int] = None\n",
    "    on_humaneval: Optional[int] = None\n",
    "    on_gbug: Optional[int] = None\n",
    "\n",
    "def calculate_f1_shift(\n",
    "    results: Results,\n",
    "    baseline_results: Results,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the shift in perfoamcene in terms of F1 score % changed\n",
    "    \"\"\"\n",
    "    f1_shift = (results.f1 - baseline_results.f1) / baseline_results.f1 * 100\n",
    "    \n",
    "    return f1_shift\n",
    "\n",
    "def test_baseline_classifier(clf, \n",
    "                             vectorizer, \n",
    "                             df, \n",
    "                             train_indexes,\n",
    "                             before_func_col=\"func_before\", \n",
    "                             after_func_col=\"func_after\") -> Results:\n",
    "    \"\"\"\n",
    "    Test the baseline classifier on the test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"tokenized_before\"] = df[before_func_col].progress_apply(\n",
    "        lambda x: vectorizer.transform([x]).toarray()[0]\n",
    "    )\n",
    "    df[\"tokenized_after\"] = df[after_func_col].progress_apply(\n",
    "        lambda x: vectorizer.transform([x]).toarray()[0]\n",
    "    )\n",
    "    # Pad to 5000 tokens\n",
    "    df[\"tokenized_before\"] = df[\"tokenized_before\"].apply(\n",
    "        lambda x: x[:5000] + [0] * (5000 - len(x)) if len(x) < 5000 else x[:5000]\n",
    "    )\n",
    "    df[\"tokenized_after\"] = df[\"tokenized_after\"].apply(\n",
    "        lambda x: x[:5000] + [0] * (5000 - len(x)) if len(x) < 5000 else x[:5000]\n",
    "    )\n",
    "\n",
    "    df_test = df.drop(train_indexes)\n",
    "\n",
    "    df_classical_test = pd.DataFrame()\n",
    "    for row in df_test.iterrows():\n",
    "        row = row[1]\n",
    "        df_classical_test = pd.concat(\n",
    "            [\n",
    "                df_classical_test,\n",
    "                pd.DataFrame(\n",
    "                    {\"tokens\": [row[\"tokenized_before\"].tolist()], \"vuln\": 1}, index=[0]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        df_classical_test = pd.concat(\n",
    "            [\n",
    "                df_classical_test,\n",
    "                pd.DataFrame(\n",
    "                    {\"tokens\": [row[\"tokenized_after\"].tolist()], \"vuln\": 0}, index=[0]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_test = df_classical_test[\"tokens\"].values.tolist()\n",
    "    X_test = [torch.tensor(x) for x in X_test]\n",
    "    y_test = df_classical_test[\"vuln\"]\n",
    "\n",
    "    # Get the prediction\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision, recall, accuracy, f1 = get_metrics(y_pred, y_test)\n",
    "    logger.info(\n",
    "        \"Classification report:\",\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        accuracy=accuracy,\n",
    "        f1=f1,\n",
    "    )\n",
    "    return Results(\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        accuracy=accuracy,\n",
    "        f1=f1,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1720f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 3945.50it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 4841.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.6666666666666666\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.6774193548387096\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.65625\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.7\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 465/465 [00:00<00:00, 6626.66it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6679.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.4431137724550898\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.3978494623655914\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 7042.24it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7635.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.48484848484848486\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.43333333333333324\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.48148148148148145\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.3939393939393939\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_gbug_knn = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "results_gbug_knn_defects = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "results_gbug_knn_human = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "\n",
    "transf_knn_gbug_on_defects= calculate_f1_shift(\n",
    "    results_gbug_knn_defects,\n",
    "    results_gbug_knn,\n",
    ")\n",
    "transf_knn_gbug_on_human= calculate_f1_shift(\n",
    "    results_gbug_knn_human,\n",
    "    results_gbug_knn,\n",
    ")\n",
    "\n",
    "transf_knn_gbug = TransferabilityPerformance(\n",
    "    on_defects=transf_knn_gbug_on_defects,\n",
    "    on_humaneval=transf_knn_gbug_on_human,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba69065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 4733.72it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 5198.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:24:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.75\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.7058823529411764\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.8571428571428571\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.6\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 465/465 [00:00<00:00, 7168.78it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 7024.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:24:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5161290322580645\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.1176470588235294\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.6666666666666666\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.06451612903225806\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 3930.32it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 6022.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:24:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.48484848484848486\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.43333333333333324\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.48148148148148145\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.3939393939393939\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Random Forest from Gbug\n",
    "results_gbug_rf = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "results_gbug_rf_defects = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "results_gbug_rf_human = test_baseline_classifier(\n",
    "    load_baseline_classifier(GBUG_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(GBUG_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "\n",
    "transf_rf_gbug_on_defects= calculate_f1_shift(\n",
    "    results_gbug_rf_defects,\n",
    "    results_gbug_rf,\n",
    ")\n",
    "transf_rf_gbug_on_human= calculate_f1_shift(\n",
    "    results_gbug_rf_human,\n",
    "    results_gbug_rf,\n",
    ")\n",
    "\n",
    "transf_rf_gbug = TransferabilityPerformance(\n",
    "    on_defects=transf_rf_gbug_on_defects,\n",
    "    on_humaneval=transf_rf_gbug_on_human,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dfc67a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 6626.30it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6975.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:25:39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5376344086021505\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.35820895522388063\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5853658536585366\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.25806451612903225\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 5247.67it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 4808.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:25:39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5333333333333333\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.43999999999999995\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.55\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.36666666666666664\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 7323.37it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7360.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:25:39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5454545454545454\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.4642857142857143\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5652173913043478\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.3939393939393939\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_defects_knn = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "results_defects_knn_gbug = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "results_defects_knn_human = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "transf_knn_defects_on_gbug= calculate_f1_shift(\n",
    "    results_defects_knn_gbug,\n",
    "    results_defects_knn,\n",
    ")\n",
    "transf_knn_defects_on_human= calculate_f1_shift(\n",
    "    results_defects_knn_human,\n",
    "    results_defects_knn,\n",
    ")\n",
    "\n",
    "transf_knn_defects = TransferabilityPerformance(\n",
    "    on_defects=transf_knn_defects_on_gbug,\n",
    "    on_humaneval=transf_knn_defects_on_human,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d73cf0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 6360.91it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6919.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.521505376344086\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.41830065359477125\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5333333333333333\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.34408602150537637\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 5642.17it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 5108.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5333333333333333\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.36363636363636365\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5714285714285714\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.26666666666666666\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 8152.59it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 3012.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.6117647058823529\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.7878787878787878\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_defects_rf = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "results_defects_rf_gbug = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "results_defects_rf_human = test_baseline_classifier(\n",
    "    load_baseline_classifier(DEFECTS4J_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(DEFECTS4J_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "transf_rf_defects_on_gbug= calculate_f1_shift(\n",
    "    results_defects_rf_gbug,\n",
    "    results_defects_rf,\n",
    ")\n",
    "transf_rf_defects_on_human= calculate_f1_shift(\n",
    "    results_defects_rf_human,\n",
    "    results_defects_rf,\n",
    ")\n",
    "\n",
    "transf_rf_defects = TransferabilityPerformance(\n",
    "    on_defects=transf_rf_defects_on_gbug,\n",
    "    on_humaneval=transf_rf_defects_on_human,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8f920934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 6077.89it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7935.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5757575757575758\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5625\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5806451612903226\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.5454545454545454\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 148/148 [00:00<00:00, 5185.38it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 5131.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.48333333333333334\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5373134328358209\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.4864864864864865\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.6\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 6854.45it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6708.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:26:39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5053763440860215\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5054945054945055\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.4946236559139785\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_humaneval_knn = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_knn_gbug = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_knn_defects = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "transf_knn_humaneval_on_gbug= calculate_f1_shift(\n",
    "    results_humaneval_knn_gbug,\n",
    "    results_humaneval_knn,\n",
    ")\n",
    "transf_knn_humaneval_on_defects= calculate_f1_shift(\n",
    "    results_humaneval_knn_defects,\n",
    "    results_humaneval_knn,\n",
    ")\n",
    "\n",
    "transf_knn_humaneval = TransferabilityPerformance(\n",
    "    on_defects=transf_knn_humaneval_on_defects,\n",
    "    on_gbug=transf_knn_humaneval_on_gbug,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "56e13d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 7209.61it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7751.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5757575757575758\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5625\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5806451612903226\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.5454545454545454\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 4932.51it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 5297.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.48333333333333334\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5373134328358209\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.4864864864864865\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.6\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 6772.59it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6714.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5053763440860215\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5054945054945055\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.4946236559139785\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_humaneval_knn = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_knn_gbug = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_knn_defects = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_KNN_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_KNN_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "transf_knn_humaneval_on_gbug= calculate_f1_shift(\n",
    "    results_humaneval_knn_gbug,\n",
    "    results_humaneval_knn,\n",
    ")\n",
    "transf_knn_humaneval_on_defects= calculate_f1_shift(\n",
    "    results_humaneval_knn_defects,\n",
    "    results_humaneval_knn,\n",
    ")\n",
    "transf_knn_humaneval = TransferabilityPerformance(\n",
    "    on_defects=transf_knn_humaneval_on_defects,\n",
    "    on_gbug=transf_knn_humaneval_on_gbug,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3ff3b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:00<00:00, 7087.49it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 7137.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5606060606060606\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.4912280701754386\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5833333333333334\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.42424242424242425\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 148/148 [00:00<00:00, 5375.54it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 2934.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.16666666666666669\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.5\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.1\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 6698.65it/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 7032.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-21 19:23:51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClassification report:        \u001b[0m \u001b[36maccuracy\u001b[0m=\u001b[35m0.4946236559139785\u001b[0m \u001b[36mf1\u001b[0m=\u001b[35m0.11320754716981131\u001b[0m \u001b[36mprecision\u001b[0m=\u001b[35m0.46153846153846156\u001b[0m \u001b[36mrecall\u001b[0m=\u001b[35m0.06451612903225806\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_humaneval_rf = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(HUMAN_DATASET.dataset_path),\n",
    "    load_training_indexes(HUMAN_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_rf_gbug = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(GBUG_DATASET.dataset_path),\n",
    "    load_training_indexes(GBUG_DATASET.training_idx_path),\n",
    ")\n",
    "results_humaneval_rf_defects = test_baseline_classifier(\n",
    "    load_baseline_classifier(HUMANEVAL_RF_BASELINE),\n",
    "    load_tfidf_vectorizer(HUMANEVAL_RF_BASELINE.tfidf_vectorizer_path),\n",
    "    pd.read_csv(DEFECT_DATASET.dataset_path),\n",
    "    load_training_indexes(DEFECT_DATASET.training_idx_path),\n",
    ")\n",
    "transf_rf_humaneval_on_gbug= calculate_f1_shift(\n",
    "    results_humaneval_rf_gbug,\n",
    "    results_humaneval_rf,\n",
    ")\n",
    "transf_rf_humaneval_on_defects= calculate_f1_shift(\n",
    "    results_humaneval_rf_defects,\n",
    "    results_humaneval_rf,\n",
    ")\n",
    "transf_rf_humaneval = TransferabilityPerformance(\n",
    "    on_defects=transf_rf_humaneval_on_defects,\n",
    "    on_gbug=transf_rf_humaneval_on_gbug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6abf3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 7))\n",
    "fig.suptitle(\"Transferability Performance of KNN and RF Classifiers\", fontsize=16)\n",
    "\n",
    "# Gbug KNN\n",
    "ax[0, 0].barh(\n",
    "    [\"Defects4J\", \"HumanEval\"],\n",
    "    [transf_knn_gbug.on_defects, transf_knn_gbug.on_humaneval],\n",
    ")\n",
    "ax[0, 0].set_title(\"Gbug KNN\")\n",
    "ax[0, 0].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[0, 0].set_xlim(-100, 100)\n",
    "\n",
    "# Defects4J KNN\n",
    "ax[0, 1].barh(\n",
    "    [\"Gbug\", \"HumanEval\"],\n",
    "    [transf_knn_defects.on_defects, transf_knn_defects.on_humaneval],\n",
    ")\n",
    "ax[0, 1].set_title(\"Defects4J KNN\")\n",
    "ax[0, 1].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[0, 1].set_xlim(-100, 100)\n",
    "\n",
    "# HumanEval KNN\n",
    "ax[0, 2].barh(\n",
    "    [\"Gbug\", \"Defects4J\"],\n",
    "    [transf_knn_humaneval.on_gbug, transf_knn_humaneval.on_defects],\n",
    ")\n",
    "ax[0, 2].set_title(\"HumanEval KNN\")\n",
    "ax[0, 2].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[0, 2].set_xlim(-100, 100)\n",
    "\n",
    "# Gbug RF\n",
    "ax[1, 0].barh(\n",
    "    [\"Defects4J\", \"HumanEval\"],\n",
    "    [transf_rf_gbug.on_defects, transf_rf_gbug.on_humaneval],\n",
    ")\n",
    "ax[1, 0].set_title(\"Gbug RF\")\n",
    "ax[1, 0].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[1, 0].set_xlim(-100, 100)\n",
    "\n",
    "# Defects4J RF\n",
    "ax[1, 1].barh(\n",
    "    [\"Gbug\", \"HumanEval\"],\n",
    "    [transf_rf_defects.on_defects, transf_rf_defects.on_humaneval],\n",
    ")\n",
    "ax[1, 1].set_title(\"Defects4J RF\")\n",
    "ax[1, 1].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[1, 1].set_xlim(-100, 100)\n",
    "\n",
    "# HumanEval RF\n",
    "ax[1, 2].barh(\n",
    "    [\"Gbug\", \"Defects4J\"],\n",
    "    [transf_rf_humaneval.on_gbug, transf_rf_humaneval.on_defects],\n",
    ")\n",
    "ax[1, 2].set_title(\"HumanEval RF\")\n",
    "ax[1, 2].set_xlabel(\"F1 Shift (%)\")\n",
    "ax[1, 2].set_xlim(-100, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(\"transferability_performance_horizontal.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f70e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
