{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    dataset_path: str\n",
    "    training_idx_path: str\n",
    "\n",
    "GBUG_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/gbug-java.csv\",\n",
    "    training_idx_path=\"../artifacts/gbug-java_train_indexes.json\",\n",
    ")\n",
    "\n",
    "DEFECT_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/defects4j.csv\",\n",
    "    training_idx_path=\"../artifacts/defects4j_train_indexes.json\",\n",
    ")\n",
    "\n",
    "HUMAN_DATASET = Dataset(\n",
    "    dataset_path=\"../artifacts/humaneval.csv\",\n",
    "    training_idx_path=\"../artifacts/humaneval_train_indexes.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_testing_dataset(dataset: Dataset):\n",
    "    \"\"\"\n",
    "    Get the testing dataset path and the training indexes path.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(dataset.dataset_path)\n",
    "    print(df.shape)\n",
    "    with open( dataset.training_idx_path, \"r\") as f:\n",
    "        training_indices = json.load(f)\n",
    "    train_df = df.iloc[training_indices]\n",
    "    test_df = df.drop(train_df.index)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d736d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SAE_ACTIVATIONS:\n",
    "    feature_diff_path: str\n",
    "    model_path: str\n",
    "    layer: int\n",
    "    top_k: int\n",
    "    dataset: Dataset\n",
    "    gbug_feature_safe_path: str\n",
    "    gbug_feature_vuln_path: str\n",
    "    defects_feature_safe_path: str\n",
    "    defects_feature_vuln_path: str\n",
    "    humaneval_feature_safe_path: str\n",
    "    humaneval_feature_vuln_path: str\n",
    "\n",
    "SAE_ACTIVATIONS_GBUG_LAYER_1 = SAE_ACTIVATIONS(\n",
    "    feature_diff_path=\"../gpt2_gbug-java/layer1/feature_importance_diff.jsonl\",\n",
    "    gbug_feature_safe_path=\"../gpt2_gbug-java/layer1/feature_importance_safe.jsonl\",\n",
    "    gbug_feature_vuln_path=\"../gpt2_gbug-java/layer1/feature_importance_vuln.jsonl\",\n",
    "    defects_feature_safe_path=\"../gpt2_defects4j/layer1/feature_importance_safe.jsonl\",\n",
    "    defects_feature_vuln_path=\"../gpt2_defects4j/layer1/feature_importance_vuln.jsonl\",\n",
    "    humaneval_feature_safe_path=\"../gpt2_humaneval/layer1/feature_importance_safe.jsonl\",\n",
    "    humaneval_feature_vuln_path=\"../gpt2_humaneval/layer1/feature_importance_vuln.jsonl\",\n",
    "    model_path = \"models/gbug_decision_tree_layer10_k_76.pt\",\n",
    "    layer = 10,\n",
    "    top_k = 76,\n",
    "    dataset = GBUG_DATASET,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_jsonl_file(jsonl_path):\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def get_feature_diff_path(dataset: Dataset, training_indexes):\n",
    "    \"\"\"\n",
    "    Get the feature diff path for the given dataset.\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    diff_data = list(read_jsonl_file(dataset.feature_diff_path))\n",
    "    diff_df = pd.DataFrame(diff_data)\n",
    "\n",
    "    columns = diff_df.columns.to_list()\n",
    "    columns.remove(\"values\")\n",
    "\n",
    "    diff_df.drop(columns=columns, inplace=True)\n",
    "\n",
    "    for i in trange(len(diff_df[\"values\"][0])):\n",
    "        diff_df[f\"feature_{i}\"] = diff_df[\"values\"].apply(lambda x: x[i])\n",
    "\n",
    "    diff_df.drop(columns=[\"values\"], inplace=True)\n",
    "\n",
    "    \n",
    "    return diff_df\n",
    "\n",
    "\n",
    "\n",
    "def get_most_important_features(train_df_diff, n=100):\n",
    "    features = train_df_diff.sum(axis=0).sort_values(ascending=False).index[1 : n + 1]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUR_CONFIG = SAE_ACTIVATIONS_GBUG_LAYER_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bd1fea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24576/24576 [00:34<00:00, 706.45it/s]\n"
     ]
    }
   ],
   "source": [
    "_, test_df = get_testing_dataset(OUR_CONFIG.dataset)\n",
    "\n",
    "with open(OUR_CONFIG.dataset.training_idx_path, \"r\") as f:\n",
    "    training_indices = json.load(f)\n",
    "\n",
    "train_df_diff = get_feature_diff_path(\n",
    "    SAE_ACTIVATIONS_GBUG_LAYER_1, training_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7cb728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_k = get_most_important_features(train_df_diff, n=OUR_CONFIG.top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e4bdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vuln_safe_data(vuln_jsonl_path, safe_jsonl_path, train_indexes):\n",
    "    vuln_data = list(read_jsonl_file(vuln_jsonl_path))\n",
    "    safe_data = list(read_jsonl_file(safe_jsonl_path))\n",
    "    vuln_df = pd.DataFrame(vuln_data)\n",
    "    safe_df = pd.DataFrame(safe_data)\n",
    "    vuln_df.drop(columns=[\"labels\", \"model\", \"plot_type\"], inplace=True)\n",
    "    vuln_df[\"vuln\"] = 1\n",
    "\n",
    "    safe_df.drop(columns=[\"labels\", \"model\", \"plot_type\"], inplace=True)\n",
    "    safe_df[\"vuln\"] = 0\n",
    "\n",
    "    for i in trange(len(vuln_df[\"values\"][0])):\n",
    "        vuln_df[f\"feature_{i}\"] = vuln_df[\"values\"].apply(lambda x: x[i])\n",
    "        safe_df[f\"feature_{i}\"] = safe_df[\"values\"].apply(lambda x: x[i])\n",
    "\n",
    "    safe_df_train = safe_df.loc[train_indexes]\n",
    "    safe_df_test = safe_df.drop(train_indexes)\n",
    "\n",
    "    vuln_df_train = vuln_df.loc[train_indexes]\n",
    "    vuln_df_test = vuln_df.drop(train_indexes)\n",
    "\n",
    "    df_train = pd.concat([safe_df_train, vuln_df_train])\n",
    "    df_test = pd.concat([safe_df_test, vuln_df_test])\n",
    "\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "    df_train.drop(columns=[\"values\"], inplace=True)\n",
    "    df_test.drop(columns=[\"values\"], inplace=True)\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a313a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, test_df):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "    \"\"\"\n",
    "    #bug_id\tfunc_before\tfunc_after\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i, row in tqdm(test_df.iterrows()):\n",
    "        X = row[top_k.tolist()]\n",
    "        y = row[\"vuln\"]\n",
    "\n",
    "        # Get the prediction\n",
    "        pred = clf.predict([X])\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        if pred == 1 and y == 1:\n",
    "            tp += 1\n",
    "        elif pred == 1 and y == 0:\n",
    "            fp += 1\n",
    "        elif pred == 0 and y == 1:\n",
    "            fn += 1\n",
    "        elif pred == 0 and y == 0:\n",
    "            tn += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    # Calculate the precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    # Calculate the recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    # Calculate the F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tn\": tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7dd0de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24576/24576 [01:36<00:00, 255.43it/s]\n",
      "60it [00:00, 4974.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.43333333333333335,\n",
       " 'precision': 0.45,\n",
       " 'recall': 0.6,\n",
       " 'f1': 0.5142857142857143,\n",
       " 'tp': 18,\n",
       " 'fp': 22,\n",
       " 'fn': 12,\n",
       " 'tn': 8}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(SAE_ACTIVATIONS_GBUG_LAYER_1.model_path, \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "# Original (GBUG)\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.gbug_feature_vuln_path,\n",
    "    OUR_CONFIG.gbug_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5b9f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24576/24576 [01:47<00:00, 227.99it/s]\n",
      "698it [00:00, 5400.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5286532951289399,\n",
       " 'precision': 0.5208333333333334,\n",
       " 'recall': 0.7163323782234957,\n",
       " 'f1': 0.6031363088057902,\n",
       " 'tp': 250,\n",
       " 'fp': 230,\n",
       " 'fn': 99,\n",
       " 'tn': 119}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defects4J\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.defects_feature_vuln_path,\n",
    "    OUR_CONFIG.defects_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b53f06f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24576/24576 [01:38<00:00, 249.19it/s]\n",
      "88it [00:00, 4920.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5,\n",
       " 'precision': 0.5,\n",
       " 'recall': 0.8409090909090909,\n",
       " 'f1': 0.6271186440677967,\n",
       " 'tp': 37,\n",
       " 'fp': 37,\n",
       " 'fn': 7,\n",
       " 'tn': 7}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defects4J\n",
    "_, df_test = get_vuln_safe_data(\n",
    "    OUR_CONFIG.humaneval_feature_vuln_path,\n",
    "    OUR_CONFIG.humaneval_feature_safe_path,\n",
    "    training_indices,\n",
    ")\n",
    "# filter columns based on top_k\n",
    "df_test_filtered = df_test[\n",
    "    top_k.tolist() + [\"vuln\"]\n",
    "]\n",
    "\n",
    "results = evaluate_clf(clf, df_test_filtered)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfedeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720f421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
