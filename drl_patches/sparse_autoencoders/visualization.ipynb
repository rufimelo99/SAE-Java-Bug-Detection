{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_jsonl(data):\n",
    "    parsed_data = []\n",
    "    for line in data:\n",
    "        parsed_data.append(json.loads(line))\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "def get_main_df(path, file_in_question):\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if \"layer\" not in root:\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            if file == file_in_question:\n",
    "                with open(os.path.join(root, file)) as f:\n",
    "                    data = f.readlines()\n",
    "\n",
    "\n",
    "                parsed_data = parse_jsonl(data)\n",
    "                df = pd.DataFrame(parsed_data)\n",
    "                \n",
    "                # We have tp, fp, tn, fn\n",
    "                # We want precision, recall, f1\n",
    "                df[\"precision\"] = df[\"tp\"] / (df[\"tp\"] + df[\"fp\"])\n",
    "                df[\"recall\"] = df[\"tp\"] / (df[\"tp\"] + df[\"fn\"])\n",
    "                df[\"f1\"] = 2 * (df[\"precision\"] * df[\"recall\"]) / (df[\"precision\"] + df[\"recall\"])\n",
    "                df[\"accuracy\"] = (df[\"tp\"] + df[\"tn\"]) / (df[\"tp\"] + df[\"tn\"] + df[\"fp\"] + df[\"fn\"])\n",
    "                df[\"layer\"] = re.search(r\"layer(\\d+)\", root).group(1)\n",
    "\n",
    "                main_df = pd.concat([main_df, df])\n",
    "\n",
    "    return main_df\n",
    "\n",
    "def get_best(main_df):\n",
    "    best_accuracy = main_df[main_df[\"accuracy\"] == main_df[\"accuracy\"].max()][\"accuracy\"]\n",
    "    best_f1 = main_df[main_df[\"f1\"] == main_df[\"f1\"].max()][\"f1\"]\n",
    "    layer = main_df[main_df[\"f1\"] == main_df[\"f1\"].max()][\"layer\"]\n",
    "    print(f\"Best layer: {layer.values[0]}\")\n",
    "    return best_accuracy, best_f1, main_df[main_df[\"f1\"] == main_df[\"f1\"].max()]\n",
    "\n",
    "\n",
    "path = \"gpt2_gbug-java\"\n",
    "file_in_question = \"random_forest.jsonl\"\n",
    "main_df = get_main_df(path, file_in_question)\n",
    "best_accuracy, best_f1, best_restult = get_best(main_df)\n",
    "print(f\"For {file_in_question} in {path}\")\n",
    "print(f\"BEST F1: {best_f1}\")\n",
    "print(f\"BEST ACCURACY: {best_accuracy}\")\n",
    "best_restult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Metric:\n",
    "    name: str\n",
    "    label: str\n",
    "\n",
    "F1 = Metric(\"f1\", \"F1 Score\")\n",
    "ACCURACY = Metric(\"accuracy\", \"Accuracy\")\n",
    "\n",
    "ACTIVE_METRIC = F1\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot mean F1 score across all layers with confidence interval\n",
    "sns.lineplot(data=main_df, x=\"n_features\", y=ACTIVE_METRIC.name, ci=95, label=f\"Mean {ACTIVE_METRIC.label}\", color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "# Plot Layer 11\n",
    "# df_11 = main_df[main_df[\"layer\"] == \"11\"]\n",
    "# plt.plot(df_11[\"n_features\"], df_11[ACTIVE_METRIC.name], label=\"Layer 11\", color=\"red\", linestyle=\"-\",alpha=0.3)\n",
    "\n",
    "# # Plot Layer 1\n",
    "# df_1 = main_df[main_df[\"layer\"] == \"1\"]\n",
    "# plt.plot(df_1[\"n_features\"], df_1[ACTIVE_METRIC.name], label=\"Layer 1\", color=\"blue\", linestyle=\"-\",alpha=0.3)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Number of Features\", fontsize=12)\n",
    "plt.ylabel(ACTIVE_METRIC.label, fontsize=12)\n",
    "plt.title(f\"{ACTIVE_METRIC.label} with Confidence Interval Across Layers\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# make the x log scale\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# Improve layout\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "#define axis limits\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
